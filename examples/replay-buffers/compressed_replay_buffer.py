# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
"""
Demonstrating the use of compressing a rollout of Atari transitions on the GPU and batch decompressing them on the GPU.
This example may be helpful in the multi-environment case, or when environments are run on the GPU.
Additionally, we can batch our decompression on the GPU in one go using the collate function.

Results showing transitions per second (T/s).
Mode (using zstd)   Rollout T/s  Sample T/s   Compression Ratio
------------------------------------------------------------
gpu_only            1103         27616        96x
cpu_to_gpu          2095         27870        97x
cpu_only
"""

from __future__ import annotations

import sys

import time
from typing import Any, NamedTuple

import gymnasium as gym

import numpy as np
import torch
from tensordict import TensorDict
from torchrl import torchrl_logger as logger
from torchrl.data import CompressedListStorage, ListStorage, ReplayBuffer


def get_cpu_codec():
    """
    Returns a codec for CPU compression.
    """
    if sys.version_info >= (3, 14):
        from compression import zstd
    else:
        try:
            import zstd
        except ImportError:
            raise ImportError(
                "Please `pip install zstd` to use this example with CPU compression."
            )

    return zstd.compress, zstd.decompress


class AtariTransition(NamedTuple):
    """Transition tuple generated by the Atari gymnasium environment."""

    observations: np.uint8
    actions: np.uint8
    next_observations: np.uint8
    rewards: np.float32
    terminated: np.bool
    truncated: np.bool
    info: dict[str, Any]


def setup_atari_environment(seed: int = 42) -> gym.Env:
    """Create and configure the Atari Pong environment."""
    import ale_py

    gym.register_envs(ale_py)
    env = gym.make("ALE/Pong-v5", frameskip=1)
    env = gym.wrappers.AtariPreprocessing(env, frame_skip=5)
    env = gym.wrappers.RecordEpisodeStatistics(env)
    env = gym.wrappers.TransformReward(env, np.sign)
    env = gym.wrappers.FrameStackObservation(env, 4)
    env.action_space.seed(seed)
    env.observation_space.seed(seed)
    return env


def get_gpu_codec():
    """
    Returns a codec for GPU compression using NVIDIA NVCOMP.
    """
    try:
        import nvidia.nvcomp as nvcomp
    except ImportError:
        raise ImportError(
            "Please pip install nvidia-nvcomp to use this example with GPU compression."
        )

    # RAW = Does not add header with nvCOMP metadata, so that the codec can read compressed data from the CPU library
    bitstream_kind = nvcomp.BitstreamKind.RAW
    codec = nvcomp.Codec(algorithm="Zstd", bitstream_kind=bitstream_kind)

    def compressor_fn(data: nvcomp.Array) -> nvcomp.Array:
        return codec.encode(data)

    def decompressor_fn(compressed_data: nvcomp.Array) -> nvcomp.Array:
        return codec.decode(compressed_data, data_type="|u1")

    return compressor_fn, decompressor_fn


def make_compressing_replay_buffer(decompressor_fn) -> ReplayBuffer:
    """
    Creates a ReplayBuffer with CompressedListStorage for GPU compression.
    """
    try:
        import nvidia.nvcomp as nvcomp
    except ImportError:
        raise ImportError(
            "Please pip install nvidia-nvcomp to use this example with GPU compression."
        )
    storage = ListStorage(
        max_size=1000,
        device="cuda",
    )

    def collate_compressed_data_and_batch_decompress(
        data: list[AtariTransition],
    ) -> list[AtariTransition]:
        """We collate the compressed data together so that we can decompress it in a single batch operation."""
        transitions = data

        # gather compressed data
        compressed_obs = [transition.observations for transition in transitions]
        compressed_next_obs = [
            transition.next_observations for transition in transitions
        ]

        # optional checks
        assert all(isinstance(arr, nvcomp.nvcomp_impl.Array) for arr in compressed_obs)
        assert all(
            isinstance(arr, nvcomp.nvcomp_impl.Array) for arr in compressed_next_obs
        )

        # batched decompress is faster
        decompressed_data = decompressor_fn(compressed_obs + compressed_next_obs)

        # gather decompressed data
        decompressed_obses = decompressed_data[: len(compressed_obs)]
        decompressed_next_obses = decompressed_data[len(compressed_obs) :]

        # repack data
        for i, (transition, obs, next_obs) in enumerate(
            zip(transitions, decompressed_obses, decompressed_next_obses)
        ):
            transitions[i] = transition._replace(
                observations=torch.from_dlpack(obs).clone().view(4, 84, 84),
                next_observations=torch.from_dlpack(next_obs).clone().view(4, 84, 84),
            )

        return transitions

    return ReplayBuffer(
        storage=storage,
        batch_size=32,
        collate_fn=collate_compressed_data_and_batch_decompress,
    )


def cpu_compress_to_gpu_decompress():
    import time

    import nvidia.nvcomp as nvcomp

    # Create Pong environment and get a frame
    env = setup_atari_environment(seed=0)

    compressor_fn, _ = get_cpu_codec()
    _, decompressor_fn = get_gpu_codec()

    obs, _ = env.reset(seed=0)
    compressed_obs = compressor_fn(obs.tobytes())
    decompressed_obs = decompressor_fn(compressed_obs)
    pt_obs = torch.from_dlpack(decompressed_obs).clone().view(4, 84, 84)
    assert np.allclose(obs, pt_obs.cpu().numpy())

    rb = make_compressing_replay_buffer(decompressor_fn)

    compression_ratios = []
    num_transitions_in_rollout = 2000

    torch.cuda.synchronize()

    obs, _ = env.reset(seed=0)
    compressed_obs: bytes = compressor_fn(obs.tobytes())
    compressed_nv_obs = nvcomp.as_array(compressed_obs).cuda(synchronize=False)

    start_time = time.time()
    for _ in range(num_transitions_in_rollout):
        # get the torch observation onto the gpu as we would normally do inference here...
        pt_obs = torch.from_numpy(obs).cuda(non_blocking=True)
        action = env.action_space.sample()

        next_obs, reward, terminated, truncated, info = env.step(action)

        # replay buffer
        compressed_next_obs: bytes = compressor_fn(next_obs.tobytes())
        compressed_nv_next_obs = nvcomp.as_array(compressed_next_obs).cuda(
            synchronize=False
        )

        transition = AtariTransition(
            compressed_nv_obs,
            action,
            compressed_nv_next_obs,
            reward,
            terminated,
            truncated,
            info,
        )
        rb.add(transition)

        # logging
        compression_ratios.append(len(next_obs.tobytes()) / len(compressed_next_obs))

        # reset
        if terminated or truncated:
            obs, _ = env.reset()
            nvcomp.as_array(obs).cuda()
        else:
            obs: np.ndarray = next_obs

    rollout_time = time.time() - start_time

    batch_size = 32
    torch.cuda.synchronize()
    start_time = time.time()
    for _ in range(100):
        rb.sample(batch_size)
    sample_time = time.time() - start_time

    output = [
        "\nListStorage + ReplayBuffer (CPU compress, GPU decompress) Example:",
        f"avg_compression_ratio={np.array(compression_ratios).mean():0.0f}",
        "rollout with zstd, @ transitions/s={:0.0f}".format(
            num_transitions_in_rollout / rollout_time
        ),
        "batch sampling and decompression with zstd @ transitions/s={:0.0f}".format(
            (100 * batch_size) / sample_time
        ),
    ]

    logger.info("\n\t".join(output))


def cpu_only():
    compressor_fn, decompressor_fn = get_cpu_codec()

    def compress_from_torch(data: torch.Tensor) -> bytes:
        """
        Convert a tensor to a byte stream for compression.
        """
        return compressor_fn(data.cpu().numpy().tobytes())

    def decompress_from_bytes(data: bytes, metadata: dict) -> torch.Tensor:
        """
        Convert a byte stream back to a tensor.
        """
        decompressed_data = decompressor_fn(data)
        dtype = metadata.get("dtype", torch.float32)
        device = metadata.get("device", "cpu")
        shape = metadata.get("shape", ())

        return (
            torch.frombuffer(
                decompressed_data,
                dtype=dtype,
            )
            .view(shape)
            .to(device)
        )

    # {
    #     "type": "tensor",
    #     "shape": torch.Size([]),
    #     "dtype": torch.int64,
    #     "device": device(type="cpu"),
    # }

    storage = CompressedListStorage(
        max_size=1000,
        compression_level=3,  # zstd compression level (1-22)
        device="cpu",
        compression_fn=compress_from_torch,
        decompression_fn=decompress_from_bytes,
    )

    # Create replay buffer with compressed storage
    rb = ReplayBuffer(storage=storage, batch_size=32)

    # Simulate Atari-like image data (84x84 RGB frames)
    print("Generating sample image data...")
    num_frames = 100
    image_data = torch.zeros(num_frames, 3, 84, 84, dtype=torch.float32)
    image_data.copy_(
        torch.arange(num_frames * 3 * 84 * 84).reshape(num_frames, 3, 84, 84)
        // (3 * 84 * 84)
    )

    # Create TensorDict with image observations
    data = TensorDict(
        {
            "obs": image_data,
            "action": torch.randint(0, 4, (num_frames,)),  # 4 possible actions
            "reward": torch.randn(num_frames),
            "done": torch.randint(0, 2, (num_frames,), dtype=torch.bool),
        },
        batch_size=[num_frames],
    )

    # Measure memory usage before adding data
    print(f"Original data size: {data.bytes() / 1024 / 1024: .2f} MB")

    # Add data to replay buffer
    print("Adding data to replay buffer...")
    start_time = time.time()
    rb.extend(data)
    add_time = time.time() - start_time
    print(f"Time to add data: {add_time: .3f} seconds")

    # Sample from replay buffer
    print("Sampling from replay buffer...")
    start_time = time.time()
    sample = rb.sample(32)
    sample_time = time.time() - start_time
    print(f"Time to sample: {sample_time: .3f} seconds")

    # Verify data integrity
    print("\nVerifying data integrity...")
    original_shape = image_data.shape
    sampled_shape = sample["obs"].shape
    print(f"Original shape: {original_shape}")
    print(f"Sampled shape: {sampled_shape}")

    # Check that shapes match (accounting for batch size)
    assert sampled_shape[1:] == original_shape[1:], "Shape mismatch!"
    print("✓ Data integrity verified!")

    # Demonstrate compression ratio
    print("\n=== Compression Analysis ===")

    # Estimate compressed size (this is approximate)
    compressed_size_estimate = storage.bytes()

    original_size = data.bytes()
    compression_ratio = (
        original_size / compressed_size_estimate if compressed_size_estimate > 0 else 1
    )

    print(f"Original size: {original_size / 1024 / 1024: .2f} MB")
    print(
        f"Compressed size (estimate): {compressed_size_estimate / 1024 / 1024: .2f} MB"
    )
    print(f"Compression ratio: {compression_ratio: .1f}x")

    # Test with different compression levels
    print("\n=== Testing Different Compression Levels ===")

    for level in [1, 3, 6, 9]:
        print(f"\nTesting compression level {level}...")

        # Create new storage with different compression level
        test_storage = CompressedListStorage(
            max_size=100, compression_level=level, device="cpu"
        )

        # Test with a smaller dataset
        N = 100
        obs = torch.zeros(N, 3, 84, 84, dtype=torch.float32)
        obs.copy_(torch.arange(N * 3 * 84 * 84).reshape(N, 3, 84, 84) // (3 * 84 * 84))
        test_data = TensorDict(
            {
                "obs": obs,
            },
            batch_size=[N],
        )

        test_rb = ReplayBuffer(storage=test_storage, batch_size=5)

        # Measure compression time
        start_time = time.time()
        test_rb.extend(test_data)
        compress_time = time.time() - start_time

        # Measure decompression time
        start_time = time.time()
        test_rb.sample(5)
        decompress_time = time.time() - start_time

        print(f"  Compression time: {compress_time: .3f}s")
        print(f"  Decompression time: {decompress_time: .3f}s")

        # Estimate compression ratio
        test_ratio = test_data.bytes() / test_storage.bytes()
        print(f"  Compression ratio: {test_ratio: .1f}x")

    print("\n=== Example Complete ===")
    print(
        "The CompressedStorage successfully reduces memory usage while maintaining data integrity!"
    )


def gpu_only():
    # pip install gymnasium ale-py opencv-python-headless
    import time

    try:
        import nvidia.nvcomp as nvcomp
    except ImportError:
        raise ImportError(
            "Please pip install nvidia-nvcomp to use this example with GPU compression."
        )

    # Create Pong environment and get a frame
    env = setup_atari_environment(seed=0)

    compressor_fn, decompressor_fn = get_gpu_codec()

    obs, _ = env.reset(seed=0)
    nv_obs = nvcomp.as_array(obs).cuda(synchronize=False)
    compressed_obs = compressor_fn(nv_obs)
    decompressed_obs = decompressor_fn(compressed_obs)
    pt_obs = torch.from_dlpack(decompressed_obs).clone().view(4, 84, 84)
    assert np.allclose(obs, pt_obs.cpu().numpy())

    rb = make_compressing_replay_buffer(decompressor_fn)

    obs, _ = env.reset(seed=0)
    nv_obs = nvcomp.as_array(obs).cuda(synchronize=False)
    compressed_obs = compressor_fn(nv_obs)

    compression_ratios = []
    num_transitions_in_rollout = 2000

    torch.cuda.synchronize()
    start_time = time.time()
    for _ in range(num_transitions_in_rollout):
        pt_obs = torch.from_dlpack(nv_obs).clone()
        action = env.action_space.sample()

        next_obs, reward, terminated, truncated, info = env.step(action)
        nv_next_obs = nvcomp.as_array(next_obs).cuda(synchronize=False)
        compressed_next_obs = compressor_fn(nv_next_obs)

        compression_ratios.append(
            nv_next_obs.buffer_size / compressed_next_obs.buffer_size
        )

        transition = AtariTransition(
            compressed_obs,
            action,
            compressed_next_obs,
            reward,
            terminated,
            truncated,
            info,
        )
        rb.add(transition)

        if terminated or truncated:
            obs, _ = env.reset()
            nv_obs = nvcomp.as_array(obs).cuda()
        else:
            nv_obs = nv_next_obs
            compressed_obs = compressed_next_obs
    rollout_time = time.time() - start_time

    batched_sampling_and_decompression_duration = 1000
    assert (batched_sampling_and_decompression_duration * 2) <= (
        num_transitions_in_rollout
    )

    batch_size = 32
    torch.cuda.synchronize()
    start_time = time.time()
    for _ in range(100):
        rb.sample(batch_size)
    sample_time = time.time() - start_time

    output = [
        "\nListStorage + ReplayBuffer (GPU compress, GPU decompress) Example:",
        f"avg_compression_ratio={np.array(compression_ratios).mean():0.0f}",
        "rollout with zstd, @ transitions/s={:0.0f}".format(
            num_transitions_in_rollout / rollout_time
        ),
        "batch sampling and decompression with zstd @ transitions/s={:0.0f}".format(
            (100 * batch_size) / sample_time
        ),
    ]

    logger.info("\n\t".join(output))


if __name__ == "__main__":
    cpu_only()
    gpu_only()
    cpu_compress_to_gpu_decompress()
