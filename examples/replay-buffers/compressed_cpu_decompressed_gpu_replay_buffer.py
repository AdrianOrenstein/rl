#!/usr/bin/env python3
"""
Example demonstrating the use of CompressedStorage for memory-efficient replay buffers on the GPU.
"""

import sys
from typing import Any, Dict, List, NamedTuple

import ale_py
import gymnasium as gym

import numpy as np

from torchrl.data.replay_buffers.storages import ListStorage

gym.register_envs(ale_py)
import torch
from torchrl.data import ReplayBuffer


class AtariTransition(NamedTuple):
    """Transition tuple generated by the Atari gymnasium environment."""

    observations: np.uint8
    actions: np.uint8
    next_observations: np.uint8
    rewards: np.float32
    terminated: np.bool
    truncated: np.bool
    info: Dict[str, Any]


def main():
    # pip install gymnasium ale-py opencv-python-headless lz4 zstd
    import time

    import nvidia.nvcomp as nvcomp

    algo = "Zstd"
    bitstream = nvcomp.BitstreamKind.RAW

    if algo == "Zstd":
        if sys.version_info >= (3, 14):
            from compression import zstd

        else:
            import zstd

        compressor_fn = zstd.compress

    elif algo == "LZ4":
        import lz4

        compressor_fn = lz4.compress

    else:
        raise ValueError(f"Unsupported algo {algo}")

    # Create Pong environment and get a frame
    seed = 42
    env = gym.make("ALE/Pong-v5", frameskip=1)
    env = gym.wrappers.AtariPreprocessing(env, frame_skip=5)
    env = gym.wrappers.RecordEpisodeStatistics(env)
    env = gym.wrappers.TransformReward(env, np.sign)
    env = gym.wrappers.FrameStackObservation(env, 4)
    env.action_space.seed(seed)
    env.observation_space.seed(seed)

    codec = nvcomp.Codec(algorithm=algo, bitstream_kind=bitstream)

    obs, _ = env.reset(seed=0)
    compressed_obs: bytes = compressor_fn(obs.tobytes())
    compressed_nv_obs = nvcomp.as_array(compressed_obs).cuda(synchronize=False)

    decompressed_obs = codec.decode(compressed_nv_obs, data_type="|u1")
    pt_obs = torch.from_dlpack(decompressed_obs).clone().view(4, 84, 84)
    assert np.allclose(obs, pt_obs.cpu().numpy())

    print("passed correctness checks")

    # === CompressedListStorage + ReplayBuffer with GPU compression ===
    print(
        "\n=== ListStorage + ReplayBuffer (CPU compress, GPU decompress) Example ===\n"
    )

    print("Creating compressed storage...")
    storage = ListStorage(
        max_size=1000,
        device="cuda",
    )

    def collate_compressed_data_and_batch_decompress(
        data: List[AtariTransition],
    ) -> List[AtariTransition]:
        transitions = data

        # gather compressed data
        compressed_obs: List[nvcomp.nvcomp_impl.Array] = [
            transition.observations for transition in transitions
        ]
        compressed_next_obs: List[nvcomp.nvcomp_impl.Array] = [
            transition.next_observations for transition in transitions
        ]

        # batched decompress is faster
        decompressed_data = codec.decode(
            compressed_obs + compressed_next_obs, data_type="|u1"
        )

        # gather decompressed data
        decompressed_obses = decompressed_data[: len(compressed_obs)]
        decompressed_next_obses = decompressed_data[len(compressed_obs) :]

        # repack data
        for i, (transition, obs, next_obs) in enumerate(
            zip(transitions, decompressed_obses, decompressed_next_obses)
        ):
            transitions[i] = transition._replace(
                observations=torch.from_dlpack(obs).clone().view(4, 84, 84),
                next_observations=torch.from_dlpack(next_obs).clone().view(4, 84, 84),
            )

        return transitions

    rb = ReplayBuffer(
        storage=storage,
        batch_size=32,
        collate_fn=collate_compressed_data_and_batch_decompress,
    )

    print("Starting rollout benchmark")

    compression_ratios = []
    num_transitions_in_rollout = 2000

    print(f"...adding {num_transitions_in_rollout} transitions to replay buffer")
    torch.cuda.synchronize()

    obs, _ = env.reset(seed=0)
    nv_obs = nvcomp.as_array(obs).cuda(synchronize=False)
    compressed_obs: bytes = compressor_fn(obs.tobytes())
    compressed_nv_obs = nvcomp.as_array(compressed_obs).cuda(synchronize=False)

    start_time = time.time()
    for _ in range(num_transitions_in_rollout):
        # get the torch observation onto the gpu as we would normally do inference here...
        pt_obs = torch.from_numpy(obs).cuda(non_blocking=True)
        action = env.action_space.sample()

        next_obs, reward, terminated, truncated, info = env.step(action)

        # replay buffer
        compressed_next_obs: bytes = compressor_fn(next_obs.tobytes())
        compressed_nv_next_obs = nvcomp.as_array(compressed_next_obs).cuda(
            synchronize=False
        )

        transition = AtariTransition(
            compressed_nv_obs,
            action,
            compressed_nv_next_obs,
            reward,
            terminated,
            truncated,
            info,
        )
        rb.add(transition)

        # logging
        nv_obs = nvcomp.as_array(obs).cuda(synchronize=False)
        compression_ratios.append(nv_obs.buffer_size / compressed_nv_obs.buffer_size)

        # reset
        if terminated or truncated:
            obs, _ = env.reset()
            nv_obs = nvcomp.as_array(obs).cuda()
        else:
            obs: np.ndarray = next_obs

    rollout_time = time.time() - start_time
    print(
        f"done rollout with {algo} and {bitstream}, "
        + f"avg_compression_ratio={np.array(compression_ratios).mean():0.0f} "
        + f"@ transitions/s={num_transitions_in_rollout / rollout_time:0.0f}\n"
    )

    print("Sampling from replay buffer...")
    batch_size = 32
    torch.cuda.synchronize()
    start_time = time.time()
    _ = rb.sample(batch_size)
    sample_time = time.time() - start_time
    print(
        f"done batch sampling and decompression with {algo} and {bitstream} @ transitions/s={batch_size / sample_time:0.0f}"
    )


if __name__ == "__main__":
    main()
