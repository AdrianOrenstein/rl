Search.setIndex({"docnames": ["index", "reference/collectors", "reference/data", "reference/envs", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION", "reference/generated/torchrl.auto_unwrap_transformed_env", "reference/generated/torchrl.collectors.DataCollectorBase", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater", "reference/generated/torchrl.collectors.MultiSyncDataCollector", "reference/generated/torchrl.collectors.MultiaSyncDataCollector", "reference/generated/torchrl.collectors.RayWeightUpdater", "reference/generated/torchrl.collectors.SyncDataCollector", "reference/generated/torchrl.collectors.VanillaWeightUpdater", "reference/generated/torchrl.collectors.WeightUpdaterBase", "reference/generated/torchrl.collectors.aSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.llm.LLMCollector", "reference/generated/torchrl.collectors.llm.vLLMUpdater", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.AdaptiveKLController", "reference/generated/torchrl.data.Binary", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec", "reference/generated/torchrl.data.BinaryToDecimal", "reference/generated/torchrl.data.Bounded", "reference/generated/torchrl.data.BoundedTensorSpec", "reference/generated/torchrl.data.Categorical", "reference/generated/torchrl.data.Composite", "reference/generated/torchrl.data.CompositeSpec", "reference/generated/torchrl.data.ConstantKLController", "reference/generated/torchrl.data.DensifyReward", "reference/generated/torchrl.data.DiscreteTensorSpec", "reference/generated/torchrl.data.Flat2TED", "reference/generated/torchrl.data.H5Combine", "reference/generated/torchrl.data.H5Split", "reference/generated/torchrl.data.HashToInt", "reference/generated/torchrl.data.LazyStackedCompositeSpec", "reference/generated/torchrl.data.LazyStackedTensorSpec", "reference/generated/torchrl.data.MCTSForest", "reference/generated/torchrl.data.MultiCategorical", "reference/generated/torchrl.data.MultiDiscreteTensorSpec", "reference/generated/torchrl.data.MultiOneHot", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec", "reference/generated/torchrl.data.MultiStep", "reference/generated/torchrl.data.Nested2TED", "reference/generated/torchrl.data.NonTensor", "reference/generated/torchrl.data.NonTensorSpec", "reference/generated/torchrl.data.OneHot", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec", "reference/generated/torchrl.data.PairwiseDataset", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.PromptData", "reference/generated/torchrl.data.PromptTensorDictTokenizer", "reference/generated/torchrl.data.QueryModule", "reference/generated/torchrl.data.RandomProjectionHash", "reference/generated/torchrl.data.RayReplayBuffer", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.RewardData", "reference/generated/torchrl.data.RolloutFromModel", "reference/generated/torchrl.data.SipHash", "reference/generated/torchrl.data.Stacked", "reference/generated/torchrl.data.StackedComposite", "reference/generated/torchrl.data.TED2Flat", "reference/generated/torchrl.data.TED2Nested", "reference/generated/torchrl.data.TensorDictMap", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorDictTokenizer", "reference/generated/torchrl.data.TensorMap", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.TokenizedDatasetLoader", "reference/generated/torchrl.data.Tree", "reference/generated/torchrl.data.Unbounded", "reference/generated/torchrl.data.UnboundedContinuous", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec", "reference/generated/torchrl.data.UnboundedDiscrete", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec", "reference/generated/torchrl.data.check_no_exclusive_keys", "reference/generated/torchrl.data.consolidate_spec", "reference/generated/torchrl.data.contains_lazy_spec", "reference/generated/torchrl.data.create_infinite_iterator", "reference/generated/torchrl.data.get_dataloader", "reference/generated/torchrl.data.llm.History", "reference/generated/torchrl.data.llm.LLMData", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.ReplayBufferEnsemble", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble", "reference/generated/torchrl.envs.AsyncEnvPool", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.ChessEnv", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.IsaacLabWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.LLMHashingEnv", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.MeltingpotEnv", "reference/generated/torchrl.envs.MeltingpotWrapper", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.OpenSpielEnv", "reference/generated/torchrl.envs.OpenSpielWrapper", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PendulumEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool", "reference/generated/torchrl.envs.RandomPolicy", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool", "reference/generated/torchrl.envs.TicTacToeEnv", "reference/generated/torchrl.envs.UnityMLAgentsEnv", "reference/generated/torchrl.envs.UnityMLAgentsWrapper", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_env_specs", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.exploration_type", "reference/generated/torchrl.envs.get_available_libraries", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.llm.ChatEnv", "reference/generated/torchrl.envs.llm.DatasetChatEnv", "reference/generated/torchrl.envs.llm.GSM8KEnv", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion", "reference/generated/torchrl.envs.llm.GSM8KRewardParser", "reference/generated/torchrl.envs.llm.IFEvalEnv", "reference/generated/torchrl.envs.llm.IFEvalScoreData", "reference/generated/torchrl.envs.llm.IfEvalScorer", "reference/generated/torchrl.envs.llm.LLMEnv", "reference/generated/torchrl.envs.llm.LLMHashingEnv", "reference/generated/torchrl.envs.llm.MLGymWrapper", "reference/generated/torchrl.envs.llm.make_gsm8k_env", "reference/generated/torchrl.envs.llm.make_mlgym", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform", "reference/generated/torchrl.envs.llm.transforms.Tokenizer", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor", "reference/generated/torchrl.envs.make_composite_from_td", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.register_gym_spec_conversion", "reference/generated/torchrl.envs.set_exploration_type", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.step_mdp", "reference/generated/torchrl.envs.terminated_or_truncated", "reference/generated/torchrl.envs.transforms.ActionDiscretizer", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.AutoResetEnv", "reference/generated/torchrl.envs.transforms.AutoResetTransform", "reference/generated/torchrl.envs.transforms.BatchSizeTransform", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch", "reference/generated/torchrl.envs.transforms.ConditionalSkip", "reference/generated/torchrl.envs.transforms.Crop", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.Hash", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.LineariseRewards", "reference/generated/torchrl.envs.transforms.MultiAction", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SignTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.Stack", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.Timer", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Tokenizer", "reference/generated/torchrl.envs.transforms.TrajCounter", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnaryTransform", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.VecNormV2", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.envs.transforms.rb_transforms.MultiStepTransform", "reference/generated/torchrl.implement_for", "reference/generated/torchrl.modules.AdditiveGaussianModule", "reference/generated/torchrl.modules.BatchRenorm1d", "reference/generated/torchrl.modules.CEMPlanner", "reference/generated/torchrl.modules.ConsistentDropout", "reference/generated/torchrl.modules.ConsistentDropoutModule", "reference/generated/torchrl.modules.Conv3dNet", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueHook", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.EGreedyModule", "reference/generated/torchrl.modules.GRU", "reference/generated/torchrl.modules.GRUCell", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTM", "reference/generated/torchrl.modules.LSTMCell", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MPCPlannerBase", "reference/generated/torchrl.modules.MPPIPlanner", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.MaskedOneHotCategorical", "reference/generated/torchrl.modules.MultiAgentConvNet", "reference/generated/torchrl.modules.MultiAgentMLP", "reference/generated/torchrl.modules.MultiAgentNetBase", "reference/generated/torchrl.modules.NoisyLazyLinear", "reference/generated/torchrl.modules.NoisyLinear", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OneHotOrdinal", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.Ordinal", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule", "reference/generated/torchrl.modules.QMixer", "reference/generated/torchrl.modules.QValueHook", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.Squeeze2dLayer", "reference/generated/torchrl.modules.SqueezeLayer", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.VDNMixer", "reference/generated/torchrl.modules.VmapModule", "reference/generated/torchrl.modules.llm.CategoricalSequential", "reference/generated/torchrl.modules.llm.LLMOnDevice", "reference/generated/torchrl.modules.llm.TransformersWrapper", "reference/generated/torchrl.modules.llm.make_vllm_worker", "reference/generated/torchrl.modules.llm.stateless_init_process_group", "reference/generated/torchrl.modules.llm.vLLMWorker", "reference/generated/torchrl.modules.llm.vLLMWrapper", "reference/generated/torchrl.modules.recurrent_mode", "reference/generated/torchrl.modules.reset_noise", "reference/generated/torchrl.modules.set_recurrent_mode", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.QValueActor", "reference/generated/torchrl.modules.tensordict_module.QValueModule", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.modules.tensordict_module.ValueOperator", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper", "reference/generated/torchrl.modules.utils.biased_softplus", "reference/generated/torchrl.modules.utils.get_primers_from_module", "reference/generated/torchrl.modules.utils.inv_softplus", "reference/generated/torchrl.modules.utils.mappings", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.CrossQLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteIQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.GAILLoss", "reference/generated/torchrl.objectives.HardUpdate", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.SoftUpdate", "reference/generated/torchrl.objectives.TD3BCLoss", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.default_value_kwargs", "reference/generated/torchrl.objectives.distance_loss", "reference/generated/torchrl.objectives.group_optimizers", "reference/generated/torchrl.objectives.hold_out_net", "reference/generated/torchrl.objectives.hold_out_params", "reference/generated/torchrl.objectives.llm.GRPOLoss", "reference/generated/torchrl.objectives.llm.GRPOLossOutput", "reference/generated/torchrl.objectives.llm.MCAdvantage", "reference/generated/torchrl.objectives.multiagent.QMixerLoss", "reference/generated/torchrl.objectives.next_state_value", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.reward2go", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate", "reference/generated/torchrl.record.PixelRenderTransform", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.set_auto_unwrap_transformed_env", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogScalar", "reference/generated/torchrl.trainers.LogValidationReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/llms", "reference/modules", "reference/objectives", "reference/trainers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/export", "tutorials/getting-started-0", "tutorials/getting-started-1", "tutorials/getting-started-2", "tutorials/getting-started-3", "tutorials/getting-started-4", "tutorials/getting-started-5", "tutorials/index", "tutorials/multi_task", "tutorials/multiagent_competitive_ddpg", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/data.rst", "reference/envs.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/knowledge_base/VIDEO_CUSTOMISATION.rst", "reference/generated/torchrl.auto_unwrap_transformed_env.rst", "reference/generated/torchrl.collectors.DataCollectorBase.rst", "reference/generated/torchrl.collectors.MultiProcessedWeightUpdater.rst", "reference/generated/torchrl.collectors.MultiSyncDataCollector.rst", "reference/generated/torchrl.collectors.MultiaSyncDataCollector.rst", "reference/generated/torchrl.collectors.RayWeightUpdater.rst", "reference/generated/torchrl.collectors.SyncDataCollector.rst", "reference/generated/torchrl.collectors.VanillaWeightUpdater.rst", "reference/generated/torchrl.collectors.WeightUpdaterBase.rst", "reference/generated/torchrl.collectors.aSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCWeightUpdater.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.llm.LLMCollector.rst", "reference/generated/torchrl.collectors.llm.vLLMUpdater.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.AdaptiveKLController.rst", "reference/generated/torchrl.data.Binary.rst", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec.rst", "reference/generated/torchrl.data.BinaryToDecimal.rst", "reference/generated/torchrl.data.Bounded.rst", "reference/generated/torchrl.data.BoundedTensorSpec.rst", "reference/generated/torchrl.data.Categorical.rst", "reference/generated/torchrl.data.Composite.rst", "reference/generated/torchrl.data.CompositeSpec.rst", "reference/generated/torchrl.data.ConstantKLController.rst", "reference/generated/torchrl.data.DensifyReward.rst", "reference/generated/torchrl.data.DiscreteTensorSpec.rst", "reference/generated/torchrl.data.Flat2TED.rst", "reference/generated/torchrl.data.H5Combine.rst", "reference/generated/torchrl.data.H5Split.rst", "reference/generated/torchrl.data.HashToInt.rst", "reference/generated/torchrl.data.LazyStackedCompositeSpec.rst", "reference/generated/torchrl.data.LazyStackedTensorSpec.rst", "reference/generated/torchrl.data.MCTSForest.rst", "reference/generated/torchrl.data.MultiCategorical.rst", "reference/generated/torchrl.data.MultiDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiOneHot.rst", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiStep.rst", "reference/generated/torchrl.data.Nested2TED.rst", "reference/generated/torchrl.data.NonTensor.rst", "reference/generated/torchrl.data.NonTensorSpec.rst", "reference/generated/torchrl.data.OneHot.rst", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.PairwiseDataset.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.PromptData.rst", "reference/generated/torchrl.data.PromptTensorDictTokenizer.rst", "reference/generated/torchrl.data.QueryModule.rst", "reference/generated/torchrl.data.RandomProjectionHash.rst", "reference/generated/torchrl.data.RayReplayBuffer.rst", "reference/generated/torchrl.data.RemoteTensorDictReplayBuffer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.RewardData.rst", "reference/generated/torchrl.data.RolloutFromModel.rst", "reference/generated/torchrl.data.SipHash.rst", "reference/generated/torchrl.data.Stacked.rst", "reference/generated/torchrl.data.StackedComposite.rst", "reference/generated/torchrl.data.TED2Flat.rst", "reference/generated/torchrl.data.TED2Nested.rst", "reference/generated/torchrl.data.TensorDictMap.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictTokenizer.rst", "reference/generated/torchrl.data.TensorMap.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.TokenizedDatasetLoader.rst", "reference/generated/torchrl.data.Tree.rst", "reference/generated/torchrl.data.Unbounded.rst", "reference/generated/torchrl.data.UnboundedContinuous.rst", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec.rst", "reference/generated/torchrl.data.UnboundedDiscrete.rst", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec.rst", "reference/generated/torchrl.data.check_no_exclusive_keys.rst", "reference/generated/torchrl.data.consolidate_spec.rst", "reference/generated/torchrl.data.contains_lazy_spec.rst", "reference/generated/torchrl.data.create_infinite_iterator.rst", "reference/generated/torchrl.data.get_dataloader.rst", "reference/generated/torchrl.data.llm.History.rst", "reference/generated/torchrl.data.llm.LLMData.rst", "reference/generated/torchrl.data.replay_buffers.FlatStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.H5StorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.ImmutableDatasetWriter.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyStackStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.NestedStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.ReplayBufferEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.StorageCheckpointerBase.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsemble.rst", "reference/generated/torchrl.data.replay_buffers.StorageEnsembleCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorageCheckpointer.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.data.replay_buffers.WriterEnsemble.rst", "reference/generated/torchrl.envs.AsyncEnvPool.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.ChessEnv.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.IsaacLabWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.LLMHashingEnv.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.MeltingpotEnv.rst", "reference/generated/torchrl.envs.MeltingpotWrapper.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.OpenSpielEnv.rst", "reference/generated/torchrl.envs.OpenSpielWrapper.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PendulumEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.ProcessorAsyncEnvPool.rst", "reference/generated/torchrl.envs.RandomPolicy.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.ThreadingAsyncEnvPool.rst", "reference/generated/torchrl.envs.TicTacToeEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsEnv.rst", "reference/generated/torchrl.envs.UnityMLAgentsWrapper.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_env_specs.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.exploration_type.rst", "reference/generated/torchrl.envs.get_available_libraries.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.llm.ChatEnv.rst", "reference/generated/torchrl.envs.llm.DatasetChatEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KEnv.rst", "reference/generated/torchrl.envs.llm.GSM8KPrepareQuestion.rst", "reference/generated/torchrl.envs.llm.GSM8KRewardParser.rst", "reference/generated/torchrl.envs.llm.IFEvalEnv.rst", "reference/generated/torchrl.envs.llm.IFEvalScoreData.rst", "reference/generated/torchrl.envs.llm.IfEvalScorer.rst", "reference/generated/torchrl.envs.llm.LLMEnv.rst", "reference/generated/torchrl.envs.llm.LLMHashingEnv.rst", "reference/generated/torchrl.envs.llm.MLGymWrapper.rst", "reference/generated/torchrl.envs.llm.make_gsm8k_env.rst", "reference/generated/torchrl.envs.llm.make_mlgym.rst", "reference/generated/torchrl.envs.llm.transforms.DataLoadingPrimer.rst", "reference/generated/torchrl.envs.llm.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.llm.transforms.PythonInterpreter.rst", "reference/generated/torchrl.envs.llm.transforms.TemplateTransform.rst", "reference/generated/torchrl.envs.llm.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.llm.transforms.as_nested_tensor.rst", "reference/generated/torchrl.envs.llm.transforms.as_padded_tensor.rst", "reference/generated/torchrl.envs.make_composite_from_td.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerDecoder.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.register_gym_spec_conversion.rst", "reference/generated/torchrl.envs.set_exploration_type.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.step_mdp.rst", "reference/generated/torchrl.envs.terminated_or_truncated.rst", "reference/generated/torchrl.envs.transforms.ActionDiscretizer.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.AutoResetEnv.rst", "reference/generated/torchrl.envs.transforms.AutoResetTransform.rst", "reference/generated/torchrl.envs.transforms.BatchSizeTransform.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.ConditionalPolicySwitch.rst", "reference/generated/torchrl.envs.transforms.ConditionalSkip.rst", "reference/generated/torchrl.envs.transforms.Crop.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.Hash.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.LineariseRewards.rst", "reference/generated/torchrl.envs.transforms.MultiAction.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RemoveEmptySpecs.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SignTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.Stack.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.Timer.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Tokenizer.rst", "reference/generated/torchrl.envs.transforms.TrajCounter.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnaryTransform.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.VecNormV2.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.envs.transforms.rb_transforms.MultiStepTransform.rst", "reference/generated/torchrl.implement_for.rst", "reference/generated/torchrl.modules.AdditiveGaussianModule.rst", "reference/generated/torchrl.modules.BatchRenorm1d.rst", "reference/generated/torchrl.modules.CEMPlanner.rst", "reference/generated/torchrl.modules.ConsistentDropout.rst", "reference/generated/torchrl.modules.ConsistentDropoutModule.rst", "reference/generated/torchrl.modules.Conv3dNet.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueHook.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.EGreedyModule.rst", "reference/generated/torchrl.modules.GRU.rst", "reference/generated/torchrl.modules.GRUCell.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTM.rst", "reference/generated/torchrl.modules.LSTMCell.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MPCPlannerBase.rst", "reference/generated/torchrl.modules.MPPIPlanner.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.MaskedOneHotCategorical.rst", "reference/generated/torchrl.modules.MultiAgentConvNet.rst", "reference/generated/torchrl.modules.MultiAgentMLP.rst", "reference/generated/torchrl.modules.MultiAgentNetBase.rst", "reference/generated/torchrl.modules.NoisyLazyLinear.rst", "reference/generated/torchrl.modules.NoisyLinear.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OneHotOrdinal.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.Ordinal.rst", "reference/generated/torchrl.modules.OrnsteinUhlenbeckProcessModule.rst", "reference/generated/torchrl.modules.QMixer.rst", "reference/generated/torchrl.modules.QValueHook.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.Squeeze2dLayer.rst", "reference/generated/torchrl.modules.SqueezeLayer.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.VDNMixer.rst", "reference/generated/torchrl.modules.VmapModule.rst", "reference/generated/torchrl.modules.llm.CategoricalSequential.rst", "reference/generated/torchrl.modules.llm.LLMOnDevice.rst", "reference/generated/torchrl.modules.llm.TransformersWrapper.rst", "reference/generated/torchrl.modules.llm.make_vllm_worker.rst", "reference/generated/torchrl.modules.llm.stateless_init_process_group.rst", "reference/generated/torchrl.modules.llm.vLLMWorker.rst", "reference/generated/torchrl.modules.llm.vLLMWrapper.rst", "reference/generated/torchrl.modules.recurrent_mode.rst", "reference/generated/torchrl.modules.reset_noise.rst", "reference/generated/torchrl.modules.set_recurrent_mode.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.MultiStepActorWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.modules.tensordict_module.ValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper.rst", "reference/generated/torchrl.modules.utils.biased_softplus.rst", "reference/generated/torchrl.modules.utils.get_primers_from_module.rst", "reference/generated/torchrl.modules.utils.inv_softplus.rst", "reference/generated/torchrl.modules.utils.mappings.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.CrossQLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteIQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.GAILLoss.rst", "reference/generated/torchrl.objectives.HardUpdate.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.SoftUpdate.rst", "reference/generated/torchrl.objectives.TD3BCLoss.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.default_value_kwargs.rst", "reference/generated/torchrl.objectives.distance_loss.rst", "reference/generated/torchrl.objectives.group_optimizers.rst", "reference/generated/torchrl.objectives.hold_out_net.rst", "reference/generated/torchrl.objectives.hold_out_params.rst", "reference/generated/torchrl.objectives.llm.GRPOLoss.rst", "reference/generated/torchrl.objectives.llm.GRPOLossOutput.rst", "reference/generated/torchrl.objectives.llm.MCAdvantage.rst", "reference/generated/torchrl.objectives.multiagent.QMixerLoss.rst", "reference/generated/torchrl.objectives.next_state_value.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.reward2go.rst", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate.rst", "reference/generated/torchrl.record.PixelRenderTransform.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.set_auto_unwrap_transformed_env.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogScalar.rst", "reference/generated/torchrl.trainers.LogValidationReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/llms.rst", "reference/modules.rst", "reference/objectives.rst", "reference/trainers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/export.rst", "tutorials/getting-started-0.rst", "tutorials/getting-started-1.rst", "tutorials/getting-started-2.rst", "tutorials/getting-started-3.rst", "tutorials/getting-started-4.rst", "tutorials/getting-started-5.rst", "tutorials/index.rst", "tutorials/multi_task.rst", "tutorials/multiagent_competitive_ddpg.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "torchrl.data package", "torchrl.envs package", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "Customising Video Renders", "auto_unwrap_transformed_env", "DataCollectorBase", "MultiProcessedWeightUpdater", "MultiSyncDataCollector", "MultiaSyncDataCollector", "RayWeightUpdater", "SyncDataCollector", "VanillaWeightUpdater", "WeightUpdaterBase", "aSyncDataCollector", "DistributedDataCollector", "DistributedSyncDataCollector", "DistributedWeightUpdater", "RPCDataCollector", "RPCWeightUpdater", "RayCollector", "submitit_delayed_launcher", "LLMCollector", "vLLMUpdater", "split_trajectories", "AdaptiveKLController", "Binary", "BinaryDiscreteTensorSpec", "BinaryToDecimal", "Bounded", "BoundedTensorSpec", "Categorical", "Composite", "CompositeSpec", "ConstantKLController", "DensifyReward", "DiscreteTensorSpec", "Flat2TED", "H5Combine", "H5Split", "HashToInt", "LazyStackedCompositeSpec", "LazyStackedTensorSpec", "MCTSForest", "MultiCategorical", "MultiDiscreteTensorSpec", "MultiOneHot", "MultiOneHotDiscreteTensorSpec", "MultiStep", "Nested2TED", "NonTensor", "NonTensorSpec", "OneHot", "OneHotDiscreteTensorSpec", "PairwiseDataset", "PrioritizedReplayBuffer", "PromptData", "PromptTensorDictTokenizer", "QueryModule", "RandomProjectionHash", "RayReplayBuffer", "RemoteTensorDictReplayBuffer", "ReplayBuffer", "RewardData", "RolloutFromModel", "SipHash", "Stacked", "StackedComposite", "TED2Flat", "TED2Nested", "TensorDictMap", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorDictTokenizer", "TensorMap", "TensorSpec", "TokenizedDatasetLoader", "Tree", "Unbounded", "UnboundedContinuous", "UnboundedContinuousTensorSpec", "UnboundedDiscrete", "UnboundedDiscreteTensorSpec", "check_no_exclusive_keys", "consolidate_spec", "contains_lazy_spec", "create_infinite_iterator", "get_dataloader", "History", "LLMData", "FlatStorageCheckpointer", "H5StorageCheckpointer", "ImmutableDatasetWriter", "LazyMemmapStorage", "LazyStackStorage", "LazyTensorStorage", "ListStorage", "ListStorageCheckpointer", "NestedStorageCheckpointer", "PrioritizedSampler", "PrioritizedSliceSampler", "RandomSampler", "ReplayBufferEnsemble", "RoundRobinWriter", "Sampler", "SamplerEnsemble", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "StorageCheckpointerBase", "StorageEnsemble", "StorageEnsembleCheckpointer", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "TensorStorageCheckpointer", "Writer", "WriterEnsemble", "AsyncEnvPool", "BraxEnv", "BraxWrapper", "ChessEnv", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "IsaacLabWrapper", "JumanjiEnv", "JumanjiWrapper", "LLMHashingEnv", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "MeltingpotEnv", "MeltingpotWrapper", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "OpenSpielEnv", "OpenSpielWrapper", "ParallelEnv", "PendulumEnv", "PettingZooEnv", "PettingZooWrapper", "ProcessorAsyncEnvPool", "RandomPolicy", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "ThreadingAsyncEnvPool", "TicTacToeEnv", "UnityMLAgentsEnv", "UnityMLAgentsWrapper", "VmasEnv", "VmasWrapper", "check_env_specs", "check_marl_grouping", "exploration_type", "get_available_libraries", "gym_backend", "ChatEnv", "DatasetChatEnv", "GSM8KEnv", "GSM8KPrepareQuestion", "GSM8KRewardParser", "IFEvalEnv", "IFEvalScoreData", "IfEvalScorer", "LLMEnv", "LLMHashingEnv", "MLGymWrapper", "make_gsm8k_env", "make_mlgym", "DataLoadingPrimer", "KLRewardTransform", "PythonInterpreter", "TemplateTransform", "Tokenizer", "as_nested_tensor", "as_padded_tensor", "make_composite_from_td", "DreamerDecoder", "DreamerEnv", "register_gym_spec_conversion", "set_exploration_type", "set_gym_backend", "step_mdp", "terminated_or_truncated", "ActionDiscretizer", "ActionMask", "AutoResetEnv", "AutoResetTransform", "BatchSizeTransform", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "ConditionalPolicySwitch", "ConditionalSkip", "Crop", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "Hash", "InitTracker", "KLRewardTransform", "LineariseRewards", "MultiAction", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RemoveEmptySpecs", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SignTransform", "SqueezeTransform", "Stack", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "Timer", "ToTensorImage", "Tokenizer", "TrajCounter", "Transform", "TransformedEnv", "UnaryTransform", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "VecNormV2", "gSDENoise", "MultiStepTransform", "implement_for", "AdditiveGaussianModule", "BatchRenorm1d", "CEMPlanner", "ConsistentDropout", "ConsistentDropoutModule", "Conv3dNet", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueHook", "DreamerActor", "DuelingCnnDQNet", "EGreedyModule", "GRU", "GRUCell", "GRUModule", "IndependentNormal", "LSTM", "LSTMCell", "LSTMModule", "MLP", "MPCPlannerBase", "MPPIPlanner", "MaskedCategorical", "MaskedOneHotCategorical", "MultiAgentConvNet", "MultiAgentMLP", "MultiAgentNetBase", "NoisyLazyLinear", "NoisyLinear", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OneHotOrdinal", "OnlineDTActor", "Ordinal", "OrnsteinUhlenbeckProcessModule", "QMixer", "QValueHook", "RSSMPosterior", "RSSMPrior", "Squeeze2dLayer", "SqueezeLayer", "TanhDelta", "TanhNormal", "TruncatedNormal", "VDNMixer", "VmapModule", "CategoricalSequential", "LLMOnDevice", "TransformersWrapper", "make_vllm_worker", "stateless_init_process_group", "vLLMWorker", "vLLMWrapper", "recurrent_mode", "reset_noise", "set_recurrent_mode", "Actor", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "DecisionTransformerInferenceWrapper", "DistributionalQValueActor", "DistributionalQValueModule", "LMHeadActorValueOperator", "MultiStepActorWrapper", "ProbabilisticActor", "QValueActor", "QValueModule", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "ValueOperator", "WorldModelWrapper", "biased_softplus", "get_primers_from_module", "inv_softplus", "mappings", "A2CLoss", "CQLLoss", "ClipPPOLoss", "CrossQLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteIQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "GAILLoss", "HardUpdate", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "SoftUpdate", "TD3BCLoss", "TD3Loss", "ValueEstimators", "default_value_kwargs", "distance_loss", "group_optimizers", "hold_out_net", "hold_out_params", "GRPOLoss", "GRPOLossOutput", "MCAdvantage", "QMixerLoss", "next_state_value", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "generalized_advantage_estimate", "reward2go", "td0_advantage_estimate", "td0_return_estimate", "td1_advantage_estimate", "td1_return_estimate", "td_lambda_advantage_estimate", "td_lambda_return_estimate", "vec_generalized_advantage_estimate", "vec_td1_advantage_estimate", "vec_td1_return_estimate", "vec_td_lambda_advantage_estimate", "vec_td_lambda_return_estimate", "PixelRenderTransform", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "WandbLogger", "set_auto_unwrap_transformed_env", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogScalar", "LogValidationReward", "OptimizerHook", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "Trainer", "TrainerHookBase", "UpdateWeights", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "README Tutos", "API Reference", "Knowledge Base", "LLM interface", "torchrl.modules package", "torchrl.objectives package", "torchrl.trainers package", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "Exporting TorchRL modules", "Get started with Environments, TED and transforms", "Get started with TorchRL\u2019s modules", "Getting started with model optimization", "Get started with data collection and storage", "Get started with logging", "Get started with your own first training loop", "README Tutos", "Task-specific policy in multi-task environments", "Competitive Multi-Agent Reinforcement Learning (DDPG) with TorchRL Tutorial", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 1, 2, 3, 5, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 93, 95, 96, 99, 100, 101, 102, 103, 107, 109, 110, 112, 114, 115, 116, 118, 120, 121, 122, 124, 125, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 143, 144, 150, 151, 153, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 172, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 214, 220, 222, 223, 226, 230, 235, 236, 240, 241, 242, 243, 245, 254, 255, 256, 257, 258, 260, 261, 262, 265, 268, 269, 270, 272, 275, 279, 280, 282, 283, 284, 285, 287, 292, 293, 295, 297, 299, 300, 301, 305, 306, 308, 316, 321, 322, 324, 328, 330, 332, 334, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 351, 352, 356, 360, 361, 362, 363, 364, 366, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 417, 419, 422, 426, 432, 433, 437, 438, 441, 448, 449, 450, 451, 454, 455, 456, 457, 461, 462, 465, 467, 468, 469, 470, 471, 473, 474, 475, 477, 478, 480, 481], "open": [0, 5, 7, 61, 63, 70, 84, 95, 96, 100, 183, 273, 332, 395, 462, 474, 475, 480], "sourc": [0, 1, 4, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "reinforc": [0, 3, 9, 148, 149, 178, 212, 270, 277, 282, 283, 284, 285, 289, 316, 344, 361, 362, 364, 367, 368, 369, 371, 376, 377, 383, 384, 385, 386, 453, 460, 462, 466, 467, 472, 476, 479, 480], "learn": [0, 3, 7, 8, 9, 22, 55, 132, 148, 149, 153, 156, 165, 178, 212, 270, 277, 282, 283, 284, 285, 289, 302, 309, 315, 316, 344, 361, 362, 364, 367, 368, 369, 371, 375, 376, 377, 382, 383, 384, 385, 386, 453, 457, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 476, 478, 479, 480, 481], "rl": [0, 1, 2, 3, 5, 8, 10, 15, 16, 18, 21, 29, 141, 150, 212, 254, 309, 338, 347, 355, 361, 363, 378, 379, 381, 383, 428, 452, 454, 455, 456, 457, 458, 461, 462, 463, 469, 472, 474, 475, 477, 478, 481], "librari": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 15, 16, 22, 23, 25, 64, 80, 129, 130, 131, 140, 151, 175, 184, 334, 453, 454, 456, 457, 459, 461, 462, 463, 465, 466, 467, 469, 474, 475, 476, 481], "pytorch": [0, 1, 2, 3, 29, 31, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 182, 185, 186, 187, 212, 257, 258, 277, 293, 297, 308, 309, 437, 452, 454, 456, 458, 461, 463, 464, 468, 472, 474, 475, 476, 480, 481], "you": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 18, 22, 23, 25, 29, 35, 42, 47, 55, 65, 66, 72, 77, 80, 126, 129, 132, 136, 140, 144, 147, 148, 149, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 212, 233, 261, 269, 270, 272, 277, 297, 315, 328, 330, 334, 351, 394, 396, 426, 427, 454, 455, 456, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "can": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 106, 107, 109, 113, 114, 115, 120, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 140, 142, 143, 144, 147, 148, 149, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 202, 204, 205, 206, 208, 209, 211, 212, 215, 216, 218, 220, 222, 223, 224, 227, 230, 234, 235, 236, 240, 241, 245, 248, 252, 253, 254, 255, 259, 260, 261, 262, 263, 265, 267, 269, 270, 272, 273, 276, 278, 279, 280, 282, 292, 293, 295, 296, 297, 299, 301, 302, 303, 305, 306, 307, 309, 316, 325, 327, 328, 330, 334, 338, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 417, 419, 426, 427, 432, 449, 450, 451, 454, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "directli": [0, 4, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 109, 126, 127, 128, 129, 132, 135, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 230, 231, 232, 236, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 263, 265, 266, 268, 269, 270, 272, 351, 379, 386, 394, 396, 451, 462, 463, 465, 466, 474, 475, 476, 478], "from": [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 103, 106, 107, 109, 112, 113, 114, 115, 116, 118, 120, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 215, 217, 218, 220, 221, 222, 223, 224, 225, 230, 231, 232, 233, 236, 238, 240, 241, 242, 243, 244, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 267, 268, 269, 270, 272, 273, 275, 276, 277, 278, 279, 282, 283, 284, 285, 286, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 312, 314, 315, 316, 317, 318, 324, 325, 326, 328, 330, 331, 334, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 377, 378, 379, 381, 382, 383, 384, 386, 387, 389, 394, 395, 396, 397, 398, 399, 400, 401, 402, 405, 417, 418, 419, 428, 434, 437, 440, 441, 445, 447, 448, 451, 453, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481], "pypi": [0, 2, 480], "see": [0, 1, 2, 3, 6, 7, 8, 9, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 94, 101, 107, 109, 114, 115, 126, 129, 132, 136, 139, 141, 143, 144, 148, 149, 151, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 216, 218, 234, 240, 255, 258, 260, 261, 262, 265, 267, 269, 270, 271, 272, 277, 278, 279, 280, 293, 295, 296, 297, 299, 300, 306, 307, 308, 315, 317, 325, 326, 328, 330, 334, 337, 339, 341, 347, 350, 351, 364, 375, 379, 386, 394, 396, 419, 426, 434, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 474, 475, 476, 478, 480, 481], "more": [0, 1, 2, 3, 4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 107, 109, 120, 126, 129, 132, 135, 136, 137, 139, 140, 143, 144, 148, 149, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 258, 261, 265, 270, 271, 272, 273, 274, 275, 278, 289, 297, 300, 308, 328, 330, 334, 338, 343, 344, 350, 351, 355, 361, 371, 379, 381, 394, 396, 399, 404, 412, 426, 433, 454, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 473, 474, 475, 476, 477, 480, 481], "about": [0, 3, 5, 7, 9, 22, 23, 25, 26, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 80, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 456, 457, 461, 462, 463, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 478, 480, 481], "instruct": [0, 6, 7, 10, 28, 141, 179, 184, 222, 224, 455, 457, 461, 462, 463, 464, 474, 475, 478], "dedic": [0, 1, 2, 3, 22, 23, 25, 27, 50, 69, 78, 79, 109, 156, 165, 339, 340, 341, 455, 456, 461, 466, 468, 469, 471, 473, 475], "section": [0, 2, 3, 4, 32, 132, 293, 297, 455, 462, 465, 466, 471, 474, 475], "below": [0, 2, 3, 7, 15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 55, 65, 66, 69, 72, 77, 78, 79, 85, 94, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 218, 234, 240, 255, 260, 261, 262, 265, 267, 272, 279, 280, 293, 296, 297, 300, 306, 325, 328, 330, 334, 347, 350, 394, 396, 434, 461, 462, 463, 464, 465, 466, 474, 476], "pip": [0, 10, 465, 466, 467, 468, 469, 470, 471, 475, 480, 481], "provid": [0, 1, 2, 3, 5, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 39, 40, 41, 42, 47, 48, 50, 51, 53, 55, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 77, 78, 79, 83, 84, 91, 94, 95, 96, 100, 101, 103, 107, 108, 109, 112, 114, 115, 123, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 205, 209, 211, 212, 213, 214, 215, 219, 220, 223, 227, 230, 235, 236, 238, 240, 241, 244, 245, 248, 249, 254, 255, 256, 259, 260, 262, 264, 265, 267, 268, 269, 270, 272, 273, 279, 280, 286, 287, 289, 292, 293, 294, 295, 297, 298, 299, 300, 301, 303, 304, 305, 306, 327, 328, 330, 334, 338, 342, 344, 346, 347, 348, 349, 351, 354, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 423, 428, 434, 441, 447, 454, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "python": [0, 1, 3, 5, 6, 7, 10, 15, 16, 27, 62, 67, 68, 69, 72, 77, 78, 79, 84, 109, 152, 168, 169, 192, 202, 293, 294, 295, 297, 298, 299, 303, 304, 455, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "first": [0, 1, 2, 3, 4, 5, 7, 8, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 65, 73, 74, 82, 84, 85, 86, 87, 88, 89, 100, 102, 107, 114, 115, 120, 122, 126, 129, 132, 135, 136, 137, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 208, 209, 212, 213, 217, 218, 227, 234, 236, 240, 241, 257, 258, 262, 265, 270, 273, 280, 287, 293, 295, 297, 299, 300, 303, 304, 306, 308, 311, 338, 342, 343, 344, 347, 348, 350, 351, 363, 373, 378, 379, 381, 394, 418, 419, 436, 456, 460, 461, 462, 463, 464, 465, 466, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481], "low": [0, 3, 36, 39, 66, 77, 82, 85, 107, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 205, 215, 222, 230, 233, 255, 263, 323, 324, 325, 342, 344, 347, 351, 354, 461, 462, 463, 465, 474, 475, 476, 480], "high": [0, 3, 9, 36, 39, 61, 63, 70, 78, 84, 85, 95, 96, 107, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 197, 205, 215, 222, 230, 233, 235, 255, 263, 323, 324, 325, 342, 344, 347, 351, 354, 395, 399, 404, 412, 461, 462, 463, 474, 475, 476, 478, 480], "level": [0, 2, 3, 4, 28, 39, 40, 48, 62, 67, 68, 69, 74, 78, 79, 109, 135, 137, 212, 253, 261, 295, 299, 378, 461, 462, 465, 469, 480], "abstract": [0, 1, 3, 8, 20, 81, 82, 124, 132, 237, 301, 403, 429, 438, 458, 463, 465, 476, 480], "ar": [0, 1, 2, 3, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 95, 96, 97, 98, 100, 101, 102, 103, 105, 109, 112, 113, 114, 115, 116, 118, 120, 122, 126, 129, 132, 133, 135, 136, 137, 143, 144, 147, 148, 149, 150, 153, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 203, 204, 205, 207, 208, 209, 211, 212, 215, 216, 218, 220, 221, 222, 223, 224, 226, 227, 230, 232, 233, 234, 235, 238, 240, 245, 248, 252, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 272, 274, 276, 277, 285, 287, 292, 293, 294, 295, 297, 298, 299, 301, 303, 304, 305, 306, 307, 309, 312, 317, 320, 328, 330, 333, 334, 337, 342, 343, 346, 347, 348, 350, 351, 352, 353, 354, 358, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 390, 391, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 417, 426, 427, 434, 437, 447, 451, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "intend": [0, 7, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 83, 85, 86, 87, 88, 89, 211, 222, 327, 379, 456, 480], "effici": [0, 1, 2, 4, 8, 17, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 293, 309, 364, 456, 461, 462, 463, 464, 465, 468, 469, 471, 473, 474, 475, 477, 478, 480], "modular": [0, 353, 455, 465, 478, 480], "document": [0, 2, 5, 7, 11, 22, 23, 27, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 141, 144, 154, 155, 156, 157, 160, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 328, 330, 334, 394, 396, 452, 462, 464, 465, 466, 469, 472, 480], "properli": [0, 1, 3, 29, 85, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 218, 295, 299, 399, 463, 470, 474, 475, 476, 480], "test": [0, 3, 5, 29, 126, 127, 128, 129, 132, 136, 142, 143, 144, 148, 149, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 190, 260, 265, 432, 447, 455, 463, 464, 465, 477, 480], "The": [0, 1, 3, 4, 5, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 106, 107, 109, 112, 114, 115, 116, 120, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 140, 142, 143, 144, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 200, 203, 204, 205, 208, 209, 211, 212, 216, 217, 218, 220, 223, 224, 225, 230, 233, 234, 236, 238, 240, 245, 247, 248, 249, 252, 253, 254, 255, 257, 260, 261, 262, 265, 267, 268, 269, 270, 272, 274, 275, 276, 277, 282, 283, 284, 285, 286, 289, 293, 294, 295, 297, 298, 299, 301, 302, 303, 304, 305, 309, 313, 315, 316, 318, 319, 320, 328, 330, 332, 334, 337, 338, 339, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 355, 356, 357, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 417, 419, 421, 424, 425, 426, 427, 428, 433, 447, 449, 450, 453, 455, 456, 457, 458, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 480, 481], "code": [0, 3, 5, 7, 8, 15, 16, 66, 72, 126, 129, 132, 136, 141, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 192, 240, 262, 265, 275, 293, 294, 297, 298, 347, 351, 353, 455, 460, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481], "aim": [0, 2, 3, 7, 50, 73, 74, 240, 265, 267, 300, 440, 454, 456, 457, 461, 462, 480], "support": [0, 1, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 42, 61, 63, 65, 70, 77, 84, 94, 95, 96, 100, 102, 116, 118, 122, 123, 125, 126, 127, 128, 129, 135, 137, 142, 151, 153, 156, 158, 162, 175, 183, 185, 194, 209, 212, 224, 230, 236, 255, 256, 259, 263, 270, 289, 313, 315, 324, 327, 328, 330, 334, 343, 344, 347, 350, 353, 371, 379, 394, 395, 399, 400, 401, 402, 424, 453, 455, 456, 458, 463, 464, 466, 467, 475, 476, 478, 480], "research": [0, 7, 9, 148, 149, 275, 480], "most": [0, 1, 2, 3, 7, 8, 15, 16, 55, 57, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 222, 268, 461, 463, 465, 466, 467, 468, 469, 470, 471, 476, 480, 481], "written": [0, 1, 2, 3, 29, 44, 61, 62, 63, 65, 67, 68, 69, 70, 75, 78, 79, 83, 84, 95, 96, 98, 100, 107, 109, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 183, 184, 185, 186, 187, 191, 203, 204, 205, 212, 224, 227, 232, 233, 248, 253, 256, 257, 262, 268, 272, 273, 278, 316, 338, 347, 350, 351, 355, 361, 363, 378, 381, 383, 394, 395, 398, 417, 418, 419, 456, 457, 458, 461, 464, 465, 467, 473, 476, 480], "highli": [0, 2, 466, 480, 481], "wai": [0, 1, 2, 3, 4, 109, 120, 140, 178, 179, 182, 212, 240, 243, 260, 261, 267, 268, 295, 297, 299, 381, 399, 400, 401, 402, 456, 461, 462, 463, 465, 466, 468, 469, 473, 474, 475, 476, 477, 478, 480, 481], "easili": [0, 1, 2, 3, 7, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 455, 457, 461, 462, 463, 466, 467, 468, 471, 474, 475, 480, 481], "swap": [0, 1, 3, 135, 268, 463, 465, 477, 480], "compon": [0, 1, 2, 3, 62, 66, 67, 68, 69, 78, 79, 100, 101, 102, 103, 109, 116, 118, 122, 289, 318, 343, 344, 349, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 433, 437, 455, 461, 462, 463, 464, 465, 467, 468, 471, 473, 474, 475, 476, 477, 480], "transform": [0, 1, 4, 8, 15, 16, 18, 19, 20, 21, 22, 23, 25, 27, 29, 42, 50, 55, 62, 64, 67, 68, 69, 71, 78, 79, 80, 95, 97, 98, 105, 109, 118, 123, 126, 129, 132, 133, 136, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 278, 281, 282, 286, 289, 290, 295, 299, 314, 317, 318, 324, 326, 330, 334, 342, 345, 346, 354, 357, 358, 360, 367, 380, 396, 417, 419, 434, 451, 453, 460, 462, 464, 465, 467, 469, 470, 471, 472, 477, 479], "them": [0, 2, 3, 7, 9, 11, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 35, 39, 40, 42, 47, 48, 62, 64, 65, 66, 67, 68, 69, 72, 74, 77, 78, 79, 109, 120, 125, 126, 129, 132, 133, 136, 140, 144, 147, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 194, 220, 223, 230, 233, 255, 259, 262, 263, 269, 270, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 326, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 362, 364, 370, 377, 378, 382, 384, 386, 387, 400, 401, 402, 419, 461, 462, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "write": [0, 2, 3, 8, 15, 16, 18, 21, 29, 31, 50, 55, 61, 62, 63, 64, 67, 68, 69, 70, 78, 79, 83, 84, 95, 96, 107, 109, 114, 118, 125, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 238, 239, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 264, 265, 266, 268, 269, 272, 338, 350, 351, 353, 355, 364, 365, 366, 368, 369, 370, 377, 382, 384, 386, 387, 395, 396, 398, 403, 419, 455, 456, 458, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481], "new": [0, 1, 2, 3, 4, 8, 15, 16, 18, 21, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 106, 107, 109, 113, 126, 129, 132, 136, 144, 151, 156, 157, 160, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 209, 248, 252, 261, 262, 269, 270, 272, 287, 293, 295, 299, 316, 328, 330, 334, 350, 351, 356, 361, 362, 363, 366, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 395, 396, 397, 426, 457, 461, 463, 466, 468, 474, 475, 476, 480, 481], "ones": [0, 2, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 114, 115, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 161, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 213, 216, 217, 220, 221, 223, 236, 240, 245, 252, 255, 261, 262, 265, 267, 270, 272, 277, 303, 304, 315, 327, 328, 330, 334, 350, 361, 362, 363, 364, 365, 377, 378, 381, 382, 384, 386, 387, 394, 396, 405, 461, 463, 465, 474, 475, 476, 478, 480, 481], "littl": [0, 1, 3, 80, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262, 277, 361, 363, 378, 381, 383, 463, 464, 465, 469, 478, 480, 481], "effort": [0, 3, 476, 478, 480], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 97, 98, 100, 101, 102, 103, 105, 106, 107, 109, 112, 113, 114, 115, 116, 118, 120, 122, 123, 125, 126, 127, 128, 129, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 153, 156, 157, 158, 159, 160, 161, 165, 166, 167, 168, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 200, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 234, 236, 239, 240, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 318, 319, 320, 322, 324, 325, 327, 328, 330, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 356, 357, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 417, 418, 426, 427, 428, 430, 432, 434, 437, 439, 440, 441, 447, 451, 454, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "repo": [0, 6, 212, 256, 265, 454, 475, 480], "attempt": [0, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 65, 66, 72, 77, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 272, 277, 328, 330, 334, 351, 366, 369, 377, 394, 396, 397, 457, 468, 480], "align": [0, 293, 297, 480], "exist": [0, 1, 2, 3, 4, 22, 27, 35, 42, 47, 50, 55, 61, 63, 65, 66, 70, 72, 77, 83, 84, 95, 96, 100, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 213, 221, 260, 262, 272, 273, 287, 328, 330, 334, 351, 364, 384, 394, 395, 396, 441, 451, 455, 474, 475, 480, 481], "ecosystem": [0, 465, 469, 480], "ha": [0, 1, 2, 3, 4, 5, 7, 8, 10, 12, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 102, 109, 112, 114, 120, 122, 126, 129, 132, 133, 136, 140, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 212, 234, 253, 254, 255, 256, 257, 259, 260, 261, 262, 272, 274, 293, 295, 297, 299, 305, 307, 324, 328, 330, 334, 344, 346, 351, 361, 364, 378, 379, 381, 383, 394, 395, 396, 399, 419, 455, 457, 461, 462, 463, 464, 465, 466, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "dataset": [0, 46, 50, 61, 62, 63, 64, 69, 70, 71, 76, 78, 79, 83, 84, 94, 95, 96, 99, 107, 109, 112, 114, 115, 153, 178, 179, 182, 183, 184, 185, 188, 269, 395, 419, 453, 455, 461, 462, 466, 477, 478, 480, 481], "pillar": [0, 480], "environ": [0, 2, 5, 8, 10, 13, 14, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 66, 67, 72, 73, 74, 82, 84, 85, 86, 87, 88, 89, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 177, 178, 179, 182, 185, 186, 187, 188, 189, 190, 194, 199, 205, 206, 208, 209, 211, 212, 213, 217, 218, 220, 221, 222, 223, 228, 234, 235, 236, 240, 241, 242, 245, 248, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 268, 269, 270, 273, 276, 278, 295, 299, 301, 302, 346, 368, 372, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 427, 428, 430, 432, 440, 441, 442, 443, 447, 448, 449, 450, 451, 453, 454, 456, 457, 460, 465, 467, 468, 469, 470, 472, 477, 478, 479], "model": [0, 3, 8, 9, 15, 16, 18, 21, 22, 23, 25, 27, 32, 35, 41, 42, 47, 55, 61, 63, 65, 66, 70, 71, 72, 77, 83, 84, 95, 96, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 220, 240, 255, 265, 267, 271, 272, 279, 280, 281, 286, 288, 300, 301, 302, 306, 307, 314, 317, 326, 328, 330, 331, 334, 339, 340, 341, 345, 350, 356, 358, 361, 362, 363, 364, 366, 367, 368, 369, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 394, 395, 396, 397, 437, 442, 443, 444, 453, 454, 457, 458, 460, 463, 466, 469, 472, 474, 475, 476, 478, 479, 481], "data": [0, 3, 8, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 141, 142, 143, 144, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 172, 177, 178, 179, 182, 183, 184, 185, 186, 187, 189, 190, 194, 197, 204, 206, 209, 211, 212, 217, 220, 221, 223, 225, 227, 230, 232, 236, 242, 245, 252, 253, 259, 261, 262, 263, 268, 270, 272, 276, 277, 289, 292, 295, 299, 302, 305, 306, 316, 318, 327, 330, 331, 332, 334, 337, 338, 343, 346, 347, 348, 350, 351, 353, 354, 355, 361, 362, 363, 364, 365, 366, 368, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 395, 397, 399, 400, 401, 402, 403, 417, 419, 426, 428, 434, 437, 439, 442, 447, 449, 450, 451, 453, 456, 457, 458, 460, 464, 465, 466, 467, 468, 472, 476, 477, 478, 479, 481], "util": [0, 3, 15, 16, 18, 21, 22, 23, 25, 27, 28, 31, 35, 42, 47, 55, 65, 66, 69, 71, 72, 77, 114, 115, 126, 127, 128, 129, 132, 136, 142, 143, 144, 149, 156, 157, 158, 159, 160, 165, 166, 167, 173, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 240, 245, 255, 267, 272, 275, 278, 279, 280, 286, 293, 295, 297, 299, 328, 330, 334, 357, 358, 359, 360, 379, 394, 396, 447, 453, 459, 461, 463, 465, 467, 468, 469, 475, 476, 478, 480, 481], "e": [0, 1, 2, 3, 7, 8, 10, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 102, 106, 107, 120, 122, 126, 129, 132, 133, 136, 137, 144, 156, 157, 160, 165, 166, 167, 170, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 209, 211, 213, 216, 217, 218, 219, 227, 230, 233, 234, 236, 240, 248, 255, 257, 260, 261, 262, 265, 267, 272, 273, 293, 295, 296, 297, 299, 302, 306, 318, 324, 325, 328, 330, 332, 334, 337, 342, 344, 346, 347, 349, 350, 351, 361, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 395, 396, 398, 399, 400, 401, 402, 417, 428, 440, 450, 455, 456, 457, 462, 463, 465, 467, 468, 470, 474, 475, 477, 478, 480, 481], "g": [0, 1, 2, 3, 7, 8, 10, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 120, 126, 129, 132, 133, 136, 137, 144, 156, 157, 160, 165, 166, 167, 170, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 209, 211, 213, 216, 217, 227, 230, 233, 236, 240, 248, 255, 257, 260, 261, 262, 265, 267, 272, 273, 293, 295, 296, 297, 298, 299, 302, 306, 324, 325, 328, 330, 332, 334, 342, 347, 350, 351, 364, 384, 394, 395, 396, 398, 408, 409, 410, 411, 413, 414, 415, 416, 417, 450, 456, 457, 462, 463, 465, 467, 470, 474, 475, 476, 477, 478, 480, 481], "collector": [0, 2, 3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 44, 55, 62, 67, 68, 69, 71, 75, 78, 79, 109, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 209, 212, 245, 253, 272, 277, 295, 299, 316, 363, 378, 381, 394, 434, 437, 439, 442, 443, 447, 449, 450, 453, 457, 458, 465, 478, 481], "contain": [0, 2, 3, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 92, 95, 96, 99, 106, 107, 109, 110, 112, 114, 115, 116, 121, 124, 125, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 205, 212, 216, 220, 223, 230, 240, 252, 255, 260, 261, 262, 265, 267, 268, 269, 270, 272, 276, 279, 280, 293, 294, 297, 298, 300, 302, 305, 306, 328, 330, 334, 338, 343, 344, 347, 349, 350, 351, 355, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 423, 428, 440, 447, 448, 449, 450, 451, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 480, 481], "etc": [0, 2, 3, 7, 8, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 252, 262, 272, 273, 300, 306, 324, 328, 330, 334, 394, 396, 455, 457, 462, 463, 469, 478, 480, 481], "have": [0, 1, 2, 3, 5, 6, 7, 8, 9, 15, 16, 21, 22, 24, 25, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 82, 83, 85, 86, 87, 88, 89, 109, 113, 116, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 200, 204, 205, 208, 212, 217, 220, 223, 224, 232, 235, 236, 252, 253, 255, 259, 260, 261, 262, 269, 270, 272, 274, 277, 279, 280, 300, 305, 306, 307, 316, 327, 328, 330, 334, 346, 352, 353, 361, 363, 378, 381, 383, 386, 390, 391, 394, 396, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 428, 437, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "few": [0, 2, 8, 115, 136, 187, 419, 428, 455, 463, 464, 467, 474, 475, 478, 480, 481], "depend": [0, 1, 2, 3, 4, 7, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 36, 61, 63, 85, 126, 129, 132, 135, 136, 137, 138, 144, 156, 157, 160, 162, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 220, 223, 351, 355, 381, 421, 456, 461, 463, 464, 474, 475, 476, 480, 481], "possibl": [0, 2, 3, 4, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 101, 107, 114, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 216, 240, 255, 260, 261, 262, 265, 267, 272, 279, 280, 293, 294, 297, 298, 328, 330, 334, 350, 394, 396, 417, 432, 437, 456, 461, 463, 464, 465, 467, 469, 470, 474, 475, 476, 478, 480, 481], "standard": [0, 2, 3, 57, 129, 236, 247, 269, 270, 274, 275, 276, 290, 302, 308, 309, 314, 342, 363, 378, 381, 386, 387, 399, 400, 401, 402, 461, 462, 466, 467, 475, 478, 480], "numpi": [0, 3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 230, 258, 263, 273, 437, 465, 476, 478, 480, 481], "common": [0, 2, 3, 4, 82, 126, 136, 142, 206, 224, 339, 340, 341, 345, 361, 362, 363, 364, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 447, 454, 456, 457, 458, 461, 463, 467, 470, 473, 474, 475, 476, 477, 480, 481], "openai": [0, 7, 32, 135, 137, 144, 162, 186, 463, 476, 480, 481], "gym": [0, 1, 3, 4, 8, 15, 16, 18, 21, 27, 28, 29, 67, 126, 129, 132, 133, 135, 136, 137, 138, 140, 141, 144, 148, 149, 151, 152, 156, 157, 160, 162, 165, 166, 167, 170, 171, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 202, 208, 212, 215, 224, 231, 232, 236, 238, 243, 245, 248, 255, 261, 268, 269, 272, 273, 396, 447, 454, 461, 462, 463, 464, 466, 470, 471, 476, 477, 478], "onli": [0, 1, 2, 3, 4, 7, 15, 16, 18, 20, 21, 22, 23, 25, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 100, 102, 106, 107, 109, 114, 115, 122, 126, 129, 130, 131, 132, 135, 136, 137, 138, 140, 143, 144, 151, 152, 156, 157, 158, 159, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 208, 212, 213, 215, 216, 217, 218, 220, 222, 223, 227, 230, 234, 236, 240, 241, 245, 252, 253, 254, 255, 256, 260, 261, 262, 265, 267, 269, 270, 272, 273, 277, 297, 299, 305, 306, 328, 330, 334, 338, 342, 343, 347, 348, 350, 351, 352, 353, 361, 363, 364, 365, 369, 370, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 394, 396, 399, 400, 401, 402, 403, 419, 426, 441, 455, 457, 458, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 473, 474, 475, 476, 478, 480, 481], "option": [0, 1, 2, 3, 4, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 103, 106, 107, 108, 109, 110, 112, 113, 114, 115, 118, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 219, 220, 222, 223, 224, 225, 227, 228, 230, 231, 232, 233, 234, 235, 236, 240, 241, 243, 244, 247, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 264, 265, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 295, 296, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 316, 318, 319, 320, 323, 324, 325, 327, 328, 330, 331, 334, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 355, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 408, 409, 410, 411, 413, 414, 415, 416, 417, 419, 421, 424, 426, 428, 430, 431, 432, 433, 434, 435, 437, 441, 447, 449, 450, 451, 456, 464, 466, 469, 474, 475, 476, 478, 480], "On": [0, 3, 7, 22, 23, 25, 27, 39, 294, 298, 456, 462, 474, 475], "end": [0, 2, 3, 15, 16, 21, 29, 35, 42, 47, 50, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 84, 98, 107, 109, 113, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 224, 230, 238, 253, 254, 260, 262, 272, 279, 280, 293, 294, 297, 298, 301, 328, 330, 334, 346, 364, 384, 394, 396, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "come": [0, 1, 2, 3, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 50, 55, 120, 126, 129, 132, 136, 143, 144, 147, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 220, 223, 337, 338, 339, 340, 341, 347, 355, 361, 363, 378, 381, 383, 419, 461, 462, 463, 464, 468, 469, 470, 471, 474, 475, 478, 480, 481], "set": [0, 1, 2, 3, 7, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 38, 39, 40, 42, 43, 47, 48, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 84, 95, 96, 100, 101, 102, 109, 113, 116, 122, 126, 129, 132, 134, 136, 137, 143, 144, 148, 149, 150, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 201, 202, 204, 206, 208, 209, 212, 213, 216, 220, 223, 230, 231, 232, 233, 240, 245, 253, 254, 255, 256, 260, 261, 262, 265, 267, 269, 270, 272, 273, 293, 295, 297, 299, 301, 305, 306, 313, 315, 316, 324, 328, 330, 334, 337, 342, 350, 351, 363, 364, 370, 375, 378, 379, 381, 384, 394, 395, 396, 399, 403, 419, 427, 428, 432, 434, 443, 451, 454, 455, 456, 457, 459, 461, 462, 463, 464, 465, 467, 468, 469, 473, 474, 475, 476, 477, 478, 480, 481], "re": [0, 2, 3, 8, 13, 22, 23, 25, 35, 42, 47, 50, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 84, 109, 113, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 227, 272, 299, 303, 304, 307, 328, 330, 334, 347, 351, 394, 396, 426, 458, 461, 463, 464, 466, 468, 473, 474, 476, 480, 481], "usabl": [0, 458, 464, 480], "function": [0, 2, 3, 8, 15, 16, 18, 21, 22, 23, 25, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 95, 96, 100, 101, 102, 103, 109, 116, 118, 122, 126, 129, 132, 133, 136, 137, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 202, 203, 204, 208, 209, 220, 223, 230, 232, 259, 260, 262, 263, 269, 270, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 303, 304, 305, 306, 307, 310, 311, 312, 314, 316, 319, 320, 322, 325, 327, 328, 330, 334, 339, 340, 341, 342, 344, 346, 347, 349, 350, 351, 353, 354, 355, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 377, 378, 379, 381, 382, 383, 384, 386, 387, 388, 389, 390, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 437, 447, 453, 455, 456, 461, 464, 465, 466, 467, 470, 473, 476, 478, 481], "cost": [0, 2, 38, 101, 361, 363, 378, 381, 383, 457, 461, 462, 465, 474, 475, 476, 478], "return": [0, 2, 3, 7, 8, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 99, 101, 107, 109, 110, 112, 114, 115, 118, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 160, 162, 165, 166, 167, 170, 171, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 276, 277, 280, 281, 282, 283, 284, 285, 287, 289, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 312, 314, 317, 319, 320, 323, 324, 325, 326, 328, 330, 332, 334, 335, 338, 339, 340, 341, 342, 346, 347, 349, 350, 351, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 419, 423, 427, 437, 440, 442, 447, 448, 449, 450, 451, 453, 455, 456, 458, 461, 462, 463, 465, 467, 468, 470, 473, 474, 475, 476, 477, 478, 480, 481], "process": [0, 1, 3, 4, 5, 8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 35, 42, 47, 55, 61, 62, 63, 65, 66, 69, 70, 72, 77, 78, 79, 80, 83, 84, 95, 96, 102, 106, 107, 110, 114, 122, 126, 129, 132, 133, 136, 140, 144, 147, 151, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 211, 212, 220, 223, 230, 255, 258, 260, 269, 270, 272, 295, 299, 305, 306, 316, 328, 330, 331, 332, 333, 334, 344, 349, 394, 395, 396, 453, 458, 461, 462, 464, 465, 466, 474, 475, 476, 477, 478, 480, 481], "good": [0, 1, 4, 9, 156, 461, 463, 464, 465, 467, 475, 480, 481], "runtim": [0, 2, 3, 31, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 476], "perform": [0, 1, 2, 3, 4, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 71, 72, 73, 74, 77, 82, 83, 85, 86, 87, 88, 89, 95, 126, 129, 130, 131, 132, 135, 136, 137, 138, 143, 144, 156, 157, 160, 162, 165, 166, 167, 170, 171, 173, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 220, 223, 230, 235, 257, 260, 262, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 307, 310, 311, 314, 315, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 363, 364, 373, 381, 384, 394, 396, 432, 437, 457, 461, 462, 463, 464, 465, 466, 469, 471, 473, 474, 475, 476, 481], "To": [0, 1, 2, 3, 4, 6, 7, 8, 9, 20, 22, 23, 25, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 71, 72, 77, 78, 79, 98, 107, 109, 114, 115, 118, 125, 126, 127, 128, 129, 132, 135, 136, 137, 142, 143, 144, 147, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 170, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 218, 253, 255, 269, 272, 278, 295, 299, 316, 328, 330, 334, 339, 340, 341, 351, 364, 370, 375, 379, 386, 394, 396, 419, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 455, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 480, 481], "read": [0, 2, 3, 7, 31, 39, 40, 44, 48, 62, 64, 67, 68, 69, 71, 74, 75, 78, 79, 100, 101, 102, 103, 106, 109, 116, 118, 122, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 205, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 220, 221, 222, 224, 225, 226, 227, 228, 231, 232, 238, 239, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 259, 260, 261, 264, 265, 266, 268, 269, 272, 278, 312, 338, 339, 340, 341, 343, 346, 347, 350, 351, 353, 355, 356, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 396, 397, 399, 400, 401, 402, 403, 419, 432, 437, 456, 461, 462, 463, 465, 466, 467, 473, 474, 475, 476, 477, 480, 481], "philosophi": [0, 9], "capabl": [0, 1, 3, 7, 9, 11, 17, 27, 31, 458, 461, 466, 469, 473, 477, 481], "beyond": [0, 50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 465], "api": [0, 1, 2, 3, 5, 31, 39, 40, 42, 48, 50, 65, 74, 77, 82, 129, 132, 158, 159, 162, 187, 189, 240, 267, 269, 270, 277, 328, 330, 334, 394, 456, 457, 458, 465, 466, 467, 468, 469, 470, 474, 475, 476, 478, 480, 481], "check": [0, 2, 3, 4, 5, 6, 7, 9, 15, 16, 18, 21, 22, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 90, 92, 97, 98, 105, 114, 126, 129, 132, 133, 135, 136, 137, 144, 150, 156, 157, 160, 165, 166, 167, 172, 173, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 213, 218, 226, 232, 241, 255, 258, 262, 272, 273, 287, 328, 330, 333, 334, 338, 343, 344, 347, 348, 349, 350, 351, 364, 375, 386, 394, 396, 419, 452, 456, 457, 462, 463, 464, 465, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "paper": [0, 127, 128, 130, 131, 138, 142, 143, 148, 149, 151, 152, 162, 170, 171, 240, 265, 267, 280, 293, 317, 326, 368, 376, 386, 461, 463, 474, 475], "releas": [0, 4, 7, 10, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "sync": [0, 1, 15, 16, 21, 22, 23, 24, 25, 26, 27, 126, 331, 439, 447, 458, 461], "so": [0, 1, 2, 3, 4, 6, 7, 10, 11, 35, 42, 47, 50, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 84, 95, 96, 109, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 255, 260, 269, 272, 277, 328, 330, 334, 352, 353, 394, 395, 396, 399, 419, 461, 463, 464, 468, 471, 474, 475, 476, 481], "make": [0, 1, 2, 3, 4, 7, 11, 35, 42, 47, 50, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 82, 84, 95, 96, 109, 112, 116, 118, 125, 126, 129, 132, 136, 137, 140, 141, 143, 144, 146, 152, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 203, 205, 218, 225, 233, 236, 240, 241, 245, 249, 253, 257, 261, 265, 272, 275, 278, 293, 294, 295, 297, 298, 299, 305, 306, 308, 328, 330, 334, 343, 351, 361, 363, 378, 381, 383, 394, 395, 396, 399, 400, 401, 402, 417, 434, 443, 451, 455, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "sure": [0, 1, 3, 4, 7, 42, 116, 129, 136, 140, 182, 187, 189, 218, 245, 343, 451, 456, 461, 463, 464, 465, 468, 474, 475, 476, 478, 480, 481], "alwai": [0, 2, 3, 15, 16, 25, 35, 36, 42, 47, 55, 65, 66, 72, 77, 82, 85, 94, 97, 98, 105, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 235, 257, 269, 270, 272, 328, 330, 333, 334, 371, 379, 394, 396, 456, 457, 462, 463, 464, 465, 474, 475, 476, 478], "enjoi": [0, 2, 3, 469], "latest": [0, 1, 2, 3, 10, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 151, 154, 155, 158, 159, 434, 463, 474, 475, 476, 480], "featur": [0, 2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 31, 35, 42, 59, 65, 77, 82, 83, 107, 114, 115, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 191, 209, 212, 227, 230, 232, 238, 255, 256, 264, 269, 275, 279, 280, 290, 291, 293, 294, 295, 297, 298, 299, 300, 305, 308, 309, 328, 330, 334, 351, 358, 361, 363, 378, 381, 383, 394, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 451, 456, 457, 461, 462, 463, 464, 465, 467, 468, 469, 471, 476, 478, 480, 481], "recent": [0, 7, 268, 270, 273, 481], "version": [0, 1, 2, 3, 6, 29, 34, 35, 37, 40, 42, 43, 47, 48, 49, 52, 54, 55, 58, 60, 61, 63, 65, 66, 71, 72, 77, 86, 87, 88, 89, 114, 126, 129, 132, 135, 136, 137, 138, 144, 151, 152, 156, 157, 158, 160, 162, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 212, 259, 268, 269, 270, 272, 273, 275, 295, 299, 307, 313, 328, 330, 334, 341, 361, 363, 378, 379, 381, 383, 384, 394, 396, 399, 402, 454, 455, 456, 457, 461, 463, 464, 465, 466, 468, 471, 474, 475, 476, 477, 481], "although": [0, 1, 3, 8, 27, 35, 42, 47, 65, 66, 72, 77, 85, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 457, 458, 461, 462, 469, 478], "core": [0, 2, 3, 8, 62, 67, 68, 69, 78, 79, 109, 458, 464, 467, 480], "guarante": [0, 2, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 102, 103, 116, 118, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 269, 270, 272, 328, 330, 334, 351, 394, 395, 396, 469], "backward": [0, 8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 293, 294, 297, 298, 315, 328, 330, 334, 351, 361, 362, 364, 365, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 396, 461, 463, 464, 465, 468, 469, 471, 474, 475, 476], "compat": [0, 2, 3, 7, 15, 16, 18, 31, 35, 42, 47, 55, 65, 66, 72, 77, 101, 109, 112, 114, 115, 116, 120, 126, 129, 132, 136, 138, 144, 153, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 253, 265, 269, 270, 272, 273, 293, 294, 295, 297, 298, 299, 328, 330, 334, 348, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 383, 384, 386, 387, 390, 394, 396, 399, 461, 464, 478], "2": [0, 1, 2, 3, 8, 9, 10, 15, 16, 18, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 74, 75, 77, 78, 79, 80, 83, 84, 94, 95, 100, 102, 106, 107, 109, 114, 115, 120, 122, 126, 127, 128, 129, 132, 133, 136, 142, 143, 144, 147, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 204, 208, 209, 211, 213, 216, 217, 218, 220, 221, 222, 223, 232, 233, 236, 238, 240, 242, 245, 248, 252, 253, 254, 255, 260, 261, 262, 265, 267, 269, 270, 272, 273, 278, 279, 280, 281, 282, 283, 284, 285, 286, 289, 291, 292, 293, 294, 295, 297, 298, 299, 300, 303, 304, 305, 306, 307, 314, 315, 316, 324, 327, 328, 330, 334, 342, 343, 344, 346, 350, 354, 355, 361, 362, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 396, 398, 399, 400, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 428, 455, 456, 457, 460, 461, 462, 463, 464, 465, 467, 468, 473, 474, 475, 476, 478, 479, 480, 481], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16, 17, 18, 21, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 100, 101, 102, 106, 107, 109, 114, 115, 122, 126, 127, 128, 129, 132, 135, 136, 138, 139, 142, 143, 144, 150, 151, 152, 154, 155, 156, 157, 160, 162, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 196, 205, 206, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 221, 222, 224, 225, 226, 228, 231, 232, 233, 234, 235, 236, 239, 240, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 308, 309, 312, 315, 316, 319, 320, 323, 324, 325, 327, 328, 330, 331, 333, 334, 338, 342, 344, 349, 350, 351, 353, 354, 357, 358, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389, 394, 395, 396, 397, 398, 399, 400, 401, 402, 405, 406, 407, 428, 435, 447, 451, 455, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481], "nightli": [0, 6], "via": [0, 1, 3, 4, 7, 8, 20, 25, 26, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 65, 69, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 101, 136, 156, 165, 185, 187, 233, 240, 243, 267, 328, 330, 334, 364, 367, 379, 394, 457, 458, 461, 462, 463, 464, 467, 469, 478, 480, 481], "tensordict": [0, 1, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 97, 98, 100, 101, 102, 103, 105, 106, 107, 109, 112, 114, 115, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 142, 143, 144, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 197, 203, 204, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 234, 236, 238, 239, 240, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 274, 276, 277, 278, 288, 289, 292, 295, 299, 301, 302, 305, 306, 316, 317, 318, 326, 327, 328, 330, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 417, 418, 428, 432, 433, 434, 436, 437, 453, 455, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 481], "git": [0, 6, 7, 10], "clone": [0, 2, 4, 8, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 65, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 100, 179, 192, 232, 242, 260, 261, 270, 328, 330, 334, 339, 340, 341, 350, 369, 377, 386, 453, 461, 474, 476, 480], "willing": 0, "contribut": [0, 2], "cd": [0, 7], "path": [0, 3, 6, 7, 35, 42, 47, 50, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 83, 84, 94, 95, 96, 98, 100, 109, 117, 123, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 168, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 240, 267, 272, 302, 328, 330, 334, 394, 395, 396, 421, 426, 437, 458, 462, 465, 471, 474], "root": [0, 2, 3, 39, 40, 48, 50, 62, 67, 68, 69, 74, 78, 79, 84, 97, 98, 105, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 212, 234, 256, 257, 295, 296, 299, 324, 325, 399, 457, 464, 466, 474, 475, 476, 478, 481], "http": [0, 2, 5, 6, 7, 10, 15, 16, 22, 23, 25, 32, 62, 80, 106, 107, 127, 128, 130, 131, 138, 140, 142, 143, 148, 149, 151, 152, 153, 154, 155, 158, 159, 162, 168, 169, 170, 171, 184, 212, 240, 265, 275, 281, 282, 283, 284, 285, 286, 289, 290, 291, 297, 302, 303, 304, 309, 310, 311, 315, 316, 317, 319, 320, 326, 344, 361, 362, 364, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 380, 381, 382, 383, 384, 385, 386, 399, 404, 412, 452, 472, 477, 480], "github": [0, 2, 5, 6, 7, 10, 22, 23, 25, 32, 127, 128, 130, 131, 135, 138, 142, 143, 148, 149, 151, 152, 154, 155, 158, 159, 162, 168, 169, 170, 171, 209, 212, 265, 275, 467, 471, 474, 475, 480], "com": [0, 2, 5, 6, 7, 10, 22, 23, 25, 32, 127, 128, 130, 131, 138, 140, 142, 143, 148, 149, 151, 152, 154, 155, 158, 159, 162, 168, 169, 170, 171, 212, 275, 480], "setup": [0, 1, 7, 127, 128, 140, 142, 143, 168, 455], "py": [0, 3, 32, 135, 137, 202, 212, 287, 317, 326, 458, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481], "develop": [0, 3, 4, 7, 50, 140, 461, 480], "A": [0, 1, 3, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 113, 114, 116, 120, 121, 122, 123, 124, 126, 129, 132, 134, 136, 138, 139, 141, 144, 156, 157, 160, 161, 162, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 203, 205, 207, 208, 209, 211, 212, 215, 217, 218, 222, 228, 232, 234, 240, 241, 243, 250, 255, 257, 260, 261, 262, 265, 266, 268, 269, 270, 271, 272, 273, 274, 276, 278, 279, 280, 289, 292, 293, 294, 295, 297, 298, 299, 300, 302, 303, 304, 306, 307, 309, 315, 327, 328, 329, 330, 332, 334, 342, 343, 344, 346, 347, 348, 351, 353, 354, 357, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 390, 394, 395, 396, 397, 399, 400, 401, 402, 403, 405, 417, 420, 421, 424, 426, 427, 430, 437, 439, 447, 453, 455, 457, 460, 461, 463, 465, 467, 468, 469, 472, 476, 479, 481], "seri": [0, 2, 3, 7, 8, 59, 99, 110, 120, 121, 124, 125, 165, 235, 261, 419, 456, 457, 461, 462, 463, 470, 471, 474, 475, 478, 481], "quick": [0, 465], "ramp": 0, "up": [0, 1, 2, 3, 8, 9, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 71, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 211, 230, 233, 256, 261, 272, 275, 381, 396, 454, 456, 457, 461, 462, 463, 464, 467, 471, 474, 475, 476, 478, 480, 481], "If": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 103, 107, 109, 110, 112, 113, 114, 115, 120, 122, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 143, 144, 148, 149, 150, 151, 152, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 172, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 200, 203, 204, 205, 208, 209, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 225, 227, 230, 232, 233, 234, 235, 236, 240, 241, 244, 245, 248, 249, 254, 255, 256, 257, 258, 259, 260, 262, 263, 265, 267, 269, 270, 272, 273, 278, 279, 280, 292, 293, 294, 295, 297, 298, 299, 300, 303, 304, 305, 306, 307, 316, 327, 328, 330, 334, 338, 342, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 360, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 373, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 413, 414, 415, 416, 417, 423, 426, 427, 433, 434, 437, 439, 441, 447, 451, 454, 457, 461, 462, 463, 464, 465, 466, 468, 470, 471, 473, 474, 475, 476, 478, 480, 481], "hurri": [0, 466], "last": [0, 1, 2, 3, 4, 15, 16, 18, 21, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 64, 65, 73, 74, 82, 84, 85, 86, 87, 88, 89, 113, 114, 115, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 151, 152, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 205, 208, 211, 217, 227, 234, 236, 241, 254, 256, 258, 268, 273, 274, 279, 280, 292, 293, 295, 297, 299, 300, 303, 304, 310, 321, 324, 327, 342, 346, 351, 364, 399, 401, 402, 455, 462, 463, 464, 465, 466, 467, 474, 475, 476, 477, 478, 480, 481], "item": [0, 2, 3, 8, 15, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 67, 68, 69, 73, 74, 77, 78, 79, 82, 83, 85, 86, 87, 88, 89, 94, 101, 107, 109, 113, 120, 177, 205, 226, 261, 270, 303, 304, 365, 366, 368, 428, 457, 458, 461, 463, 464, 468, 469, 474, 475, 476, 478], "navig": [0, 475], "previou": [0, 3, 4, 10, 55, 62, 67, 68, 69, 71, 78, 79, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 227, 255, 272, 293, 297, 320, 342, 463, 464, 465, 466, 467, 471, 476, 481], "whenev": [0, 1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 69, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 106, 107, 114, 115, 130, 131, 135, 137, 138, 148, 149, 162, 170, 171, 178, 179, 182, 202, 227, 231, 262, 268, 328, 330, 334, 379, 394, 399, 400, 401, 402, 417, 439, 456, 470, 478], "want": [0, 1, 2, 3, 6, 7, 8, 18, 29, 42, 65, 77, 115, 177, 212, 236, 315, 328, 330, 334, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 456, 461, 462, 463, 464, 465, 466, 468, 469, 470, 474, 475, 476, 477, 478, 480, 481], "ted": [0, 44, 56, 75, 76, 97, 98, 105, 453, 460, 472, 479], "s": [0, 1, 2, 3, 6, 7, 8, 11, 13, 15, 16, 17, 18, 21, 22, 23, 25, 27, 29, 35, 39, 42, 47, 50, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 82, 84, 95, 96, 109, 114, 115, 120, 126, 127, 128, 129, 132, 136, 140, 142, 143, 144, 148, 149, 151, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 216, 217, 230, 234, 240, 253, 255, 258, 259, 260, 261, 262, 265, 267, 269, 270, 272, 274, 277, 279, 280, 287, 292, 295, 299, 304, 305, 306, 309, 315, 317, 324, 326, 328, 330, 331, 334, 339, 341, 344, 346, 347, 350, 351, 354, 362, 363, 364, 369, 375, 377, 378, 379, 381, 384, 386, 394, 395, 396, 399, 400, 401, 402, 403, 417, 455, 456, 457, 460, 461, 462, 463, 464, 465, 466, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481], "modul": [0, 1, 2, 3, 4, 8, 11, 15, 16, 18, 21, 22, 23, 25, 27, 29, 32, 35, 41, 42, 47, 55, 65, 66, 71, 72, 77, 120, 126, 127, 128, 129, 132, 136, 144, 147, 150, 153, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 211, 216, 222, 224, 230, 232, 240, 241, 254, 255, 260, 261, 262, 265, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 392, 394, 396, 397, 399, 400, 401, 402, 403, 417, 437, 444, 447, 453, 457, 458, 460, 462, 463, 466, 468, 469, 470, 472, 473, 474, 475, 476, 477, 478, 479], "optim": [0, 1, 2, 8, 35, 42, 47, 55, 65, 66, 71, 72, 77, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 276, 302, 308, 309, 315, 324, 328, 330, 334, 362, 364, 379, 380, 381, 384, 391, 394, 396, 432, 433, 437, 447, 457, 458, 460, 463, 464, 465, 466, 467, 469, 472, 474, 475, 476, 479], "collect": [0, 1, 2, 3, 4, 8, 13, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 50, 55, 62, 67, 68, 69, 78, 79, 109, 113, 126, 129, 132, 136, 144, 156, 157, 160, 162, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 190, 209, 212, 227, 236, 240, 267, 316, 346, 362, 365, 368, 370, 382, 384, 386, 387, 419, 428, 434, 437, 439, 440, 441, 447, 455, 458, 460, 461, 464, 465, 466, 467, 468, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481], "storag": [0, 1, 8, 15, 16, 18, 21, 29, 35, 42, 44, 47, 50, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 79, 81, 84, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 109, 113, 114, 115, 117, 118, 119, 120, 122, 123, 126, 129, 132, 134, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 211, 212, 220, 223, 245, 272, 328, 330, 334, 363, 378, 381, 394, 395, 396, 453, 458, 460, 462, 463, 464, 465, 466, 468, 471, 472, 474, 475, 477, 479], "log": [0, 3, 4, 8, 11, 71, 287, 288, 289, 303, 304, 312, 324, 325, 330, 334, 343, 344, 347, 351, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 426, 430, 431, 432, 437, 447, 456, 457, 458, 460, 461, 462, 463, 466, 467, 471, 472, 474, 475, 476, 479, 480], "your": [0, 1, 2, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 29, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 140, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 328, 330, 334, 351, 394, 396, 427, 451, 453, 454, 455, 456, 457, 460, 462, 463, 464, 466, 467, 468, 469, 470, 472, 474, 475, 478, 479, 480], "own": [0, 1, 15, 16, 21, 27, 28, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 419, 453, 457, 460, 462, 463, 466, 472, 474, 475, 476, 479], "train": [0, 1, 2, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 32, 35, 38, 42, 47, 55, 61, 63, 65, 66, 70, 71, 72, 77, 83, 84, 94, 95, 96, 126, 129, 132, 136, 141, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 220, 228, 240, 254, 259, 262, 265, 267, 272, 274, 275, 277, 282, 284, 292, 316, 328, 330, 331, 332, 334, 361, 362, 363, 364, 365, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 437, 439, 447, 453, 455, 456, 458, 460, 462, 466, 469, 470, 472, 477, 478, 479, 480, 481], "loop": [0, 1, 8, 18, 29, 61, 63, 70, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 274, 292, 315, 316, 362, 364, 370, 377, 381, 382, 384, 386, 387, 395, 399, 400, 401, 402, 437, 457, 458, 460, 461, 462, 466, 468, 469, 470, 472, 473, 478, 479, 480], "ppo": [0, 1, 4, 8, 347, 351, 363, 378, 381, 394, 453, 456, 460, 461, 462, 465, 467, 468, 472, 474, 479], "pendulum": [0, 3, 15, 16, 18, 21, 27, 28, 29, 67, 120, 126, 129, 130, 131, 132, 133, 135, 136, 137, 144, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 215, 216, 218, 225, 231, 232, 236, 243, 245, 249, 250, 253, 255, 256, 257, 260, 261, 262, 263, 269, 270, 272, 278, 295, 299, 396, 447, 456, 460, 462, 463, 466, 467, 468, 472, 479, 480, 481], "introduct": [0, 457, 460, 466, 472, 474, 475, 479, 481], "multi": [0, 1, 7, 9, 15, 16, 21, 35, 42, 47, 55, 62, 65, 66, 69, 72, 73, 74, 77, 78, 79, 97, 98, 105, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 233, 262, 272, 293, 295, 297, 299, 300, 305, 306, 307, 328, 330, 334, 346, 351, 394, 396, 397, 399, 400, 401, 402, 453, 460, 461, 462, 463, 464, 466, 467, 472, 476, 479, 480], "agent": [0, 9, 68, 73, 74, 141, 147, 148, 149, 154, 155, 158, 159, 163, 164, 168, 169, 170, 171, 173, 233, 252, 253, 254, 303, 304, 305, 306, 307, 309, 317, 326, 363, 378, 381, 397, 453, 460, 466, 472, 476, 479], "env": [0, 1, 2, 5, 6, 7, 8, 11, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 35, 39, 42, 44, 47, 50, 55, 65, 66, 67, 71, 72, 75, 77, 84, 95, 109, 120, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 276, 278, 295, 299, 301, 302, 328, 330, 334, 346, 350, 379, 394, 396, 417, 418, 419, 427, 441, 442, 443, 447, 449, 450, 451, 453, 455, 456, 457, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 478, 479], "us": [0, 1, 2, 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 100, 101, 105, 106, 107, 108, 109, 114, 115, 120, 122, 126, 127, 128, 129, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 286, 288, 289, 290, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 312, 314, 315, 316, 317, 318, 324, 325, 326, 327, 328, 330, 331, 332, 334, 337, 338, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 407, 412, 417, 419, 422, 423, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 479, 481], "pretrain": [0, 460, 472, 479], "recurr": [0, 2, 211, 293, 294, 295, 297, 299, 320, 337, 399, 460, 462, 467, 472, 478, 479], "dqn": [0, 2, 205, 224, 280, 289, 343, 344, 361, 362, 364, 365, 366, 368, 370, 371, 372, 376, 377, 379, 381, 382, 383, 384, 385, 386, 387, 394, 397, 444, 453, 456, 460, 465, 467, 468, 471, 472, 479], "polici": [0, 3, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 44, 55, 67, 75, 126, 127, 128, 129, 132, 136, 144, 150, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 191, 201, 217, 222, 232, 234, 254, 257, 274, 277, 278, 289, 292, 295, 299, 305, 306, 309, 316, 318, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 354, 361, 362, 363, 364, 365, 369, 370, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 432, 439, 442, 443, 447, 449, 450, 453, 455, 456, 458, 460, 462, 466, 468, 469, 472, 477, 478, 479, 480, 481], "replai": [0, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 55, 62, 67, 68, 69, 78, 79, 106, 107, 108, 109, 110, 111, 113, 115, 116, 118, 120, 121, 125, 211, 212, 222, 241, 245, 255, 261, 272, 364, 365, 366, 368, 369, 370, 377, 382, 384, 386, 387, 396, 434, 437, 445, 447, 453, 455, 457, 458, 460, 465, 472, 476, 477, 479], "buffer": [0, 4, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 120, 121, 122, 125, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 211, 212, 216, 222, 230, 240, 241, 245, 255, 260, 261, 262, 265, 267, 272, 274, 316, 328, 330, 334, 342, 350, 353, 363, 364, 365, 366, 368, 369, 370, 377, 378, 381, 382, 384, 386, 387, 394, 395, 396, 399, 400, 401, 402, 403, 434, 437, 445, 447, 453, 455, 457, 458, 460, 465, 470, 472, 476, 477, 479, 481], "export": [0, 6, 7, 460, 472, 479], "competit": [0, 3, 148, 149, 460, 472, 475, 479], "ddpg": [0, 282, 283, 284, 285, 365, 376, 385, 453, 456, 460, 462, 468, 472, 475, 479], "task": [0, 2, 3, 9, 71, 73, 74, 83, 126, 129, 130, 131, 132, 136, 139, 144, 148, 149, 156, 157, 158, 159, 160, 162, 165, 166, 167, 170, 171, 177, 178, 179, 182, 184, 185, 186, 187, 189, 240, 253, 262, 265, 267, 369, 377, 455, 460, 461, 462, 463, 464, 466, 467, 472, 474, 475, 476, 479, 481], "specif": [0, 1, 2, 5, 8, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 154, 155, 156, 157, 160, 165, 166, 167, 170, 177, 178, 179, 182, 185, 186, 187, 190, 200, 234, 255, 270, 286, 295, 299, 342, 361, 379, 381, 383, 394, 419, 437, 453, 455, 457, 458, 460, 463, 464, 466, 467, 468, 469, 470, 471, 472, 474, 475, 478, 479, 480], "object": [0, 2, 3, 4, 6, 7, 15, 16, 17, 18, 21, 22, 23, 25, 27, 29, 32, 35, 39, 42, 47, 55, 57, 61, 63, 65, 66, 70, 72, 77, 82, 83, 84, 95, 96, 100, 101, 102, 103, 109, 112, 116, 118, 122, 125, 126, 129, 132, 136, 142, 144, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 220, 223, 224, 230, 233, 236, 240, 260, 261, 262, 265, 269, 270, 272, 295, 299, 302, 305, 306, 317, 324, 326, 328, 330, 334, 338, 339, 347, 350, 351, 352, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 441, 442, 443, 446, 447, 451, 453, 456, 458, 460, 462, 463, 464, 465, 469, 471, 472, 474, 475, 476, 478, 479, 481], "loss": [0, 3, 8, 63, 224, 303, 315, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 394, 397, 398, 399, 433, 437, 444, 447, 455, 457, 458, 460, 465, 466, 468, 469, 470, 472, 476, 478, 479], "trainer": [0, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 460, 461, 472, 479], "exampl": [0, 1, 2, 4, 9, 10, 15, 16, 18, 21, 22, 27, 28, 29, 31, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 83, 84, 85, 94, 95, 96, 100, 101, 102, 106, 107, 109, 114, 115, 120, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 198, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 228, 230, 231, 232, 233, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 272, 273, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 291, 292, 293, 294, 295, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 312, 314, 315, 316, 317, 318, 326, 327, 328, 330, 331, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 388, 389, 394, 395, 396, 397, 399, 400, 401, 402, 405, 417, 419, 427, 428, 429, 430, 431, 433, 434, 435, 436, 439, 447, 453, 455, 456, 457, 458, 460, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481], "packag": [0, 6, 7, 10, 202, 453, 454, 481], "batch": [0, 2, 15, 16, 17, 18, 21, 22, 23, 25, 27, 29, 31, 39, 55, 57, 59, 62, 64, 67, 68, 69, 71, 78, 79, 80, 82, 94, 100, 101, 102, 103, 107, 108, 109, 113, 114, 115, 120, 122, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 150, 151, 153, 154, 155, 156, 157, 160, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 209, 212, 216, 218, 227, 234, 236, 238, 241, 245, 252, 255, 257, 261, 262, 264, 268, 269, 270, 272, 275, 287, 293, 294, 295, 297, 298, 299, 303, 304, 305, 306, 307, 308, 312, 316, 317, 323, 327, 330, 334, 337, 346, 350, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 428, 431, 434, 435, 436, 437, 439, 449, 450, 451, 453, 456, 457, 458, 462, 463, 464, 465, 466, 469, 471, 473, 474, 475, 477, 480, 481], "size": [0, 2, 15, 16, 18, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 103, 106, 107, 108, 109, 113, 114, 115, 116, 122, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 203, 205, 209, 211, 212, 213, 216, 219, 220, 223, 224, 225, 227, 230, 233, 234, 238, 240, 242, 243, 245, 249, 251, 252, 253, 255, 257, 258, 261, 262, 263, 264, 267, 269, 272, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 299, 300, 302, 303, 304, 305, 306, 312, 313, 314, 315, 316, 317, 318, 319, 320, 323, 326, 327, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 353, 355, 358, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 419, 428, 434, 453, 456, 457, 462, 463, 464, 465, 466, 467, 469, 474, 475, 476, 481], "copi": [0, 2, 3, 14, 17, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 42, 43, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 71, 72, 73, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 100, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 208, 212, 230, 243, 254, 260, 261, 262, 269, 270, 272, 273, 295, 299, 307, 328, 330, 334, 342, 364, 379, 384, 394, 395, 396, 399, 417, 453, 457, 461, 462, 464, 466, 474, 478, 480], "weight": [0, 4, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 35, 42, 47, 55, 62, 65, 66, 71, 72, 77, 107, 109, 112, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 230, 233, 240, 255, 260, 261, 262, 265, 267, 272, 293, 294, 295, 297, 298, 299, 305, 307, 309, 328, 330, 331, 333, 334, 350, 361, 362, 363, 364, 370, 373, 384, 386, 394, 396, 439, 446, 453, 455, 456, 458, 461, 462, 463, 473, 476, 478, 480], "synchron": [0, 3, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 61, 63, 70, 84, 95, 96, 151, 183, 395, 449, 450, 453, 462, 463, 474], "distribut": [0, 2, 3, 4, 9, 10, 14, 17, 20, 22, 23, 24, 25, 26, 27, 28, 62, 67, 68, 69, 78, 79, 109, 129, 158, 159, 191, 232, 236, 270, 274, 276, 287, 288, 289, 290, 296, 302, 303, 304, 312, 313, 314, 315, 319, 320, 323, 324, 325, 332, 342, 343, 344, 347, 351, 352, 361, 362, 363, 364, 369, 370, 371, 377, 378, 381, 382, 383, 384, 386, 387, 394, 453, 457, 458, 462, 463, 465, 467, 469, 474, 475, 476, 480, 481], "interoper": [0, 15, 16, 453], "run": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 27, 29, 35, 42, 47, 55, 65, 66, 67, 72, 77, 107, 114, 115, 126, 127, 128, 129, 130, 131, 132, 135, 136, 142, 143, 144, 150, 151, 152, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 230, 235, 236, 252, 260, 261, 262, 269, 272, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 351, 352, 353, 354, 357, 364, 370, 384, 394, 396, 419, 426, 432, 449, 450, 451, 453, 454, 455, 456, 457, 458, 461, 462, 463, 464, 467, 468, 469, 470, 471, 474, 475, 476, 480], "asynchron": [0, 3, 9, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 361, 394, 395, 396, 449, 453, 461, 462, 463], "singl": [0, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 39, 40, 42, 45, 47, 48, 50, 53, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 77, 78, 79, 80, 84, 95, 96, 101, 109, 115, 120, 126, 129, 132, 135, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 205, 212, 213, 233, 240, 245, 255, 260, 262, 267, 272, 279, 280, 293, 294, 295, 297, 298, 299, 300, 306, 328, 330, 334, 349, 353, 362, 363, 364, 366, 368, 370, 371, 377, 378, 381, 382, 384, 386, 387, 391, 394, 395, 396, 399, 400, 401, 402, 408, 409, 410, 411, 413, 414, 415, 416, 417, 451, 453, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 473, 474, 475, 476, 477, 478, 480], "node": [0, 2, 20, 22, 23, 25, 27, 28, 39, 40, 48, 50, 61, 63, 70, 74, 84, 95, 96, 144, 183, 186, 260, 332, 395, 453, 469, 480], "helper": [0, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 461, 462, 464, 474, 476], "compos": [0, 3, 35, 42, 47, 55, 62, 65, 66, 69, 72, 77, 78, 79, 108, 109, 110, 111, 120, 121, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 217, 218, 230, 244, 260, 261, 262, 269, 272, 328, 330, 334, 345, 346, 364, 373, 384, 394, 396, 419, 453, 461, 462, 463, 464, 465, 469, 473, 475, 477, 478, 480, 481], "episod": [0, 3, 50, 107, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 208, 245, 248, 254, 276, 399, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 453, 462, 466, 471, 474, 475, 478], "format": [0, 1, 3, 35, 42, 44, 47, 53, 54, 55, 56, 59, 60, 65, 66, 72, 75, 76, 77, 84, 95, 97, 98, 105, 112, 120, 126, 129, 132, 136, 144, 156, 157, 158, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 212, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396, 419, 453, 455, 461, 462, 465, 466, 468, 470, 480, 481], "tensorspec": [0, 3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 85, 86, 87, 88, 89, 90, 91, 92, 126, 129, 132, 136, 144, 150, 156, 157, 160, 161, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 205, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 227, 229, 231, 232, 233, 234, 236, 238, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 274, 292, 316, 320, 338, 342, 343, 344, 347, 348, 349, 350, 351, 352, 354, 362, 364, 366, 369, 370, 382, 384, 386, 387, 396, 397, 453, 476], "tree": [0, 1, 50, 61, 63, 70, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 212, 395, 453, 474, 478], "forest": [0, 50, 84, 453], "larg": [0, 3, 4, 38, 61, 63, 70, 84, 95, 96, 114, 115, 183, 220, 223, 265, 361, 363, 378, 381, 383, 394, 395, 453, 462, 463, 474, 475, 478], "languag": [0, 32, 71, 185, 453], "human": [0, 32, 178, 453, 476], "feedback": [0, 178, 453, 471, 480], "rlhf": [0, 178, 191, 232, 453, 456], "spec": [0, 1, 2, 15, 16, 18, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 126, 127, 128, 129, 132, 134, 135, 136, 137, 138, 141, 142, 143, 144, 150, 151, 152, 154, 155, 156, 157, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 200, 203, 204, 205, 206, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221, 222, 223, 224, 225, 227, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 274, 289, 292, 295, 299, 316, 318, 320, 338, 342, 343, 344, 347, 348, 349, 350, 351, 353, 354, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 396, 397, 453, 456, 457, 461, 462, 463, 464, 465, 466, 467, 471, 473, 474, 475, 480], "lock": [0, 39, 40, 48, 61, 63, 70, 74, 84, 95, 96, 126, 129, 132, 136, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 209, 218, 255, 269, 270, 395, 453, 457, 476], "method": [0, 1, 2, 4, 13, 15, 16, 18, 20, 21, 22, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 103, 106, 107, 109, 114, 115, 116, 117, 118, 120, 122, 126, 129, 132, 135, 136, 137, 138, 143, 144, 156, 157, 160, 161, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 224, 225, 226, 227, 228, 231, 232, 234, 236, 239, 240, 241, 242, 243, 244, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 272, 273, 274, 276, 277, 278, 287, 292, 295, 299, 305, 306, 307, 328, 330, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 352, 358, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 375, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 403, 417, 418, 448, 453, 457, 458, 459, 462, 463, 464, 465, 466, 467, 468, 469, 470, 474, 476, 478, 481], "partial": [0, 2, 15, 16, 18, 21, 29, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 211, 212, 254, 255, 256, 347, 437, 453, 464], "step": [0, 1, 4, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 42, 50, 55, 71, 84, 97, 98, 105, 107, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 203, 204, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 227, 228, 231, 232, 234, 236, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 272, 274, 275, 276, 290, 292, 293, 295, 297, 299, 301, 302, 315, 316, 346, 347, 351, 361, 372, 381, 396, 398, 399, 400, 401, 402, 405, 406, 407, 418, 421, 428, 432, 437, 453, 455, 458, 462, 464, 465, 467, 468, 470, 471, 473, 476, 477, 480], "reset": [0, 1, 2, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 50, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 109, 115, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 207, 208, 209, 212, 224, 227, 231, 235, 240, 248, 253, 254, 255, 256, 257, 260, 261, 262, 265, 268, 269, 272, 273, 278, 293, 295, 299, 307, 316, 328, 330, 334, 336, 346, 379, 394, 396, 418, 453, 455, 457, 461, 462, 463, 464, 466, 469, 473, 474, 475, 480], "vector": [0, 1, 8, 33, 59, 127, 128, 137, 142, 143, 147, 158, 159, 162, 170, 171, 222, 268, 270, 282, 284, 293, 294, 297, 298, 300, 399, 402, 412, 413, 414, 415, 416, 453, 456, 457, 461, 462, 464, 473, 474, 475, 476, 477, 481], "async": [0, 15, 16, 18, 21, 22, 23, 25, 27, 29, 67, 126, 160, 166, 268, 453, 455], "custom": [0, 1, 2, 5, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 35, 42, 47, 55, 65, 66, 72, 77, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 265, 272, 305, 306, 328, 330, 334, 354, 360, 371, 381, 388, 394, 396, 451, 453, 455, 456, 461, 462, 463, 464, 467, 468, 470, 474, 475], "nativ": [0, 1, 7, 9, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 419, 453, 464, 478], "auto": [0, 102, 122, 132, 137, 207, 208, 262, 268, 316, 362, 364, 370, 380, 382, 384, 386, 387, 453, 457, 474, 475], "dynam": [0, 2, 7, 15, 16, 18, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 197, 272, 369, 377, 453, 463, 466, 476], "mask": [0, 1, 4, 31, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 206, 241, 272, 277, 278, 289, 292, 303, 304, 318, 330, 334, 342, 343, 344, 348, 349, 370, 384, 434, 453, 462, 464, 465, 481], "action": [0, 2, 8, 9, 15, 16, 18, 21, 27, 29, 44, 50, 59, 67, 71, 75, 77, 84, 106, 107, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 203, 205, 206, 209, 215, 216, 217, 220, 221, 222, 223, 224, 225, 227, 228, 230, 232, 234, 235, 236, 238, 242, 243, 245, 249, 253, 255, 259, 261, 262, 263, 264, 268, 272, 274, 276, 278, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 292, 295, 299, 300, 301, 302, 303, 304, 305, 314, 316, 317, 318, 320, 323, 324, 326, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 351, 354, 355, 361, 362, 363, 364, 365, 366, 368, 369, 370, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 447, 451, 453, 455, 456, 458, 461, 462, 463, 465, 466, 467, 468, 473, 474, 475, 477, 480, 481], "record": [0, 2, 11, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 198, 205, 232, 272, 328, 330, 334, 381, 394, 396, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 432, 447, 453, 462, 463, 467, 471, 474], "domain": [0, 2, 8, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 95, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 222, 230, 255, 263, 338, 343, 344, 347, 348, 349, 350, 351, 352, 353, 358, 453, 463, 468, 474, 475, 476, 480, 481], "llm": [0, 2, 29, 30, 71, 83, 94, 95, 96, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 328, 329, 330, 331, 332, 333, 334, 394, 395, 396, 453], "interfac": [0, 1, 3, 126, 139, 153, 300, 308, 330, 334, 453, 456, 457, 461, 463, 465, 470, 476, 478], "structur": [0, 1, 3, 7, 50, 57, 61, 62, 63, 69, 70, 71, 78, 79, 82, 83, 84, 95, 96, 101, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 184, 185, 186, 187, 190, 204, 220, 223, 255, 305, 316, 330, 334, 361, 370, 381, 384, 395, 399, 400, 401, 402, 403, 453, 457, 461, 463, 464, 466, 469, 474, 475, 476, 477], "actor": [0, 3, 4, 27, 30, 161, 191, 232, 276, 281, 282, 284, 289, 290, 292, 302, 314, 316, 318, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 394, 397, 453, 457, 462, 464, 466, 468, 471, 474, 477, 480], "explor": [0, 1, 271, 274, 277, 292, 309, 316, 338, 343, 344, 347, 348, 349, 350, 351, 361, 379, 432, 442, 443, 447, 453, 463, 464, 465, 466, 468, 469, 471, 474, 475, 476], "valu": [0, 1, 2, 3, 8, 15, 16, 18, 21, 22, 23, 25, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 106, 107, 109, 114, 115, 120, 126, 129, 132, 136, 137, 144, 147, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 202, 203, 204, 205, 208, 210, 212, 213, 215, 218, 220, 221, 222, 223, 224, 230, 235, 236, 240, 241, 244, 245, 246, 248, 250, 252, 255, 256, 260, 261, 262, 267, 268, 269, 270, 272, 273, 274, 275, 278, 282, 283, 284, 285, 287, 288, 289, 290, 291, 292, 295, 296, 299, 300, 302, 303, 304, 305, 306, 308, 309, 312, 316, 317, 318, 323, 324, 325, 326, 328, 330, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 351, 354, 355, 357, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 389, 390, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 427, 428, 430, 431, 432, 433, 434, 437, 447, 453, 458, 462, 465, 468, 469, 470, 473, 474, 475, 476, 478, 480, 481], "gener": [0, 1, 2, 3, 7, 8, 9, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 62, 65, 69, 71, 73, 74, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 109, 111, 113, 126, 129, 132, 133, 136, 144, 148, 149, 150, 153, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 209, 216, 218, 220, 221, 225, 230, 232, 234, 236, 242, 243, 248, 249, 253, 255, 259, 261, 263, 268, 270, 272, 277, 278, 287, 295, 299, 303, 304, 312, 330, 334, 338, 347, 351, 355, 356, 375, 382, 389, 396, 399, 404, 412, 422, 437, 453, 457, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "hook": [0, 2, 35, 42, 44, 47, 55, 62, 65, 66, 67, 68, 69, 72, 75, 77, 78, 79, 109, 123, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 318, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 394, 396, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 453], "planner": [0, 276, 302, 453], "torch": [0, 1, 2, 3, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 106, 107, 109, 110, 113, 114, 115, 120, 121, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 203, 204, 205, 206, 208, 209, 210, 211, 213, 216, 217, 218, 220, 221, 222, 223, 224, 225, 230, 232, 233, 236, 238, 240, 242, 243, 245, 247, 248, 249, 250, 252, 253, 254, 255, 256, 258, 261, 262, 263, 265, 267, 269, 270, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 308, 309, 312, 313, 314, 315, 316, 317, 318, 323, 324, 325, 326, 327, 328, 330, 331, 332, 334, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 359, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 421, 428, 435, 436, 447, 453, 456, 458, 461, 462, 463, 464, 465, 467, 468, 469, 471, 473, 474, 475, 476, 477, 478, 480, 481], "vmap": [0, 293, 294, 297, 298, 307, 327, 350, 353, 362, 364, 370, 377, 379, 382, 384, 386, 387, 394, 399, 400, 401, 402, 453, 456], "random": [0, 1, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 66, 71, 73, 74, 82, 85, 86, 87, 88, 89, 108, 120, 126, 129, 132, 136, 144, 150, 156, 157, 160, 161, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 190, 205, 222, 235, 236, 255, 262, 278, 292, 293, 295, 297, 347, 350, 351, 358, 362, 379, 382, 394, 432, 441, 453, 456, 461, 462, 463, 465, 466, 467, 469, 476, 477, 478, 480, 481], "sac": [0, 370, 382, 384, 453], "redq": [0, 382, 453], "crossq": [0, 364, 453], "iql": [0, 369, 377, 453, 461, 474, 475], "cql": [0, 362, 368, 453], "gail": [0, 375, 453], "dt": [0, 157, 316, 453, 476], "td3": [0, 386, 387, 453], "bc": [0, 5, 386, 453], "a2c": [0, 361, 453], "dreamer": [0, 198, 199, 290, 372, 373, 374, 453, 456], "checkpoint": [0, 69, 98, 100, 104, 116, 117, 119, 123, 453, 478], "builder": [0, 184, 188, 453, 462, 481], "logger": [0, 3, 11, 417, 419, 421, 422, 423, 424, 425, 426, 431, 437, 447, 451, 453, 462, 474], "_util": [0, 3, 156, 273, 453, 465, 471], "implement_for": [0, 3, 453], "set_auto_unwrap_transformed_env": [0, 12, 262, 453], "auto_unwrap_transformed_env": [0, 427, 453], "thing": [0, 1, 3, 7, 8, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 261, 305, 306, 370, 384, 454, 463, 464, 465, 466, 467, 468, 469, 470, 474, 475, 478, 481], "consid": [0, 1, 2, 3, 8, 14, 15, 16, 17, 18, 22, 24, 25, 26, 27, 29, 35, 39, 40, 42, 47, 48, 55, 62, 65, 66, 69, 72, 74, 77, 78, 79, 100, 102, 114, 115, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 222, 269, 272, 287, 305, 306, 323, 328, 330, 334, 362, 364, 377, 382, 384, 386, 387, 394, 396, 399, 401, 402, 454, 457, 461, 466, 467, 468, 476, 478], "when": [0, 1, 2, 3, 5, 8, 13, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 109, 113, 114, 115, 116, 118, 122, 126, 129, 132, 133, 135, 136, 137, 143, 144, 147, 148, 149, 151, 153, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 203, 206, 208, 211, 212, 216, 217, 220, 222, 223, 232, 233, 235, 236, 240, 241, 248, 255, 257, 260, 261, 262, 265, 267, 268, 269, 270, 272, 273, 275, 276, 287, 289, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 315, 318, 324, 328, 330, 334, 346, 347, 350, 351, 353, 357, 362, 363, 364, 366, 370, 371, 377, 378, 379, 381, 382, 384, 386, 387, 388, 394, 396, 397, 398, 399, 400, 401, 402, 417, 418, 419, 421, 424, 426, 434, 451, 454, 455, 456, 457, 458, 461, 462, 463, 464, 465, 467, 469, 470, 474, 475, 476, 477, 478, 480, 481], "debug": [0, 6, 8, 50, 71, 84, 257, 454, 481], "work": [0, 1, 2, 3, 4, 8, 24, 26, 35, 42, 47, 55, 65, 66, 69, 72, 77, 100, 107, 112, 114, 115, 118, 125, 126, 129, 132, 135, 136, 137, 140, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 203, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 270, 272, 273, 279, 280, 300, 328, 330, 334, 344, 349, 354, 363, 378, 381, 394, 396, 437, 454, 455, 456, 461, 462, 463, 464, 466, 469, 473, 474, 475, 476, 477, 478, 480, 481], "habitat": [0, 3, 138, 454, 477], "lab": [0, 3, 130, 131, 138, 141, 454], "mujoco": [0, 6, 8, 162, 454, 461, 463, 464], "error": [0, 1, 3, 7, 10, 33, 34, 35, 38, 42, 43, 47, 51, 52, 53, 54, 55, 59, 60, 61, 63, 65, 66, 70, 72, 73, 77, 84, 95, 96, 100, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 168, 172, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 241, 260, 272, 273, 328, 330, 334, 379, 394, 395, 396, 454, 457, 461, 463, 474, 475, 481], "solut": [0, 2, 3, 6, 7, 9, 27, 114, 454, 456, 458, 465, 480], "resourc": [0, 1, 13, 22, 23, 25, 27, 138, 454, 455, 461, 463, 465, 474, 475], "issu": [0, 2, 3, 4, 5, 8, 67, 98, 100, 102, 114, 122, 126, 129, 132, 135, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 212, 241, 256, 338, 343, 344, 347, 348, 349, 350, 351, 454, 480], "customis": [0, 454, 462, 470], "video": [0, 4, 9, 419, 421, 424, 426, 432, 451, 453, 454, 471, 474, 475], "render": [0, 3, 8, 143, 170, 417, 419, 432, 454, 461, 462, 463, 465, 466, 470], "index": [0, 3, 7, 8, 10, 18, 29, 33, 34, 36, 37, 38, 39, 40, 43, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 99, 100, 101, 102, 106, 107, 109, 110, 112, 114, 118, 120, 121, 122, 124, 125, 126, 129, 132, 136, 144, 148, 149, 154, 155, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 183, 185, 186, 187, 203, 207, 212, 216, 222, 262, 303, 304, 346, 395, 453, 466, 473, 474, 475, 478, 480], "search": [0, 2, 39, 40, 48, 74, 84, 153, 204, 462], "page": [0, 7, 32, 426, 468], "import": [1, 2, 3, 4, 6, 10, 11, 15, 16, 18, 21, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 106, 107, 109, 114, 115, 120, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 146, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 202, 203, 204, 205, 206, 208, 209, 211, 212, 215, 217, 218, 224, 225, 230, 231, 232, 233, 236, 238, 240, 242, 243, 244, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 260, 261, 263, 267, 269, 270, 272, 273, 276, 278, 282, 283, 284, 285, 288, 289, 291, 292, 293, 294, 295, 297, 298, 299, 300, 302, 305, 306, 307, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 417, 419, 430, 432, 447, 455, 456, 457, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "syncdatacollector": [1, 2, 3, 15, 16, 19, 21, 22, 23, 25, 27, 29, 44, 55, 75, 209, 212, 245, 277, 295, 299, 447, 450, 453, 461, 462, 463, 464, 465, 469, 471, 474, 475, 478], "currentmodul": 1, "somewhat": [1, 2, 190, 457, 467, 481], "equival": [1, 3, 27, 33, 34, 35, 38, 39, 42, 43, 47, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 77, 78, 79, 83, 84, 94, 95, 96, 126, 127, 128, 129, 132, 135, 136, 137, 138, 141, 142, 143, 144, 151, 152, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 221, 224, 255, 257, 262, 272, 289, 297, 300, 318, 328, 330, 334, 343, 344, 348, 349, 381, 394, 395, 396, 434, 469, 480, 481], "dataload": [1, 29, 94, 113, 115, 185, 190, 462, 469, 478], "except": [1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 28, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 226, 245, 254, 255, 256, 260, 262, 272, 274, 292, 293, 295, 297, 299, 312, 316, 328, 330, 334, 361, 364, 379, 381, 384, 394, 395, 396, 419, 456, 461, 462, 466, 474, 478, 480, 481], "1": [1, 2, 3, 4, 8, 10, 15, 16, 18, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 100, 101, 102, 106, 107, 109, 114, 115, 120, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 142, 143, 144, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 197, 203, 205, 206, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 228, 230, 232, 233, 234, 236, 238, 240, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 265, 267, 269, 270, 272, 273, 274, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 308, 309, 312, 314, 315, 316, 317, 319, 320, 322, 323, 324, 325, 326, 328, 330, 333, 334, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 357, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 373, 377, 378, 380, 381, 382, 383, 384, 385, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 405, 407, 408, 409, 413, 414, 416, 417, 419, 428, 432, 434, 435, 447, 451, 454, 455, 456, 457, 458, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481], "thei": [1, 2, 3, 4, 8, 9, 15, 16, 18, 20, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 107, 109, 126, 129, 132, 135, 136, 137, 144, 147, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 211, 226, 232, 240, 249, 257, 261, 262, 267, 272, 299, 328, 330, 334, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 434, 437, 456, 457, 458, 461, 462, 463, 464, 465, 468, 473, 474, 475, 476, 477, 478, 480, 481], "over": [1, 2, 3, 4, 8, 15, 16, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 72, 73, 74, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 89, 93, 107, 109, 113, 114, 115, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 205, 222, 236, 248, 256, 270, 272, 312, 315, 324, 327, 328, 330, 334, 353, 371, 373, 379, 394, 396, 399, 405, 417, 440, 456, 458, 461, 462, 463, 465, 466, 467, 468, 469, 474, 475, 476, 481], "non": [1, 2, 3, 8, 15, 16, 18, 21, 22, 23, 25, 27, 33, 35, 36, 37, 39, 40, 42, 47, 48, 49, 55, 57, 58, 61, 62, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 101, 103, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 209, 210, 212, 216, 227, 240, 252, 255, 261, 262, 263, 264, 265, 267, 270, 272, 278, 293, 295, 297, 299, 305, 328, 330, 334, 350, 351, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 456, 461, 464, 465, 474, 475, 476, 478, 481], "static": [1, 42, 65, 71, 77, 83, 107, 114, 115, 138, 157, 181, 187, 269, 273, 328, 330, 334, 377, 394, 466, 476, 478], "like": [1, 2, 3, 4, 7, 11, 24, 27, 35, 39, 40, 42, 47, 48, 50, 55, 57, 62, 65, 66, 69, 72, 74, 77, 78, 79, 83, 103, 109, 115, 126, 129, 132, 133, 136, 138, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 224, 255, 258, 272, 293, 297, 306, 328, 330, 334, 345, 351, 361, 363, 378, 381, 382, 383, 394, 396, 456, 457, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 480, 481], "being": [1, 2, 3, 7, 8, 15, 16, 18, 20, 21, 22, 23, 25, 26, 27, 35, 42, 47, 55, 65, 66, 72, 73, 77, 94, 101, 120, 123, 126, 129, 132, 135, 136, 137, 138, 143, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 211, 220, 222, 223, 230, 235, 243, 255, 260, 261, 262, 272, 292, 295, 299, 316, 328, 330, 334, 363, 364, 378, 379, 381, 384, 394, 396, 419, 434, 439, 449, 450, 451, 456, 457, 461, 462, 463, 464, 469, 474, 475, 476, 478], "accept": [1, 2, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 35, 42, 47, 55, 61, 63, 65, 66, 69, 70, 72, 77, 84, 85, 94, 95, 96, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 207, 212, 216, 227, 230, 240, 248, 252, 255, 260, 261, 262, 263, 264, 265, 267, 272, 300, 327, 328, 330, 334, 350, 351, 352, 364, 384, 394, 395, 396, 419, 458, 463, 466, 470, 478, 480, 481], "two": [1, 2, 3, 4, 8, 10, 35, 42, 47, 50, 51, 52, 53, 54, 55, 62, 65, 66, 69, 71, 72, 77, 78, 79, 84, 109, 113, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 217, 236, 240, 260, 267, 272, 285, 293, 295, 297, 299, 305, 306, 321, 324, 328, 330, 334, 351, 378, 386, 390, 394, 396, 432, 437, 457, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 478, 480, 481], "main": [1, 2, 3, 5, 15, 16, 20, 25, 28, 31, 67, 133, 212, 217, 351, 437, 455, 456, 457, 461, 462, 473, 480, 481], "argument": [1, 2, 3, 11, 14, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 100, 101, 102, 106, 107, 109, 112, 113, 114, 115, 118, 120, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 151, 152, 154, 155, 156, 157, 158, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 203, 205, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 221, 224, 225, 226, 228, 230, 231, 232, 234, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 278, 279, 280, 292, 293, 295, 297, 299, 300, 303, 304, 305, 306, 308, 316, 327, 328, 330, 331, 334, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 355, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 375, 376, 377, 378, 380, 381, 382, 383, 384, 386, 387, 389, 394, 395, 396, 397, 399, 400, 401, 402, 403, 407, 417, 418, 419, 424, 426, 430, 437, 440, 447, 448, 451, 461, 462, 463, 464, 465, 466, 467, 469, 474, 475, 476, 478, 480, 481], "list": [1, 2, 3, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 91, 95, 96, 101, 103, 109, 112, 113, 114, 115, 116, 118, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 173, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 203, 210, 211, 215, 220, 221, 223, 232, 233, 236, 238, 240, 248, 250, 258, 259, 260, 261, 262, 264, 265, 267, 269, 272, 278, 279, 280, 282, 288, 291, 295, 299, 300, 303, 304, 310, 318, 328, 330, 331, 334, 344, 346, 348, 349, 351, 353, 354, 355, 362, 364, 377, 379, 382, 384, 386, 387, 393, 394, 396, 399, 402, 417, 418, 432, 434, 449, 450, 457, 461, 463, 466, 467, 468, 469, 473, 474, 476, 477, 478, 480, 481], "constructor": [1, 2, 3, 15, 16, 18, 22, 23, 25, 27, 29, 67, 69, 78, 79, 83, 106, 120, 126, 129, 132, 136, 144, 151, 156, 157, 160, 165, 166, 167, 170, 177, 178, 179, 182, 184, 185, 186, 187, 208, 212, 260, 279, 280, 300, 337, 347, 351, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 399, 400, 401, 402, 403, 448, 451, 456, 461, 462, 463, 466, 469, 474, 475, 478, 480], "iter": [1, 2, 3, 16, 18, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 93, 94, 103, 109, 113, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 225, 236, 249, 272, 273, 275, 277, 278, 279, 280, 300, 305, 306, 322, 328, 330, 334, 338, 343, 347, 348, 350, 352, 353, 355, 379, 393, 394, 396, 432, 436, 437, 457, 458, 461, 463, 464, 469, 471, 474, 475, 476], "execut": [1, 2, 3, 6, 7, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 64, 66, 67, 68, 69, 72, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 100, 101, 109, 114, 115, 126, 127, 128, 129, 132, 133, 136, 137, 138, 140, 142, 143, 144, 150, 151, 156, 157, 160, 162, 165, 166, 167, 168, 177, 178, 179, 182, 185, 186, 187, 192, 206, 217, 218, 234, 257, 262, 292, 293, 295, 297, 299, 307, 337, 346, 352, 353, 379, 386, 394, 396, 441, 451, 455, 456, 457, 458, 460, 462, 463, 464, 465, 466, 467, 468, 469, 470, 474, 475, 478, 479, 480, 481], "queri": [1, 2, 3, 15, 35, 42, 47, 50, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 101, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 240, 265, 269, 272, 328, 330, 334, 353, 394, 395, 396, 457, 461, 468, 476, 480], "defin": [1, 2, 3, 15, 16, 18, 20, 21, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 67, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 241, 254, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 307, 310, 311, 314, 315, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 358, 366, 368, 379, 394, 396, 399, 400, 401, 402, 403, 418, 448, 456, 461, 462, 464, 468, 471, 476, 478, 481], "number": [1, 2, 3, 8, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 103, 106, 107, 109, 112, 114, 115, 122, 126, 127, 128, 129, 132, 135, 136, 137, 142, 143, 144, 150, 151, 152, 153, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 222, 224, 225, 226, 228, 231, 232, 235, 236, 239, 241, 242, 243, 245, 247, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 272, 274, 275, 276, 279, 280, 287, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 305, 306, 310, 311, 316, 317, 319, 320, 323, 324, 325, 326, 328, 330, 332, 334, 338, 342, 346, 347, 350, 351, 355, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 424, 426, 428, 430, 432, 437, 439, 440, 441, 449, 450, 451, 455, 456, 457, 461, 462, 463, 464, 466, 467, 469, 471, 474, 475, 476, 477, 478, 481], "befor": [1, 2, 3, 4, 6, 7, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 33, 34, 35, 38, 42, 43, 47, 50, 51, 52, 55, 65, 66, 72, 77, 83, 84, 113, 115, 120, 126, 129, 132, 136, 137, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 209, 210, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 227, 229, 230, 231, 232, 233, 234, 235, 236, 238, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 268, 269, 270, 272, 277, 293, 295, 299, 300, 308, 309, 328, 330, 334, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 400, 401, 402, 434, 455, 461, 463, 464, 465, 469, 470, 474, 475, 476, 478, 481], "deliv": [1, 2, 3, 18, 190, 461, 462, 466, 469, 480], "stack": [1, 2, 3, 7, 8, 15, 16, 18, 22, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 92, 95, 96, 101, 106, 109, 126, 129, 132, 135, 136, 137, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 190, 195, 196, 212, 217, 234, 269, 293, 295, 297, 298, 299, 346, 352, 353, 362, 364, 377, 382, 384, 386, 387, 395, 399, 418, 428, 453, 455, 462, 465, 466, 473, 474, 476, 480], "user": [1, 2, 3, 5, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 35, 42, 47, 50, 55, 65, 66, 72, 77, 84, 95, 107, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 168, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 213, 230, 254, 260, 262, 272, 286, 328, 330, 334, 364, 381, 384, 386, 394, 396, 419, 448, 455, 457, 458, 461, 462, 466, 468, 469, 476, 480, 481], "reach": [1, 3, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 71, 113, 126, 129, 132, 136, 143, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 234, 253, 274, 292, 316, 461, 463, 471, 474, 475, 480, 481], "done": [1, 2, 3, 4, 7, 8, 13, 15, 16, 18, 21, 22, 23, 25, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 88, 89, 97, 98, 105, 107, 109, 114, 115, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 205, 206, 208, 209, 212, 220, 221, 223, 224, 225, 230, 234, 235, 236, 238, 242, 243, 245, 247, 249, 252, 253, 255, 256, 259, 260, 261, 262, 263, 269, 272, 276, 293, 295, 299, 302, 324, 346, 361, 362, 363, 364, 365, 366, 368, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 456, 457, 461, 463, 464, 465, 466, 468, 469, 471, 473, 474, 475, 476, 478, 480, 481], "state": [1, 2, 3, 4, 15, 16, 18, 20, 21, 29, 35, 42, 44, 47, 50, 55, 62, 65, 66, 67, 68, 69, 71, 72, 75, 77, 78, 79, 84, 97, 98, 105, 109, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 150, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 208, 211, 212, 213, 215, 216, 218, 221, 224, 227, 230, 234, 236, 243, 253, 254, 259, 260, 261, 262, 263, 264, 269, 270, 272, 276, 281, 286, 290, 293, 294, 295, 297, 298, 299, 300, 302, 307, 310, 314, 317, 319, 320, 326, 328, 330, 334, 339, 346, 350, 356, 361, 363, 364, 368, 370, 378, 379, 381, 382, 383, 384, 394, 396, 397, 398, 399, 400, 401, 402, 403, 437, 451, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 474, 475, 476, 481], "after": [1, 2, 3, 8, 13, 15, 16, 21, 22, 23, 25, 27, 35, 42, 44, 47, 55, 61, 63, 65, 66, 70, 71, 72, 77, 84, 95, 96, 102, 109, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 140, 141, 142, 143, 144, 151, 152, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 205, 206, 208, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 227, 229, 230, 231, 232, 233, 234, 235, 236, 238, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 274, 275, 292, 293, 295, 299, 308, 328, 330, 334, 343, 348, 364, 373, 384, 386, 394, 395, 396, 399, 462, 463, 464, 465, 466, 467, 469, 471, 474, 475, 476, 477, 478, 481], "predefin": [1, 419, 462, 464, 469, 478, 480], "becaus": [1, 2, 3, 4, 7, 35, 42, 47, 55, 61, 63, 65, 66, 70, 71, 72, 77, 84, 95, 96, 101, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 224, 232, 253, 268, 272, 285, 306, 328, 330, 334, 338, 343, 344, 346, 347, 348, 349, 350, 351, 361, 381, 394, 395, 396, 399, 456, 461, 462, 464, 465, 467, 468, 469, 473, 474, 475, 476, 478, 481], "potenti": [1, 2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 476, 478], "comput": [1, 3, 4, 8, 15, 17, 18, 27, 29, 35, 38, 42, 47, 55, 65, 66, 71, 72, 77, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 236, 250, 262, 266, 270, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 303, 304, 305, 306, 307, 310, 311, 312, 314, 316, 319, 320, 322, 324, 325, 327, 328, 330, 334, 339, 342, 344, 346, 347, 349, 351, 354, 357, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 390, 392, 393, 394, 396, 397, 398, 399, 400, 401, 402, 403, 405, 441, 455, 457, 461, 463, 464, 465, 466, 467, 473, 474, 475, 477, 478], "heavi": [1, 8, 478], "crucial": [1, 2, 3, 274, 292, 316, 369, 377, 379, 455, 461, 462, 463, 464, 466, 468, 470, 474, 475, 476, 480, 481], "configur": [1, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 71, 129, 178, 191, 232, 281, 286, 314, 330, 334, 379, 381, 394, 456, 461, 462, 463, 468, 474, 475, 476], "hyperparamet": [1, 112, 272, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 461, 470, 476, 478], "appropri": [1, 3, 4, 7, 99, 110, 120, 121, 124, 125, 144, 156, 165, 186, 187, 224, 448, 451, 455, 461, 470, 478], "paramet": [1, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 100, 101, 102, 103, 106, 107, 108, 109, 110, 112, 113, 116, 118, 120, 122, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 197, 201, 202, 203, 204, 205, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 447, 448, 449, 450, 451, 456, 457, 461, 464, 465, 467, 471, 474, 475, 476, 477, 480], "take": [1, 2, 3, 8, 31, 35, 42, 47, 50, 65, 66, 71, 72, 77, 117, 123, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 184, 185, 186, 187, 215, 217, 253, 256, 257, 261, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 333, 334, 342, 344, 345, 346, 347, 349, 351, 354, 357, 360, 381, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 428, 439, 455, 456, 458, 461, 462, 463, 465, 466, 467, 468, 474, 475, 476, 478, 481], "consider": [1, 2, 3, 8, 135, 137, 261, 462, 474, 475, 478], "whether": [1, 2, 3, 15, 16, 17, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 95, 100, 102, 109, 110, 122, 126, 129, 132, 136, 143, 144, 148, 149, 150, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 208, 217, 218, 220, 223, 254, 260, 262, 269, 270, 272, 279, 280, 295, 299, 300, 328, 330, 331, 334, 346, 351, 355, 361, 362, 363, 364, 365, 366, 368, 370, 371, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 427, 451, 461, 462, 463, 465, 466, 474, 475, 476, 480, 481], "should": [1, 2, 3, 4, 5, 7, 8, 11, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 100, 103, 107, 109, 114, 115, 116, 120, 123, 126, 129, 130, 131, 132, 135, 136, 137, 138, 143, 144, 147, 150, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 205, 208, 209, 212, 215, 216, 217, 220, 221, 224, 225, 227, 232, 233, 234, 236, 241, 242, 243, 245, 248, 249, 253, 254, 256, 259, 261, 262, 263, 268, 269, 270, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 306, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 347, 349, 350, 351, 354, 357, 361, 363, 364, 370, 376, 378, 379, 381, 382, 383, 384, 385, 386, 394, 395, 396, 398, 399, 400, 401, 402, 403, 419, 421, 427, 432, 433, 434, 437, 447, 449, 450, 451, 456, 457, 458, 461, 462, 463, 464, 465, 467, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "occur": [1, 8, 16, 42, 65, 73, 74, 77, 84, 126, 129, 132, 136, 138, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 213, 225, 236, 241, 268, 275, 328, 330, 334, 338, 343, 344, 347, 348, 349, 350, 351, 373, 394, 465, 478, 481], "serial": [1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 72, 75, 77, 78, 79, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 269, 270, 272, 328, 330, 334, 394, 396], "parallel": [1, 3, 8, 126, 129, 132, 135, 136, 137, 144, 156, 157, 158, 159, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 262, 268, 295, 299, 361, 448, 449, 450, 451, 462, 463, 474, 475, 480], "worker": [1, 2, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 61, 63, 70, 82, 83, 84, 94, 95, 96, 133, 151, 156, 165, 183, 260, 269, 270, 331, 332, 333, 395, 449, 450, 451, 461, 462, 463, 480, 481], "multisyncdatacollector": [1, 16, 22, 23, 25, 27, 277, 450, 453, 463, 469, 480], "split": [1, 15, 16, 18, 21, 22, 23, 25, 27, 39, 40, 46, 48, 61, 63, 74, 83, 94, 107, 114, 115, 147, 158, 159, 178, 293, 297, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 456, 458, 463, 467, 478, 480], "workload": 1, "across": [1, 3, 8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 66, 69, 72, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 107, 114, 115, 127, 128, 130, 131, 135, 137, 138, 140, 142, 143, 151, 152, 156, 162, 167, 260, 269, 270, 272, 295, 299, 305, 315, 316, 379, 394, 396, 439, 453, 455, 456, 457, 461, 466, 470, 474, 475, 476], "aggreg": [1, 3, 35, 65, 107, 120, 158, 159, 184, 204, 233, 270, 279, 280, 282, 283, 353, 457, 475], "result": [1, 2, 3, 7, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 35, 36, 42, 47, 55, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 84, 85, 95, 96, 107, 109, 113, 114, 115, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 205, 208, 209, 210, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 227, 229, 230, 231, 232, 233, 234, 235, 236, 238, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 274, 277, 292, 293, 295, 297, 299, 300, 305, 318, 324, 328, 330, 334, 342, 344, 349, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 439, 457, 462, 464, 466, 467, 470, 471, 476, 477, 480, 481], "final": [1, 2, 3, 4, 27, 50, 61, 63, 70, 71, 84, 95, 96, 179, 182, 183, 255, 268, 274, 292, 293, 295, 297, 299, 305, 316, 345, 352, 395, 399, 432, 456, 461, 462, 463, 465, 470, 471, 474, 475, 476, 481], "multiasyncdatacollector": [1, 15, 21, 22, 23, 25, 27, 277, 449, 453, 461, 462, 463, 469, 480], "sever": [1, 2, 3, 8, 35, 42, 47, 51, 55, 65, 66, 72, 77, 83, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 213, 215, 233, 262, 272, 328, 330, 334, 381, 394, 396, 461, 463, 465, 470, 471, 478, 481], "gather": [1, 3, 22, 25, 27, 50, 83, 94, 100, 102, 107, 114, 122, 234, 241, 304, 307, 312, 379, 394, 398, 441, 454, 455, 462, 463, 464, 469, 474, 475, 476, 478, 480, 481], "continu": [1, 2, 3, 9, 36, 39, 50, 85, 86, 87, 95, 115, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 197, 205, 230, 255, 263, 282, 283, 284, 285, 315, 316, 353, 358, 362, 385, 399, 404, 412, 456, 461, 463, 467, 474, 475, 478], "concomitantli": [1, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187], "network": [1, 4, 8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 279, 280, 282, 283, 284, 285, 288, 290, 291, 297, 300, 305, 306, 307, 309, 310, 311, 313, 315, 317, 319, 320, 321, 326, 328, 330, 334, 339, 340, 341, 342, 350, 354, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 392, 394, 396, 397, 399, 400, 401, 402, 403, 446, 447, 456, 457, 458, 465, 468, 471, 473, 476, 481], "impli": [1, 84, 481], "mai": [1, 2, 3, 4, 5, 7, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 95, 96, 98, 101, 107, 114, 126, 129, 132, 135, 136, 137, 138, 144, 156, 157, 160, 162, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 236, 249, 260, 262, 264, 269, 270, 272, 275, 295, 299, 300, 305, 328, 330, 334, 351, 363, 370, 378, 381, 384, 394, 395, 396, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 474, 475, 476, 477, 478, 481], "slightli": [1, 31, 457, 464, 465, 474, 476, 477, 478, 481], "lag": [1, 461, 462, 463], "therefor": [1, 2, 3, 7, 62, 69, 78, 79, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 245, 381, 396, 397, 455, 465, 468, 474, 481], "fastest": 1, "price": [1, 2], "suitabl": [1, 2, 212], "where": [1, 2, 3, 4, 7, 8, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 33, 35, 42, 44, 46, 47, 50, 55, 56, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 94, 95, 96, 98, 100, 102, 107, 109, 114, 115, 120, 122, 123, 126, 129, 132, 136, 144, 147, 150, 153, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 203, 204, 205, 206, 209, 212, 217, 224, 232, 240, 245, 248, 253, 254, 255, 256, 257, 261, 262, 264, 267, 268, 272, 274, 292, 293, 294, 295, 297, 298, 299, 303, 304, 305, 313, 315, 316, 328, 330, 334, 342, 347, 350, 351, 360, 361, 362, 363, 364, 369, 370, 371, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 394, 395, 396, 398, 399, 400, 401, 402, 403, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 457, 458, 461, 462, 463, 465, 466, 473, 474, 475, 476, 478, 481], "off": [1, 2, 4, 296, 325, 343, 384, 417, 432, 442, 456, 458, 461, 462, 463, 467, 468, 474, 475, 477, 480, 481], "curriculum": [1, 4], "For": [1, 2, 3, 4, 7, 8, 9, 10, 11, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 42, 43, 47, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 100, 102, 107, 109, 114, 122, 126, 129, 132, 135, 136, 137, 141, 143, 144, 156, 157, 158, 159, 160, 165, 166, 167, 168, 170, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 220, 223, 227, 236, 254, 261, 262, 268, 272, 289, 293, 295, 297, 299, 303, 306, 308, 328, 330, 334, 339, 341, 342, 344, 348, 361, 369, 371, 377, 381, 394, 396, 432, 456, 457, 458, 461, 462, 463, 464, 466, 467, 469, 470, 474, 475, 476, 477, 478, 481], "remot": [1, 2, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 62, 67, 68, 69, 78, 79, 109, 156, 165, 270, 331, 481], "rollout": [1, 2, 3, 11, 15, 16, 18, 21, 27, 29, 31, 50, 71, 77, 84, 120, 126, 127, 128, 129, 132, 136, 138, 139, 142, 143, 144, 148, 149, 150, 151, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 170, 171, 172, 177, 178, 179, 182, 185, 186, 187, 190, 205, 206, 208, 209, 212, 215, 217, 218, 220, 223, 224, 225, 230, 232, 233, 238, 242, 243, 248, 249, 250, 253, 254, 256, 257, 260, 263, 269, 270, 272, 276, 277, 278, 295, 299, 302, 316, 346, 361, 417, 419, 441, 456, 461, 463, 464, 467, 468, 469, 470, 471, 477, 478, 480], "necessari": [1, 4, 6, 8, 15, 16, 18, 21, 22, 23, 25, 27, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 249, 382, 399, 400, 401, 402, 403, 455, 457, 461, 463, 467, 468, 469], "synchronis": [1, 133, 474, 475], "either": [1, 2, 5, 28, 33, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 71, 72, 77, 78, 79, 84, 94, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 234, 253, 254, 270, 272, 328, 330, 334, 356, 379, 386, 387, 394, 396, 423, 458, 461, 462, 464, 474, 477, 478, 480, 481], "update_policy_weights_": [1, 13, 15, 16, 18, 20, 21, 22, 23, 25, 27, 29, 461, 475, 480], "update_at_each_batch": [1, 15, 16, 21], "true": [1, 2, 3, 4, 8, 11, 12, 13, 15, 16, 18, 21, 22, 23, 24, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 106, 107, 109, 110, 112, 113, 114, 115, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 203, 204, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 222, 225, 227, 230, 231, 232, 233, 234, 235, 236, 240, 241, 243, 244, 247, 248, 249, 252, 253, 255, 258, 259, 260, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 275, 276, 279, 280, 282, 283, 284, 285, 291, 293, 294, 295, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 308, 309, 315, 316, 323, 324, 325, 328, 330, 331, 334, 337, 338, 339, 340, 341, 343, 344, 347, 348, 349, 350, 351, 352, 353, 354, 361, 362, 363, 364, 365, 366, 368, 369, 370, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 399, 400, 401, 402, 405, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 426, 427, 430, 431, 432, 434, 437, 451, 455, 456, 457, 458, 461, 462, 463, 464, 465, 467, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "second": [1, 2, 3, 8, 15, 16, 18, 21, 29, 31, 50, 51, 52, 53, 54, 120, 156, 209, 257, 293, 295, 297, 299, 344, 363, 378, 381, 384, 419, 421, 424, 426, 436, 461, 463, 469, 474, 475, 476, 478, 480, 481], "devic": [1, 2, 3, 7, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 106, 114, 115, 122, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 200, 203, 205, 209, 216, 220, 221, 223, 224, 225, 230, 232, 233, 238, 239, 240, 242, 243, 245, 249, 252, 253, 255, 258, 261, 262, 263, 265, 267, 269, 272, 274, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 291, 292, 293, 294, 295, 297, 298, 299, 300, 302, 305, 306, 308, 309, 314, 316, 317, 318, 326, 328, 329, 330, 331, 332, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 355, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 417, 434, 439, 445, 456, 461, 462, 463, 464, 465, 474, 475, 476, 477, 480], "oper": [1, 2, 3, 4, 7, 8, 15, 16, 18, 21, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 70, 72, 73, 74, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 101, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 227, 232, 257, 259, 263, 270, 272, 288, 289, 294, 298, 328, 330, 334, 339, 340, 341, 343, 344, 345, 350, 356, 361, 363, 365, 366, 371, 378, 381, 383, 394, 395, 396, 397, 398, 399, 400, 401, 402, 437, 453, 455, 457, 458, 461, 462, 463, 464, 465, 466, 467, 473, 474, 475, 476, 481], "instanc": [1, 2, 3, 4, 7, 8, 12, 15, 16, 18, 21, 22, 23, 25, 27, 29, 30, 35, 36, 42, 47, 55, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 80, 82, 83, 84, 85, 95, 96, 97, 98, 100, 101, 102, 105, 107, 109, 114, 115, 122, 126, 129, 131, 132, 133, 135, 136, 137, 141, 144, 150, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 204, 236, 255, 262, 269, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 305, 306, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 331, 332, 334, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 362, 364, 366, 369, 370, 377, 379, 382, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 417, 419, 423, 427, 432, 441, 442, 443, 447, 449, 450, 455, 456, 457, 458, 461, 463, 464, 465, 466, 467, 476, 478, 481], "cpu": [1, 2, 3, 8, 10, 15, 16, 18, 21, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 106, 109, 114, 122, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 203, 205, 209, 216, 220, 221, 223, 224, 225, 230, 233, 238, 240, 242, 243, 245, 249, 252, 253, 255, 261, 262, 263, 265, 267, 272, 276, 278, 288, 293, 294, 295, 297, 298, 299, 302, 308, 309, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 353, 355, 358, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 417, 456, 461, 462, 463, 464, 474, 475, 476, 477, 480], "slower": [1, 474], "than": [1, 2, 3, 4, 8, 13, 15, 16, 18, 21, 22, 23, 24, 25, 27, 29, 32, 33, 35, 65, 84, 107, 114, 115, 118, 120, 126, 129, 132, 136, 140, 144, 154, 155, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 217, 233, 234, 243, 270, 274, 285, 295, 297, 299, 300, 327, 338, 343, 350, 351, 355, 379, 394, 396, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 454, 456, 457, 461, 462, 463, 465, 466, 468, 474, 475, 476, 478, 480, 481], "one": [1, 2, 3, 4, 5, 7, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 97, 98, 99, 100, 105, 106, 107, 109, 110, 114, 115, 116, 118, 120, 121, 124, 125, 126, 127, 128, 129, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143, 144, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 209, 212, 215, 217, 218, 220, 221, 222, 223, 230, 233, 235, 236, 240, 245, 248, 251, 252, 254, 255, 256, 261, 262, 264, 267, 269, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 306, 307, 310, 311, 312, 313, 314, 316, 318, 319, 320, 322, 327, 328, 330, 334, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 354, 355, 357, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 391, 394, 395, 396, 397, 399, 400, 401, 402, 406, 407, 419, 421, 430, 432, 433, 437, 441, 451, 454, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 473, 474, 475, 476, 477, 478, 481], "cuda": [1, 2, 3, 7, 15, 16, 18, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 127, 128, 129, 132, 136, 138, 139, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 232, 239, 240, 255, 261, 262, 265, 267, 272, 293, 294, 297, 298, 328, 330, 331, 334, 350, 394, 396, 429, 461, 462, 463, 464, 474, 475, 477, 481], "multipl": [1, 2, 3, 5, 8, 14, 15, 16, 18, 21, 22, 23, 24, 25, 27, 53, 65, 69, 78, 79, 80, 84, 102, 109, 110, 122, 126, 127, 128, 142, 143, 156, 165, 167, 185, 190, 213, 215, 222, 231, 234, 235, 245, 248, 252, 253, 260, 269, 293, 297, 299, 305, 308, 309, 338, 343, 347, 348, 350, 351, 354, 363, 370, 378, 381, 391, 405, 451, 456, 457, 458, 461, 462, 463, 466, 468, 469, 474, 475, 476, 478, 480], "infer": [1, 3, 14, 15, 16, 17, 18, 20, 22, 24, 25, 26, 27, 29, 30, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 212, 269, 308, 331, 342, 347, 351, 368, 417, 455, 461, 463, 465, 469, 471, 478, 480], "dispatch": [1, 3, 22, 23, 25, 27, 42, 65, 77, 180, 181, 184, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 327, 328, 330, 334, 346, 394, 396, 419, 461, 481], "avail": [1, 2, 3, 4, 6, 27, 62, 69, 78, 79, 107, 113, 114, 115, 127, 128, 130, 131, 140, 142, 143, 148, 149, 154, 155, 156, 158, 159, 162, 168, 169, 170, 171, 189, 191, 205, 208, 211, 230, 232, 289, 318, 347, 351, 379, 394, 419, 449, 450, 453, 461, 462, 463, 464, 465, 466, 467, 474, 475, 476, 478, 481], "speed": [1, 2, 3, 4, 8, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 457, 461, 462, 463, 464, 474, 475, 476, 478, 480], "avoid": [1, 2, 3, 35, 42, 47, 55, 65, 66, 72, 77, 100, 102, 114, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 212, 230, 260, 262, 269, 270, 272, 275, 324, 328, 330, 334, 338, 350, 355, 363, 364, 378, 381, 384, 394, 396, 440, 463, 465, 475], "oom": [1, 3, 61, 63, 70, 84, 95, 96, 100, 102, 122, 183, 395], "choic": [1, 2, 57, 156, 190, 456, 457, 461, 462, 468, 474, 475], "pass": [1, 2, 3, 4, 13, 15, 16, 18, 19, 20, 21, 22, 23, 25, 27, 28, 33, 35, 39, 40, 42, 47, 48, 55, 57, 62, 65, 66, 67, 69, 71, 72, 74, 77, 78, 79, 82, 83, 95, 98, 100, 102, 107, 109, 114, 115, 120, 122, 126, 129, 132, 133, 134, 136, 137, 144, 147, 151, 156, 157, 158, 159, 160, 165, 166, 167, 170, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 206, 208, 209, 212, 218, 220, 223, 233, 234, 242, 243, 260, 264, 269, 272, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 306, 307, 308, 310, 311, 314, 316, 317, 319, 320, 322, 326, 327, 328, 330, 331, 334, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 357, 362, 363, 364, 377, 378, 379, 381, 382, 384, 386, 387, 394, 396, 399, 400, 401, 402, 403, 417, 434, 437, 449, 450, 451, 455, 456, 461, 462, 463, 464, 465, 466, 467, 468, 469, 473, 474, 475, 476, 478, 480, 481], "ie": [1, 2, 3, 22, 25, 28, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 73, 74, 77, 78, 82, 83, 85, 86, 87, 88, 89, 106, 115, 126, 129, 132, 136, 140, 144, 153, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 205, 212, 227, 252, 255, 264, 269, 295, 299, 328, 330, 334, 342, 350, 394, 456, 457, 462, 475], "store": [1, 3, 8, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 27, 29, 35, 39, 42, 45, 46, 47, 50, 55, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 80, 83, 84, 94, 95, 96, 98, 100, 101, 102, 103, 106, 107, 109, 114, 120, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 230, 257, 268, 269, 270, 272, 274, 276, 277, 302, 316, 328, 330, 334, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 426, 453, 455, 458, 461, 463, 464, 467, 469, 471, 474, 475, 477, 481], "while": [1, 2, 3, 7, 8, 15, 16, 18, 21, 29, 31, 35, 42, 47, 55, 65, 66, 67, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 245, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 369, 377, 378, 381, 394, 396, 456, 457, 461, 463, 464, 467, 469, 470, 474, 475, 476, 477, 478, 480], "wait": [1, 13, 15, 16, 21, 22, 23, 24, 25, 27, 28, 67, 168, 464, 476], "also": [1, 2, 3, 8, 9, 11, 15, 16, 31, 33, 34, 35, 38, 42, 43, 47, 51, 52, 53, 54, 55, 59, 60, 61, 63, 65, 66, 69, 70, 72, 77, 78, 79, 82, 84, 94, 95, 96, 100, 101, 102, 107, 109, 114, 115, 120, 122, 126, 129, 132, 136, 143, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 202, 203, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 222, 224, 225, 226, 228, 230, 231, 232, 236, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 268, 269, 272, 273, 279, 280, 293, 297, 300, 320, 328, 330, 334, 346, 347, 352, 353, 354, 361, 362, 364, 365, 366, 368, 369, 370, 375, 377, 381, 384, 386, 394, 395, 396, 399, 406, 407, 417, 419, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 473, 474, 475, 476, 478, 480, 481], "impact": [1, 2, 3, 13, 22, 23, 25, 143, 220, 223, 275, 361, 363, 378, 381, 383, 394, 462, 464, 474, 475], "memori": [1, 3, 8, 27, 35, 38, 42, 47, 55, 61, 63, 65, 66, 67, 70, 72, 77, 83, 84, 95, 96, 98, 100, 101, 105, 126, 129, 132, 133, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 216, 240, 255, 261, 262, 265, 267, 269, 270, 272, 287, 297, 298, 328, 330, 334, 350, 394, 395, 396, 451, 453, 458, 461, 462, 464, 474, 478, 480], "manag": [1, 3, 8, 13, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 29, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 277, 295, 299, 337, 392, 393, 399, 400, 401, 402, 427, 432, 455, 456, 464, 465, 468, 480], "kei": [1, 2, 7, 15, 16, 18, 21, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 106, 107, 109, 112, 114, 115, 120, 126, 129, 132, 136, 142, 143, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 236, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 272, 274, 276, 278, 288, 289, 292, 295, 299, 301, 302, 316, 318, 328, 330, 334, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 417, 419, 431, 432, 433, 435, 436, 437, 441, 457, 458, 461, 463, 464, 465, 466, 468, 473, 474, 475, 476, 478, 480, 481], "control": [1, 3, 5, 8, 18, 31, 32, 39, 40, 41, 48, 69, 74, 78, 79, 107, 109, 114, 126, 129, 130, 131, 132, 136, 143, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 222, 282, 283, 284, 285, 295, 299, 301, 302, 316, 320, 327, 329, 330, 334, 350, 351, 352, 361, 363, 364, 378, 379, 381, 385, 394, 399, 404, 412, 417, 427, 456, 458, 461, 462, 463, 464, 465, 466, 467, 468, 474, 475, 476, 478, 480], "which": [1, 2, 3, 4, 7, 8, 14, 15, 16, 18, 20, 21, 22, 23, 25, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 101, 109, 112, 113, 120, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 140, 142, 143, 144, 148, 149, 151, 152, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 196, 212, 213, 217, 220, 223, 228, 230, 232, 233, 235, 236, 240, 241, 243, 253, 255, 256, 259, 260, 261, 262, 263, 265, 269, 272, 273, 288, 293, 294, 295, 296, 297, 298, 299, 303, 304, 305, 306, 307, 313, 315, 325, 328, 330, 334, 339, 340, 341, 342, 346, 347, 350, 351, 352, 353, 361, 362, 363, 364, 366, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 397, 399, 400, 401, 402, 417, 419, 428, 433, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 473, 474, 475, 476, 477, 478, 481], "storing_devic": [1, 15, 16, 18, 21, 22, 23, 25, 27, 462, 475], "dure": [1, 2, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 38, 43, 51, 52, 53, 54, 59, 60, 62, 63, 66, 67, 68, 69, 71, 72, 78, 79, 83, 94, 98, 103, 107, 109, 112, 114, 126, 129, 132, 133, 136, 143, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 189, 190, 193, 194, 208, 209, 212, 215, 220, 223, 225, 227, 228, 230, 234, 238, 250, 252, 255, 257, 259, 260, 262, 263, 264, 269, 270, 272, 275, 277, 278, 295, 299, 306, 346, 399, 401, 402, 432, 437, 457, 461, 462, 463, 464, 467, 468, 469, 471, 474, 475, 476, 478, 481], "heurist": [1, 4, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 274, 346, 351, 461, 465, 469, 481], "usual": [1, 2, 3, 4, 6, 7, 8, 15, 16, 18, 21, 22, 23, 25, 27, 112, 120, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 260, 309, 381, 386, 398, 399, 400, 401, 402, 403, 418, 454, 455, 456, 457, 458, 461, 462, 463, 464, 467, 469, 470, 475, 478, 481], "same": [1, 2, 3, 4, 18, 22, 23, 25, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 80, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 113, 114, 115, 118, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 147, 151, 152, 156, 157, 158, 159, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 212, 220, 222, 223, 228, 230, 233, 234, 235, 236, 252, 260, 261, 262, 269, 272, 273, 279, 280, 294, 298, 300, 303, 304, 305, 306, 316, 324, 328, 330, 334, 342, 354, 362, 364, 377, 379, 382, 384, 386, 387, 391, 394, 395, 396, 457, 461, 462, 463, 466, 467, 469, 473, 474, 475, 477, 478, 481], "default": [1, 2, 3, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 98, 100, 101, 102, 106, 107, 109, 110, 112, 113, 114, 115, 120, 122, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 243, 245, 247, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 316, 318, 319, 320, 322, 323, 324, 325, 328, 330, 331, 332, 334, 337, 338, 342, 343, 344, 346, 347, 348, 349, 350, 351, 354, 355, 357, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 389, 390, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 421, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 447, 451, 457, 458, 461, 462, 463, 464, 467, 474, 477, 478, 480, 481], "behavior": [1, 2, 3, 4, 15, 16, 27, 35, 42, 47, 55, 65, 66, 72, 77, 82, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 213, 220, 223, 236, 241, 254, 262, 270, 272, 275, 295, 296, 299, 325, 328, 330, 334, 369, 377, 386, 394, 396, 417, 427, 432, 456, 462, 464, 474, 475, 476, 478], "besid": 1, "those": [1, 2, 3, 5, 7, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 194, 212, 217, 220, 223, 230, 236, 255, 256, 259, 263, 299, 315, 347, 351, 352, 353, 439, 449, 450, 456, 461, 462, 466, 467, 475, 476, 481], "choos": [1, 3, 11, 57, 126, 129, 147, 295, 299, 381, 453, 457, 461, 462, 463, 465, 474, 475, 478, 480], "follow": [1, 2, 3, 6, 7, 8, 11, 20, 35, 42, 47, 50, 55, 61, 63, 64, 65, 66, 70, 71, 72, 77, 82, 84, 95, 96, 107, 114, 115, 126, 127, 128, 129, 132, 135, 136, 137, 142, 143, 144, 150, 153, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 208, 212, 232, 240, 265, 269, 270, 272, 279, 280, 293, 295, 297, 299, 300, 328, 330, 334, 344, 347, 348, 349, 360, 361, 362, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 395, 396, 419, 437, 456, 457, 458, 461, 462, 463, 464, 465, 468, 469, 473, 474, 475, 476, 478, 480, 481], "max_frames_per_traj": [1, 15, 16, 18, 21, 22, 23, 25, 27, 440, 461, 463, 480], "frame": [1, 2, 11, 15, 16, 18, 21, 22, 23, 25, 27, 29, 55, 177, 212, 228, 272, 274, 292, 316, 346, 418, 419, 421, 424, 426, 430, 432, 437, 440, 441, 455, 461, 462, 463, 464, 467, 474, 475, 478, 480, 481], "call": [1, 2, 3, 7, 8, 11, 13, 15, 16, 18, 20, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 100, 101, 102, 103, 107, 108, 109, 113, 114, 116, 118, 122, 123, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 151, 152, 153, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 204, 205, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 221, 222, 224, 225, 226, 227, 228, 230, 231, 232, 234, 236, 238, 239, 240, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 302, 306, 307, 308, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 350, 351, 353, 354, 357, 362, 363, 364, 370, 377, 378, 379, 381, 382, 384, 386, 387, 394, 395, 396, 398, 399, 400, 401, 402, 417, 418, 421, 432, 457, 458, 462, 463, 464, 465, 466, 467, 469, 470, 474, 475, 476, 478, 480, 481], "frames_per_batch": [1, 2, 15, 16, 18, 21, 22, 23, 25, 27, 29, 44, 55, 67, 75, 209, 212, 245, 295, 299, 440, 461, 462, 463, 464, 465, 469, 471, 474, 475, 478, 480], "each": [1, 2, 3, 4, 7, 8, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 31, 35, 39, 40, 42, 46, 47, 48, 50, 51, 53, 55, 56, 65, 66, 69, 71, 72, 74, 76, 77, 78, 84, 107, 109, 112, 114, 115, 117, 120, 126, 129, 132, 133, 136, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 231, 233, 234, 240, 245, 248, 253, 254, 255, 256, 260, 261, 267, 269, 270, 272, 273, 274, 289, 292, 293, 294, 295, 297, 299, 305, 306, 310, 317, 318, 326, 328, 330, 334, 337, 343, 344, 349, 351, 353, 363, 378, 381, 394, 396, 399, 405, 408, 409, 410, 411, 413, 414, 415, 416, 419, 432, 434, 449, 450, 457, 461, 462, 463, 464, 467, 468, 469, 471, 474, 475, 476, 477, 478, 480, 481], "init_random_fram": [1, 15, 16, 18, 21, 22, 23, 25, 27, 440, 461, 462, 465, 471], "rand_step": [1, 2, 3, 44, 75, 126, 129, 130, 131, 132, 133, 135, 136, 137, 144, 145, 146, 150, 151, 152, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 231, 255, 269, 476, 480, 481], "reset_at_each_it": [1, 15, 16, 18, 21, 22, 23, 25, 27, 29, 461], "split_traj": [1, 15, 16, 18, 21, 22, 23, 25, 27, 461, 462, 463], "trajectori": [1, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 42, 45, 46, 55, 56, 76, 78, 84, 106, 107, 114, 115, 120, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 241, 253, 260, 272, 276, 299, 302, 316, 381, 396, 399, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 428, 453, 457, 461, 462, 463, 464, 466, 469, 471, 476, 480, 481], "pad": [1, 2, 3, 31, 64, 80, 95, 190, 194, 196, 212, 259, 279, 280, 282, 283, 299, 303, 304, 305, 330, 334, 434], "along": [1, 2, 3, 15, 16, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 71, 72, 73, 74, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 102, 107, 109, 114, 115, 120, 122, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 196, 197, 211, 212, 213, 234, 236, 238, 241, 248, 252, 258, 272, 299, 300, 303, 304, 309, 328, 330, 334, 343, 347, 350, 351, 364, 379, 386, 394, 395, 396, 461, 462, 464, 466, 468, 474, 475, 476, 478, 480], "point": [1, 2, 3, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 67, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 99, 106, 107, 110, 120, 121, 124, 125, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 265, 266, 267, 268, 269, 272, 301, 328, 330, 334, 350, 360, 371, 394, 396, 437, 454, 462, 463, 473, 474, 475, 476, 478, 480, 481], "boolean": [1, 3, 15, 16, 18, 21, 22, 23, 25, 27, 31, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 71, 73, 74, 82, 85, 86, 87, 88, 89, 107, 114, 115, 136, 187, 204, 208, 217, 241, 253, 303, 304, 316, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 458, 464], "repres": [1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 39, 40, 44, 48, 50, 57, 74, 75, 77, 78, 84, 101, 126, 129, 130, 131, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 228, 241, 257, 269, 272, 289, 303, 304, 318, 324, 330, 334, 343, 344, 348, 349, 390, 399, 434, 456, 461, 463, 464, 465, 466, 467, 468, 474, 475], "valid": [1, 2, 3, 31, 61, 63, 64, 83, 84, 94, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 173, 177, 178, 179, 182, 185, 186, 187, 208, 241, 260, 262, 272, 274, 279, 280, 300, 303, 304, 316, 363, 370, 378, 381, 384, 399, 400, 401, 402, 434, 458, 465, 481], "exploration_typ": [1, 15, 16, 18, 21, 22, 23, 25, 27, 432, 453, 456, 461, 462], "strategi": [1, 2, 3, 18, 95, 112, 147, 205, 292, 304, 312, 456, 458, 461, 462, 465, 467, 474, 475, 478, 480], "reset_when_don": [1, 15, 16, 18, 21], "its": [1, 2, 3, 4, 5, 7, 9, 11, 13, 14, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 69, 70, 72, 73, 74, 77, 78, 82, 84, 85, 86, 87, 88, 89, 91, 95, 96, 102, 109, 114, 115, 126, 129, 132, 136, 143, 144, 150, 156, 157, 158, 159, 160, 165, 166, 167, 170, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 211, 212, 218, 224, 232, 253, 254, 255, 260, 262, 268, 269, 270, 272, 273, 274, 279, 280, 295, 299, 303, 304, 305, 306, 315, 328, 329, 330, 334, 343, 347, 348, 351, 354, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 380, 381, 382, 383, 384, 387, 394, 395, 396, 397, 419, 437, 447, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 480, 481], "organ": [1, 2, 476, 478], "within": [1, 2, 3, 15, 16, 20, 21, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 101, 106, 107, 115, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 270, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 337, 342, 344, 346, 349, 351, 354, 357, 358, 366, 371, 386, 394, 395, 396, 397, 399, 417, 419, 455, 456, 457, 462, 465, 466, 467, 468, 469, 470, 471, 474, 476, 480], "differ": [1, 2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 71, 72, 73, 74, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 109, 112, 126, 127, 128, 129, 132, 133, 136, 142, 143, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 212, 217, 221, 222, 233, 236, 243, 252, 260, 262, 264, 272, 273, 289, 293, 294, 297, 298, 300, 302, 305, 306, 307, 318, 328, 330, 334, 351, 377, 379, 381, 390, 394, 396, 399, 400, 401, 405, 406, 407, 432, 437, 439, 449, 450, 455, 456, 457, 458, 461, 462, 463, 465, 466, 468, 470, 473, 474, 475, 476, 477, 478, 480, 481], "how": [1, 2, 3, 11, 20, 22, 23, 25, 32, 35, 42, 47, 55, 62, 65, 66, 72, 77, 78, 106, 107, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 233, 272, 307, 328, 330, 334, 347, 361, 363, 376, 378, 379, 381, 394, 396, 419, 421, 437, 454, 456, 461, 462, 463, 464, 465, 466, 467, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "tabl": [1, 35, 456, 462, 467], "summar": [1, 3, 476], "what": [1, 3, 8, 11, 41, 42, 62, 82, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 203, 224, 255, 260, 348, 364, 375, 379, 386, 394, 454, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 471, 474, 475, 476, 477, 478, 480, 481], "expect": [1, 2, 3, 4, 7, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 72, 73, 74, 77, 82, 83, 85, 86, 87, 88, 89, 107, 113, 114, 126, 129, 132, 136, 144, 150, 153, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 227, 229, 231, 232, 233, 234, 236, 238, 240, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 293, 294, 295, 297, 298, 299, 305, 306, 316, 328, 330, 334, 344, 350, 353, 361, 362, 363, 364, 365, 366, 368, 369, 370, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 391, 394, 396, 397, 441, 454, 456, 457, 458, 461, 463, 464, 466, 467, 468, 469, 474, 475, 476, 478, 481], "n": [1, 2, 3, 6, 7, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 71, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 222, 227, 264, 272, 293, 294, 297, 302, 313, 315, 316, 328, 330, 334, 346, 351, 361, 362, 370, 379, 394, 396, 398, 434, 455, 458, 462, 464, 465, 478, 480, 481], "b": [1, 2, 3, 7, 8, 29, 31, 39, 40, 42, 48, 61, 63, 65, 69, 70, 71, 72, 74, 77, 78, 79, 84, 95, 96, 100, 101, 120, 129, 183, 230, 263, 293, 294, 297, 298, 305, 306, 308, 309, 317, 326, 328, 330, 334, 354, 394, 395, 399, 400, 401, 402, 403, 405, 419, 462, 478], "cat_result": [1, 15, 16], "na": [1, 179, 182, 192], "t": [1, 2, 3, 4, 6, 7, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 97, 106, 107, 109, 113, 114, 115, 120, 126, 129, 132, 133, 135, 136, 144, 151, 152, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 230, 231, 232, 239, 240, 241, 242, 243, 244, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 267, 268, 269, 272, 273, 293, 295, 297, 299, 316, 328, 330, 334, 343, 350, 361, 385, 394, 395, 396, 399, 400, 401, 402, 403, 405, 419, 426, 437, 439, 451, 454, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "p": [1, 2, 4, 109, 112, 133, 163, 164, 277, 278, 331], "In": [1, 2, 3, 4, 5, 7, 8, 10, 11, 15, 16, 18, 20, 21, 22, 23, 25, 27, 28, 29, 35, 42, 47, 55, 65, 66, 72, 77, 115, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 220, 221, 223, 231, 240, 245, 249, 254, 255, 258, 260, 261, 262, 265, 267, 268, 270, 272, 273, 293, 296, 297, 300, 305, 320, 324, 325, 328, 330, 334, 350, 351, 353, 360, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 439, 449, 450, 451, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 481], "case": [1, 3, 4, 5, 7, 8, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 73, 74, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 97, 98, 105, 106, 107, 109, 120, 126, 129, 132, 135, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 183, 185, 186, 187, 220, 221, 223, 231, 236, 255, 258, 262, 263, 273, 299, 300, 306, 307, 347, 350, 351, 353, 354, 360, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 399, 400, 401, 402, 419, 428, 439, 449, 450, 451, 453, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 469, 470, 474, 475, 476, 478, 480, 481], "dimens": [1, 3, 15, 16, 18, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 69, 70, 71, 73, 74, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 102, 107, 114, 115, 120, 122, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 183, 184, 185, 186, 187, 190, 196, 197, 205, 211, 212, 213, 227, 234, 236, 238, 241, 248, 251, 252, 255, 258, 264, 269, 270, 279, 280, 281, 286, 287, 295, 297, 299, 300, 303, 304, 305, 308, 309, 314, 317, 321, 322, 323, 324, 327, 343, 346, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 451, 453, 457, 461, 462, 463, 464, 466, 474, 475, 476, 478], "time": [1, 2, 3, 4, 7, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 71, 72, 77, 78, 79, 84, 95, 97, 100, 109, 120, 126, 127, 128, 129, 132, 133, 136, 142, 143, 144, 147, 153, 156, 157, 158, 159, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 203, 211, 212, 213, 234, 241, 248, 255, 256, 257, 260, 262, 269, 272, 278, 290, 293, 297, 299, 316, 328, 330, 334, 337, 346, 351, 362, 363, 364, 370, 373, 377, 378, 379, 381, 382, 384, 386, 387, 394, 396, 399, 400, 401, 402, 403, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 437, 457, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 478, 480, 481], "adapt": [1, 32, 206, 234, 253, 269, 275, 378, 461, 465, 476], "equal": [1, 15, 16, 21, 35, 84, 107, 114, 115, 129, 151, 154, 155, 156, 165, 185, 235, 236, 279, 280, 293, 295, 297, 299, 300, 303, 304, 306, 385, 390, 428, 449, 450, 461, 463, 477], "introduc": [1, 2, 156, 165, 293, 295, 297, 299, 316, 461, 474], "some": [1, 2, 3, 4, 7, 8, 9, 28, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 67, 69, 72, 73, 74, 77, 82, 83, 84, 85, 86, 87, 88, 89, 100, 102, 109, 120, 122, 126, 127, 128, 129, 132, 135, 136, 137, 142, 143, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 240, 255, 262, 265, 272, 282, 295, 322, 328, 330, 334, 351, 352, 353, 394, 396, 419, 428, 440, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 474, 475, 476, 478, 480, 481], "confus": [1, 33, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 328, 330, 334, 394, 396], "other": [1, 2, 3, 4, 7, 8, 11, 15, 16, 18, 21, 22, 23, 25, 27, 28, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 72, 73, 74, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 102, 103, 109, 112, 113, 114, 115, 116, 118, 122, 126, 129, 132, 135, 136, 137, 141, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 215, 217, 221, 222, 242, 249, 255, 258, 265, 269, 270, 272, 277, 292, 293, 295, 299, 309, 328, 330, 334, 337, 342, 344, 349, 351, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 395, 396, 397, 399, 417, 434, 449, 450, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 474, 475, 476, 477, 480, 481], "better": [1, 3, 8, 9, 15, 16, 31, 143, 295, 299, 457, 463, 466, 476, 480], "consist": [1, 2, 3, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 69, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 268, 272, 277, 280, 300, 328, 330, 334, 394, 396, 455, 461, 462, 463, 476, 477, 481], "interact": [1, 2, 3, 4, 5, 7, 8, 15, 16, 18, 21, 22, 23, 25, 27, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 188, 262, 347, 351, 455, 461, 463, 465, 466, 467, 469, 474, 475, 476, 481], "keep": [1, 2, 3, 4, 7, 8, 16, 62, 69, 78, 79, 109, 113, 120, 129, 156, 165, 203, 236, 240, 267, 269, 270, 272, 316, 346, 396, 419, 430, 437, 461, 462, 463, 464, 469, 470, 471, 475, 476, 478, 481], "separ": [1, 2, 4, 8, 15, 16, 18, 21, 22, 25, 27, 29, 31, 39, 40, 48, 69, 74, 78, 79, 212, 240, 267, 362, 365, 368, 370, 382, 384, 386, 387, 399, 457, 461, 462, 467, 468, 474, 475, 478, 481], "interchang": [1, 305, 306, 463, 466, 470, 477, 478], "between": [1, 2, 3, 4, 5, 15, 16, 17, 18, 21, 24, 27, 29, 32, 35, 42, 47, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 84, 95, 96, 102, 107, 109, 110, 113, 114, 115, 122, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 222, 235, 246, 257, 260, 262, 269, 270, 272, 279, 280, 288, 293, 295, 299, 300, 305, 306, 328, 330, 332, 334, 344, 347, 351, 361, 363, 364, 365, 368, 369, 370, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 399, 432, 437, 457, 461, 462, 464, 465, 469, 474, 475, 476, 478, 481], "wherea": [1, 2, 28, 29, 35, 42, 47, 55, 65, 66, 72, 77, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 151, 152, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 222, 260, 262, 272, 328, 330, 334, 364, 379, 384, 394, 396, 458, 470], "correspond": [1, 2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 70, 72, 73, 74, 77, 78, 82, 84, 85, 86, 87, 88, 89, 95, 96, 106, 107, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 230, 240, 255, 260, 262, 267, 269, 270, 272, 277, 292, 295, 297, 299, 303, 304, 316, 328, 330, 334, 347, 351, 364, 366, 369, 370, 384, 394, 395, 396, 397, 399, 400, 401, 402, 403, 456, 461, 462, 463, 465, 466, 468, 469, 470, 474, 475, 476, 477], "sub": [1, 2, 3, 15, 16, 21, 22, 23, 25, 27, 35, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 107, 114, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 241, 260, 270, 272, 328, 330, 334, 352, 353, 394, 396, 428, 437, 456, 457, 461, 462, 463, 469, 473, 480, 481], "doesn": [1, 4, 35, 42, 47, 55, 65, 66, 72, 77, 120, 126, 129, 132, 136, 144, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 220, 223, 272, 273, 328, 330, 334, 394, 396, 465, 466], "understood": [1, 461], "serv": [1, 3, 22, 25, 27, 138, 478, 480, 481], "basi": [1, 120, 305, 478, 480], "we": [1, 2, 3, 5, 7, 9, 11, 31, 32, 35, 39, 42, 47, 50, 55, 62, 65, 66, 69, 71, 72, 77, 78, 79, 100, 113, 115, 120, 126, 127, 128, 129, 132, 133, 136, 140, 142, 143, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 217, 232, 240, 243, 249, 260, 265, 268, 269, 270, 272, 273, 276, 299, 305, 306, 307, 328, 330, 334, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 419, 454, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "anoth": [1, 2, 3, 8, 14, 17, 19, 20, 24, 26, 30, 50, 77, 82, 95, 101, 107, 114, 126, 129, 132, 135, 136, 137, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 209, 218, 220, 221, 223, 255, 261, 300, 330, 334, 347, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 457, 461, 463, 464, 465, 467, 468, 473, 474, 475, 476, 481], "wise": [1, 234], "requir": [1, 3, 4, 7, 8, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 101, 106, 107, 114, 115, 126, 129, 132, 136, 140, 144, 151, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 212, 216, 217, 230, 240, 252, 255, 260, 261, 262, 265, 267, 270, 272, 277, 295, 299, 300, 307, 327, 328, 330, 334, 350, 351, 352, 353, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 417, 419, 421, 455, 456, 458, 461, 462, 463, 464, 466, 467, 468, 470, 474, 475, 476, 478, 480, 481], "op": [1, 17, 33, 34, 36, 37, 38, 43, 51, 52, 53, 54, 57, 58, 59, 60, 82, 85, 86, 87, 88, 89, 235, 268, 274, 277, 292, 419, 439], "sinc": [1, 2, 3, 4, 5, 7, 11, 31, 35, 42, 47, 50, 55, 62, 65, 66, 69, 72, 77, 78, 79, 106, 107, 115, 120, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 162, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 218, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 343, 344, 346, 348, 349, 354, 357, 394, 396, 417, 419, 457, 461, 462, 463, 464, 466, 467, 468, 474, 476, 477, 478, 480, 481], "goal": [1, 3, 4, 144, 186, 254, 455, 461, 462, 463, 464, 475, 476], "policy_devic": [1, 15, 16, 18, 21, 22, 23, 25, 27, 462], "explicitli": [1, 2, 3, 4, 38, 83, 97, 98, 105, 109, 208, 315, 347, 427, 457, 462, 464, 469, 474, 475, 478], "do": [1, 2, 3, 4, 7, 57, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 192, 203, 205, 217, 241, 255, 260, 268, 269, 295, 299, 306, 308, 340, 351, 379, 394, 399, 419, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 478, 480, 481], "deepcopi": [1, 307, 379, 394, 474], "place": [1, 2, 3, 19, 32, 35, 41, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 100, 102, 109, 112, 114, 122, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 208, 216, 224, 240, 255, 261, 262, 265, 267, 268, 269, 272, 307, 328, 330, 334, 342, 346, 350, 394, 395, 396, 399, 434, 439, 440, 457, 462, 463, 467, 470, 474, 475, 476, 478], "instanti": [1, 2, 3, 15, 16, 27, 61, 62, 63, 67, 68, 69, 70, 78, 79, 82, 84, 95, 96, 106, 107, 109, 140, 143, 183, 187, 208, 230, 255, 306, 395, 399, 400, 401, 402, 403, 417, 461, 462, 467, 468, 470, 474, 475, 476, 478, 481], "all": [1, 2, 3, 4, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 91, 95, 96, 109, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 143, 144, 148, 149, 150, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 173, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 201, 203, 205, 211, 212, 215, 216, 220, 221, 223, 226, 232, 235, 236, 240, 248, 250, 252, 255, 256, 261, 262, 265, 267, 269, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 306, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 337, 342, 344, 346, 349, 350, 351, 353, 354, 357, 358, 361, 362, 364, 373, 377, 379, 381, 382, 383, 384, 386, 387, 391, 394, 395, 396, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 419, 433, 437, 440, 449, 450, 451, 454, 456, 457, 458, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 474, 475, 476, 478, 480, 481], "graph": [1, 3, 4, 8, 42, 65, 77, 127, 128, 142, 143, 328, 330, 334, 392, 393, 394, 461, 465, 476], "reli": [1, 2, 3, 11, 31, 66, 72, 177, 255, 293, 294, 295, 297, 298, 299, 332, 361, 381, 399, 457, 461, 463, 465, 467, 469, 476, 481], "third": [1, 236, 257, 344, 474, 475], "parti": 1, "try": [1, 2, 4, 7, 8, 9, 15, 16, 18, 21, 22, 23, 25, 27, 39, 40, 48, 61, 63, 70, 74, 84, 95, 96, 183, 395, 461, 462, 463, 464, 465, 468, 469, 474, 475, 476, 480, 481], "limit": [1, 2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 71, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 191, 212, 232, 361, 363, 378, 379, 381, 383, 394, 457, 461, 462, 464, 474, 475, 476], "chart": 1, "show": [1, 2, 11, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 272, 306, 328, 330, 334, 394, 396, 419, 461, 463, 464, 465, 474, 475, 476, 478, 480], "decis": [1, 2, 3, 281, 286, 314, 342, 367, 380, 456, 464, 466, 467, 474, 475, 478, 481], "multiprocess": [1, 2, 3, 14, 15, 16, 22, 23, 25, 69, 78, 79, 101, 109, 126, 133, 134, 156, 160, 165, 269, 270, 461, 462, 463, 464, 469, 474, 475, 476, 477, 481], "ensur": [1, 2, 3, 13, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 29, 35, 42, 47, 55, 62, 65, 66, 72, 77, 78, 84, 106, 107, 113, 126, 129, 132, 136, 141, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 212, 240, 253, 262, 265, 269, 270, 272, 295, 299, 328, 330, 334, 343, 363, 378, 381, 394, 396, 456, 462, 463, 476, 478], "flexibl": [1, 3, 9, 151, 388, 455, 457, 458, 461, 465, 478, 481], "extens": [1, 2, 62, 69, 78, 79, 115, 277, 458, 478], "mechan": [1, 4, 14, 17, 19, 24, 26, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 328, 330, 334, 394, 396, 462, 468, 476], "accommod": [1, 2, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 466, 467], "variou": [1, 2, 3, 14, 129, 177, 261, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 388, 394, 397, 419, 449, 450, 455, 461, 462, 463, 465, 466, 467, 468, 470, 474, 475, 478, 481], "deploy": [1, 465], "scenario": [1, 2, 19, 24, 26, 148, 149, 156, 170, 171, 217, 260, 417, 461, 467, 474, 475, 476], "facilit": [1, 2, 3, 7, 239, 240, 255, 265, 267, 339, 340, 341, 456, 461, 464, 467, 476], "weightupdaterbas": [1, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 455], "These": [1, 2, 7, 50, 71, 123, 170, 240, 267, 270, 330, 334, 455, 456, 457, 461, 463, 474, 475, 476, 478, 481], "base": [1, 3, 4, 8, 9, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 27, 35, 50, 62, 69, 72, 78, 79, 83, 111, 117, 120, 121, 123, 124, 126, 127, 128, 129, 132, 136, 140, 142, 143, 144, 150, 151, 152, 156, 157, 160, 165, 166, 167, 170, 177, 178, 179, 182, 185, 186, 187, 188, 194, 195, 196, 203, 217, 221, 245, 259, 261, 265, 266, 295, 299, 305, 307, 330, 334, 339, 345, 361, 362, 364, 365, 366, 368, 369, 370, 372, 377, 381, 382, 383, 384, 386, 387, 426, 437, 455, 456, 457, 458, 461, 462, 464, 466, 467, 468, 470, 474, 475, 476, 478, 481], "implement": [1, 2, 3, 9, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 67, 72, 73, 74, 77, 81, 82, 85, 86, 87, 88, 89, 104, 116, 117, 126, 129, 132, 136, 144, 150, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 216, 220, 221, 225, 228, 232, 234, 242, 243, 249, 253, 259, 261, 262, 263, 269, 270, 272, 273, 277, 279, 293, 294, 295, 296, 297, 298, 299, 323, 324, 325, 328, 330, 334, 361, 362, 364, 367, 368, 369, 375, 377, 379, 380, 381, 383, 384, 386, 394, 396, 417, 428, 442, 455, 456, 458, 461, 462, 463, 464, 465, 474, 475, 476, 480], "logic": [1, 3, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 455, 474], "allow": [1, 2, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 32, 35, 39, 40, 42, 47, 48, 55, 57, 59, 61, 63, 65, 66, 69, 70, 72, 73, 74, 77, 78, 79, 84, 95, 96, 101, 107, 109, 112, 114, 115, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 208, 209, 243, 270, 272, 273, 300, 328, 330, 334, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 388, 390, 394, 395, 396, 397, 455, 456, 458, 461, 463, 464, 465, 466, 467, 468, 474, 475, 476, 478, 480, 481], "tailor": [1, 185, 455, 480], "need": [1, 2, 3, 4, 7, 8, 10, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 32, 35, 41, 42, 47, 55, 61, 63, 65, 66, 72, 77, 82, 116, 120, 126, 129, 132, 136, 140, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 215, 217, 218, 227, 233, 240, 243, 256, 260, 261, 262, 267, 269, 270, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 308, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 347, 348, 349, 350, 354, 357, 360, 370, 383, 384, 394, 396, 398, 403, 419, 437, 451, 455, 456, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 478, 480, 481], "handl": [1, 2, 3, 14, 15, 16, 22, 25, 27, 35, 42, 47, 55, 57, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 268, 269, 270, 272, 299, 300, 328, 330, 331, 334, 361, 379, 381, 394, 396, 437, 449, 450, 455, 461, 462, 463, 464, 466, 468, 475, 478], "well": [1, 2, 3, 8, 27, 31, 35, 42, 47, 55, 62, 64, 65, 66, 69, 72, 77, 78, 79, 82, 107, 112, 116, 123, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 261, 262, 272, 273, 277, 282, 297, 319, 320, 328, 330, 334, 351, 379, 381, 386, 394, 396, 399, 403, 455, 456, 461, 462, 464, 465, 466, 467, 468, 470, 477, 478, 480, 481], "server": [1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "everi": [1, 3, 8, 15, 16, 17, 18, 21, 29, 35, 39, 40, 42, 47, 48, 55, 59, 62, 65, 66, 67, 68, 69, 72, 74, 77, 78, 79, 84, 109, 116, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 253, 254, 269, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 305, 306, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 363, 378, 379, 381, 394, 396, 437, 458, 461, 462, 463, 464, 466, 467, 474, 475, 476], "even": [1, 2, 3, 4, 8, 11, 16, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 77, 82, 85, 86, 87, 88, 89, 100, 101, 102, 103, 107, 114, 116, 118, 122, 126, 129, 132, 133, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 208, 461, 463, 466, 474, 475, 476, 481], "simplest": [1, 42, 65, 77, 120, 328, 330, 334, 354, 394, 461, 463, 464, 467, 474, 475, 478, 481], "vanillaweightupdat": 1, "dict": [1, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 55, 57, 58, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 98, 107, 109, 114, 115, 126, 129, 132, 133, 134, 135, 136, 137, 144, 148, 149, 151, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 168, 169, 170, 171, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 232, 255, 260, 262, 268, 269, 270, 272, 273, 279, 280, 281, 282, 283, 284, 285, 286, 291, 300, 314, 328, 330, 334, 347, 351, 364, 384, 386, 394, 395, 396, 419, 423, 424, 432, 437, 442, 443, 449, 450, 451, 456, 461, 462, 463, 478, 480, 481], "assum": [1, 2, 3, 6, 14, 15, 16, 17, 18, 24, 26, 30, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 71, 72, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 97, 98, 105, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 197, 211, 214, 219, 227, 240, 241, 248, 255, 262, 265, 267, 278, 295, 299, 327, 337, 354, 366, 370, 371, 384, 396, 397, 408, 409, 410, 411, 413, 414, 415, 416, 419, 461, 463, 473, 476], "divers": [1, 4, 156, 165], "abl": [1, 3, 50, 126, 147, 158, 159, 160, 166, 295, 299, 455, 461, 463, 464, 467, 473, 474, 475, 476, 478], "leav": [1, 2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 69, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 183, 185, 186, 187, 204, 249, 395, 457, 461, 469, 478], "untouch": [1, 180, 181, 184, 190, 191, 192, 193, 194, 209, 216, 220, 221, 225, 232, 234, 242, 243, 249, 253, 259, 261, 263, 270, 272, 396], "particularli": [1, 2, 3, 465, 480, 481], "benefici": [1, 2], "involv": [1, 135, 137, 138, 148, 149, 162, 209, 212, 260, 295, 299, 466, 468], "complex": [1, 2, 3, 14, 17, 19, 20, 24, 26, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396, 461, 462, 466, 467], "architectur": [1, 4, 286, 468, 474, 475, 480], "special": [1, 3, 86, 88, 187, 453, 455, 461, 464, 465, 481], "hardwar": [1, 3, 465], "By": [1, 2, 3, 18, 20, 39, 40, 48, 59, 74, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 148, 149, 156, 157, 158, 159, 160, 162, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 234, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 327, 351, 379, 394, 396, 427, 432, 451, 455, 457, 461, 464, 474, 477, 478, 481], "retriev": [1, 3, 14, 17, 20, 24, 26, 50, 61, 62, 63, 65, 67, 68, 69, 70, 78, 79, 84, 95, 96, 109, 112, 114, 115, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 190, 203, 213, 221, 224, 236, 276, 279, 302, 330, 334, 346, 347, 351, 354, 358, 361, 362, 363, 364, 366, 378, 381, 382, 384, 386, 387, 394, 395, 397, 399, 400, 401, 402, 451, 458, 462, 463, 467, 476, 481], "appli": [1, 2, 3, 4, 14, 17, 18, 24, 26, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 82, 85, 86, 87, 88, 89, 95, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 222, 224, 225, 226, 227, 228, 231, 232, 233, 235, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 268, 269, 272, 277, 293, 297, 307, 324, 328, 330, 334, 343, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 380, 381, 382, 383, 384, 386, 387, 394, 396, 399, 417, 433, 458, 461, 462, 463, 469, 474, 476, 480, 481], "seamless": [1, 2, 300], "integr": [1, 2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 285, 295, 299, 302, 328, 330, 334, 350, 394, 396, 456, 466, 467, 469, 474, 475, 476, 477], "infrastructur": [1, 3, 474, 475], "transit": [1, 35, 42, 47, 55, 65, 66, 72, 77, 107, 115, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 275, 277, 328, 330, 334, 356, 394, 396, 461, 464, 466, 467, 469, 474, 476, 478], "sampl": [1, 4, 8, 9, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 71, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 94, 100, 101, 102, 106, 107, 108, 109, 112, 113, 114, 115, 118, 120, 122, 126, 129, 132, 136, 144, 150, 153, 156, 157, 160, 165, 166, 167, 174, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 270, 272, 274, 276, 287, 292, 296, 302, 303, 304, 312, 314, 315, 316, 319, 324, 325, 328, 330, 334, 335, 338, 343, 344, 345, 347, 348, 349, 350, 351, 361, 362, 363, 364, 365, 366, 368, 378, 380, 381, 386, 387, 394, 396, 428, 434, 437, 440, 453, 456, 457, 461, 462, 463, 464, 465, 466, 467, 469, 471, 474, 475, 477, 480, 481], "attent": [1, 2, 8, 185, 212, 330, 334, 461, 464, 481], "given": [1, 2, 3, 15, 16, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 90, 91, 107, 109, 114, 115, 126, 129, 132, 136, 144, 150, 154, 155, 156, 157, 160, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 216, 222, 230, 236, 240, 255, 259, 261, 262, 263, 265, 267, 269, 270, 272, 274, 276, 278, 289, 290, 292, 293, 295, 297, 299, 302, 307, 318, 322, 328, 330, 334, 338, 343, 344, 346, 349, 350, 351, 352, 353, 355, 360, 365, 366, 368, 379, 394, 396, 398, 399, 400, 401, 402, 403, 405, 429, 432, 447, 456, 457, 458, 461, 462, 463, 466, 467, 468, 469, 470, 475, 476, 481], "built": [1, 2, 3, 5, 7, 109, 127, 128, 135, 142, 143, 153, 154, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 388, 394, 397, 445, 447, 448, 451, 461, 462, 463, 464, 465, 468, 470, 476, 478, 481], "flatten": [1, 29, 33, 34, 36, 37, 38, 39, 40, 43, 44, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 120, 183, 209, 227, 395, 396, 399, 434, 453, 464, 475], "suffici": [1, 3, 4, 461], "preprocess": [1, 2, 83, 261, 462, 465], "popul": [1, 2, 3, 15, 16, 18, 27, 29, 62, 67, 68, 69, 76, 78, 79, 109, 185, 231, 255, 287, 307, 379, 394, 455, 461, 463, 464, 467, 469, 476, 478], "replaybuff": [1, 2, 3, 15, 16, 18, 21, 27, 29, 44, 62, 67, 68, 75, 78, 79, 100, 101, 106, 107, 108, 109, 114, 115, 124, 212, 241, 245, 272, 366, 371, 397, 445, 447, 453, 463, 465, 469, 471, 474, 475, 477, 478, 480], "lazytensorstorag": [1, 2, 15, 16, 18, 21, 29, 62, 69, 77, 78, 79, 106, 114, 115, 120, 245, 272, 463, 465, 471, 474, 475, 478], "lambda": [1, 2, 15, 16, 18, 21, 27, 28, 29, 42, 50, 65, 69, 77, 84, 120, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 202, 209, 217, 218, 230, 232, 255, 263, 270, 272, 273, 278, 327, 328, 330, 334, 343, 346, 347, 348, 372, 374, 375, 386, 394, 399, 402, 410, 411, 415, 416, 417, 447, 457, 461, 462, 465, 474, 475, 477, 478, 480, 481], "reshap": [1, 2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 114, 120, 209, 295, 299, 300, 315, 417, 463, 474, 475], "slice": [1, 2, 3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 67, 68, 69, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 107, 109, 114, 115, 205, 211, 212, 478], "recommend": [1, 2, 4, 7, 15, 16, 18, 21, 22, 23, 25, 27, 61, 62, 63, 69, 70, 78, 79, 84, 95, 96, 114, 120, 140, 177, 178, 179, 182, 183, 212, 307, 332, 395, 457, 469, 474, 475], "achiev": [1, 2, 3, 4, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 254, 272, 278, 328, 330, 334, 347, 394, 396, 434, 458, 461, 462, 463, 464, 465, 474, 475, 476, 478, 480, 481], "creat": [1, 2, 3, 4, 5, 6, 7, 10, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 101, 103, 109, 120, 126, 129, 132, 133, 136, 140, 144, 156, 157, 158, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 203, 209, 212, 217, 230, 240, 260, 261, 262, 265, 268, 269, 270, 272, 279, 280, 282, 283, 284, 285, 286, 287, 291, 295, 299, 300, 301, 305, 306, 328, 330, 332, 334, 342, 350, 351, 358, 364, 366, 371, 382, 384, 394, 395, 396, 397, 419, 434, 441, 442, 443, 447, 449, 450, 455, 456, 461, 462, 463, 464, 465, 467, 470, 474, 475, 476, 477, 478, 480, 481], "multidimension": [1, 2, 78, 106, 107, 478], "slicesampl": [1, 2, 107, 115, 212, 478], "sampler": [1, 2, 62, 67, 68, 69, 78, 79, 100, 101, 102, 103, 106, 107, 108, 109, 112, 113, 114, 115, 116, 118, 120, 122, 212, 241, 315, 366, 371, 397, 461, 463, 474, 475, 478], "One": [1, 2, 3, 4, 8, 33, 34, 38, 39, 40, 43, 48, 53, 54, 59, 60, 74, 83, 120, 126, 127, 128, 156, 160, 165, 166, 212, 245, 265, 274, 312, 350, 354, 385, 390, 423, 461, 462, 478, 481], "must": [1, 2, 3, 7, 11, 15, 16, 18, 19, 20, 21, 22, 23, 25, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 100, 101, 102, 103, 107, 109, 114, 115, 116, 117, 118, 120, 122, 126, 127, 129, 132, 133, 136, 142, 144, 154, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 170, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 205, 208, 209, 212, 215, 217, 218, 224, 228, 230, 232, 234, 236, 238, 249, 252, 254, 255, 256, 259, 260, 262, 263, 264, 269, 272, 279, 280, 289, 295, 299, 300, 303, 304, 305, 306, 318, 328, 330, 334, 338, 343, 344, 346, 347, 348, 349, 350, 351, 354, 355, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 385, 386, 387, 394, 396, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 421, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 457, 461, 462, 463, 464, 467, 473, 476, 478], "shape": [1, 2, 3, 15, 16, 18, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 100, 101, 102, 106, 109, 114, 120, 122, 126, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 147, 148, 149, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 172, 177, 178, 179, 182, 183, 184, 185, 186, 187, 190, 197, 203, 205, 209, 211, 213, 220, 223, 224, 225, 230, 232, 233, 236, 238, 242, 243, 245, 249, 252, 253, 255, 258, 263, 269, 271, 272, 276, 278, 281, 282, 283, 284, 285, 286, 287, 288, 291, 293, 294, 295, 297, 298, 299, 300, 302, 303, 304, 305, 306, 308, 312, 313, 314, 315, 316, 317, 318, 323, 324, 326, 328, 330, 331, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 390, 394, 395, 397, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 428, 434, 437, 447, 456, 457, 461, 462, 463, 464, 465, 467, 468, 471, 473, 474, 475, 477, 478, 480, 481], "clearli": [1, 2], "practic": [1, 2, 3, 4, 5, 8, 29, 57, 261, 296, 324, 325, 360, 454, 461, 462, 463, 464, 465, 468, 474, 475, 477, 481], "dimension": [1, 62, 66, 69, 77, 78, 79, 185, 222, 295, 299, 399, 404, 412, 457, 475], "num_slic": [1, 2, 107, 114, 115, 478], "4": [1, 2, 3, 7, 33, 35, 39, 40, 44, 48, 50, 53, 54, 55, 59, 62, 65, 67, 68, 69, 71, 72, 74, 75, 77, 78, 79, 100, 101, 102, 109, 114, 115, 122, 126, 127, 128, 129, 130, 131, 132, 136, 142, 143, 144, 145, 146, 147, 150, 152, 156, 157, 160, 163, 164, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 205, 206, 208, 209, 212, 217, 218, 224, 245, 252, 253, 254, 260, 269, 270, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 289, 290, 291, 292, 293, 294, 297, 298, 300, 302, 303, 304, 305, 306, 310, 311, 312, 314, 315, 316, 317, 318, 326, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 353, 355, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 417, 418, 455, 456, 460, 461, 462, 463, 464, 470, 474, 475, 476, 478, 479, 480, 481], "trajectory_kei": [1, 31, 114, 115], "traj_id": [1, 2, 3, 15, 16, 18, 29, 31, 44, 75, 209, 245, 469, 478], "total_fram": [1, 2, 15, 16, 18, 21, 22, 23, 25, 27, 29, 44, 55, 67, 75, 209, 212, 245, 437, 440, 447, 458, 461, 462, 463, 464, 465, 469, 471, 474, 475, 478, 480], "dim": [1, 2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 69, 70, 73, 74, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 114, 183, 196, 212, 213, 234, 238, 251, 252, 255, 264, 269, 298, 322, 327, 346, 395, 451, 457, 462, 463, 465, 474, 476, 478], "ndim": [1, 2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 69, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 100, 102, 106, 107, 120, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 234, 272, 346], "parallelenv": [1, 2, 3, 15, 16, 18, 21, 25, 29, 120, 126, 129, 132, 136, 144, 151, 157, 158, 159, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 260, 270, 295, 299, 417, 448, 453, 461, 462, 463, 466, 473, 480, 481], "make_env": [1, 3, 156, 165, 171, 260, 269, 270, 417, 442, 443, 461, 462, 480, 481], "regular": [1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 61, 63, 70, 84, 95, 96, 106, 112, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 272, 275, 277, 288, 295, 299, 318, 344, 348, 349, 350, 351, 371, 381, 395, 396, 439, 453, 458, 461, 462, 465, 466, 467, 471, 478, 481], "behav": [1, 3, 138, 150, 293, 297, 312, 369, 377, 379, 394, 465, 477], "accordingli": [1, 2, 3, 107, 218, 234, 253, 254, 297, 348, 464], "3": [1, 2, 3, 6, 7, 10, 11, 15, 16, 18, 21, 27, 29, 33, 34, 35, 38, 39, 40, 42, 43, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 77, 78, 79, 84, 95, 96, 100, 102, 107, 109, 114, 115, 120, 122, 126, 129, 130, 131, 132, 135, 136, 137, 138, 139, 144, 147, 148, 149, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 206, 208, 209, 212, 216, 217, 218, 222, 224, 225, 230, 232, 236, 238, 240, 242, 243, 245, 248, 249, 252, 253, 254, 255, 258, 260, 261, 262, 263, 265, 267, 270, 272, 273, 275, 276, 278, 279, 280, 282, 283, 284, 286, 289, 291, 293, 294, 295, 297, 298, 299, 300, 302, 303, 305, 306, 307, 312, 315, 317, 327, 328, 330, 334, 338, 339, 340, 341, 343, 344, 347, 349, 350, 353, 354, 355, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 373, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 405, 408, 409, 410, 411, 413, 414, 415, 416, 417, 419, 436, 456, 458, 460, 461, 462, 463, 464, 466, 467, 469, 470, 474, 475, 476, 478, 479, 480, 481], "isn": [1, 2, 3, 8, 15, 16, 18, 21, 22, 23, 25, 27, 61, 63, 70, 84, 95, 96, 106, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 183, 185, 186, 187, 208, 224, 230, 343, 350, 395, 399, 467, 468, 470, 474, 475], "current": [1, 2, 3, 12, 14, 15, 16, 17, 24, 26, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 104, 107, 109, 115, 126, 129, 132, 136, 138, 144, 151, 154, 155, 156, 157, 160, 165, 166, 167, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 208, 209, 212, 230, 241, 254, 255, 256, 260, 261, 262, 270, 272, 290, 316, 320, 324, 328, 330, 332, 334, 335, 346, 361, 363, 364, 371, 378, 381, 383, 384, 394, 395, 396, 399, 422, 458, 461, 462, 463, 464, 468, 474, 475, 476, 478, 481], "fulli": [1, 8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 294, 298, 328, 330, 334, 394, 396, 462, 465, 468, 476, 478], "ani": [1, 2, 3, 5, 8, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 98, 99, 100, 101, 102, 103, 109, 110, 113, 115, 116, 118, 120, 121, 122, 124, 125, 126, 129, 132, 133, 136, 137, 144, 151, 156, 157, 158, 159, 160, 165, 166, 167, 168, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 227, 228, 230, 231, 232, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 272, 278, 279, 280, 286, 287, 300, 309, 315, 328, 330, 334, 342, 346, 350, 351, 352, 353, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 399, 401, 402, 417, 419, 424, 437, 454, 457, 461, 462, 463, 464, 465, 467, 468, 474, 475, 476, 478, 480, 481], "consecut": [1, 3, 113, 140, 299, 316, 419, 464, 466, 469, 475, 478, 481], "won": [1, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 133, 135, 136, 144, 151, 152, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 240, 267, 272, 328, 330, 334, 361, 394, 395, 396, 437, 451, 462, 463, 466, 467], "therebi": [1, 32, 417, 457, 461, 462], "interrupt": [1, 2, 136, 187, 346, 405], "start": [1, 2, 3, 4, 5, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 32, 50, 67, 82, 83, 84, 107, 114, 115, 126, 129, 132, 133, 136, 141, 144, 147, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 219, 433, 460, 461, 462, 465, 472, 475, 476, 478, 479, 481], "get": [1, 2, 3, 4, 6, 7, 8, 9, 12, 39, 40, 42, 48, 50, 61, 62, 63, 65, 66, 69, 70, 72, 74, 77, 84, 95, 96, 100, 102, 107, 114, 115, 116, 118, 120, 122, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 206, 211, 213, 217, 220, 222, 223, 232, 236, 241, 254, 255, 258, 262, 269, 270, 292, 328, 330, 331, 334, 338, 347, 348, 351, 358, 394, 395, 399, 400, 401, 402, 403, 419, 423, 456, 457, 460, 461, 462, 463, 464, 465, 472, 474, 475, 476, 478, 479, 480, 481], "rid": [1, 42, 65, 77, 328, 330, 334, 394], "natur": [1, 2, 3, 13, 22, 23, 25, 461, 467, 468, 469, 478], "background": [1, 13, 15, 16, 21, 22, 23, 25, 478], "simpli": [1, 3, 6, 61, 63, 70, 83, 84, 95, 96, 118, 120, 125, 183, 189, 225, 249, 268, 379, 394, 395, 399, 456, 457, 461, 463, 468, 474, 475, 481], "replay_buff": [1, 2, 8, 15, 16, 18, 21, 27, 29, 62, 67, 68, 69, 78, 79, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 212, 434, 447, 461, 462, 463, 469, 474, 475, 478], "rb": [1, 2, 15, 16, 18, 21, 29, 44, 62, 67, 68, 69, 75, 78, 79, 101, 106, 107, 109, 114, 115, 120, 212, 245, 272, 462, 464, 465, 469, 471, 475, 477, 478, 480], "paus": [1, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29], "sleep": [1, 15, 16, 18, 21, 29, 67, 133, 481], "10": [1, 2, 3, 7, 28, 31, 33, 34, 35, 38, 42, 43, 50, 51, 55, 62, 67, 68, 69, 71, 77, 78, 79, 80, 83, 84, 100, 101, 102, 106, 109, 114, 115, 120, 122, 126, 127, 128, 129, 132, 133, 136, 142, 143, 144, 150, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 190, 192, 205, 206, 209, 211, 212, 217, 218, 254, 256, 257, 258, 269, 270, 272, 276, 278, 281, 282, 284, 286, 288, 292, 293, 294, 295, 297, 298, 299, 302, 303, 304, 314, 316, 327, 347, 351, 354, 358, 362, 366, 368, 375, 381, 382, 383, 387, 397, 399, 400, 401, 402, 405, 419, 428, 458, 461, 462, 463, 464, 465, 466, 467, 471, 474, 476, 478, 480, 481], "i": [1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 39, 40, 42, 44, 47, 48, 55, 62, 65, 66, 69, 72, 74, 75, 77, 79, 80, 84, 100, 102, 106, 107, 114, 115, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 218, 219, 234, 240, 245, 248, 260, 262, 267, 272, 294, 295, 298, 299, 318, 328, 330, 334, 337, 344, 346, 347, 349, 350, 351, 361, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 396, 399, 400, 401, 402, 428, 440, 455, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 474, 475, 476, 478, 480, 481], "rang": [1, 2, 3, 4, 8, 62, 67, 68, 69, 71, 78, 79, 100, 102, 109, 120, 126, 129, 132, 133, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 245, 258, 269, 272, 273, 294, 298, 315, 333, 378, 386, 387, 457, 458, 461, 463, 464, 465, 468, 469, 471, 474, 475, 476, 478, 480], "optim_step": [1, 276, 302, 465, 471], "rest": [1, 15, 16, 21, 42, 277, 456, 463, 464, 474, 476, 480], "multithread": [1, 2, 3, 62, 69, 78, 79, 94, 151, 152, 469, 478], "mind": [1, 3, 107, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 474, 475], "gil": 1, "relat": [1, 2, 3, 4, 10, 62, 156, 182, 227, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 462, 471, 476], "restrict": [1, 2, 3, 457, 462, 477, 478, 481], "hand": [1, 2, 3, 7, 27, 39, 474, 475, 476], "let": [1, 2, 3, 6, 7, 11, 31, 35, 42, 47, 50, 55, 62, 65, 66, 69, 72, 77, 78, 79, 80, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 272, 305, 306, 328, 330, 334, 343, 394, 396, 432, 455, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "child": [1, 20, 35, 42, 47, 50, 55, 65, 66, 72, 77, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 462], "fill": [1, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 136, 187, 208, 255, 268, 299, 464, 476, 477], "truli": [1, 268, 480], "decoupl": [1, 13, 15, 16, 18, 21, 22, 23, 25, 29, 461, 468, 480], "been": [1, 2, 3, 5, 7, 8, 12, 22, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 71, 73, 74, 82, 85, 86, 87, 88, 89, 109, 113, 126, 129, 132, 136, 140, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 191, 232, 253, 254, 261, 262, 293, 295, 297, 299, 307, 346, 361, 379, 381, 383, 394, 461, 462, 463, 464, 473, 474, 475, 476, 478, 480, 481], "shut": [1, 13, 15, 16, 18, 21, 22, 23, 25, 29, 160, 166], "down": [1, 4, 13, 15, 16, 18, 21, 22, 23, 25, 29, 160, 166, 457, 464, 466], "async_shutdown": [1, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 67], "mean": [1, 2, 3, 4, 7, 15, 16, 17, 18, 21, 22, 23, 25, 27, 29, 61, 63, 70, 78, 82, 84, 95, 96, 101, 106, 107, 114, 115, 120, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 208, 236, 260, 269, 270, 274, 275, 276, 287, 290, 293, 295, 297, 299, 302, 314, 315, 323, 324, 347, 351, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 399, 400, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 456, 457, 461, 462, 463, 465, 467, 474, 475, 476, 478, 481], "drastic": [1, 143, 156, 478], "load": [1, 2, 6, 7, 15, 16, 18, 21, 29, 35, 42, 44, 47, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 83, 84, 95, 96, 98, 100, 101, 102, 103, 109, 116, 117, 118, 122, 123, 126, 129, 131, 132, 136, 144, 156, 157, 160, 165, 166, 167, 168, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 269, 270, 272, 328, 330, 334, 394, 395, 396, 437, 451, 455, 458, 461, 463, 465, 478], "factor": [1, 8, 11, 32, 42, 55, 245, 272, 274, 275, 292, 296, 309, 316, 324, 325, 362, 368, 371, 372, 374, 385, 405, 461, 462, 465, 467, 471, 474, 475, 478, 481], "signific": [1, 3, 5, 8, 463, 480, 481], "understand": [1, 2, 8, 13, 22, 23, 25, 42, 461, 462, 465, 466, 467, 474, 475], "affect": [1, 3, 8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 218, 262, 270, 272, 328, 330, 334, 394, 396, 399, 400, 401, 402, 474], "algorithm": [1, 2, 3, 8, 9, 13, 22, 23, 25, 150, 205, 252, 361, 381, 382, 384, 453, 457, 458, 461, 462, 463, 464, 465, 467, 468, 469, 470, 474, 475, 477, 478, 480], "legitim": [1, 457, 481], "unless": [1, 2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 97, 113, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 270, 272, 277, 328, 330, 334, 361, 362, 364, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 463], "benchmark": [1, 2, 3, 9, 127, 128, 136, 142, 143, 187], "tool": [1, 2, 3, 5, 192, 455, 456, 457, 464, 466, 474, 476, 478, 481], "backend": [1, 3, 7, 15, 16, 18, 21, 22, 23, 27, 28, 29, 84, 126, 129, 132, 135, 136, 144, 156, 157, 160, 165, 166, 167, 176, 177, 178, 179, 182, 185, 186, 187, 202, 273, 334, 455, 458, 461, 463, 464, 465, 466, 469, 470, 476], "gloo": [1, 22, 23, 28], "nccl": [1, 22, 23, 332], "mpi": [1, 22, 23], "distributeddatacollector": [1, 24, 28, 453], "rpc": [1, 25, 26, 28, 68], "rpcdatacollector": [1, 26, 28, 453], "launcher": [1, 22, 23, 25, 28], "rai": [1, 17, 18, 27, 29, 30, 62, 67, 68, 69, 78, 79, 109, 331, 333], "submitit": [1, 22, 23, 25, 28], "mode": [1, 3, 6, 13, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 141, 144, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 220, 223, 254, 262, 269, 270, 272, 277, 287, 295, 296, 299, 304, 312, 323, 324, 325, 328, 330, 334, 337, 347, 351, 379, 394, 396, 417, 427, 432, 456, 457, 461, 462, 474, 475, 480, 481], "find": [1, 4, 6, 7, 22, 23, 25, 62, 64, 80, 114, 115, 274, 297, 316, 431, 435, 461, 462, 465, 467, 468, 474, 475], "folder": [1, 2, 61, 63, 70, 84, 95, 96, 170, 183, 212, 395, 462], "machin": [1, 2, 7, 22, 23, 25, 55, 140, 474, 475, 480], "wonder": 1, "why": [1, 2, 3, 203, 457, 474, 476, 481], "instead": [1, 2, 3, 4, 7, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 35, 38, 42, 47, 55, 65, 66, 67, 72, 77, 81, 84, 126, 129, 132, 136, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 227, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 350, 354, 357, 361, 363, 364, 366, 369, 370, 371, 377, 378, 381, 382, 383, 384, 394, 396, 397, 399, 403, 407, 451, 457, 465, 466, 467, 471, 476, 478, 481], "lower": [1, 2, 3, 27, 35, 36, 215, 269, 270, 319, 320, 354, 463, 474, 476], "io": [1, 11, 142, 143, 151, 154, 155, 168, 169, 297, 298, 465], "footprint": [1, 2, 478], "commun": [1, 2, 3, 24, 26, 144, 156, 160, 165, 186, 332, 454, 463, 481], "yet": [1, 127, 128, 142, 396, 477], "plai": [1, 3, 158, 159, 167, 177, 212, 462, 463, 468, 478, 481], "role": [1, 3, 95, 149, 177, 179, 182, 462, 468, 481], "opposit": [1, 474], "direct": [1, 2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 293, 297, 328, 330, 334, 379, 394, 396, 462, 468], "faster": [1, 2, 4, 31, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 151, 303, 399, 400, 401, 402, 464, 465, 474, 475], "share": [1, 3, 6, 8, 15, 16, 18, 21, 29, 31, 61, 63, 69, 70, 78, 79, 82, 84, 95, 96, 98, 100, 101, 102, 103, 107, 109, 110, 114, 116, 118, 122, 133, 156, 165, 183, 252, 260, 269, 270, 295, 299, 305, 306, 339, 340, 341, 361, 362, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 395, 451, 453, 456, 457, 463, 465, 471, 473, 474, 475, 480, 481], "among": [1, 3, 57, 158, 159, 260, 370, 384, 457, 474, 475], "prohibit": [1, 3, 18, 120], "slow": [1, 3, 4, 11, 61, 63, 70, 84, 95, 96, 101, 114, 115, 183, 395], "compar": [1, 3, 120, 362, 364, 377, 382, 384, 386, 387, 432, 457, 461, 463, 465, 467, 468, 474, 475, 478, 481], "gpu": [1, 7, 8, 35, 42, 47, 55, 65, 66, 72, 77, 100, 102, 122, 126, 129, 132, 136, 137, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 461, 463, 464, 474, 475, 481], "driver": [1, 7], "keyword": [1, 2, 3, 11, 14, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 100, 101, 102, 106, 107, 109, 112, 114, 115, 118, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 148, 149, 151, 152, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 205, 206, 208, 209, 211, 212, 213, 215, 216, 217, 218, 221, 224, 225, 226, 228, 230, 231, 232, 234, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 273, 274, 275, 278, 292, 295, 299, 303, 304, 305, 306, 316, 328, 330, 331, 334, 338, 342, 343, 346, 347, 348, 350, 351, 354, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 375, 376, 377, 378, 380, 381, 382, 383, 384, 386, 387, 389, 394, 395, 396, 397, 399, 400, 401, 402, 403, 407, 417, 419, 424, 426, 437, 448, 461, 462, 463, 465, 467, 470, 474, 475, 478, 480, 481], "build": [1, 2, 3, 7, 31, 35, 39, 42, 47, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 82, 109, 126, 127, 128, 129, 132, 136, 137, 138, 142, 143, 144, 148, 149, 151, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 245, 269, 270, 272, 276, 302, 328, 330, 334, 345, 347, 351, 394, 396, 437, 444, 445, 446, 456, 457, 458, 463, 464, 465, 467, 468, 469, 470, 474, 475, 476, 477, 480, 481], "mani": [1, 2, 3, 4, 69, 127, 128, 130, 131, 132, 135, 137, 138, 142, 143, 151, 152, 162, 185, 190, 255, 361, 363, 370, 378, 381, 394, 456, 461, 462, 463, 465, 466, 467, 469, 471, 474, 475, 476, 478, 480, 481], "eg": [1, 2, 3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 102, 103, 116, 118, 122, 126, 129, 130, 131, 132, 135, 136, 137, 138, 140, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 222, 253, 262, 273, 305, 342, 395, 419], "gymnasium": [1, 2, 3, 5, 15, 16, 18, 21, 29, 77, 126, 129, 132, 135, 136, 137, 141, 144, 145, 146, 156, 157, 160, 165, 166, 167, 176, 177, 178, 179, 182, 185, 186, 187, 202, 225, 249, 253, 268, 273, 462, 463, 465, 476, 480], "warn": [1, 3, 66, 72, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 269, 274, 292, 316, 427, 462], "quickli": [1, 3, 462, 474, 475, 481], "becom": [1, 2, 3, 4, 27, 293, 297, 474, 475, 481], "quit": [1, 3, 11, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 461, 462, 463, 465, 467, 474, 475, 481], "annoi": [1, 3], "filter": [1, 2, 3, 4, 83, 107, 114, 115, 361, 362, 364, 365, 369, 370, 377, 381, 382, 384, 466], "out": [1, 2, 3, 4, 5, 9, 14, 17, 19, 20, 24, 26, 27, 30, 35, 42, 47, 50, 55, 61, 63, 65, 66, 70, 72, 77, 83, 84, 95, 96, 98, 107, 114, 115, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 252, 255, 272, 274, 293, 294, 297, 303, 304, 307, 308, 309, 328, 330, 334, 338, 342, 343, 344, 347, 348, 349, 350, 351, 379, 392, 393, 394, 395, 396, 457, 458, 461, 462, 463, 464, 465, 466, 467, 469, 474, 475, 476, 478, 480, 481], "still": [1, 2, 3, 9, 42, 65, 77, 84, 85, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 260, 316, 328, 330, 334, 378, 379, 394, 457, 461, 462, 464, 473, 476, 478, 481], "wish": [1, 3, 11, 15, 16, 21, 202, 468, 478], "displai": [1, 3, 7, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 437, 458, 461, 462, 475, 476], "filter_warnings_subprocess": [1, 3], "fals": [1, 2, 3, 11, 12, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 109, 110, 112, 113, 114, 115, 116, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 197, 203, 204, 205, 206, 208, 209, 212, 213, 216, 218, 220, 223, 224, 225, 227, 230, 231, 232, 234, 235, 236, 238, 240, 241, 242, 243, 245, 247, 248, 249, 252, 253, 255, 258, 259, 260, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 275, 276, 278, 279, 280, 282, 288, 289, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304, 305, 306, 307, 316, 317, 318, 324, 325, 326, 328, 330, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 361, 362, 363, 364, 365, 366, 368, 369, 370, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 397, 399, 400, 401, 402, 408, 409, 410, 411, 413, 414, 415, 416, 417, 419, 426, 427, 430, 431, 432, 434, 435, 437, 451, 456, 457, 458, 461, 462, 463, 465, 470, 471, 473, 474, 475, 476, 477, 480, 481], "central": [2, 14, 20, 24, 26, 305, 306, 307, 461, 462, 466, 474, 475, 478], "part": [2, 3, 4, 8, 35, 42, 47, 55, 65, 66, 71, 72, 77, 84, 126, 127, 129, 132, 136, 142, 144, 154, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 211, 236, 245, 248, 272, 328, 330, 334, 355, 394, 396, 428, 451, 455, 457, 461, 463, 464, 465, 471, 474, 476, 481], "wide": [2, 3, 5, 480], "give": [2, 3, 7, 78, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 363, 378, 381, 454, 455, 457, 461, 462, 465, 474, 475, 476, 477, 480], "abil": [2, 379, 476, 478], "panel": [2, 463], "usag": [2, 3, 5, 7, 15, 16, 18, 21, 22, 23, 25, 27, 42, 65, 77, 98, 120, 178, 209, 212, 224, 277, 295, 299, 328, 330, 334, 364, 369, 377, 384, 388, 394, 456, 461, 463, 464, 467, 468, 470, 474, 475, 478], "includ": [2, 3, 4, 7, 9, 27, 35, 42, 47, 55, 65, 66, 72, 77, 82, 84, 97, 98, 100, 101, 102, 103, 105, 116, 118, 122, 126, 129, 132, 136, 144, 150, 154, 155, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 227, 230, 254, 260, 262, 269, 270, 272, 295, 299, 328, 330, 334, 361, 364, 379, 384, 394, 396, 440, 455, 456, 458, 461, 462, 463, 464, 465, 474, 475, 476, 478, 481], "almost": [2, 270, 303, 304, 464], "physic": [2, 6, 7, 98, 156, 157, 162, 458, 461, 474, 475, 476], "theori": 2, "crude": 2, "made": [2, 3, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 100, 101, 102, 103, 116, 118, 122, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 255, 272, 307, 316, 328, 330, 334, 366, 379, 394, 396, 397, 461, 462, 464, 474, 475, 477, 478, 480], "liststorag": [2, 50, 62, 67, 68, 69, 77, 78, 79, 101, 109, 478], "veri": [2, 3, 142, 143, 182, 462, 466, 469, 474, 476, 478, 480, 481], "ineffici": [2, 4], "tensor": [2, 8, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 109, 110, 112, 114, 115, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 142, 143, 144, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 197, 203, 204, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 222, 223, 224, 225, 227, 230, 231, 233, 236, 238, 240, 241, 242, 243, 245, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 267, 269, 270, 272, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 312, 313, 314, 315, 316, 317, 318, 321, 322, 323, 324, 325, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 357, 359, 361, 362, 364, 365, 366, 368, 369, 370, 373, 374, 377, 379, 381, 382, 383, 384, 386, 387, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 474, 475, 476, 480, 481], "contigu": [2, 3, 8, 36, 39, 47, 85, 101, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 230, 233, 255, 263, 476, 478, 480], "tensorstorag": [2, 69, 77, 100, 106, 107, 120, 123, 469, 478], "lazymemmapstorag": [2, 44, 62, 67, 68, 69, 75, 78, 79, 107, 109, 114, 115, 211, 212, 461, 462, 464, 469, 474, 477, 478], "class": [2, 5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 132, 133, 134, 135, 136, 137, 138, 143, 144, 147, 150, 153, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 449, 450, 451, 453, 456, 457, 458, 461, 462, 463, 464, 466, 467, 468, 469, 470, 474, 475, 478, 481], "citizen": 2, "pytre": [2, 62, 67, 68, 69, 78, 79, 103, 109, 123], "tupl": [2, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 98, 103, 107, 109, 114, 118, 120, 126, 129, 130, 131, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 230, 232, 236, 272, 278, 282, 288, 289, 295, 298, 299, 300, 307, 314, 317, 318, 328, 330, 334, 343, 344, 348, 349, 354, 361, 362, 363, 364, 365, 369, 370, 372, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 399, 400, 401, 402, 431, 432, 435, 444, 478, 480], "dictionari": [2, 14, 15, 16, 18, 21, 22, 23, 24, 25, 27, 29, 35, 39, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 83, 84, 95, 96, 107, 112, 114, 115, 126, 129, 132, 135, 136, 137, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 255, 260, 262, 270, 272, 328, 330, 334, 347, 351, 364, 384, 386, 394, 395, 396, 432, 449, 450, 451, 458, 462, 463, 466, 468, 474, 476, 481], "nest": [2, 3, 31, 35, 39, 40, 42, 44, 46, 47, 48, 55, 56, 61, 63, 65, 66, 69, 70, 72, 74, 75, 76, 77, 84, 90, 95, 96, 100, 101, 102, 105, 109, 122, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 204, 212, 253, 256, 260, 272, 328, 330, 334, 346, 394, 395, 396, 399, 400, 401, 402, 403, 417, 427, 458, 462, 463, 465, 475, 476, 478, 480], "construct": [2, 3, 5, 31, 35, 42, 47, 55, 62, 65, 66, 69, 72, 77, 78, 79, 82, 109, 126, 129, 132, 133, 135, 136, 144, 156, 157, 158, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 220, 223, 270, 272, 295, 299, 320, 328, 330, 334, 351, 394, 396, 437, 455, 456, 462, 463, 464, 467, 474, 476, 478, 481], "ram": [2, 135, 137, 470, 478], "prealloc": [2, 3, 156, 165, 476], "ve": [2, 71, 461, 464, 471], "extend": [2, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 44, 50, 62, 65, 67, 68, 69, 75, 78, 79, 84, 99, 100, 103, 106, 107, 109, 110, 114, 115, 118, 120, 121, 124, 125, 180, 181, 184, 190, 191, 192, 193, 194, 205, 211, 245, 261, 272, 275, 379, 394, 396, 434, 453, 455, 457, 458, 461, 462, 463, 464, 465, 469, 471, 474, 475, 477, 478, 480], "here": [2, 3, 4, 7, 8, 9, 10, 15, 16, 27, 120, 126, 129, 130, 131, 132, 136, 140, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 192, 212, 260, 307, 330, 426, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 467, 469, 471, 474, 475, 476, 478, 480, 481], "add": [2, 3, 4, 6, 27, 35, 39, 40, 42, 47, 48, 50, 55, 62, 65, 66, 67, 68, 69, 72, 74, 77, 78, 79, 95, 99, 101, 106, 109, 110, 120, 121, 124, 125, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 230, 232, 259, 262, 272, 295, 299, 308, 328, 330, 334, 345, 361, 394, 396, 433, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 478, 480], "string": [2, 22, 23, 25, 35, 42, 47, 50, 55, 57, 64, 65, 66, 72, 77, 83, 84, 94, 101, 126, 129, 132, 136, 144, 148, 154, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 202, 230, 240, 253, 259, 267, 272, 295, 299, 328, 330, 334, 343, 346, 347, 348, 360, 394, 396, 418, 436, 457, 461, 463, 464, 478], "element": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 31, 33, 50, 51, 53, 59, 61, 62, 63, 67, 68, 69, 70, 77, 78, 79, 82, 84, 95, 96, 100, 101, 102, 103, 106, 107, 109, 114, 115, 120, 122, 126, 129, 132, 136, 144, 153, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 190, 205, 212, 217, 218, 241, 250, 254, 255, 270, 274, 279, 280, 293, 294, 297, 337, 338, 343, 346, 350, 351, 355, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 399, 428, 455, 457, 461, 463, 467, 469, 478, 481], "30": [2, 3, 69, 77, 114, 115, 208, 235, 319, 320, 417, 421, 424, 426, 469, 475, 476, 478], "none": [2, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 100, 101, 102, 103, 105, 106, 107, 109, 112, 114, 115, 116, 118, 120, 122, 126, 129, 132, 133, 135, 136, 144, 147, 148, 149, 150, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 197, 198, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 219, 220, 221, 223, 227, 229, 230, 232, 233, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 316, 317, 318, 324, 326, 327, 328, 330, 332, 334, 337, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 375, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 423, 424, 425, 431, 432, 433, 434, 435, 436, 437, 441, 442, 443, 444, 446, 447, 449, 450, 451, 456, 458, 461, 462, 464, 465, 476, 478, 480], "int": [2, 3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 99, 100, 101, 102, 103, 106, 107, 108, 109, 110, 112, 114, 115, 116, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 156, 157, 158, 159, 160, 162, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 196, 197, 205, 207, 208, 209, 211, 212, 213, 214, 216, 219, 222, 227, 228, 230, 234, 235, 236, 238, 240, 241, 244, 251, 252, 253, 256, 259, 260, 262, 264, 267, 272, 274, 275, 276, 279, 280, 281, 282, 284, 286, 287, 289, 290, 291, 292, 293, 294, 296, 297, 298, 300, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 316, 317, 318, 319, 320, 322, 323, 324, 326, 327, 328, 330, 331, 332, 334, 342, 343, 344, 346, 347, 349, 351, 361, 362, 363, 370, 372, 373, 378, 379, 380, 381, 382, 386, 387, 394, 395, 396, 399, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416, 418, 419, 421, 424, 426, 428, 429, 430, 432, 434, 437, 439, 449, 450, 451, 465, 476, 478], "entri": [2, 3, 15, 16, 21, 31, 35, 39, 40, 42, 44, 47, 48, 50, 55, 61, 63, 64, 65, 66, 70, 72, 74, 75, 77, 83, 84, 91, 95, 96, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 148, 149, 156, 157, 160, 162, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 208, 212, 214, 215, 218, 219, 220, 221, 223, 224, 227, 231, 233, 234, 236, 238, 240, 243, 245, 248, 250, 252, 253, 254, 255, 257, 260, 262, 264, 267, 269, 272, 295, 303, 304, 328, 330, 334, 342, 343, 346, 348, 349, 362, 364, 384, 394, 395, 396, 399, 400, 401, 402, 456, 461, 463, 464, 466, 467, 468, 470, 474, 475, 476, 477, 478, 480, 481], "onto": [2, 8, 59, 61, 63, 70, 84, 95, 96, 183, 197, 221, 274, 316, 338, 343, 344, 347, 348, 349, 350, 351, 395, 399, 464, 476], "__setitem__": 2, "indic": [2, 3, 8, 15, 16, 17, 18, 21, 22, 23, 25, 27, 31, 33, 34, 36, 37, 38, 39, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 71, 73, 74, 75, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 99, 106, 107, 109, 110, 112, 113, 114, 115, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 151, 152, 156, 157, 160, 162, 165, 166, 167, 170, 171, 177, 178, 179, 182, 183, 185, 186, 187, 204, 205, 212, 213, 217, 253, 254, 255, 256, 262, 270, 272, 273, 279, 280, 300, 303, 304, 306, 316, 330, 334, 346, 348, 349, 357, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 397, 441, 451, 454, 458, 463, 464, 465, 469, 470, 471, 476, 478, 481], "without": [2, 3, 7, 9, 14, 15, 16, 17, 18, 24, 26, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 71, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 220, 223, 258, 261, 272, 293, 294, 297, 298, 328, 330, 332, 334, 340, 341, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 396, 398, 399, 400, 401, 402, 403, 447, 454, 456, 461, 462, 463, 465, 466, 467, 468, 469, 474, 475, 476, 478, 481], "updat": [2, 3, 4, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 35, 41, 42, 47, 50, 55, 61, 62, 63, 65, 66, 70, 71, 72, 77, 78, 84, 95, 96, 106, 107, 126, 129, 132, 136, 144, 150, 156, 157, 158, 159, 160, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 206, 208, 209, 220, 222, 223, 230, 242, 253, 254, 260, 262, 266, 269, 270, 272, 274, 276, 277, 292, 293, 302, 307, 316, 328, 330, 331, 333, 334, 347, 348, 349, 350, 351, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 432, 437, 439, 442, 443, 446, 447, 453, 455, 458, 462, 463, 464, 465, 468, 471, 474, 475, 476, 478, 481], "length": [2, 25, 33, 34, 35, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 65, 71, 73, 74, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 107, 114, 115, 118, 126, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 205, 212, 233, 241, 269, 276, 279, 280, 282, 284, 286, 293, 297, 300, 302, 305, 306, 330, 334, 338, 350, 355, 396, 428, 434, 461, 463, 464, 469, 471, 476, 478, 481], "cursor": [2, 62, 67, 68, 69, 78, 79, 109], "afterward": [2, 35, 42, 47, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 474, 481], "tell": [2, 3, 4, 7, 126, 158, 159, 177, 260, 461, 464, 469, 474, 475], "our": [2, 3, 7, 8, 11, 22, 50, 69, 177, 212, 217, 419, 457, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 477, 478, 480], "far": [2, 62, 67, 68, 69, 71, 78, 79, 109, 177, 182, 296, 324, 325, 471, 476, 481], "empti": [2, 3, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 103, 109, 126, 129, 132, 136, 143, 144, 153, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 220, 223, 240, 242, 256, 262, 265, 267, 270, 272, 328, 330, 334, 350, 394, 395, 396, 423, 461, 476], "64": [2, 3, 61, 63, 70, 84, 95, 96, 109, 183, 212, 244, 282, 283, 291, 295, 299, 306, 307, 317, 395, 397, 461, 462, 463, 464, 465, 467, 471, 473, 476, 478, 480, 481], "dtype": [2, 3, 15, 16, 18, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 100, 101, 102, 106, 107, 114, 115, 122, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 200, 203, 204, 205, 206, 209, 210, 216, 217, 220, 221, 222, 223, 224, 225, 230, 232, 233, 236, 238, 240, 242, 243, 245, 249, 252, 253, 255, 257, 258, 261, 262, 263, 265, 267, 272, 276, 278, 288, 289, 293, 294, 295, 297, 298, 299, 302, 308, 309, 316, 317, 318, 326, 328, 330, 331, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 355, 358, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 405, 456, 465, 473, 476, 478, 480, 481], "unit8": 2, "img": 2, "randint": [2, 83, 109, 190, 258, 478], "255": [2, 109, 258, 478], "uint8": [2, 3, 39, 61, 63, 70, 84, 95, 96, 130, 131, 148, 149, 183, 224, 230, 238, 258, 395, 462, 478], "next": [2, 3, 4, 8, 15, 16, 18, 31, 39, 40, 42, 44, 46, 48, 50, 55, 62, 67, 68, 69, 71, 74, 75, 77, 78, 79, 84, 94, 97, 98, 105, 107, 109, 114, 115, 120, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 142, 143, 144, 148, 149, 150, 154, 155, 156, 157, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 182, 185, 186, 187, 190, 192, 197, 203, 205, 208, 209, 211, 212, 217, 218, 220, 223, 224, 225, 230, 231, 232, 233, 234, 238, 242, 243, 245, 248, 249, 253, 255, 257, 260, 263, 268, 269, 270, 272, 276, 294, 295, 298, 299, 302, 320, 346, 356, 358, 361, 362, 364, 365, 366, 368, 369, 370, 371, 377, 381, 382, 383, 384, 386, 387, 396, 397, 398, 399, 400, 401, 402, 403, 419, 431, 432, 435, 462, 464, 465, 467, 471, 476, 477, 480, 481], "ask": [2, 3, 8, 107, 114, 115, 419, 463, 464, 466, 467, 474, 475, 477, 481], "automat": [2, 3, 5, 12, 20, 36, 50, 82, 85, 100, 102, 109, 115, 122, 126, 129, 132, 135, 136, 137, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 220, 223, 236, 255, 268, 270, 279, 295, 299, 332, 338, 346, 347, 351, 417, 427, 456, 461, 463, 466, 467, 474, 475, 476, 478, 480], "look": [2, 3, 5, 7, 8, 35, 42, 47, 55, 65, 66, 72, 77, 107, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 230, 240, 241, 265, 272, 277, 328, 330, 334, 347, 351, 352, 353, 394, 396, 457, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 477, 478, 480, 481], "lead": [2, 3, 4, 8, 10, 29, 31, 39, 40, 48, 55, 62, 69, 74, 84, 113, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 255, 273, 296, 317, 324, 325, 337, 461, 464, 465, 474, 475, 476, 478, 480], "match": [2, 3, 6, 8, 15, 16, 18, 21, 22, 23, 25, 27, 28, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 97, 109, 118, 126, 129, 130, 131, 132, 133, 135, 136, 137, 138, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221, 222, 224, 225, 227, 229, 231, 232, 233, 234, 236, 238, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 272, 279, 280, 287, 295, 299, 300, 305, 306, 323, 328, 330, 334, 338, 342, 343, 347, 348, 350, 351, 354, 355, 362, 363, 364, 370, 378, 380, 381, 382, 384, 394, 396, 434, 439, 456, 457, 461, 463, 465, 473, 475, 476, 478, 481], "don": [2, 3, 4, 6, 7, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 177, 212, 261, 462, 463, 465, 469, 478, 480, 481], "throw": [2, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 395, 396, 481], "rb_td": 2, "batch_siz": [2, 3, 8, 15, 16, 18, 29, 31, 39, 42, 44, 50, 57, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 83, 84, 94, 95, 96, 100, 101, 102, 106, 107, 108, 109, 114, 115, 120, 122, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 203, 204, 205, 209, 211, 212, 216, 220, 223, 224, 225, 230, 238, 242, 243, 245, 249, 252, 253, 255, 261, 262, 263, 272, 276, 278, 286, 287, 288, 289, 292, 295, 299, 302, 316, 317, 318, 326, 327, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 419, 428, 434, 455, 456, 457, 461, 462, 463, 464, 469, 474, 475, 476, 478, 480, 481], "max": [2, 31, 59, 63, 78, 83, 94, 106, 107, 120, 143, 222, 256, 316, 362, 363, 364, 370, 380, 382, 384, 394, 461, 463, 464, 465, 471], "label": [2, 63, 64, 71, 83, 84, 461, 474, 478], "100": [2, 15, 16, 18, 21, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 80, 82, 85, 86, 87, 88, 89, 100, 102, 109, 114, 115, 120, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 215, 217, 224, 236, 245, 250, 253, 272, 303, 304, 305, 328, 330, 334, 344, 346, 394, 396, 419, 429, 447, 462, 463, 465, 466, 468, 471, 473, 474, 475, 476, 478, 480, 481], "rb_pytre": 2, "randn": [2, 3, 62, 65, 67, 68, 69, 78, 79, 100, 101, 102, 107, 109, 114, 115, 122, 126, 197, 211, 236, 278, 281, 282, 286, 288, 289, 293, 294, 297, 298, 303, 304, 305, 312, 314, 318, 338, 339, 340, 341, 342, 343, 347, 348, 350, 353, 354, 355, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 383, 384, 386, 387, 394, 399, 400, 401, 402, 436, 456, 465, 478, 480, 481], "c": [2, 3, 6, 7, 15, 16, 18, 21, 29, 39, 42, 61, 63, 65, 69, 70, 77, 78, 79, 84, 95, 96, 101, 183, 236, 258, 263, 297, 298, 328, 330, 334, 394, 395, 462, 478], "zero": [2, 3, 4, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 100, 102, 109, 114, 115, 120, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 203, 209, 211, 213, 217, 220, 222, 223, 236, 242, 245, 252, 270, 272, 275, 276, 283, 284, 285, 291, 292, 293, 294, 295, 297, 298, 299, 303, 304, 306, 307, 316, 317, 326, 328, 330, 334, 349, 351, 357, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 405, 464, 465, 478, 480, 481], "assert": [2, 3, 6, 18, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 109, 120, 126, 129, 132, 136, 139, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 183, 185, 186, 187, 197, 202, 205, 209, 212, 215, 220, 223, 232, 243, 250, 262, 269, 278, 306, 327, 395, 399, 400, 401, 402, 427, 428, 436, 469, 473, 478, 481], "len": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 62, 67, 68, 69, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 100, 102, 109, 122, 190, 238, 279, 280, 300, 306, 461, 465, 469, 471, 474, 476, 477, 478, 480], "ambigu": [2, 62, 67, 68, 69, 78, 79, 109], "signatur": [2, 15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 50, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 84, 109, 118, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 209, 216, 230, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396, 457, 461, 465, 466, 476], "deal": [2, 3, 62, 67, 68, 69, 78, 79, 109, 379, 394, 457, 461, 463, 475, 478], "interpret": [2, 3, 62, 67, 68, 69, 78, 79, 109, 455, 462], "put": [2, 62, 67, 68, 69, 78, 79, 109, 136, 148, 149, 167, 170, 171, 269, 426, 451, 456, 462, 463, 464, 466, 474, 476], "solv": [2, 4, 7, 9, 10, 62, 67, 68, 69, 78, 79, 109, 454, 461, 462, 463, 469, 471, 474, 475, 476, 478], "clear": [2, 3, 11, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 109, 126, 129, 132, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 429, 466, 469], "cut": [2, 62, 67, 68, 69, 78, 79, 109], "distinct": [2, 3, 62, 67, 68, 69, 78, 79, 109, 209, 212, 468, 473], "view": [2, 3, 8, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 272, 289, 293, 297, 300, 328, 330, 334, 394, 396, 466, 476, 478, 480, 481], "through": [2, 3, 4, 5, 8, 15, 16, 18, 20, 21, 22, 25, 27, 29, 39, 40, 48, 62, 66, 67, 68, 69, 72, 74, 78, 79, 84, 109, 126, 127, 128, 129, 132, 135, 136, 137, 140, 142, 143, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 218, 220, 223, 241, 273, 278, 300, 317, 346, 347, 351, 352, 353, 357, 360, 379, 399, 400, 401, 402, 427, 455, 456, 457, 461, 462, 463, 466, 468, 473, 474, 475, 476, 477, 478, 481], "collate_fn": [2, 62, 67, 68, 69, 77, 78, 79, 109, 178, 179, 182, 478, 480], "__init__": [2, 3, 7, 132, 150, 168, 180, 181, 184, 190, 191, 192, 193, 194, 202, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 276, 287, 289, 293, 297, 302, 331, 355, 362, 364, 365, 370, 377, 382, 384, 386, 387, 396, 458, 476, 481], "major": 2, "worri": [2, 80, 481], "though": [2, 4, 11, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 300, 463, 474, 475], "too": [2, 7, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 64, 65, 71, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 235, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 296, 324, 325, 328, 330, 334, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 462, 467, 470, 476, 478, 481], "latter": [2, 22, 23, 25, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 381, 394, 396, 449, 450], "inv": [2, 3, 180, 181, 184, 190, 191, 192, 193, 194, 205, 215, 222, 225, 230, 238, 245, 250, 252, 257, 261, 264, 272, 396, 476], "obvious": [2, 465], "ignor": [2, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 64, 65, 66, 72, 73, 74, 77, 80, 82, 85, 86, 87, 88, 89, 98, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 222, 225, 249, 258, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 303, 304, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 394, 396, 399, 478], "thread": [2, 3, 15, 16, 18, 21, 29, 61, 63, 70, 84, 95, 96, 126, 127, 128, 142, 143, 156, 165, 166, 183, 270, 395], "prefetch": [2, 62, 69, 78, 79, 94, 461, 462, 464, 478], "advis": [2, 11, 470, 481], "techniqu": [2, 8, 156, 165, 462, 465, 469, 478], "real": [2, 5, 351, 457, 464, 465, 476, 477], "life": [2, 224, 477], "adopt": [2, 3, 5, 461, 481], "throughput": [2, 9, 143, 461], "constant": [2, 11, 41, 212, 236, 254, 458, 461, 463, 464, 481], "throughout": [2, 3, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 463, 474, 481], "further": [2, 3, 5, 32, 461, 463, 465, 466], "refin": [2, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397], "coupl": [2, 464, 467, 468, 476, 478], "first_elt": 2, "128": [2, 115, 127, 128, 142, 143, 283, 286, 462, 464, 465, 471, 474, 477, 478], "wa": [2, 3, 5, 7, 39, 40, 42, 48, 50, 62, 65, 67, 68, 69, 74, 77, 78, 79, 84, 107, 109, 113, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 204, 212, 230, 262, 297, 328, 330, 334, 361, 363, 376, 378, 381, 383, 385, 394, 405, 457, 462, 463, 466, 467, 473, 474, 478, 480], "print": [2, 3, 6, 7, 15, 16, 18, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 106, 107, 109, 114, 115, 120, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 170, 171, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 202, 203, 204, 205, 208, 209, 212, 213, 217, 218, 220, 221, 222, 223, 231, 236, 242, 243, 245, 248, 253, 255, 256, 257, 258, 269, 270, 272, 279, 280, 282, 283, 284, 285, 286, 289, 291, 292, 295, 299, 300, 303, 304, 305, 306, 312, 315, 316, 318, 328, 330, 334, 338, 339, 340, 341, 342, 343, 346, 347, 348, 350, 351, 353, 355, 358, 379, 394, 395, 396, 417, 447, 455, 456, 458, 462, 463, 464, 465, 466, 467, 468, 469, 470, 473, 474, 475, 476, 477, 478, 480, 481], "influenti": 2, "latenc": [2, 3], "especi": [2, 3, 7, 8, 213], "larger": [2, 4, 77, 295, 299, 369, 377, 480], "volum": 2, "due": [2, 3, 5, 13, 22, 23, 25, 31, 468, 477, 478, 481], "memorymappedtensor": [2, 44, 61, 63, 75, 83, 100, 421, 469], "specifi": [2, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 109, 126, 129, 132, 136, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 219, 220, 221, 223, 248, 251, 254, 259, 263, 264, 272, 273, 276, 297, 328, 330, 332, 334, 350, 351, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 394, 396, 426, 456, 461, 463, 464, 465, 469, 474], "file": [2, 6, 7, 8, 61, 63, 70, 84, 95, 96, 98, 170, 183, 395, 418, 419, 421, 437, 458, 460, 462, 474, 478, 479], "locat": [2, 7, 61, 63, 70, 83, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 200, 219, 224, 236, 247, 270, 296, 324, 325, 395, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 461, 462, 463, 470, 474, 475, 478], "improv": [2, 4, 11, 228, 361, 457, 465, 474, 475, 478], "failur": [2, 4], "recoveri": 2, "were": [2, 7, 15, 16, 18, 21, 22, 23, 25, 27, 156, 165, 230, 455, 463, 474, 478], "found": [2, 3, 6, 7, 10, 15, 16, 18, 21, 27, 31, 35, 39, 40, 42, 47, 48, 50, 55, 61, 63, 65, 66, 70, 72, 74, 77, 83, 84, 95, 96, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 206, 212, 233, 245, 248, 256, 269, 270, 272, 292, 305, 306, 328, 330, 334, 347, 351, 378, 379, 381, 394, 395, 396, 457, 461, 462, 464, 465, 466, 468, 470, 476, 478, 480], "rough": 2, "1x": 2, "83x": 2, "44x": 2, "long": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 64, 73, 74, 82, 85, 86, 87, 88, 89, 100, 107, 154, 155, 222, 260, 275, 297, 298, 369, 464, 465, 469, 478], "sharabl": [2, 156, 165], "collabor": 2, "rather": [2, 4, 118, 154, 155, 185, 190, 243, 270, 456, 457, 461, 462, 463, 466, 468, 474, 475, 478], "incur": [2, 127, 128, 142, 143], "transmiss": 2, "overhead": [2, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 351], "content": [2, 3, 8, 18, 39, 40, 48, 61, 62, 63, 69, 70, 74, 78, 79, 84, 95, 96, 113, 114, 115, 126, 129, 132, 135, 136, 137, 144, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 181, 182, 183, 185, 186, 187, 242, 279, 280, 300, 305, 306, 347, 379, 394, 395, 463, 476, 480], "map": [2, 3, 8, 14, 17, 19, 24, 26, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 70, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 100, 105, 106, 107, 126, 129, 132, 136, 144, 147, 148, 149, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 170, 171, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 205, 209, 210, 212, 213, 214, 215, 216, 219, 220, 221, 222, 223, 224, 225, 227, 229, 230, 231, 232, 233, 234, 236, 238, 242, 243, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 268, 269, 270, 272, 289, 328, 330, 334, 338, 339, 340, 341, 343, 347, 348, 350, 351, 353, 354, 355, 356, 363, 364, 378, 381, 384, 394, 395, 396, 397, 399, 432, 453, 456, 457, 461, 462, 463, 464, 467, 468, 477], "writer": [2, 62, 67, 68, 69, 78, 79, 99, 102, 107, 109, 110, 114, 120, 121, 122, 125, 463, 478], "tensordictroundrobinwrit": [2, 79, 109], "goe": [2, 4, 84, 158, 159, 461, 463, 474, 475, 481], "prioritizedsampl": [2, 62, 67, 68, 69, 78, 79, 107, 109, 366, 371, 397, 461, 478], "access": [2, 3, 7, 8, 11, 35, 42, 47, 55, 62, 65, 66, 72, 77, 101, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 212, 240, 261, 265, 272, 328, 330, 334, 394, 396, 451, 454, 461, 466, 474, 475, 476, 478, 480], "tensordictreplaybuff": [2, 62, 67, 68, 69, 78, 106, 107, 109, 114, 115, 120, 211, 212, 434, 447, 453, 461, 462, 464, 478], "mp": [2, 22, 23, 25, 133, 269, 270], "def": [2, 3, 28, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 109, 126, 129, 132, 133, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 202, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 270, 272, 273, 276, 289, 293, 294, 297, 298, 302, 307, 328, 330, 334, 346, 347, 355, 362, 364, 365, 370, 377, 379, 382, 384, 386, 387, 394, 396, 417, 427, 455, 457, 458, 461, 462, 465, 473, 474, 475, 476, 478, 480, 481], "td": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 39, 42, 44, 50, 61, 62, 63, 65, 67, 68, 69, 70, 75, 77, 78, 79, 84, 95, 96, 100, 109, 120, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 145, 146, 154, 155, 156, 157, 160, 161, 165, 166, 167, 168, 169, 177, 178, 179, 182, 183, 185, 186, 187, 190, 203, 206, 209, 211, 213, 217, 218, 220, 221, 222, 223, 231, 232, 233, 234, 236, 245, 248, 252, 255, 258, 262, 269, 276, 278, 288, 289, 292, 301, 302, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 347, 348, 350, 353, 355, 394, 395, 397, 400, 401, 402, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 418, 428, 436, 456, 457, 461, 462, 464, 475, 476, 477, 480], "__name__": [2, 3, 15, 16, 18, 21, 28, 29, 67, 133, 270, 417, 462, 480], "__main__": [2, 3, 15, 16, 18, 21, 28, 29, 67, 133, 270, 417, 480], "21": [2, 50, 84, 114, 115, 156, 158, 159, 165, 217], "proc": 2, "target": [2, 4, 8, 27, 32, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 254, 272, 315, 328, 330, 334, 350, 351, 361, 362, 363, 364, 365, 366, 368, 370, 371, 374, 376, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 394, 396, 397, 398, 399, 400, 401, 402, 403, 440, 446, 447, 457, 458, 464, 465, 471, 474, 476], "arg": [2, 3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 34, 35, 36, 37, 39, 40, 42, 43, 47, 48, 49, 50, 52, 54, 55, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 84, 85, 86, 87, 88, 89, 95, 96, 100, 101, 102, 103, 107, 109, 114, 115, 116, 118, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 199, 205, 206, 207, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 230, 231, 232, 234, 239, 240, 241, 242, 243, 245, 248, 249, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 272, 274, 276, 278, 279, 280, 287, 288, 292, 295, 299, 300, 301, 302, 316, 327, 328, 329, 330, 331, 333, 334, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 426, 430, 434, 437, 451, 462, 465], "join": [2, 133, 190, 453, 462, 463, 465, 474], "now": [2, 3, 7, 62, 69, 78, 79, 109, 154, 155, 156, 212, 249, 306, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 473, 474, 475, 477, 478, 481], "20": [2, 50, 77, 83, 84, 114, 115, 120, 126, 129, 132, 136, 140, 144, 154, 155, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 254, 272, 291, 293, 294, 297, 298, 315, 342, 428, 464, 478, 481], "_data": [2, 476], "It": [2, 3, 4, 7, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 64, 65, 66, 71, 72, 73, 74, 77, 78, 80, 82, 83, 85, 86, 87, 88, 89, 101, 109, 112, 120, 125, 126, 129, 132, 136, 138, 144, 150, 151, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 209, 211, 212, 224, 230, 232, 236, 241, 254, 260, 262, 268, 270, 272, 274, 282, 284, 290, 292, 305, 306, 315, 316, 317, 319, 320, 326, 327, 328, 330, 334, 344, 346, 349, 351, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 385, 387, 394, 396, 397, 398, 399, 417, 426, 432, 454, 456, 457, 461, 462, 464, 465, 466, 474, 475, 476, 477, 478, 480, 481], "difficult": [2, 4, 156, 470], "pai": [2, 8, 212, 461], "word": [2, 3, 11, 71, 379, 394, 461, 469, 476, 481], "1m": [2, 440, 461, 463, 464], "doe": [2, 3, 19, 22, 35, 42, 47, 55, 61, 62, 63, 65, 66, 70, 72, 77, 78, 83, 84, 95, 96, 97, 98, 105, 106, 107, 114, 116, 118, 125, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 270, 272, 277, 286, 287, 293, 294, 295, 297, 298, 299, 308, 315, 327, 328, 330, 334, 342, 352, 353, 361, 363, 371, 378, 379, 381, 394, 395, 396, 398, 437, 457, 458, 461, 462, 463, 464, 466, 469, 474, 476, 478, 481], "howev": [2, 3, 5, 7, 35, 42, 47, 55, 65, 66, 72, 77, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 230, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 272, 328, 330, 334, 361, 363, 364, 378, 381, 383, 384, 394, 396, 456, 461, 462, 464, 465, 468, 476, 478, 481], "capac": [2, 62, 69, 78, 79, 100, 102, 106, 114, 122, 463, 469], "There": [2, 3, 10, 109, 179, 261, 277, 295, 299, 361, 381, 456, 457, 458, 463, 464, 465, 467, 469, 474, 475, 476, 478, 480, 481], "circumv": 2, "account": [2, 100, 102, 122, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 218, 303, 304, 456, 462, 464, 478, 481], "save": [2, 3, 8, 35, 42, 47, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 79, 84, 95, 96, 97, 98, 100, 101, 102, 103, 105, 109, 116, 117, 118, 122, 123, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 268, 272, 328, 330, 334, 394, 395, 396, 418, 419, 421, 426, 437, 458, 465, 469, 470, 471, 474, 475], "convent": [2, 3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 457, 461, 464, 474, 475, 476], "overridden": [2, 3, 35, 42, 47, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 399, 401, 402, 464, 474], "dim_extend": [2, 62, 69, 78, 79], "obtain": [2, 3, 7, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 71, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 211, 240, 254, 267, 276, 278, 315, 317, 434, 461, 463, 466, 467, 468, 474, 475], "counterpart": [2, 3, 212], "desir": [2, 3, 11, 15, 16, 18, 21, 29, 35, 38, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 207, 209, 216, 218, 236, 238, 240, 241, 255, 261, 262, 265, 267, 272, 279, 280, 287, 300, 306, 328, 330, 334, 338, 343, 344, 347, 348, 349, 350, 351, 394, 396, 456, 461, 465, 474, 475, 476, 478], "diversifi": 2, "offer": [2, 3, 7, 126, 127, 128, 129, 132, 136, 142, 143, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 260, 417, 455, 456, 461, 462, 465, 466, 468, 469, 474, 476, 478, 481], "accomplish": [2, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 466], "__especially__": 2, "offlin": [2, 8, 15, 16, 18, 21, 22, 23, 25, 27, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 362, 368, 369, 377, 386, 396, 426, 458, 466, 477, 478], "docstr": [2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 466, 467], "detail": [2, 3, 5, 6, 7, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 258, 262, 272, 277, 289, 293, 297, 307, 315, 328, 330, 334, 344, 361, 371, 379, 381, 394, 396, 454, 458, 462, 465, 469, 473, 478], "happi": [2, 465], "concaten": [2, 8, 15, 16, 27, 50, 51, 53, 84, 177, 185, 212, 213, 236, 252, 297, 300, 353, 461, 462, 467, 474, 475, 476, 478, 481], "schedul": [2, 4, 7, 71, 432, 463, 476], "transformedenv": [2, 3, 11, 12, 55, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 209, 212, 215, 216, 218, 220, 223, 224, 225, 231, 232, 233, 235, 236, 238, 242, 243, 244, 245, 248, 249, 250, 253, 254, 255, 256, 260, 261, 269, 272, 295, 299, 346, 396, 419, 427, 461, 462, 463, 464, 465, 466, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "stepcount": [2, 50, 55, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 218, 260, 261, 262, 272, 278, 396, 461, 462, 463, 464, 465, 466, 471, 474, 475, 480], "gymenv": [2, 3, 5, 11, 15, 16, 18, 21, 27, 28, 29, 44, 50, 55, 67, 75, 77, 120, 126, 129, 132, 133, 136, 138, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 208, 209, 212, 215, 216, 217, 218, 224, 230, 231, 232, 236, 238, 243, 244, 245, 248, 250, 254, 255, 256, 257, 260, 261, 262, 263, 269, 270, 272, 278, 295, 299, 346, 396, 417, 419, 447, 453, 456, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 477, 478, 480, 481], "randompolici": [2, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 55, 212, 245, 453, 469, 478], "cartpol": [2, 3, 11, 44, 55, 75, 77, 126, 129, 130, 131, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 209, 212, 217, 248, 254, 269, 272, 346, 417, 462, 464, 467, 469, 470, 471, 478, 481], "v1": [2, 3, 11, 15, 16, 18, 21, 27, 28, 29, 44, 55, 67, 75, 77, 120, 126, 129, 132, 133, 135, 136, 137, 142, 143, 144, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 209, 212, 215, 217, 218, 225, 231, 232, 236, 243, 245, 248, 249, 250, 253, 254, 255, 256, 257, 260, 261, 263, 269, 270, 272, 278, 295, 299, 346, 390, 396, 408, 409, 410, 411, 413, 414, 415, 416, 417, 456, 462, 464, 466, 467, 468, 469, 470, 471, 476, 478, 480, 481], "action_spec": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 55, 126, 127, 128, 129, 132, 136, 142, 143, 144, 150, 156, 157, 158, 159, 160, 161, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 209, 212, 216, 220, 221, 223, 232, 236, 242, 245, 261, 262, 263, 264, 272, 276, 289, 302, 318, 320, 338, 343, 347, 348, 362, 364, 366, 368, 382, 384, 386, 387, 396, 447, 456, 461, 462, 463, 464, 465, 467, 468, 469, 471, 473, 474, 475, 476, 477, 478, 480, 481], "8": [2, 3, 6, 7, 39, 40, 48, 55, 69, 74, 77, 106, 107, 114, 115, 126, 127, 128, 129, 130, 131, 132, 136, 144, 154, 155, 156, 157, 160, 165, 166, 167, 168, 177, 178, 179, 182, 185, 186, 187, 205, 208, 217, 218, 254, 257, 263, 270, 279, 280, 282, 283, 291, 300, 339, 340, 341, 347, 350, 353, 377, 461, 462, 476, 478, 480], "traj_kei": [2, 107, 114, 115, 478], "truncated_kei": [2, 107, 114, 115, 245, 253], "strict_length": [2, 107, 114, 115, 419], "enumer": [2, 15, 16, 18, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 72, 73, 74, 75, 77, 79, 82, 85, 86, 87, 88, 89, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 388, 394, 396, 457, 461, 462, 463, 464, 471, 474, 478, 480], "break": [2, 5, 15, 16, 18, 21, 27, 29, 35, 42, 47, 55, 65, 66, 67, 69, 72, 77, 79, 94, 107, 114, 115, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 212, 245, 269, 270, 272, 295, 299, 324, 328, 330, 334, 394, 396, 419, 462, 465, 469, 471, 478, 480], "step_count": [2, 15, 16, 18, 55, 126, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 218, 253, 272, 463, 464, 465, 466, 471], "32": [2, 28, 39, 62, 67, 68, 69, 78, 79, 109, 115, 136, 143, 163, 164, 170, 171, 187, 212, 230, 279, 280, 281, 282, 283, 285, 286, 291, 300, 305, 306, 310, 311, 314, 317, 326, 397, 417, 462, 464, 465, 467, 468, 476, 477, 478, 480, 481], "33": [2, 35, 39, 42, 47, 55, 65, 66, 72, 77, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 279, 280, 300, 328, 330, 334, 394, 396], "34": [2, 279, 280, 300], "35": [2, 279, 280, 300], "36": [2, 179], "37": [2, 211], "38": [2, 7, 50], "39": [2, 142, 143], "40": [2, 77, 142, 143], "41": [2, 114], "11": [2, 10, 31, 50, 59, 77, 83, 84, 100, 101, 102, 106, 115, 122, 133, 205, 217, 258, 272, 276, 302], "12": [2, 7, 10, 50, 77, 100, 102, 115, 122, 142, 143, 156, 163, 164, 165, 179, 217, 270, 272, 419, 478], "13": [2, 5, 77, 114, 115, 162, 217, 268, 270, 272, 273], "14": [2, 6, 77, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 217, 236, 272, 273], "15": [2, 31, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 217, 272, 316, 342, 372, 478], "16": [2, 3, 15, 16, 21, 29, 35, 42, 47, 55, 65, 66, 72, 77, 107, 115, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 272, 328, 330, 334, 394, 396, 464, 478], "17": [2, 11, 114, 115, 136, 156, 187, 205, 217, 272], "could": [2, 3, 4, 6, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 351, 394, 396, 462, 463, 470, 474, 475, 477, 481], "sai": [2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 305, 328, 330, 334, 394, 396, 474, 477, 481], "interleav": 2, "cannot": [2, 3, 4, 7, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 39, 53, 59, 69, 78, 79, 102, 103, 107, 110, 114, 115, 122, 126, 129, 132, 135, 136, 137, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 220, 223, 241, 248, 260, 305, 306, 348, 361, 364, 381, 462, 463, 464, 465, 474, 475, 476], "suggest": [2, 397, 461, 475], "serialenv": [2, 3, 126, 129, 132, 136, 144, 156, 157, 160, 166, 167, 177, 178, 179, 182, 185, 186, 187, 255, 270, 272, 278, 346, 453, 480, 481], "squeez": [2, 3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 208, 209, 212, 217, 251, 254, 279, 280, 321, 322, 461, 465, 476, 478], "6": [2, 3, 7, 15, 16, 18, 21, 29, 31, 50, 55, 69, 72, 77, 84, 107, 115, 130, 131, 136, 156, 163, 164, 179, 187, 205, 208, 217, 218, 236, 238, 254, 260, 270, 278, 279, 280, 282, 283, 284, 287, 291, 294, 300, 305, 306, 307, 310, 323, 346, 347, 355, 462, 465, 480], "5": [2, 3, 15, 16, 18, 21, 29, 31, 38, 39, 40, 48, 50, 51, 52, 53, 54, 55, 59, 62, 67, 69, 72, 74, 77, 78, 79, 109, 114, 115, 120, 126, 129, 132, 133, 136, 142, 143, 144, 148, 149, 151, 156, 157, 160, 163, 164, 165, 166, 167, 170, 171, 177, 179, 182, 185, 186, 187, 192, 205, 208, 209, 211, 217, 218, 233, 245, 252, 253, 254, 260, 270, 272, 275, 276, 277, 278, 279, 280, 282, 283, 288, 289, 290, 291, 293, 296, 297, 300, 302, 305, 306, 310, 315, 318, 324, 325, 342, 343, 346, 348, 354, 378, 381, 383, 386, 387, 417, 455, 456, 460, 461, 462, 465, 467, 471, 474, 475, 476, 478, 479, 480, 481], "7": [2, 3, 6, 10, 42, 50, 55, 59, 62, 69, 77, 78, 107, 115, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 205, 208, 217, 218, 254, 257, 270, 276, 278, 279, 280, 283, 300, 302, 305, 405, 461, 478, 480], "9": [2, 3, 7, 31, 35, 50, 55, 62, 69, 77, 78, 84, 107, 115, 120, 130, 131, 147, 158, 159, 167, 205, 208, 217, 218, 254, 257, 262, 269, 270, 272, 303, 304, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 388, 394, 397, 427, 457, 461, 462, 474, 475], "18": [2, 50, 114, 115, 163, 164, 170, 171, 260, 272, 306], "19": [2, 114, 115, 120, 217, 272, 460, 479], "independ": [2, 15, 16, 18, 21, 22, 23, 25, 27, 29, 156, 165, 227, 234, 255, 264, 277, 306, 337, 361, 381, 457, 458, 461, 462, 475, 478, 480], "congruent": 2, "name": [2, 3, 6, 7, 18, 35, 39, 40, 42, 47, 48, 55, 61, 63, 65, 66, 70, 72, 74, 77, 83, 84, 94, 95, 96, 126, 127, 129, 130, 132, 136, 142, 144, 147, 148, 149, 151, 154, 156, 157, 158, 159, 160, 162, 165, 166, 167, 170, 171, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 200, 204, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 222, 224, 225, 226, 228, 230, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 268, 269, 272, 273, 295, 299, 328, 330, 331, 334, 343, 348, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 395, 396, 397, 399, 401, 402, 403, 417, 421, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 458, 461, 462, 463, 464, 465, 468, 469, 470, 474, 475, 476, 477, 481], "randomcroptensordict": [2, 461], "unlik": [2, 33, 69, 78, 79, 113, 136, 148, 149, 170, 171, 187, 275, 277, 330, 346, 371, 381, 419, 456, 462, 465, 467, 469, 480], "stop": [2, 3, 15, 16, 18, 21, 27, 29, 71, 107, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 463, 469, 474, 475, 480, 481], "signal": [2, 3, 15, 16, 18, 21, 31, 50, 107, 114, 115, 120, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 204, 212, 218, 224, 233, 253, 256, 457, 461, 463, 474, 475, 478, 481], "disk": [2, 3, 50, 61, 62, 63, 67, 68, 69, 70, 78, 79, 84, 95, 96, 100, 109, 183, 395, 437, 458, 461, 462, 464, 465, 469, 470, 474, 478], "dump": [2, 3, 11, 44, 61, 62, 63, 67, 68, 69, 70, 75, 78, 79, 84, 95, 96, 98, 100, 101, 102, 103, 109, 116, 118, 122, 183, 395, 417, 418, 419, 470, 471, 474], "json": 2, "metadata": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 364, 386, 463, 466, 468, 469, 474, 475, 481], "anticip": [2, 220, 223], "compli": [2, 277, 456], "back": [2, 32, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 194, 259, 268, 307, 338, 343, 344, 347, 348, 349, 350, 351, 463, 465, 474, 475, 476, 478], "exact": [2, 3, 31, 156, 297], "statu": [2, 3, 24, 132], "prioriti": [2, 4, 62, 78, 79, 100, 101, 102, 103, 106, 107, 116, 118, 122, 364, 365, 366, 368, 369, 370, 371, 377, 382, 384, 386, 387, 397, 458, 461, 462, 478], "heap": 2, "under": [2, 3, 4, 27, 35, 42, 47, 50, 55, 65, 66, 71, 72, 77, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 233, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 277, 328, 330, 334, 338, 343, 344, 347, 348, 349, 350, 351, 379, 394, 396, 399, 400, 401, 402, 403, 419, 457, 461, 462, 467, 474, 476, 481], "hood": [2, 3, 27, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 277, 476], "naiv": [2, 265, 466], "just": [2, 3, 4, 84, 118, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 141, 142, 143, 144, 147, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 182, 185, 186, 187, 204, 208, 215, 255, 273, 306, 331, 428, 455, 458, 461, 462, 463, 464, 465, 466, 467, 469, 474, 475, 476, 478, 480, 481], "public": [2, 68, 117, 240, 267], "serializ": 2, "consum": [2, 113, 115, 346, 462, 463, 469, 475, 478], "much": [2, 3, 8, 15, 16, 21, 62, 78, 106, 107, 156, 165, 378, 381, 463, 465, 466, 470, 474, 475, 476, 478, 481], "duplic": [2, 35, 42, 47, 55, 65, 66, 72, 77, 113, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 362, 364, 366, 371, 377, 379, 382, 384, 386, 387, 394, 396, 397], "observ": [2, 3, 8, 15, 16, 18, 21, 27, 29, 32, 44, 50, 55, 67, 75, 77, 84, 97, 98, 105, 107, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 198, 203, 205, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 227, 229, 230, 231, 232, 234, 236, 237, 238, 242, 243, 244, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 268, 269, 270, 272, 278, 281, 282, 283, 284, 285, 286, 289, 292, 295, 299, 305, 310, 311, 314, 315, 316, 318, 319, 338, 339, 340, 341, 342, 343, 346, 347, 348, 355, 356, 361, 362, 363, 364, 365, 366, 368, 369, 370, 373, 377, 378, 381, 382, 383, 384, 386, 387, 396, 397, 399, 400, 401, 402, 403, 417, 419, 447, 456, 457, 458, 462, 463, 464, 465, 466, 467, 468, 470, 471, 473, 474, 475, 476, 478, 480, 481], "plu": [2, 15, 16, 21, 71, 156, 165, 177, 476], "enabl": [2, 7, 8, 100, 102, 113, 122, 209, 295, 299, 316, 330, 334, 346, 417, 419, 432, 455, 463, 466, 474, 475, 476, 478], "three": [2, 33, 34, 38, 43, 51, 52, 53, 54, 59, 60, 65, 94, 364, 456, 458, 463, 465, 466, 467, 474, 475, 476, 478, 481], "flatstoragecheckpoint": 2, "discard": [2, 3, 83, 136, 203, 265, 418, 478, 481], "compress": 2, "At": [2, 257, 292, 301, 462, 463, 464, 469, 473, 476, 477], "correct": [2, 4, 61, 63, 70, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 189, 191, 212, 232, 395, 440, 463, 464], "addit": [2, 3, 4, 14, 17, 24, 26, 35, 42, 47, 55, 57, 65, 66, 72, 77, 84, 95, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 170, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 216, 240, 255, 259, 261, 262, 265, 267, 272, 274, 293, 328, 330, 334, 342, 346, 350, 360, 379, 394, 396, 399, 417, 419, 457, 461, 462, 465, 466, 474, 475, 478], "nestedstoragecheckpoint": 2, "represent": [2, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 101, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 240, 265, 267, 272, 328, 330, 334, 361, 381, 394, 396, 461, 476, 477, 481], "appar": [2, 3, 430], "h5storagecheckpoint": 2, "h5db": 2, "space": [2, 9, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 95, 97, 98, 105, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 200, 205, 215, 222, 230, 233, 255, 263, 274, 280, 286, 289, 305, 311, 316, 318, 338, 343, 344, 347, 348, 349, 350, 351, 353, 354, 355, 358, 361, 366, 368, 369, 370, 381, 386, 387, 397, 456, 457, 462, 463, 464, 465, 466, 467, 468, 474, 475, 476, 481], "assumpt": [2, 3, 82, 476, 478], "accur": [2, 7, 462, 476, 478], "truncat": [2, 3, 15, 16, 18, 21, 44, 46, 50, 55, 56, 64, 75, 77, 80, 83, 95, 97, 98, 105, 107, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 168, 170, 171, 177, 178, 179, 182, 185, 186, 187, 190, 204, 205, 224, 225, 230, 235, 242, 245, 249, 253, 255, 262, 263, 272, 295, 299, 325, 330, 334, 346, 399, 405, 461, 463, 466, 474, 481], "marl": [2, 147, 173, 212, 252, 256, 305, 306, 307, 370, 384, 457, 466, 474, 475], "extra": [2, 10, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 212, 269, 270, 272, 328, 330, 334, 394, 396, 426, 456, 463, 464, 478], "fail": [2, 7, 28, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 206], "concret": [2, 461, 463], "set_se": [2, 3, 15, 16, 18, 21, 27, 29, 44, 50, 55, 75, 77, 126, 127, 128, 129, 132, 136, 142, 143, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 217, 218, 236, 243, 248, 254, 256, 262, 272, 455, 465, 469, 471, 476, 480, 481], "manual_se": [2, 3, 33, 44, 51, 52, 62, 69, 75, 77, 78, 79, 101, 114, 115, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 206, 208, 217, 218, 222, 236, 245, 248, 254, 256, 270, 272, 292, 303, 304, 312, 315, 316, 338, 344, 351, 354, 361, 362, 364, 365, 369, 377, 384, 465, 469, 471, 474, 475, 476, 480, 481], "200": [2, 15, 16, 18, 27, 35, 42, 44, 47, 55, 65, 66, 67, 72, 75, 77, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 245, 272, 282, 283, 290, 319, 320, 328, 330, 334, 394, 396, 417, 419, 461, 464, 465, 469, 471, 478], "22": [2, 29, 114, 115, 268], "rb_test": 2, "_storag": [2, 477, 478], "max_siz": [2, 50, 62, 69, 77, 78, 79, 100, 101, 102, 103, 114, 115, 116, 120, 122, 463, 469], "102": 2, "path_to_save_dir": 2, "assert_allclose_td": 2, "altern": [2, 4, 38, 61, 63, 70, 84, 95, 96, 151, 183, 217, 260, 286, 303, 304, 305, 360, 364, 395, 417, 461, 463, 465, 474, 475], "state_dict": [2, 15, 16, 18, 21, 27, 29, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 269, 270, 272, 305, 306, 328, 330, 334, 364, 384, 394, 395, 396, 451, 458, 461, 462, 481], "load_state_dict": [2, 15, 16, 18, 21, 27, 29, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 269, 270, 272, 328, 330, 334, 364, 384, 394, 395, 396, 458, 461], "drawback": 2, "struggl": 2, "big": [2, 463, 469, 478, 481], "sequenti": [2, 9, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 211, 232, 272, 328, 330, 334, 337, 339, 340, 341, 347, 352, 353, 358, 361, 362, 364, 370, 377, 381, 382, 383, 384, 386, 394, 396, 456, 463, 464, 467, 475, 476, 477, 480, 481], "known": [2, 3, 5, 7, 8, 77, 136, 187, 255, 406, 407, 461, 462, 466], "indiffer": 2, "heavili": [2, 11], "smooth": [2, 275, 461, 462, 468], "essenti": [2, 3, 13, 22, 23, 25, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 462, 466, 474, 476, 478], "purpos": [2, 3, 7, 11, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 293, 361, 363, 375, 378, 381, 383, 394, 447, 461, 463, 464, 465, 468, 470, 474, 475, 477, 481], "guid": [2, 11, 158, 159, 163, 164, 254, 454, 461, 475, 480], "explan": [2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 277, 328, 330, 334, 394, 396], "effect": [2, 3, 18, 29, 35, 39, 42, 47, 55, 62, 65, 66, 69, 72, 77, 78, 79, 107, 109, 112, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 212, 218, 262, 272, 277, 328, 330, 334, 394, 396, 437, 456, 461, 467, 474, 478, 481], "realm": [2, 467], "As": [2, 3, 4, 55, 69, 78, 79, 82, 109, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 245, 287, 351, 399, 456, 461, 462, 463, 464, 465, 466, 468, 469, 474, 475, 476, 477, 478, 480, 481], "practition": 2, "often": [2, 3, 8, 307, 376, 379, 394, 437, 461, 462, 466, 468, 476, 478, 481], "encount": [2, 4, 234, 346, 454, 462, 467, 476], "situat": [2, 148, 149, 185, 190], "sometim": [2, 3, 82, 464, 481], "variabl": [2, 3, 4, 7, 8, 20, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 66, 72, 73, 74, 82, 85, 86, 87, 88, 89, 95, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 148, 149, 152, 153, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 182, 185, 186, 187, 190, 257, 261, 270, 293, 294, 295, 297, 298, 299, 302, 339, 340, 341, 379, 382, 427, 458, 462], "immedi": [2, 35, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 398, 474, 475], "199": 2, "info": [2, 3, 15, 16, 62, 67, 68, 69, 78, 79, 84, 106, 107, 109, 112, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 138, 144, 148, 149, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 182, 185, 186, 187, 230, 263, 265, 268, 271, 426, 466, 471, 474, 475, 478, 480], "glanc": [2, 466], "seem": [2, 461, 464, 466], "togeth": [2, 3, 11, 15, 16, 18, 21, 22, 23, 25, 27, 50, 65, 71, 73, 74, 101, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 241, 252, 261, 293, 295, 297, 299, 326, 339, 340, 341, 356, 456, 462, 464, 466, 474], "less": [2, 24, 151, 327, 449, 450, 457, 463, 464, 478, 480], "omit": [2, 144, 186, 274, 292, 316, 433, 463, 468, 476, 478], "proper": [2, 3, 4, 6, 7, 330, 334, 399, 400, 401, 402, 462, 463, 474, 475, 476, 478], "imposs": [2, 3, 69, 78, 79, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 361, 363, 378, 381, 383], "determin": [2, 3, 17, 50, 62, 78, 84, 106, 107, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 182, 185, 186, 187, 240, 267, 305, 316, 330, 334, 364, 462, 467, 474, 475], "complic": [2, 42, 65, 77, 328, 330, 334, 394, 476, 478, 481], "matter": [2, 41, 469], "inconsist": [2, 481], "miss": [2, 3, 4, 6, 7, 35, 39, 42, 47, 50, 55, 65, 66, 72, 77, 126, 129, 132, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 230, 260, 262, 268, 272, 273, 328, 330, 334, 352, 353, 361, 364, 384, 394, 396, 454, 461, 464], "primari": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 144, 186, 469], "elimin": [2, 3, 466], "upon": [2, 3, 8, 20, 474, 476], "canon": 2, "definit": [2, 59, 116, 305], "markov": [2, 3, 466, 481], "mdp": [2, 203, 466, 476], "context": [2, 3, 5, 8, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 65, 66, 72, 77, 115, 126, 129, 132, 133, 136, 144, 153, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 255, 264, 272, 277, 295, 299, 306, 308, 328, 330, 334, 337, 342, 392, 393, 394, 396, 399, 400, 401, 402, 404, 412, 419, 427, 432, 455, 456, 457, 461, 462, 463, 464, 465, 474, 475, 476, 477, 478, 480], "condit": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 83, 85, 86, 87, 88, 89, 185, 217, 218, 254, 269, 343, 344, 346, 348, 349, 360, 457, 461, 474, 476, 478], "complet": [2, 7, 9, 24, 29, 113, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 253, 396, 454, 457, 461, 463, 466, 473], "termin": [2, 3, 7, 15, 16, 18, 21, 29, 44, 46, 50, 55, 56, 71, 75, 77, 97, 98, 105, 114, 126, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 148, 149, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 182, 185, 186, 187, 190, 204, 205, 208, 209, 224, 230, 242, 255, 263, 272, 276, 295, 299, 302, 346, 352, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 461, 462, 463, 474, 475, 476, 480, 481], "reward": [2, 3, 15, 16, 18, 41, 42, 44, 46, 50, 55, 56, 61, 70, 71, 75, 77, 83, 84, 94, 106, 107, 120, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 162, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 197, 203, 205, 206, 209, 210, 215, 216, 220, 221, 223, 224, 225, 230, 232, 233, 234, 238, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 259, 261, 262, 263, 264, 266, 267, 269, 270, 272, 276, 295, 302, 342, 346, 356, 361, 362, 364, 365, 366, 368, 369, 370, 373, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 430, 431, 432, 435, 451, 455, 457, 458, 461, 462, 463, 464, 465, 466, 470, 474, 475, 476, 480, 481], "imit": [2, 3, 375], "inform": [2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 80, 82, 84, 85, 86, 87, 88, 89, 95, 96, 126, 129, 132, 133, 136, 139, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 278, 279, 280, 300, 306, 328, 330, 334, 394, 395, 396, 456, 457, 458, 461, 462, 463, 464, 465, 466, 474, 475, 476, 478, 480], "stateless": [2, 3, 50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 209, 218, 270, 332, 333, 379, 394, 417, 461, 466, 476, 481], "simul": [2, 3, 5, 7, 8, 82, 127, 128, 129, 138, 142, 143, 162, 170, 171, 199, 276, 302, 331, 455, 456, 461, 463, 465, 466, 470, 474, 475], "furthermor": [2, 474, 475], "certain": [2, 4, 22, 23, 25, 27, 35, 42, 47, 55, 65, 66, 72, 77, 83, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 217, 218, 228, 253, 262, 272, 292, 294, 298, 328, 330, 334, 378, 394, 396, 461, 462, 463, 465, 471, 474, 475, 481], "composit": [2, 3, 33, 34, 36, 37, 38, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 84, 85, 86, 87, 88, 89, 91, 95, 112, 118, 125, 126, 129, 132, 134, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 197, 204, 206, 209, 220, 221, 222, 223, 225, 230, 232, 234, 242, 243, 249, 253, 255, 259, 260, 261, 263, 270, 272, 274, 276, 302, 338, 347, 351, 353, 354, 358, 361, 381, 396, 453, 461, 463, 467, 476], "uniform": [2, 62, 78, 106, 107, 330, 334, 474], "unambigu": 2, "distinguish": [2, 3, 69, 78, 79, 148, 149, 170, 171], "happen": [2, 3, 24, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 273, 316, 462, 465, 468, 469, 470, 477, 481], "everyth": [2, 462, 463, 464, 470, 471], "belong": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 268, 269, 351, 461, 469, 475], "rule": [2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 220, 223, 272, 328, 330, 334, 351, 394, 396, 456, 463], "field": [2, 3, 15, 16, 18, 21, 29, 31, 35, 39, 42, 44, 47, 50, 55, 61, 63, 64, 65, 66, 70, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 95, 96, 100, 101, 102, 106, 114, 122, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 205, 209, 220, 223, 224, 225, 230, 238, 242, 243, 245, 249, 252, 253, 255, 260, 262, 263, 272, 276, 278, 288, 289, 295, 299, 302, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 353, 355, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 441, 454, 456, 462, 476], "taken": [2, 3, 33, 34, 38, 43, 51, 52, 53, 54, 59, 60, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 205, 244, 303, 304, 457, 461, 463, 464, 467, 474, 475, 476], "is_shar": [2, 3, 15, 16, 18, 29, 31, 39, 42, 44, 50, 61, 63, 64, 65, 70, 71, 75, 77, 78, 79, 80, 83, 84, 94, 95, 96, 100, 101, 102, 106, 114, 122, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 182, 183, 185, 186, 187, 190, 203, 205, 209, 220, 223, 224, 225, 230, 238, 242, 243, 245, 249, 252, 253, 255, 263, 269, 276, 278, 288, 289, 295, 299, 302, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 353, 355, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 397, 456, 476], "envbas": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 50, 84, 126, 129, 133, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 206, 209, 220, 223, 235, 242, 243, 261, 262, 269, 272, 276, 295, 299, 301, 302, 346, 396, 432, 441, 442, 443, 447, 449, 450, 451, 453, 455, 466], "brought": [2, 463, 464, 467], "step_mdp": [2, 3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 295, 299, 453, 464, 466, 476, 480, 481], "count": [2, 3, 15, 16, 18, 21, 29, 50, 55, 84, 132, 133, 217, 253, 260, 270, 316, 432, 437, 440, 461, 462, 463, 464, 478, 481], "trigger": [2, 7, 42, 65, 77, 185, 270, 328, 330, 334, 394], "turn": [2, 22, 23, 25, 27, 39, 40, 48, 61, 63, 66, 70, 72, 74, 84, 95, 96, 129, 143, 156, 167, 183, 217, 229, 261, 264, 268, 343, 395, 399, 417, 432, 457, 461, 462, 464, 467, 476, 477], "retain": [2, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "regard": [2, 289, 344, 361, 371, 381, 461, 463, 476], "expand": [2, 8, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 114, 115, 183, 209, 255, 287, 350, 353, 362, 364, 377, 379, 382, 384, 386, 387, 394, 395, 474, 475, 476, 478, 480], "recur": [2, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 399, 400, 401, 402, 403, 467], "anyth": [2, 4, 15, 16, 18, 21, 22, 23, 25, 27, 457], "els": [2, 127, 128, 190, 209, 293, 294, 297, 298, 310, 456, 458, 461, 462, 463, 464, 474, 475, 476, 477], "repetit": [2, 463, 466, 469], "embed": [2, 240, 265, 266, 267, 282, 317, 338, 339, 340, 341, 350, 351, 355, 477], "strictli": [2, 3, 8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 233, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396, 461, 463], "enforc": [2, 35, 39, 42, 47, 55, 65, 66, 72, 77, 113, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 352, 364, 384, 394, 396, 476], "n_action": [2, 346, 362, 364, 366, 368, 380, 384], "rightmost": [2, 457], "n_ob": [2, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 232, 346, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 468], "estim": [2, 4, 107, 114, 115, 178, 179, 182, 185, 190, 191, 224, 232, 282, 324, 339, 340, 341, 361, 362, 363, 364, 365, 366, 368, 370, 371, 372, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 388, 394, 397, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 457, 462, 463, 467, 468, 474, 475], "subsequ": [2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 272, 328, 330, 334, 394, 396, 464, 474], "proce": [2, 474], "state_valu": [2, 340, 341, 355, 363, 369, 377, 378, 381, 382, 384, 399, 400, 401, 402, 404, 406, 408, 410, 412, 413, 415, 456, 461, 475], "f": [2, 15, 16, 18, 21, 29, 127, 128, 136, 142, 143, 177, 187, 192, 257, 273, 298, 360, 399, 400, 401, 402, 403, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 461, 462, 463, 464, 471, 474, 475, 476, 478, 481], "next_state_valu": [2, 386, 387, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 453], "broadcast": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 287, 331, 370, 384], "left": [2, 57, 107, 114, 180, 181, 184, 185, 190, 191, 192, 193, 194, 209, 216, 217, 219, 220, 221, 225, 232, 234, 240, 242, 243, 249, 253, 256, 259, 261, 263, 265, 267, 270, 272, 292, 305, 396, 462, 463, 465, 469, 470], "would": [2, 3, 35, 42, 47, 55, 65, 66, 71, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 293, 295, 297, 299, 300, 305, 328, 330, 334, 351, 394, 396, 457, 458, 462, 463, 464, 466, 468, 469, 476, 478, 480, 481], "best": [2, 5, 9, 140, 295, 299, 474, 475, 478, 480], "bug": [2, 4], "worst": [2, 462], "twice": [2, 8, 115], "feasibl": 2, "mostli": [2, 3, 21, 315, 419, 457, 470, 478, 481], "eas": [2, 3, 474, 475], "flat": [2, 120, 399], "manner": [2, 136, 187, 240, 265, 456, 461, 462, 463, 469, 473, 476, 478], "ted2flat": [2, 44, 453], "flat2t": [2, 453], "unflatten": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 209, 346], "deseri": [2, 3, 44], "posit": [2, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 109, 126, 129, 130, 131, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 227, 228, 230, 251, 252, 253, 256, 260, 262, 264, 272, 328, 330, 334, 364, 384, 394, 396, 457, 463, 474, 475, 476, 478], "both": [2, 3, 7, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 62, 65, 66, 69, 72, 77, 78, 79, 126, 129, 132, 133, 135, 136, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 168, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 205, 212, 230, 243, 259, 260, 262, 272, 279, 280, 295, 298, 299, 300, 305, 306, 328, 330, 334, 339, 340, 341, 344, 349, 361, 363, 364, 365, 369, 370, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 399, 432, 456, 461, 463, 465, 466, 468, 474, 475, 476, 477, 478, 481], "mark": [2, 3, 18, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 257, 295, 299, 399, 401, 402, 469, 478], "identifi": [2, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 64, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 184, 185, 186, 187], "abov": [2, 3, 7, 35, 42, 47, 55, 65, 66, 72, 77, 85, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 261, 272, 296, 324, 325, 328, 330, 334, 360, 394, 396, 457, 458, 461, 463, 465, 466, 467, 474, 475, 476, 481], "output": [2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 50, 55, 62, 65, 66, 69, 72, 77, 78, 79, 82, 84, 95, 107, 114, 115, 126, 129, 130, 131, 132, 135, 136, 137, 138, 143, 144, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 204, 209, 210, 212, 215, 216, 218, 219, 220, 221, 223, 225, 227, 230, 232, 234, 236, 240, 242, 243, 248, 249, 252, 253, 256, 257, 259, 261, 262, 263, 265, 267, 268, 270, 272, 274, 279, 280, 281, 282, 283, 286, 288, 289, 290, 293, 294, 295, 297, 298, 299, 300, 305, 306, 313, 315, 316, 318, 327, 328, 330, 334, 338, 339, 342, 343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 358, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 403, 417, 419, 428, 455, 456, 457, 461, 462, 463, 464, 465, 466, 467, 470, 473, 474, 475, 476, 477, 480, 481], "typic": [2, 3, 4, 8, 13, 14, 17, 18, 19, 22, 23, 24, 25, 26, 29, 35, 42, 47, 55, 65, 66, 72, 77, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 224, 254, 272, 313, 315, 328, 330, 334, 347, 362, 364, 379, 381, 384, 394, 396, 455, 456, 457, 458, 463, 465, 466, 468, 469, 474, 475, 476], "adjust": [2, 11, 255, 461, 474, 475, 476], "grumodul": [2, 211, 255, 337, 358, 464], "lstmmodul": [2, 295, 337, 464, 465], "skip": [2, 3, 17, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 218, 228, 230, 234, 260, 262, 272, 328, 330, 334, 347, 351, 364, 379, 384, 394, 396, 399, 400, 401, 402, 418, 419, 430, 432, 461, 462, 476], "accumul": [2, 8, 272], "upcom": [2, 379, 394, 408, 409, 410, 411, 413, 414, 415, 416, 461], "popular": [2, 3, 455, 456, 464, 468, 475], "rainbow": 2, "multistep": [2, 15, 16, 18, 21, 22, 23, 25, 27, 29, 272, 453, 462], "shift": [2, 44, 46, 55, 56, 75, 97, 98, 105, 357, 399, 400, 401, 402, 463], "approxim": [2, 475, 481], "intens": [2, 3, 8], "ataridqnexperiencereplai": 2, "onlin": [2, 8, 15, 21, 212, 286, 314, 361, 367, 380, 381, 428, 451, 455, 463, 464, 475, 478], "2x": 2, "small": [2, 115, 265, 270, 275, 461, 463, 465, 474, 475, 481], "clearer": [2, 465, 467], "lazi": [2, 3, 73, 74, 91, 92, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 240, 265, 279, 305, 308, 352, 353, 461, 462, 467, 469, 473, 478, 481], "certainli": 2, "welcom": [2, 466], "wrapper": [2, 3, 21, 61, 63, 70, 71, 78, 79, 84, 95, 96, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 176, 177, 178, 179, 182, 183, 185, 186, 187, 190, 268, 273, 277, 278, 327, 329, 330, 334, 342, 346, 351, 356, 395, 399, 424, 425, 426, 451, 453, 463, 464, 466, 474, 475, 477, 480, 481], "around": [2, 5, 7, 21, 78, 79, 126, 129, 132, 136, 144, 150, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 277, 315, 329, 346, 351, 399, 455, 461, 462, 475, 481], "selecttransform": [2, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "excludetransform": [2, 249, 478], "promptli": 2, "virtual": [2, 3, 135], "instal": [2, 3, 5, 10, 22, 23, 25, 66, 77, 126, 129, 132, 136, 141, 144, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 177, 178, 179, 182, 184, 185, 186, 187, 421, 437, 454, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 481], "respons": [2, 3, 8, 15, 16, 18, 20, 22, 25, 27, 29, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 184, 185, 186, 187, 192, 330, 334, 437, 455, 468, 469, 481], "d4rl": 2, "repositori": [2, 7, 170, 171, 474, 475], "wheel": [2, 463], "publish": 2, "openml": [2, 153], "scikit": [2, 153], "panda": 2, "raw": [2, 3, 4, 71, 194, 230, 259, 263, 296, 324, 325, 462, 465, 469, 476], "go": [2, 3, 7, 101, 147, 156, 177, 218, 241, 245, 342, 405, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "modifi": [2, 3, 7, 8, 35, 42, 47, 55, 65, 66, 72, 77, 83, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 212, 216, 218, 227, 230, 232, 240, 255, 261, 262, 265, 267, 270, 272, 307, 316, 328, 330, 331, 334, 342, 350, 351, 394, 396, 440, 455, 457, 461, 462, 463, 465, 466, 474, 475, 476], "fly": [2, 212, 269, 378, 457, 463, 476, 478, 481], "least": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 65, 73, 74, 82, 85, 86, 87, 88, 89, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 215, 470, 481], "pre": [2, 7, 28, 35, 42, 47, 55, 65, 66, 72, 77, 83, 102, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 240, 259, 265, 267, 272, 328, 330, 334, 394, 396, 481], "conisder": 2, "per": [2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 107, 114, 120, 140, 142, 143, 156, 158, 159, 215, 234, 248, 279, 280, 290, 292, 305, 306, 346, 419, 421, 424, 426, 437, 449, 450, 461, 462, 463, 464, 465, 467, 468, 471, 474, 475, 478, 480], "pipelin": [2, 3, 7, 136, 187, 455, 456, 457, 463], "replac": [2, 3, 6, 7, 35, 42, 47, 55, 65, 66, 72, 77, 107, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 208, 222, 224, 231, 269, 270, 272, 292, 328, 330, 334, 362, 364, 370, 377, 382, 384, 386, 387, 394, 396, 399, 400, 401, 402, 456, 474, 478, 480], "onc": [2, 3, 7, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 234, 245, 255, 262, 272, 274, 316, 328, 330, 334, 346, 394, 395, 396, 435, 456, 458, 462, 463, 464, 467, 470, 476, 478, 481], "produc": [2, 3, 39, 40, 48, 50, 74, 114, 177, 205, 208, 209, 279, 280, 300, 306, 312, 339, 341, 342, 351, 419, 463, 464, 465, 466, 467, 469, 478, 481], "download": [2, 7, 10, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 140, 240, 267, 419, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "forc": [2, 3, 6, 7, 15, 16, 21, 22, 23, 25, 27, 157, 462, 474, 475, 476], "robosetexperiencereplai": [2, 114, 115], "fk1": 2, "v4": [2, 136, 156, 187, 205, 244, 408, 409, 410, 411, 413, 414, 415, 416, 461, 463, 477, 480], "expert": 2, "fk1_microopenrandom_v2d": 2, "func": [2, 271], "obs_norm": 2, "norm": [2, 4, 8, 127, 128, 275, 437, 461, 462, 463, 474, 475, 476], "num_work": [2, 24, 26, 61, 63, 83, 94, 151, 156, 165, 461, 462], "os": [2, 63, 83, 94, 462], "cpu_count": [2, 63, 83, 94], "num_chunk": 2, "1000": [2, 4, 18, 29, 50, 69, 77, 100, 101, 106, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 269, 274, 292, 315, 316, 347, 351, 376, 461, 462, 463, 464, 465, 467, 469, 471, 476, 477, 478], "mp_start_method": [2, 156, 165, 260, 462, 480], "fork": [2, 5, 461, 462, 463, 464, 474, 475, 477, 480], "recreat": [2, 476], "customari": 2, "moreov": [2, 3], "fine": [2, 3, 32, 69, 78, 79, 107, 109, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 191, 209, 232, 455, 465, 469, 477], "grain": [2, 3, 69, 78, 79, 107, 109, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 209], "nomenclatur": 2, "compact": [2, 50, 75, 97, 98, 105], "propos": [2, 212, 224, 277, 301, 376, 385, 456, 464, 478], "replaybufferensembl": [2, 112, 118, 125], "primit": [2, 3, 4, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 455], "individu": [2, 4, 22, 23, 25, 27, 35, 42, 47, 55, 65, 66, 72, 77, 83, 107, 109, 120, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 270, 272, 328, 330, 334, 363, 378, 381, 394, 396, 455, 461, 475], "dummi": [2, 3, 167, 190, 417, 461, 465, 469, 481], "semant": [2, 73, 74, 135, 137, 477], "ident": [2, 3, 15, 16, 18, 55, 61, 63, 69, 70, 77, 78, 79, 84, 95, 96, 100, 109, 114, 126, 129, 132, 135, 136, 137, 144, 151, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 184, 185, 186, 187, 224, 252, 261, 270, 275, 305, 306, 362, 364, 377, 382, 384, 386, 387, 395, 399, 400, 401, 402, 449, 450, 462, 466, 474, 475], "another_kei": [2, 109], "renam": [2, 3, 61, 63, 70, 84, 95, 96, 109, 183, 203, 243, 245, 395, 461], "resiz": [2, 3, 109, 212, 462, 464, 465, 466, 478, 481], "imag": [2, 3, 4, 7, 11, 212, 214, 217, 219, 240, 258, 267, 300, 417, 419, 461, 462, 465, 466, 470, 475, 477, 481], "comops": 2, "totensorimag": [2, 3, 109, 212, 244, 462, 464, 465, 478, 480, 481], "renametransform": [2, 3, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212], "rb0": [2, 109], "in_kei": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 42, 50, 65, 67, 77, 109, 126, 127, 128, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 198, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 276, 278, 288, 295, 299, 302, 317, 326, 327, 328, 330, 334, 338, 339, 340, 341, 342, 343, 346, 347, 348, 350, 351, 353, 354, 355, 358, 361, 362, 363, 364, 365, 366, 368, 369, 370, 375, 377, 378, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 418, 419, 447, 456, 461, 462, 463, 464, 465, 467, 468, 471, 473, 474, 475, 476, 477, 478, 480, 481], "pixel": [2, 3, 7, 39, 109, 129, 130, 131, 135, 137, 138, 162, 212, 214, 219, 224, 227, 229, 236, 238, 240, 244, 258, 265, 267, 282, 310, 311, 417, 419, 461, 462, 464, 465, 470, 474, 477, 478, 480, 481], "rb1": [2, 109], "out_kei": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 42, 50, 65, 67, 77, 109, 126, 127, 128, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 198, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269, 270, 272, 276, 278, 288, 289, 295, 299, 302, 317, 318, 326, 327, 328, 330, 334, 338, 339, 340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 353, 354, 355, 358, 361, 362, 363, 364, 369, 370, 375, 377, 378, 381, 382, 383, 384, 386, 394, 396, 397, 399, 400, 401, 402, 417, 419, 432, 447, 456, 461, 462, 463, 464, 465, 467, 471, 473, 474, 475, 476, 477, 478, 480, 481], "pixels33": [2, 109], "data0": [2, 101, 109], "244": [2, 109, 240, 267], "data1": [2, 101, 109, 480], "_": [2, 8, 62, 67, 68, 69, 78, 79, 101, 109, 129, 133, 140, 170, 171, 190, 213, 220, 222, 223, 232, 236, 243, 258, 269, 272, 315, 338, 350, 351, 355, 360, 361, 362, 364, 365, 369, 370, 377, 381, 382, 384, 386, 387, 399, 400, 401, 402, 421, 461, 462, 463, 464, 465, 471, 474, 475, 476, 478, 480], "parent": [2, 3, 27, 35, 42, 46, 47, 55, 57, 65, 66, 72, 77, 82, 84, 109, 118, 125, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 209, 212, 213, 216, 217, 218, 221, 224, 227, 228, 234, 236, 240, 248, 253, 254, 255, 256, 260, 261, 264, 265, 272, 295, 299, 328, 330, 334, 339, 358, 379, 381, 394, 396, 403, 417, 419, 461, 469, 476, 480, 481], "basic": [2, 3, 19, 150, 456, 463, 468, 469, 471, 474, 480, 481], "properti": [2, 3, 14, 17, 19, 20, 24, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 109, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 260, 261, 262, 269, 270, 272, 287, 296, 304, 308, 312, 323, 324, 325, 328, 330, 334, 346, 361, 364, 379, 381, 383, 384, 394, 395, 396, 467, 469, 476, 478], "input": [2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 70, 71, 72, 73, 74, 77, 80, 82, 84, 85, 86, 87, 88, 89, 95, 96, 117, 123, 126, 129, 132, 136, 144, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 234, 238, 239, 240, 241, 242, 243, 245, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 275, 277, 278, 279, 280, 282, 283, 284, 285, 288, 289, 292, 293, 294, 295, 297, 298, 299, 300, 305, 306, 307, 308, 309, 316, 318, 319, 320, 321, 322, 324, 327, 328, 330, 334, 338, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 358, 360, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 431, 435, 440, 447, 455, 456, 457, 458, 461, 462, 463, 464, 465, 466, 474, 475, 476, 480, 481], "send": [2, 3, 8, 20, 30, 160, 166, 426, 453, 480], "receiv": [2, 3, 14, 17, 19, 20, 24, 26, 30, 35, 42, 47, 55, 65, 66, 71, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 261, 262, 270, 272, 300, 328, 330, 334, 394, 396, 405, 453, 457, 461, 463, 468, 473, 476], "spawn": [2, 3, 4, 22, 28, 140, 151, 156, 165, 260, 462, 474, 475], "check_env_spec": [2, 3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 205, 230, 242, 263, 417, 453, 463, 474, 475, 476], "saniti": [2, 3, 7, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 463], "make_composite_from_td": [2, 82, 453, 476], "fall": [2, 4], "categori": [2, 39, 456, 458], "bound": [2, 3, 4, 27, 35, 37, 39, 42, 47, 55, 65, 66, 72, 77, 85, 126, 129, 132, 136, 144, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 215, 235, 269, 272, 274, 292, 316, 319, 320, 328, 330, 334, 338, 343, 344, 347, 348, 349, 350, 351, 354, 361, 362, 364, 365, 377, 381, 382, 384, 386, 387, 394, 396, 453, 456, 461, 462, 463, 465, 474, 476, 480, 481], "unbound": [2, 3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 73, 74, 78, 79, 82, 84, 86, 87, 88, 89, 95, 96, 109, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 190, 197, 206, 209, 220, 223, 242, 255, 276, 302, 338, 350, 353, 355, 383, 395, 453, 476, 478], "boundeddiscret": [2, 36, 39], "boundedcontinu": [2, 28, 36, 39, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 230, 233, 263], "unboundeddiscret": [2, 85, 157, 230, 453], "unboundedcontinu": [2, 85, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 242, 255, 353, 358, 453], "implicitli": 2, "onehot": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 60, 73, 74, 82, 85, 86, 87, 88, 89, 127, 128, 135, 137, 138, 141, 142, 143, 151, 152, 154, 155, 162, 168, 169, 289, 318, 343, 348, 366, 368, 369, 370, 397, 453, 456], "multionehot": [2, 51, 52, 54, 366, 369, 370, 397, 453], "multicategor": [2, 52, 53, 54, 453], "binari": [2, 3, 7, 34, 35, 59, 168, 206, 210, 289, 318, 343, 344, 348, 349, 366, 369, 370, 397, 453], "concept": [2, 3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 315, 462, 478], "arbitrari": [2, 3, 33, 59, 69, 126, 129, 132, 136, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 457, 461, 462, 476, 478], "combin": [2, 4, 45, 66, 386, 462, 465, 470, 478, 480], "nevertheless": [2, 3, 463, 466, 478], "otherwis": [2, 3, 12, 15, 16, 18, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 107, 109, 114, 115, 126, 127, 128, 129, 132, 135, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 213, 217, 218, 222, 230, 236, 254, 255, 256, 260, 261, 262, 269, 272, 273, 275, 277, 293, 296, 297, 305, 306, 324, 325, 328, 330, 334, 337, 343, 348, 351, 354, 362, 364, 373, 379, 380, 384, 394, 395, 396, 399, 401, 402, 432, 434, 457, 458, 461, 462, 463, 464, 476, 481], "similarli": [2, 3, 27, 35, 42, 47, 55, 65, 66, 72, 77, 113, 118, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 234, 272, 305, 328, 330, 334, 352, 353, 369, 377, 394, 396, 399, 455, 481], "possess": [2, 82], "unsqueez": [2, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 84, 85, 86, 87, 88, 89, 107, 197, 206, 209, 212, 213, 258, 264, 461, 464, 465, 474, 475, 476], "move": [2, 4, 35, 42, 47, 55, 65, 66, 72, 77, 82, 126, 129, 132, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 205, 216, 221, 240, 255, 261, 262, 265, 267, 269, 270, 272, 300, 328, 330, 334, 350, 394, 396, 435, 461, 462, 464, 466, 481], "unbind": [2, 61, 62, 63, 69, 70, 78, 79, 84, 95, 96, 183, 234, 346, 395], "said": [2, 463], "neg": [2, 8, 15, 16, 18, 21, 22, 23, 25, 27, 62, 65, 78, 82, 106, 107, 189, 212, 227, 241, 252, 264, 363, 372, 378, 381, 399, 401, 402, 457, 463, 474, 475, 476], "seen": [2, 3, 22, 23, 25, 27, 39, 40, 48, 74, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 221, 457, 461, 462, 464, 468, 474, 475, 478], "predict": [2, 3, 55, 71, 288, 290, 301, 302, 342, 356, 361, 363, 368, 371, 373, 374, 378, 381, 383, 394, 398, 461, 462, 468], "deprec": [2, 31, 34, 35, 37, 40, 42, 43, 47, 48, 49, 52, 54, 55, 58, 60, 65, 66, 72, 77, 87, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 269, 272, 328, 330, 334, 361, 363, 364, 366, 369, 370, 371, 377, 378, 381, 382, 383, 384, 394, 396, 397, 399, 400, 401, 402, 407, 481], "mont": [2, 178, 179, 182, 185, 190, 361, 363, 378, 381, 394, 396, 461], "carlo": [2, 178, 179, 182, 185, 190, 361, 363, 378, 381, 394, 396, 461], "mct": [2, 50], "act": [2, 3, 4, 114, 115, 158, 159, 262, 288, 306, 362, 364, 365, 377, 382, 384, 386, 387, 464, 465, 474, 475, 478, 480], "tradit": [2, 468, 474], "integ": [2, 15, 16, 18, 21, 29, 31, 47, 51, 53, 55, 59, 65, 66, 71, 72, 84, 107, 114, 115, 116, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187, 205, 208, 224, 228, 236, 253, 270, 279, 280, 300, 305, 306, 364, 369, 377, 384, 457, 465, 478], "advanc": [2, 3, 27, 62, 69, 78, 79, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 466, 469, 478], "rebuild": [2, 50], "initi": [2, 4, 7, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 32, 33, 34, 35, 38, 42, 43, 47, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 84, 95, 96, 109, 120, 126, 129, 132, 136, 144, 154, 155, 156, 157, 160, 165, 166, 167, 168, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 211, 230, 236, 240, 255, 262, 265, 270, 271, 272, 273, 274, 275, 276, 292, 293, 294, 297, 298, 302, 305, 306, 307, 308, 309, 316, 328, 330, 332, 333, 334, 346, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 451, 456, 457, 461, 462, 464, 466, 467, 469, 474, 476, 481], "pair": [2, 3, 55, 61, 63, 65, 70, 77, 84, 95, 96, 126, 129, 130, 131, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 245, 255, 260, 295, 339, 347, 351, 379, 394, 395, 399, 400, 401, 402, 403, 456, 457, 461, 462, 463, 467, 468, 473, 476, 481], "term": [2, 71, 101, 191, 232, 297, 298, 308, 309, 360, 361, 370, 439, 462, 463, 466, 467, 475], "pseudocod": [2, 3], "next_stat": [2, 457], "associ": [2, 3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 35, 39, 40, 42, 47, 48, 50, 55, 61, 63, 65, 66, 70, 72, 74, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 272, 319, 328, 330, 333, 334, 394, 395, 396, 451, 461, 478], "sens": [2, 4, 61, 63, 70, 84, 95, 96, 183, 190, 212, 395, 469, 476], "hard": [2, 3, 7, 120, 130, 131, 156, 376, 462, 481], "know": [2, 3, 4, 9, 62, 69, 78, 79, 135, 137, 274, 379, 382, 394, 432, 461, 462, 463, 464, 465, 466, 467, 468, 469, 474, 475, 478], "next_td": 2, "Of": [2, 3, 7, 454, 476, 481], "cours": [2, 3, 4, 454, 476, 481], "handi": [2, 3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 470], "undertaken": [2, 84, 457, 476], "link": [2, 6, 7, 132, 462, 471], "hash": [2, 47, 50, 65, 66, 72, 77, 84, 129, 144, 186], "past": [2, 4, 212, 346, 462, 478], "node_map": [2, 50], "_index": [2, 65, 77], "Then": [2, 7, 15, 16, 18, 21, 22, 23, 25, 27, 182, 268, 463, 473], "track": [2, 3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 29, 79, 106, 107, 113, 129, 185, 248, 257, 269, 270, 272, 316, 346, 396, 424, 430, 462, 464, 466, 469, 475, 476, 478], "next_data": [2, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "data_map": [2, 50], "form": [2, 15, 16, 21, 35, 42, 47, 55, 62, 65, 66, 69, 72, 77, 78, 79, 97, 98, 105, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 293, 295, 297, 299, 328, 330, 334, 351, 360, 361, 363, 378, 381, 394, 396, 437, 456, 467], "figur": [2, 3, 84, 144, 186, 461, 463, 464, 475, 476, 481], "flowchart": 2, "o": [2, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 298, 328, 330, 334, 394, 396], "get_tre": [2, 50, 84], "vertex": [2, 84], "longer": [2, 84, 273, 462, 471, 474, 475, 478], "vertic": [2, 84], "branch": [2, 50, 84], "repeat": [2, 84, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 151, 152, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 188, 190, 260, 276, 287, 463, 474, 475, 476], "depth": [2, 69, 82, 126, 129, 132, 136, 144, 150, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 276, 279, 280, 282, 283, 284, 285, 290, 291, 300, 302, 305, 306, 307, 310, 311, 343, 456, 462, 466, 468, 469, 473, 474, 475, 478], "until": [2, 3, 7, 27, 29, 143, 180, 181, 184, 190, 191, 192, 193, 194, 256, 261, 272, 396, 427, 463, 464, 471, 474, 475], "anymor": [2, 61, 63, 70, 84, 95, 96, 183, 262, 350, 395], "utmost": 2, "post": [2, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 455], "grpo": [2, 185, 190, 394, 453], "commonli": [2, 107, 114, 115, 481], "emploi": [2, 309], "scarc": 2, "address": [2, 332, 478], "subdomain": 2, "extern": [2, 3, 220, 223, 270, 332, 474, 481], "token": [2, 29, 63, 64, 71, 80, 83, 94, 95, 96, 144, 177, 178, 179, 181, 182, 185, 186, 188, 189, 192, 193, 330, 334, 455], "dm": [3, 461, 481], "experi": [3, 62, 69, 78, 79, 106, 107, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 421, 422, 423, 424, 425, 426, 454, 462, 463, 465, 469, 470, 474, 475, 478], "box": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 84, 85, 86, 87, 88, 89, 135, 137, 307, 379, 394], "lib": [3, 5, 6, 7, 9, 10, 15, 16, 18, 21, 27, 28, 29, 67, 126, 129, 132, 133, 136, 141, 144, 148, 149, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 215, 224, 231, 232, 236, 238, 243, 245, 248, 255, 261, 268, 269, 272, 396, 417, 447, 461, 462, 463, 464, 473, 475, 477, 478, 480, 481], "hope": [3, 11], "nn": [3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 32, 35, 41, 42, 47, 55, 65, 66, 67, 71, 72, 77, 126, 127, 128, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 217, 222, 224, 232, 240, 255, 261, 262, 265, 267, 272, 276, 278, 279, 280, 282, 283, 284, 285, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 302, 304, 305, 306, 307, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 346, 347, 348, 350, 351, 352, 353, 355, 358, 360, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 447, 456, 457, 461, 462, 463, 464, 465, 467, 468, 471, 473, 474, 475, 476, 477, 480], "organis": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262, 462], "attribut": [3, 4, 7, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 75, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 126, 129, 132, 135, 136, 137, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 224, 234, 240, 262, 265, 269, 270, 272, 328, 330, 334, 351, 361, 362, 364, 365, 366, 368, 370, 371, 372, 375, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 461, 464, 476], "live": [3, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 109, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 224, 272, 328, 330, 334, 394, 396], "actual": [3, 4, 7, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 268, 395, 440, 457, 461, 463, 465, 474, 475, 476], "care": [3, 8, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 419, 461, 463, 465, 474, 475, 476, 478], "parametr": [3, 309, 351, 362, 364, 369, 377, 384, 461, 463], "observation_spec": [3, 50, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 209, 212, 213, 214, 215, 216, 219, 220, 221, 223, 224, 227, 229, 230, 231, 232, 236, 238, 240, 242, 244, 248, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 268, 269, 270, 272, 276, 295, 299, 302, 396, 441, 447, 461, 463, 468, 473, 474, 475, 476, 481], "state_spec": [3, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 216, 221, 236, 261, 263, 264, 272, 276, 302, 396, 476, 481], "reward_spec": [3, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 209, 210, 215, 216, 220, 221, 223, 233, 242, 246, 247, 248, 250, 252, 259, 261, 263, 264, 270, 272, 276, 302, 396, 463, 474, 475, 476, 481], "done_spec": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 220, 221, 223, 224, 242, 252, 259, 261, 263, 272, 396, 474, 475, 476, 481], "flag": [3, 8, 42, 62, 67, 68, 69, 78, 79, 109, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 231, 316, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 456, 474, 475, 476, 477], "input_spec": [3, 84, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 209, 216, 220, 221, 222, 234, 238, 242, 243, 248, 249, 252, 253, 254, 255, 259, 261, 262, 263, 266, 272, 396, 463, 476], "full_action_spec": [3, 84, 126, 129, 132, 136, 144, 154, 155, 156, 157, 160, 165, 166, 167, 168, 169, 177, 178, 179, 182, 185, 186, 187, 205, 221, 276, 302, 474, 475], "full_state_spec": [3, 50, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 205, 221, 276, 302], "output_spec": [3, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 216, 220, 221, 225, 232, 234, 242, 243, 249, 253, 259, 261, 262, 263, 270, 272, 396, 476], "full_observation_spec": [3, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187, 276, 302], "full_reward_spec": [3, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 209, 221, 242, 474, 475], "full_done_spec": [3, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 209, 221, 242, 474, 475], "carri": [3, 27, 53, 83, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 255, 270, 379, 394, 455, 462, 464, 474, 475, 476, 478], "nontensor": [3, 58, 95, 182, 187, 230, 263, 453], "spec_lock": [3, 132], "modif": [3, 5, 35, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 227, 230, 272, 328, 330, 334, 379, 394, 396, 457, 463, 476], "children": [3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "unlock": [3, 39, 40, 48, 61, 63, 70, 74, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 395], "set_spec_lock_": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "reason": [3, 4, 8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 240, 265, 272, 299, 328, 330, 334, 394, 396, 457, 461, 462, 463, 468, 469, 474, 476, 478], "easi": [3, 5, 11, 126, 129, 130, 131, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 292, 316, 334, 456, 457, 461, 462, 463, 475, 477, 478, 480, 481], "cach": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 73, 74, 82, 83, 85, 86, 87, 88, 89, 94, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 208, 220, 223, 240, 261, 262, 267, 277, 429], "principl": 3, "new_spec": 3, "eras": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262], "relock": 3, "previous": [3, 4, 50, 463, 481], "importantli": [3, 347, 351], "action_s": 3, "help": [3, 4, 35, 42, 47, 55, 65, 66, 72, 77, 82, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 224, 272, 328, 330, 334, 361, 363, 378, 381, 383, 394, 396, 454, 457, 461, 462, 463, 464, 474, 475], "With": [3, 142, 143, 147, 254, 458, 462, 473, 474, 475, 478, 481], "necessarili": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 481], "present": [3, 29, 35, 42, 47, 55, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 82, 84, 95, 96, 106, 107, 109, 113, 126, 129, 132, 135, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 204, 225, 245, 249, 255, 260, 262, 272, 280, 281, 282, 283, 284, 285, 291, 295, 297, 299, 309, 314, 316, 328, 330, 334, 346, 350, 351, 352, 353, 361, 362, 363, 364, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 451, 455, 458, 461, 471, 473, 474, 475, 478, 480], "0s": [3, 255, 464], "step_and_maybe_reset": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 455, 466], "done_kei": [3, 31, 42, 44, 46, 50, 56, 75, 97, 98, 105, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 208, 212, 224, 245, 253, 272, 396, 474, 475], "assign": [3, 4, 15, 16, 21, 35, 36, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 85, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 332, 334, 364, 365, 366, 368, 384, 394, 395, 396, 463, 467, 474, 475, 478], "_reset": [3, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 206, 208, 209, 212, 220, 223, 231, 242, 257, 276, 302, 474], "data_": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "append": [3, 8, 11, 50, 62, 67, 68, 69, 78, 79, 95, 109, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 189, 190, 208, 215, 216, 234, 245, 255, 262, 268, 294, 295, 298, 299, 343, 348, 455, 461, 462, 463, 464, 465, 474, 475, 476, 477, 478, 480], "seed": [3, 15, 16, 18, 21, 27, 29, 69, 78, 79, 109, 126, 129, 132, 136, 144, 150, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 172, 177, 178, 179, 182, 185, 186, 187, 188, 206, 209, 220, 223, 230, 242, 262, 417, 437, 474], "determinist": [3, 15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 201, 216, 240, 255, 261, 262, 265, 267, 272, 281, 290, 310, 320, 328, 330, 334, 338, 347, 350, 351, 354, 362, 379, 394, 396, 432, 456, 461, 462, 463, 464, 465, 467, 468, 471, 474, 476, 480, 481], "preced": [3, 55, 129, 212, 464], "risk": [3, 241], "overlap": [3, 78, 120], "reproduc": [3, 66, 72, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 212, 230, 461, 463, 465, 475], "maximum": [3, 4, 13, 15, 16, 17, 18, 21, 22, 23, 25, 27, 33, 55, 61, 63, 64, 71, 77, 80, 83, 84, 85, 94, 100, 101, 102, 103, 106, 107, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 222, 246, 253, 254, 256, 275, 323, 324, 325, 354, 362, 364, 369, 370, 377, 379, 380, 384, 394, 419, 434, 456, 461, 462, 463, 464, 467, 474, 475, 478], "max_step": [3, 11, 120, 126, 129, 132, 136, 144, 148, 149, 150, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 253, 260, 272, 417, 466, 467, 468, 470, 471, 474, 475, 480, 481], "tensordictmodul": [3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 42, 65, 67, 71, 77, 126, 127, 128, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 211, 217, 232, 278, 289, 295, 299, 302, 317, 318, 326, 327, 328, 330, 334, 339, 340, 341, 342, 343, 346, 347, 348, 349, 350, 352, 353, 354, 356, 358, 362, 364, 365, 369, 370, 372, 373, 374, 375, 377, 379, 382, 384, 386, 387, 394, 397, 398, 399, 400, 401, 402, 432, 447, 453, 461, 463, 464, 468, 471, 473, 474, 475, 476, 477, 481], "trail": [3, 184, 269], "treat": [3, 55, 457, 467, 468], "brief": [3, 463, 466, 468, 478], "deliveri": 3, "metaclass": [3, 132, 137], "flank": [3, 457, 464], "dual": 3, "refer": [3, 7, 8, 9, 11, 26, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 71, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 135, 136, 137, 141, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 230, 260, 262, 269, 272, 276, 289, 290, 302, 303, 304, 305, 306, 307, 310, 311, 319, 320, 328, 330, 334, 341, 344, 361, 364, 371, 372, 373, 374, 381, 384, 394, 396, 399, 404, 412, 460, 461, 463, 465, 467, 468, 469, 470, 474, 475, 478], "union": [3, 25, 35, 39, 40, 42, 47, 48, 49, 53, 54, 55, 57, 59, 60, 65, 66, 72, 73, 74, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 305, 326, 328, 330, 334, 368, 370, 382, 394, 396, 448, 451], "assess": [3, 15, 16, 18, 21, 22, 23, 25, 27, 39, 40, 48, 74, 148, 149, 173, 182, 461], "split_trajectori": [3, 15, 16, 18, 21, 22, 23, 25, 27, 107, 114, 115, 453], "adjac": [3, 31, 227, 346], "junction": 3, "inittrack": [3, 295, 299, 346, 461, 464], "tutori": [3, 157, 452, 460, 461, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 476, 477, 478, 479, 481], "scratch": [3, 8, 462, 476], "mere": [3, 21, 465], "batch_lock": [3, 126, 129, 132, 134, 136, 144, 156, 160, 165, 166, 177, 178, 179, 182, 185, 186, 187, 209, 255, 262, 476], "contrast": [3, 293, 315, 376, 478], "notabl": 3, "braxenv": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 243, 453, 466], "jumanjienv": [3, 453], "straightforward": [3, 19, 461, 462, 466, 467, 468, 469, 478], "merg": [3, 62, 69, 78, 79, 476], "correctli": [3, 7, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "silent": [3, 35, 42, 47, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357], "_step": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 227, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396], "temporari": [3, 461], "hold": [3, 261, 392, 393, 396, 476, 478], "arm": 3, "unbatch": [3, 293, 297], "captur": [3, 274, 292, 316, 465], "base_env": [3, 126, 128, 129, 132, 136, 137, 143, 144, 155, 156, 157, 160, 165, 166, 167, 169, 177, 178, 179, 182, 185, 186, 187, 205, 206, 209, 215, 217, 218, 220, 222, 223, 232, 238, 242, 244, 250, 253, 255, 256, 260, 262, 272, 419, 427, 455, 461, 462, 463, 465, 474, 477, 480, 481], "break_when_all_don": [3, 126, 129, 132, 136, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "conditionalskip": 3, "programmat": 3, "pretti": [3, 461, 466, 470, 478], "likewis": 3, "break_when_any_don": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 208, 260, 272, 278, 346, 475], "te": 3, "paragraph": 3, "deep": [3, 9, 212, 233, 282, 283, 284, 285, 288, 316, 361, 364, 376, 384, 385, 461, 474], "dive": 3, "gym3": 3, "envpool": [3, 151, 152], "simultan": [3, 25, 143, 151, 152, 156, 165, 476], "advantag": [3, 8, 185, 190, 291, 361, 363, 378, 381, 383, 394, 396, 399, 400, 401, 402, 403, 404, 406, 408, 410, 412, 413, 415, 457, 458, 461, 462, 463, 464, 475, 476, 481], "scale": [3, 4, 32, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187, 212, 232, 236, 247, 254, 258, 269, 270, 275, 290, 296, 319, 320, 324, 325, 339, 340, 341, 347, 351, 353, 361, 362, 364, 377, 381, 382, 383, 384, 435, 441, 451, 456, 461, 462, 463, 464, 467, 475, 480], "varieti": [3, 11], "inherit": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 301, 305, 306, 379, 458, 463, 474, 475], "from_pixel": [3, 11, 127, 128, 130, 131, 135, 137, 138, 142, 143, 162, 212, 244, 417, 419, 461, 462, 464, 466, 470, 471, 477, 478, 480, 481], "81": [3, 114], "d": [3, 42, 62, 65, 69, 77, 78, 79, 94, 106, 107, 275, 293, 297, 328, 330, 334, 347, 351, 394, 480], "privat": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 268, 476, 481], "absenc": 3, "total": [3, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 51, 53, 59, 61, 62, 63, 67, 68, 69, 70, 78, 79, 84, 95, 96, 109, 115, 120, 179, 183, 217, 332, 363, 378, 381, 394, 395, 428, 430, 432, 437, 440, 441, 460, 461, 462, 463, 464, 468, 474, 475, 477, 478, 479, 480], "accord": [3, 15, 16, 18, 21, 22, 23, 25, 27, 50, 61, 63, 70, 71, 84, 95, 96, 109, 112, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 168, 169, 177, 178, 179, 182, 183, 185, 186, 187, 236, 247, 296, 308, 319, 324, 325, 395, 397, 456, 457, 467, 468, 474, 476, 478], "inner": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 222, 262, 458, 462, 463, 475, 481], "kept": [3, 24, 26, 31, 113, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 203, 222, 249, 296, 324, 325, 468, 474], "wherev": 3, "lost": [3, 8, 268], "intern": [3, 50, 81, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 270, 459], "face": [3, 5, 8, 9, 330, 334, 466, 481], "NOT": [3, 97, 98, 105, 115, 241], "right": [3, 6, 7, 31, 71, 107, 114, 187, 217, 462, 463, 465, 475, 476, 481], "preliminari": 3, "warranti": 3, "preclud": 3, "presenc": [3, 42, 65, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 328, 330, 334, 394, 468], "annihil": 3, "supersed": [3, 31], "pettingzoowrapp": [3, 453], "group": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 65, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 147, 148, 149, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 168, 169, 170, 171, 173, 177, 178, 179, 182, 185, 186, 187, 190, 233, 252, 332, 333, 391, 456, 462, 467, 469, 475, 478], "__not__": [3, 347, 362, 364, 377, 382, 384, 386, 387], "constrain": [3, 191, 232, 295, 299, 381, 481], "li": 3, "fact": [3, 7, 8, 461, 463, 466, 474, 475, 476, 477, 478, 481], "meaning": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "perfectli": [3, 458, 461, 465, 476], "meaningless": 3, "val": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 178, 270, 427, 468, 480], "agent0": [3, 465], "agent1": 3, "overrid": [3, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 69, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 272, 287, 328, 330, 334, 394, 396, 419, 451, 456], "bool": [3, 12, 13, 15, 16, 18, 21, 22, 23, 24, 25, 27, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 99, 100, 101, 102, 103, 106, 107, 109, 110, 112, 113, 114, 115, 116, 121, 122, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 197, 203, 204, 205, 206, 208, 209, 212, 213, 217, 218, 220, 222, 223, 224, 225, 227, 230, 232, 234, 235, 236, 238, 240, 242, 243, 245, 247, 248, 249, 252, 253, 255, 258, 259, 260, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 275, 276, 278, 279, 280, 282, 283, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 305, 306, 307, 308, 309, 323, 324, 325, 328, 330, 331, 334, 337, 338, 343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 397, 399, 400, 401, 402, 405, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 426, 427, 430, 431, 432, 434, 435, 437, 451, 462, 463, 465, 476, 480, 481], "500": [3, 461, 462], "note": [3, 4, 15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 204, 220, 223, 260, 269, 270, 272, 277, 293, 295, 297, 299, 316, 328, 330, 334, 347, 351, 371, 394, 396, 453, 457, 462, 465, 467, 473, 474, 475, 481], "launch": [3, 15, 16, 21, 22, 23, 25, 28, 156, 165, 331], "bottleneck": [3, 8, 107, 114, 115], "great": [3, 7, 8, 465, 474, 480], "speedup": [3, 8, 474, 481], "precis": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 203, 220, 223, 294, 298, 461, 463], "misspecifi": 3, "caus": [3, 7, 8, 15, 16, 18, 100, 102, 122, 126, 129, 132, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 241, 481], "breakag": 3, "rais": [3, 13, 15, 16, 18, 21, 22, 23, 24, 25, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 95, 96, 100, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 168, 172, 173, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 226, 235, 245, 254, 255, 256, 260, 262, 269, 272, 274, 292, 316, 328, 330, 334, 364, 379, 384, 394, 395, 396, 427, 461, 463, 474, 475, 478], "mismatch": [3, 65, 462], "subprocess": [3, 15, 16, 21, 133, 156, 165], "multithreadedenv": [3, 453], "underneath": 3, "higher": [3, 4, 107, 215, 354, 461, 462, 463, 474, 478, 481], "cover": [3, 135, 137, 454, 463, 466, 469, 470, 476, 480], "type": [3, 12, 15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 109, 126, 129, 132, 136, 144, 147, 150, 153, 156, 157, 158, 159, 160, 165, 166, 167, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 200, 201, 203, 209, 212, 216, 220, 221, 224, 225, 230, 232, 234, 240, 242, 243, 249, 253, 255, 259, 260, 261, 262, 263, 265, 267, 269, 270, 272, 274, 279, 280, 300, 305, 306, 309, 317, 326, 328, 330, 332, 334, 335, 343, 347, 350, 351, 358, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 389, 391, 394, 395, 396, 397, 405, 417, 449, 453, 456, 461, 462, 463, 465, 469, 474, 475, 476, 478, 481], "atari": [3, 4, 212, 280, 419, 465, 470, 481], "classic": [3, 141, 150, 159, 462], "benchmark_batched_env": 3, "significantli": [3, 13, 22, 23, 25, 114, 115, 212, 457, 461, 462, 468, 475], "asyncenvpool": [3, 29, 160, 166], "pool": [3, 126, 160, 166, 256], "concurr": [3, 126, 474, 475], "contrari": [3, 457], "permit": [3, 215, 227, 252, 264, 361, 363, 378, 381, 383], "job": [3, 7, 22, 23, 25, 28, 69, 78, 79, 109, 478, 480], "famili": 3, "interest": [3, 347, 351, 456, 462, 463, 466, 475, 476, 481], "prefer": [3, 15, 16, 21, 25, 31, 32, 62, 69, 78, 79, 114, 115, 126, 160, 166, 188, 241, 249, 381, 386, 434, 456, 463, 474, 475, 478, 480], "pleas": [3, 35, 42, 47, 55, 65, 66, 72, 77, 81, 126, 129, 132, 135, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 212, 230, 256, 260, 262, 272, 305, 306, 307, 328, 330, 334, 364, 384, 394, 396, 454], "lifecycl": 3, "processorasyncenvpool": 3, "inter": [3, 156, 160], "threadingasyncenvpool": 3, "executor": [3, 22, 23, 25, 166], "functool": [3, 15, 16, 18, 21, 29, 126], "s0": [3, 126], "clamp": [3, 126, 351, 354, 373, 437, 457, 474, 476], "env_index": [3, 126], "async_step_send": [3, 126, 160, 166], "s0_result": [3, 126], "async_step_recv": [3, 126, 160, 166], "close": [3, 13, 15, 16, 18, 21, 22, 23, 25, 29, 126, 136, 151, 180, 181, 184, 187, 190, 191, 192, 193, 194, 216, 232, 261, 270, 272, 361, 363, 378, 381, 394, 396, 417, 461, 462, 466, 473, 474, 476, 480], "seamlessli": [3, 476], "paradigm": [3, 21, 475], "decpodp": 3, "game": [3, 4, 5, 129, 148, 149, 154, 155, 217, 280, 419, 465, 470], "thank": [3, 461, 465, 466, 480], "carrier": [3, 463, 464, 466, 478], "particular": [3, 35, 42, 47, 55, 65, 66, 72, 77, 83, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 262, 272, 328, 330, 334, 394, 396, 457, 458, 462, 464, 466, 473, 475, 478], "thu": [3, 378, 475], "vma": [3, 170, 171, 417, 474, 475], "robot": [3, 5, 7, 240, 265, 267, 465, 475], "vmasenv": [3, 417, 453, 474, 475], "balanc": [3, 130, 131, 461, 462], "num_env": [3, 15, 16, 21, 27, 126, 135, 139, 152, 170, 171, 178, 179, 182, 188, 417, 474, 475], "n_agent": [3, 170, 171, 305, 306, 307, 317, 326, 397, 417, 457, 474, 475], "ground_rew": 3, "pos_rew": 3, "style": [3, 62, 69, 78, 79], "vari": [3, 135, 137, 138, 158, 159, 162, 170, 241, 457, 465, 475], "creation": [3, 156, 165, 481], "info_spec": [3, 156], "agent_i_action_spec": 3, "agent_i_reward_spec": 3, "agent_i_observation_spec": 3, "categor": [3, 33, 34, 36, 37, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 127, 128, 129, 132, 135, 136, 137, 138, 141, 142, 143, 144, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 182, 185, 186, 187, 204, 205, 206, 224, 242, 289, 312, 315, 318, 343, 344, 347, 348, 349, 366, 369, 370, 397, 453, 464], "simpl": [3, 9, 19, 20, 35, 42, 47, 55, 59, 65, 66, 72, 77, 82, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 282, 328, 330, 334, 346, 351, 366, 368, 379, 383, 394, 396, 399, 457, 461, 462, 463, 466, 467, 468, 474, 475, 478, 481], "prefix": [3, 31, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 83, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 257, 260, 262, 272, 328, 330, 334, 347, 364, 379, 384, 394, 395, 396, 418, 464, 468, 481], "exactli": [3, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 138, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 293, 297, 312, 328, 330, 334, 364, 384, 394, 396, 461, 464, 469, 474, 475], "action_kei": [3, 15, 16, 18, 21, 22, 23, 25, 27, 50, 126, 129, 132, 136, 144, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 191, 203, 205, 206, 222, 232, 234, 274, 276, 292, 301, 302, 316, 346, 457, 474, 475], "reward_kei": [3, 42, 44, 46, 50, 56, 75, 97, 98, 105, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 272, 276, 302, 431, 435, 474, 475], "set_kei": [3, 224, 361, 363, 364, 366, 369, 370, 371, 377, 378, 379, 381, 382, 383, 384, 394, 397, 403, 461, 474, 475], "awai": [3, 463, 466, 474, 475, 480], "leaf": [3, 15, 16, 18, 20, 21, 22, 23, 25, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 74, 82, 84, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 231, 253, 255, 261, 351], "full": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 277, 295, 299, 330, 344, 351, 428, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "autoresettransform": 3, "invalid": [3, 35, 42, 47, 55, 65, 66, 72, 77, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 173, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 303, 304, 328, 330, 334, 394, 396], "nan": [3, 208, 268], "auto_reset": [3, 50, 126, 129, 132, 136, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 208, 272, 476], "auto_reset_replac": [3, 208], "placehold": [3, 137, 138, 182, 224, 262, 268], "set_gym_backend": [3, 15, 16, 18, 21, 29, 126, 129, 132, 135, 136, 144, 156, 157, 160, 165, 166, 167, 176, 177, 178, 179, 182, 185, 186, 187, 208, 453, 466, 480], "autoresettinggymenv": [3, 208], "self": [3, 15, 16, 18, 21, 22, 23, 25, 27, 32, 35, 39, 40, 42, 47, 48, 55, 61, 63, 65, 66, 70, 72, 74, 77, 84, 95, 96, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 231, 232, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 267, 268, 269, 272, 273, 274, 276, 289, 292, 295, 299, 302, 305, 306, 317, 326, 328, 330, 334, 347, 350, 355, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 399, 400, 401, 402, 403, 458, 461, 476, 480], "super": [3, 150, 180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 276, 289, 302, 355, 362, 364, 365, 370, 377, 382, 384, 386, 387, 396, 461, 476, 480], "td_reset": [3, 177, 208], "exclud": [3, 8, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 208, 212, 225, 317, 363, 378, 381, 474, 475, 478], "r": [3, 4, 50, 55, 129, 179, 182, 192, 205, 206, 208, 215, 217, 218, 236, 250, 257, 260, 269, 270, 275, 278, 294, 351, 360, 398, 417, 462, 476, 481], "3633e": [3, 208], "02": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 270, 462, 471], "4877e": [3, 208], "01": [3, 208, 236, 270, 275, 316, 357, 361, 363, 378, 381, 394], "2849e": [3, 208], "7584e": [3, 208], "6609e": [3, 208], "6166e": [3, 208], "8366e": [3, 208], "2761e": [3, 208], "5685e": [3, 208], "4102e": [3, 208], "8111e": [3, 208], "9959e": [3, 208], "0865e": [3, 208], "5644e": [3, 208], "2119e": [3, 208], "2542e": [3, 208], "03": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 208, 236, 257], "9952e": [3, 208], "4059e": [3, 208], "2094e": [3, 208], "9009e": [3, 208], "5140e": [3, 208], "3554e": [3, 208], "2920e": [3, 208], "7893e": [3, 208], "6429e": [3, 208], "3057e": [3, 208], "2867e": [3, 208], "6963e": [3, 208], "3818e": [3, 208], "2576e": [3, 208], "2679e": [3, 208], "1640e": [3, 208], "00": [3, 127, 128, 208, 460, 479], "6972e": [3, 208], "0212e": [3, 208], "5959e": [3, 208], "4637e": [3, 208], "3121e": [3, 208], "2168e": [3, 208], "5232e": [3, 208], "7704e": [3, 208], "7457e": [3, 208], "4127e": [3, 208], "1064e": [3, 208], "0854e": [3, 208], "5712e": [3, 208], "2189e": [3, 208], "5235e": [3, 208], "8289e": [3, 208], "0009e": [3, 208], "0257e": [3, 208], "8893e": [3, 208], "5872e": [3, 208], "9405e": [3, 208], "7766e": [3, 208], "0403e": [3, 208], "0626e": [3, 208], "2959e": [3, 208], "7263e": [3, 208], "2775e": [3, 208], "9564e": [3, 208], "0411e": [3, 208], "6769e": [3, 208], "6354e": [3, 208], "8698e": [3, 208], "1765e": [3, 208], "6292e": [3, 208], "5375e": [3, 208], "1820e": [3, 208], "7023e": [3, 208], "5836e": [3, 208], "9016e": [3, 208], "4826e": [3, 208], "6191e": [3, 208], "6387e": [3, 208], "8667e": [3, 208], "2056e": [3, 208], "1147e": [3, 208], "5991e": [3, 208], "0278e": [3, 208], "5219e": [3, 208], "3067e": [3, 208], "6617e": [3, 208], "3322e": [3, 208], "2629e": [3, 208], "4599e": [3, 208], "7298e": [3, 208], "5848e": [3, 208], "0148e": [3, 208], "5745e": [3, 208], "6982e": [3, 208], "7877e": [3, 208], "3527e": [3, 208], "7285e": [3, 208], "6668e": [3, 208], "0583e": [3, 208], "6956e": [3, 208], "3962e": [3, 208], "9845e": [3, 208], "5015e": [3, 208], "5903e": [3, 208], "9993e": [3, 208], "9418e": [3, 208], "0196e": [3, 208], "6557e": [3, 208], "2109e": [3, 208], "8997e": [3, 208], "1507e": [3, 208], "7363e": [3, 208], "0310e": [3, 208], "9574e": [3, 208], "8980e": [3, 208], "0090e": [3, 208], "forecast": 3, "awar": [3, 7, 100, 101, 102, 103, 116, 118, 122, 295, 299, 462, 464], "detect": [3, 185, 379, 394, 457], "return_contigu": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 473], "tensordictbas": [3, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 68, 70, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 120, 126, 129, 132, 134, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 195, 196, 203, 204, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 224, 225, 226, 227, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 272, 274, 276, 292, 295, 299, 301, 302, 316, 328, 330, 334, 342, 344, 346, 349, 350, 351, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 437, 461, 474, 476], "envwithdynamicspec": 3, "max_count": 3, "float": [3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 32, 35, 36, 39, 41, 42, 47, 55, 59, 62, 65, 66, 71, 72, 77, 78, 85, 106, 107, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 205, 208, 212, 216, 220, 223, 232, 233, 236, 240, 245, 246, 247, 254, 255, 258, 261, 262, 265, 267, 270, 272, 274, 275, 277, 278, 287, 290, 293, 296, 297, 300, 303, 304, 308, 309, 315, 319, 320, 323, 325, 328, 330, 334, 350, 354, 357, 359, 360, 361, 362, 363, 364, 368, 369, 370, 373, 374, 375, 376, 377, 378, 380, 381, 382, 383, 384, 385, 386, 387, 394, 396, 398, 404, 405, 406, 407, 408, 409, 410, 411, 412, 435, 461, 462, 478, 481], "_set_se": [3, 206, 209, 220, 223, 242, 476], "lazystackedtensordict": [3, 29, 50, 74, 101, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 473], "float32": [3, 15, 16, 18, 36, 39, 42, 44, 50, 61, 62, 63, 65, 70, 71, 75, 77, 78, 79, 82, 83, 84, 85, 95, 96, 100, 101, 102, 106, 107, 114, 122, 126, 127, 128, 129, 132, 135, 136, 137, 142, 143, 144, 150, 153, 154, 155, 156, 157, 160, 163, 164, 165, 166, 167, 168, 170, 171, 177, 178, 179, 182, 183, 185, 186, 187, 197, 203, 205, 209, 220, 223, 224, 225, 230, 233, 236, 238, 242, 243, 245, 249, 252, 253, 255, 258, 263, 276, 278, 288, 289, 295, 299, 302, 316, 317, 318, 326, 328, 330, 334, 338, 339, 340, 341, 342, 343, 346, 347, 348, 349, 350, 353, 355, 358, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 395, 397, 456, 476], "exclusive_field": [3, 29, 50, 101, 126, 179, 182, 190], "stack_dim": [3, 29, 50, 101, 126, 179, 182, 190, 196], "dramat": 3, "carefulli": [3, 474, 475, 481], "against": [3, 5, 7, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 338, 343, 344, 347, 348, 349, 350, 351, 362, 364, 377, 382, 384, 386, 387, 394, 396, 463, 474, 475], "plain": [3, 8, 331, 362, 364, 370, 377, 382, 384, 386, 387, 400, 401, 402, 466], "expens": [3, 107, 114, 115, 417, 478], "absent": [3, 39, 40, 48, 74, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 249, 262], "torchvis": [3, 11, 240, 267, 421, 474, 480, 481], "callabl": [3, 14, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 109, 126, 129, 132, 133, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 202, 207, 209, 216, 217, 218, 224, 230, 255, 262, 263, 272, 273, 279, 280, 300, 307, 328, 330, 334, 351, 360, 379, 394, 396, 417, 442, 443, 449, 450, 451, 462, 478], "bring": [3, 463, 466, 481], "kind": [3, 69, 82, 468, 474, 478], "consult": 3, "resize_par": 3, "revers": [3, 297], "order": [3, 11, 18, 29, 35, 42, 47, 55, 59, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 109, 113, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 213, 220, 223, 230, 238, 252, 260, 262, 272, 315, 328, 330, 334, 338, 343, 350, 352, 353, 355, 361, 362, 364, 365, 369, 370, 377, 381, 382, 383, 384, 386, 387, 394, 396, 462, 474, 475], "chain": [3, 61, 62, 63, 69, 70, 78, 79, 84, 95, 96, 144, 183, 185, 186, 216, 222, 279, 280, 353, 395, 481], "in_keys_inv": [3, 194, 198, 215, 220, 221, 223, 230, 236, 237, 238, 242, 243, 245, 250, 259, 261, 263, 264, 461, 473, 476, 481], "append_transform": [3, 50, 62, 67, 68, 69, 78, 79, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 198, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 230, 231, 232, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 265, 266, 268, 269, 270, 272, 278, 295, 299, 396, 417, 455, 461, 464, 474, 476, 478, 480, 481], "doubletofloat": [3, 461, 463, 473], "float64": [3, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 130, 131, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 216, 220, 223, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "think": [3, 179, 181, 182, 454, 463, 474, 475, 481], "in_": 3, "out_": 3, "perspect": [3, 289, 344, 371, 463, 465], "outer": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262, 458, 461, 462, 481], "ob": [3, 4, 8, 31, 39, 40, 48, 50, 62, 67, 68, 69, 74, 77, 78, 79, 84, 106, 109, 114, 115, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 203, 206, 208, 217, 220, 221, 223, 236, 250, 252, 258, 282, 283, 284, 285, 305, 306, 307, 348, 355, 362, 364, 365, 370, 377, 382, 384, 386, 387, 399, 400, 401, 402, 462, 465, 473, 474, 476, 478, 480, 481], "obs_standard": 3, "out_keys_inv": [3, 194, 198, 215, 220, 221, 223, 230, 236, 237, 238, 242, 243, 250, 252, 259, 261, 263, 264, 476], "illustr": [3, 461, 462, 467, 478], "chang": [3, 5, 7, 11, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 100, 101, 102, 103, 107, 113, 114, 116, 118, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 216, 220, 221, 223, 225, 232, 234, 242, 243, 249, 253, 259, 261, 262, 263, 269, 270, 272, 297, 328, 330, 334, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 457, 461, 464, 474, 475, 476, 477, 478, 481], "schemat": [3, 457], "outermost": 3, "innermost": 3, "similar": [3, 35, 42, 47, 55, 57, 61, 63, 65, 66, 69, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 266, 267, 269, 270, 272, 328, 330, 334, 339, 341, 347, 350, 351, 394, 395, 396, 457, 461, 462, 463, 464, 465, 467, 468, 469, 470, 476, 478, 480, 481], "transform_action_spec": [3, 180, 181, 184, 190, 191, 192, 193, 194, 216, 221, 236, 261, 263, 264, 272, 396], "spec_from_random_valu": 3, "_apply_transform": [3, 180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396, 476, 481], "rand": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 67, 68, 69, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 101, 109, 127, 128, 142, 143, 150, 154, 155, 161, 168, 169, 206, 209, 220, 223, 242, 252, 276, 302, 347, 361, 362, 364, 365, 366, 368, 369, 370, 377, 379, 381, 382, 384, 386, 387, 394, 476, 480, 481], "approach": [3, 62, 69, 78, 79, 212, 236, 275, 305, 306, 332, 386, 455, 461, 463, 468, 469, 474, 481], "insid": [3, 61, 63, 70, 84, 95, 96, 156, 183, 395, 481], "did": [3, 69, 268, 405, 462, 463, 469, 478, 481], "_inv_apply_transform": [3, 180, 181, 184, 190, 191, 192, 193, 194, 205, 261, 272, 396, 476, 481], "actiondiscret": 3, "rand_act": [3, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 209, 262, 466], "action_discret": 3, "addonetoob": 3, "Is": [3, 261], "rewrit": [3, 261], "_call": [3, 180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 222, 224, 225, 226, 227, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396, 476], "_inv_cal": [3, 180, 181, 184, 190, 191, 192, 193, 194, 205, 261, 272, 396], "overwrit": [3, 261], "till": [3, 261, 268], "encapsul": [3, 261, 466, 467, 468], "forget": [3, 261, 297], "edit": [3, 261, 272, 469], "top": [3, 4, 120, 127, 128, 142, 143, 219, 261, 276, 302, 330, 334, 467], "transform_output_spec": [3, 180, 181, 184, 190, 191, 192, 193, 194, 209, 216, 220, 221, 225, 232, 234, 242, 243, 249, 253, 259, 261, 263, 270, 272, 396], "transform_input_spec": [3, 180, 181, 184, 190, 191, 192, 193, 194, 205, 209, 216, 220, 221, 222, 234, 238, 242, 243, 248, 252, 253, 254, 255, 259, 261, 263, 266, 272, 396], "transform_observation_spec": [3, 180, 181, 184, 190, 191, 192, 193, 194, 209, 212, 213, 214, 215, 216, 219, 220, 221, 224, 225, 227, 229, 231, 232, 234, 236, 238, 242, 243, 244, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 268, 269, 270, 272, 396, 476], "transform_state_spec": [3, 180, 181, 184, 190, 191, 192, 193, 194, 216, 221, 236, 261, 263, 264, 272, 396], "transform_reward_spec": [3, 180, 181, 184, 190, 191, 192, 193, 194, 209, 210, 215, 216, 220, 221, 225, 232, 233, 234, 242, 243, 246, 247, 248, 249, 250, 252, 253, 259, 261, 263, 264, 270, 272, 396], "rewardsum": [3, 180, 181, 184, 190, 191, 192, 193, 194, 203, 261, 272, 396, 474, 475], "undo": 3, "addonetoact": 3, "subtract": [3, 254], "regist": [3, 14, 17, 19, 20, 24, 26, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 109, 126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 200, 203, 220, 223, 224, 248, 260, 262, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 417, 419, 428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 458, 461, 463, 466, 478], "manipul": [3, 4, 8, 130, 131, 240, 261, 265], "third_transform": 3, "unexpect": [3, 15, 16, 18, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 481], "behviour": 3, "fortun": [3, 464, 465, 466, 467, 470], "alreadi": [3, 8, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 100, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 204, 255, 272, 273, 328, 330, 334, 351, 394, 395, 396, 399, 400, 401, 402, 461, 463, 470, 474, 475], "catfram": [3, 346, 462], "notic": [3, 120, 212, 457, 463, 471, 476], "parenthood": 3, "henc": [3, 62, 204, 241, 305, 461, 463, 474, 475, 476], "transform1": 3, "transform2": 3, "transform3": 3, "last_two": 3, "isinst": [3, 156, 165, 262, 417, 427, 476], "discret": [3, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 135, 136, 137, 144, 148, 149, 156, 157, 158, 159, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187, 205, 222, 230, 312, 315, 318, 368, 369, 370, 371, 456, 462, 467, 475], "might": [3, 61, 63, 64, 70, 84, 95, 96, 183, 395, 423, 454, 461, 466, 481], "action_mask": [3, 129, 142, 143, 158, 159, 163, 164, 206], "unavail": [3, 158, 159], "probabl": [3, 4, 8, 71, 109, 112, 277, 278, 287, 289, 292, 293, 295, 297, 299, 300, 303, 304, 312, 324, 325, 330, 334, 347, 351, 364, 381, 456, 457, 462, 465, 467, 480], "probabilistictensordictmodul": [3, 191, 232, 351, 352, 457, 480], "tensordictsequenti": [3, 42, 65, 77, 278, 292, 295, 299, 316, 328, 330, 334, 343, 346, 352, 353, 358, 394, 456, 461, 462, 464, 465, 467, 471, 473, 474, 477, 480], "maskedcategor": [3, 304, 453], "linear": [3, 15, 16, 18, 21, 27, 29, 35, 42, 47, 55, 65, 66, 67, 72, 77, 126, 127, 128, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 232, 240, 255, 261, 262, 265, 267, 272, 276, 278, 279, 280, 282, 283, 284, 285, 289, 291, 292, 300, 302, 305, 306, 308, 309, 316, 318, 319, 320, 328, 330, 334, 338, 339, 340, 341, 345, 346, 347, 348, 350, 353, 355, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 447, 456, 462, 473, 477, 480], "in_feat": 3, "out_feat": 3, "logit": [3, 63, 71, 96, 288, 303, 304, 312, 315, 344, 347, 369, 370, 456], "dist": [3, 10, 303, 304, 312, 351, 457, 467], "distribution_class": [3, 232, 339, 340, 341, 342, 347, 351, 353, 361, 362, 364, 369, 370, 377, 381, 382, 383, 384, 456, 461, 463, 467, 474, 475, 480], "wrap": [3, 5, 15, 16, 18, 21, 22, 23, 25, 27, 32, 35, 41, 42, 47, 55, 65, 66, 71, 72, 77, 126, 127, 128, 129, 132, 136, 137, 141, 142, 143, 144, 149, 152, 154, 155, 156, 157, 158, 159, 160, 165, 166, 167, 169, 171, 172, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 200, 218, 260, 262, 272, 273, 295, 299, 327, 328, 330, 334, 339, 340, 341, 346, 348, 351, 356, 379, 394, 396, 397, 455, 456, 461, 462, 463, 464, 468, 471, 474, 475, 481], "actionmask": [3, 129], "your_base_env": 3, "mask_kei": [3, 31, 206, 241, 272], "itself": [3, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 208, 272, 328, 330, 334, 379, 386, 394, 396, 455, 463, 466], "ey": 3, "report": [3, 127, 128, 142, 143, 470], "foremost": 3, "callback": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 475], "ad": [3, 4, 18, 31, 35, 42, 47, 50, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 91, 106, 107, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 212, 230, 248, 260, 262, 272, 275, 308, 309, 316, 328, 330, 334, 360, 361, 363, 364, 366, 371, 378, 381, 384, 394, 396, 397, 462, 464, 465, 467, 474, 478, 480, 481], "tensordictrecord": [3, 453], "videorecord": [3, 11, 417, 453, 463, 470, 471, 474], "csvlogger": [3, 11, 417, 419, 453, 462, 470, 471, 474], "wandblogg": [3, 453, 470], "tensorboardlogg": [3, 447, 453, 470], "tag": [3, 7, 11, 181, 182, 417, 419, 421, 424, 451, 455, 470, 471, 474], "mp4": [3, 417, 419, 421, 471, 474], "video_format": [3, 417, 419, 421, 471, 474], "whc": 3, "cwh": 3, "exp": [3, 360, 457], "al": [3, 15, 16, 18, 21, 29, 32, 135, 137, 224, 238, 276, 465, 481], "pong": [3, 15, 16, 18, 21, 29, 152, 238, 465, 481], "v5": [3, 15, 16, 18, 21, 29, 135, 137, 152, 224, 238, 465, 481], "grow": [3, 101], "tediou": [3, 466], "workspac": [3, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 230], "pixelrendertransform": [3, 453, 474], "stream": [3, 331], "alik": [3, 417], "envcreat": [3, 18, 28, 156, 165, 260, 270, 417, 447, 448, 451, 453, 461, 462, 480, 481], "render_mod": [3, 417, 476], "rgb_arrai": [3, 417, 474, 475, 476], "uncom": [3, 470], "line": [3, 7, 35, 42, 47, 50, 55, 65, 66, 72, 77, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 462, 470, 474, 475], "comment": [3, 458, 462, 480], "pixels_record": [3, 417], "mission": 3, "irrespect": [3, 350, 351], "dmcontrol": [3, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "jumanji": [3, 126, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "framework": [3, 4, 9, 28, 126, 127, 128, 129, 132, 136, 142, 143, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 293, 480, 481], "Its": [3, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 269, 272, 328, 330, 334, 350, 394, 396, 403], "success": [3, 179, 181, 185, 190, 212, 257, 292, 364, 386, 462, 469, 471, 476, 478, 480], "foundat": [3, 5, 158, 159, 463, 475], "inspir": [3, 465, 476], "gone": [3, 4, 5, 346], "maintain": [3, 5, 9, 41, 57, 212, 270, 476], "concomittantli": 3, "problem": [3, 7, 8, 9, 18, 182, 462, 463, 464, 469, 474, 475, 476, 478, 481], "decor": [3, 8, 200, 202, 273, 295, 299, 337, 379, 399, 400, 401, 402, 427, 455, 464, 480], "relev": [3, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 71, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 399, 400, 401, 402, 403, 426, 465, 476], "gym_backend": [3, 202, 453], "env1": [3, 278, 473], "venv": 3, "python3": [3, 6, 7, 10], "site": [3, 6, 7, 129, 202], "env2": [3, 473], "_env": [3, 6, 135, 481], "classic_control": 3, "pendulumenv": [3, 50, 453, 476], "0x15147e190": 3, "0x1629916a0": 3, "mo_gymnasium": [3, 146, 176, 233], "side": [3, 4, 481], "v0": [3, 15, 16, 39, 40, 48, 74, 126, 129, 132, 136, 138, 141, 142, 143, 144, 145, 146, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 216, 233, 262, 269, 270, 427, 447], "26": [3, 115, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 217], "fun": [3, 202, 273, 463, 474, 475], "reveal": 4, "curv": 4, "exploit": [4, 467], "cv": 4, "flip": [4, 143], "correspondingli": 4, "invers": [4, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 67, 68, 69, 73, 74, 78, 79, 82, 85, 86, 87, 88, 89, 109, 180, 181, 184, 190, 191, 192, 193, 194, 205, 212, 220, 223, 225, 230, 236, 243, 245, 257, 259, 261, 263, 272, 359, 369, 377, 396, 453, 476], "prescript": 4, "tune": [4, 32, 191, 232, 455, 474, 475, 477], "coeffici": [4, 32, 41, 71, 191, 232, 363, 378, 381, 475], "bonu": [4, 361, 363, 378, 381, 394], "beta": [4, 62, 78, 106, 107, 369, 377, 378, 461, 462, 478, 480], "reduc": [4, 6, 38, 120, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 212, 218, 254, 270, 275, 277, 324, 453, 462, 474], "downstream": [4, 457, 461], "formul": [4, 474, 475], "rate": [4, 11, 269, 270, 398, 462, 463, 474, 475], "gradient": [4, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 277, 296, 304, 309, 312, 324, 325, 328, 330, 334, 351, 361, 363, 364, 365, 369, 370, 375, 377, 378, 379, 381, 382, 383, 384, 386, 387, 394, 396, 398, 399, 400, 401, 402, 437, 461, 463, 474, 475, 476], "easier": [4, 66, 456, 461, 480], "local": [4, 7, 10, 13, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 35, 42, 47, 55, 65, 66, 68, 72, 77, 107, 114, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 270, 272, 305, 306, 317, 326, 328, 330, 334, 394, 396, 397, 424, 426, 465, 470, 471, 474, 475], "optima": 4, "product": [4, 9, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 293, 294, 297, 298, 449, 450], "sum": [4, 27, 35, 42, 53, 59, 77, 120, 127, 128, 130, 131, 135, 137, 138, 142, 143, 151, 152, 162, 184, 211, 233, 248, 303, 304, 324, 326, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 375, 377, 378, 380, 381, 382, 383, 384, 386, 387, 394, 398, 405, 457, 461, 462, 463, 464, 465, 468, 471, 474, 475, 476, 481], "stat": [4, 236, 269, 270, 441, 451, 462, 463], "w": [4, 109, 129, 154, 155, 212, 214, 219, 244, 258, 293, 316, 419, 462, 478], "yield": [4, 15, 16, 18, 27, 29, 35, 42, 47, 55, 65, 66, 72, 77, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396, 455, 461, 468], "insight": [4, 178, 465], "auxiliari": [4, 468], "credit": 4, "futur": [4, 31, 35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 97, 98, 105, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 240, 260, 262, 267, 272, 300, 328, 330, 334, 361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 395, 396, 397, 454], "spars": [4, 42, 464], "intermedi": [4, 15, 16, 42, 50, 65, 77, 211, 278, 295, 299, 328, 330, 334, 344, 394, 461, 465, 477], "instrument": 4, "greatli": 4, "soccer": 4, "kick": 4, "ball": [4, 179], "likelihood": [4, 461], "discov": 4, "score": [4, 71, 184, 313, 315], "undesir": 4, "unintention": 4, "valuabl": 4, "idiosyncrat": 4, "subtask": 4, "hierarch": 4, "select": [4, 42, 62, 65, 67, 68, 69, 77, 78, 79, 84, 109, 129, 148, 149, 158, 159, 161, 170, 171, 180, 181, 184, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 227, 228, 231, 232, 234, 235, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 276, 328, 330, 334, 343, 348, 394, 396, 436, 456, 457, 461, 465, 466, 474, 478], "explicit": [4, 15, 16, 18, 273, 478], "curios": 4, "magnitudin": 4, "domin": 4, "smaller": [4, 32, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 297, 369, 377, 463, 475], "addition": [4, 287], "timestep": [4, 71, 245, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 474, 475], "realli": 4, "huge": [4, 306, 464], "std": [4, 236, 269, 274, 314, 461, 481], "torchrl": [4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 455, 460, 464, 466, 468, 469, 470, 471, 472, 473, 477, 478, 479], "unseen": 4, "extrins": 4, "wrong": [4, 107, 114], "bonus": 4, "denser": 4, "prior": [4, 72, 320, 373, 475], "freshli": 4, "drop": [4, 113, 115, 203, 270], "meant": [4, 55, 150, 185, 328], "encourag": [4, 156, 315, 461, 462, 478], "measur": [4, 100, 102, 122, 127, 128, 142, 143, 180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396, 463, 469], "novelti": 4, "revisit": 4, "diminish": 4, "decreas": [4, 32, 467], "ideal": [4, 217, 236, 476], "distil": 4, "nois": [4, 271, 309, 316, 336, 382, 386, 387, 432, 451, 461, 474], "exploratori": [4, 361, 363, 378, 381, 394], "misalign": 4, "trade": [4, 467], "unavoid": 4, "bootstrap": [4, 371, 399, 400, 406, 407, 461, 464], "noisi": [4, 308, 309, 336, 456], "unstabl": [4, 296, 324, 325], "inher": [4, 361, 381], "stochast": [4, 191, 232, 290, 309, 310, 320, 362, 364, 367, 369, 370, 375, 377, 380, 382, 384, 456, 463, 467, 475], "enemi": 4, "pomdp": [4, 478], "loos": [4, 351, 456, 462, 463], "nonexist": 4, "sequenc": [4, 15, 16, 18, 21, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 71, 73, 74, 77, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 99, 109, 110, 112, 118, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 151, 152, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 194, 198, 210, 211, 212, 213, 214, 219, 220, 222, 223, 227, 229, 230, 233, 236, 237, 241, 242, 243, 244, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 263, 269, 270, 279, 280, 287, 289, 293, 297, 300, 303, 304, 305, 306, 312, 318, 322, 328, 330, 334, 342, 352, 353, 367, 394, 418, 419, 432, 433, 434, 436, 437, 456, 461, 463, 464, 465, 473, 474, 475, 481], "lstm": [4, 255, 298, 299, 465], "rel": [4, 109, 255, 287, 323, 461, 462, 474, 475, 478], "tend": 4, "stabl": [4, 9, 10, 153], "compens": 4, "descent": [4, 309], "minimum": [4, 85, 126, 156, 165, 246, 290, 323, 324, 325, 354, 357, 360, 362, 364, 370, 379, 380, 384, 394, 428, 457, 461, 463, 471, 474, 475], "manual": [4, 11, 22, 25, 27, 50, 62, 67, 68, 69, 78, 79, 109, 136, 137, 187, 461, 464, 478], "deviat": [4, 236, 269, 270, 274, 276, 290, 302, 308, 309, 314, 315, 381, 386, 387, 461, 467, 475], "radic": 4, "begin": [4, 15, 16, 18, 21, 22, 23, 25, 27, 107, 114, 208, 293, 294, 297, 298, 360, 427, 457, 465, 466, 467, 468, 469, 470, 471], "stabil": [4, 228, 277, 361, 363, 378, 381, 383, 394], "stage": [4, 461, 476], "never": [4, 15, 16, 21, 29, 36, 85, 107, 257, 469, 480], "prevent": [4, 33, 34, 38, 39, 40, 43, 48, 51, 52, 53, 54, 59, 60, 67, 74, 98, 269, 270, 296, 324, 325, 361, 363, 378, 381, 383, 394, 435, 470, 478], "entir": [4, 15, 16, 18, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 270, 305, 463, 466, 476, 478], "submit": [4, 135, 209, 454, 480], "system": [4, 5, 95, 98, 177, 179, 182, 192, 455, 463, 474, 475, 476], "adequ": [4, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 463, 474, 475], "infeas": 4, "allevi": [4, 456], "prune": [4, 144, 186], "fire": [4, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "illeg": 4, "chess": [4, 129, 154, 155], "grasp": 4, "wherein": 4, "cumul": [4, 42, 248, 254, 276, 405, 463], "q": [4, 9, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 282, 283, 284, 285, 288, 289, 291, 317, 318, 326, 341, 344, 348, 349, 362, 364, 365, 366, 368, 369, 370, 371, 376, 377, 382, 384, 386, 387, 397, 453, 461, 468], "flow": [4, 399, 461, 463, 474, 475, 476, 478], "reparameter": [4, 287, 304, 312], "soft": [4, 376, 384, 385, 474], "critic": [4, 8, 339, 345, 361, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 394, 461, 468], "clip": [4, 71, 215, 246, 361, 363, 378, 381, 383, 386, 387, 394, 437, 463, 475, 476], "oppos": [4, 83], "incorrect": [4, 114], "thought": [4, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "region": 4, "squash": [4, 464, 480], "tanh": [4, 279, 280, 293, 294, 296, 297, 298, 300, 306, 323, 324, 325, 354, 463, 467, 474, 475, 476, 477], "prob": [4, 303, 304, 312, 315, 463, 475], "rememb": [4, 474], "remap": 4, "origin": [4, 8, 42, 61, 63, 64, 65, 70, 71, 77, 80, 84, 95, 96, 140, 183, 191, 221, 222, 232, 240, 262, 267, 272, 293, 328, 330, 334, 347, 350, 351, 362, 364, 376, 377, 379, 381, 382, 384, 386, 387, 394, 395, 461, 465, 473, 476, 481], "world": [5, 150, 330, 334, 356, 373, 455, 465, 470, 474, 475, 476, 481], "histor": 5, "ceas": 5, "farama": [5, 145, 146, 158, 159, 463, 476], "gymwrapp": [5, 126, 129, 132, 136, 141, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 225, 249, 253, 268, 453, 463, 480], "feel": [5, 454, 471, 480], "free": [5, 7, 13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 203, 220, 223, 361, 373, 381, 458, 463, 471, 475, 480], "gladli": 5, "prepar": [6, 46, 180, 463], "conda": [6, 7, 454], "cmake": 6, "activ": [6, 7, 9, 50, 279, 280, 286, 290, 300, 305, 306, 363, 378, 381, 456, 476, 480], "sim": 6, "bullet": 6, "headless": [6, 7, 141], "cluster": [6, 7, 8, 22, 27, 454], "withbullet": 6, "forg": [6, 7], "aihabitat": [6, 138], "y": [6, 7, 42, 65, 69, 77, 153, 291, 305, 327, 328, 330, 334, 394, 461, 475, 478], "facebookresearch": [6, 138], "subdirectori": 6, "verbos": [6, 471], "magnum_log": 6, "quiet": 6, "habitat_sim_log": 6, "remov": [6, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 91, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 242, 251, 272, 328, 330, 334, 379, 394, 395, 396, 474, 475, 480, 481], "command": [6, 7, 10, 160, 166, 167, 463, 474, 475, 476, 481], "readm": [6, 7, 170, 480], "md": [6, 7], "habitatenv": [6, 453], "_has_habitat": 6, "available_env": [6, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 142, 143, 144, 145, 148, 149, 153, 154, 155, 156, 157, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 182, 185, 186, 187, 481], "startswith": [6, 278, 457, 461, 468], "oserror": 6, "libllvmlit": 6, "ionstal": 6, "pointer": [6, 133, 379, 461], "env_nam": [6, 126, 127, 129, 130, 132, 133, 135, 136, 138, 142, 144, 145, 151, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 461, 463, 481], "llvmlite": 6, "config": [6, 7, 240, 267, 281, 286, 314, 441, 442, 443, 445, 448], "var": [6, 7, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 270, 272, 328, 330, 334, 364, 379, 384, 394, 396], "ld_preload": [6, 7], "bind": 6, "deactiv": [6, 7, 343, 362, 364, 370, 377, 379, 382, 384, 386, 387, 400, 401, 402], "importerror": [6, 7, 10], "usr": [6, 7, 10], "x86_64": [6, 7], "linux": [6, 7], "gnu": [6, 7], "libopengl": [6, 7], "undefin": [6, 7, 10, 35, 38, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 364, 379, 384, 394, 396, 465, 478], "symbol": [6, 7, 10], "_glapi_tls_curr": [6, 7], "mujoco_env": [6, 7], "libglvnd": [6, 7], "glx": [6, 7], "cos7": [6, 7], "reinstal": [6, 7], "xvfbwrapper": [6, 7], "sysroot": [6, 7], "lib64": [6, 7], "libgldispatch": [6, 7], "offici": [7, 465], "stand": [7, 45, 130, 131, 156, 165, 473, 476], "joint": [7, 462], "contact": [7, 64, 474], "engin": [7, 162, 331, 396, 455, 476], "biomechan": 7, "graphic": 7, "anim": [7, 475], "area": 7, "demand": [7, 470, 481], "fast": [7, 9, 101, 127, 128, 203, 243, 382, 461, 462, 463, 480], "articul": 7, "acquir": [7, 463], "deepmind": [7, 8, 9, 126, 129, 130, 131, 132, 136, 144, 148, 149, 154, 155, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 224, 463, 466], "whomev": 7, "licenc": 7, "incorpor": [7, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 292, 316, 386, 464, 467, 476], "relianc": 7, "obsolet": 7, "legaci": [7, 31], "pro": [7, 454], "tip": [7, 454], "glfw": [7, 461], "osmesa": 7, "egl": 7, "advic": [7, 481], "sudo": [7, 454], "apt": [7, 475], "libglfw3": 7, "libglew2": 7, "libgl1": 7, "mesa": 7, "libosmesa6": 7, "workflow": [7, 144, 186, 339, 340, 341], "glew": 7, "mesalib": 7, "anaconda": 7, "libgl": 7, "cos6": 7, "menpo": 7, "glfw3": 7, "mujoco_gl": 7, "pyopengl_platform": 7, "mkdir": 7, "earlier": [7, 457, 461, 463, 464, 474, 475, 478], "roboti": 7, "html": [7, 15, 16, 151, 153, 154, 155], "wget": 7, "mujoco210": 7, "tar": 7, "gz": 7, "xf": 7, "charg": [7, 15, 16, 21, 156, 165], "mjkei": 7, "txt": 7, "mjlib_path": 7, "home": [7, 61, 63, 83, 94], "bin": [7, 289, 315, 344, 456], "libmujoco210": 7, "ld_library_path": 7, "mujoco_py_mujoco_path": 7, "mujoco_py_mjkey_path": 7, "reload": 7, "later": [7, 285, 347, 351, 461, 463, 465, 478], "nvidia": [7, 140, 465], "older": [7, 273], "hack": [7, 461], "adatp": 7, "script": [7, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 427, 447, 451, 455, 456, 457, 458, 461, 462, 465, 470, 474, 475, 476, 478], "unnot": [7, 241], "mujoco_pi": 7, "cymj": 7, "linuxgpuextensionbuild": 7, "filenam": [7, 98, 462, 478], "troubleshoot": 7, "gl": 7, "h": [7, 109, 212, 214, 219, 244, 258, 293, 294, 295, 297, 298, 299, 302, 419, 462, 478], "eglshim": 7, "fatal": 7, "No": [7, 15, 16, 18, 21, 22, 23, 25, 27, 29, 33, 34, 38, 43, 53, 54, 59, 60], "directori": [7, 61, 63, 70, 83, 84, 95, 96, 100, 183, 395, 424, 426, 455, 457, 458, 461, 467, 470, 474], "devel": 7, "ubuntu": [7, 140], "libglew": 7, "dev": 7, "cento": 7, "yum": 7, "glu": 7, "disappear": [7, 462, 464, 473], "libstdc": 7, "glibcxx_3": 7, "29": [7, 114, 115], "compil": [7, 15, 16, 18, 31, 35, 42, 47, 55, 65, 66, 69, 72, 77, 78, 79, 99, 100, 101, 102, 103, 107, 110, 114, 115, 116, 121, 122, 124, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 273, 293, 294, 297, 298, 324, 328, 330, 334, 394, 396, 399], "libosmesa": 7, "libgcc": 7, "filenotfounderror": 7, "errno": 7, "patchelf": 7, "fatalerror": 7, "gladloadgl": 7, "mj_env": 7, "912": 7, "glfwerror": 7, "65537": 7, "myscript": 7, "runtimeerror": [7, 8, 15, 16, 18, 21, 24, 29, 35, 38, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 235, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396, 457, 481], "slurm": 7, "mjrendercontext": 7, "pyx": 7, "46": [7, 114, 127, 128], "114": 7, "_setup_opengl_context": 7, "opengl_context": 7, "130": 7, "offscreenopenglcontext": 7, "opengl": [7, 474, 475], "global": [7, 35, 42, 47, 55, 65, 66, 69, 72, 77, 78, 79, 109, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 260, 272, 317, 326, 328, 330, 332, 334, 347, 351, 394, 396, 397, 458, 461, 474, 475], "cuda_visible_devic": 7, "id": [7, 20, 31, 71, 84, 107, 109, 114, 115, 126, 129, 132, 135, 136, 144, 156, 157, 160, 165, 166, 167, 168, 169, 177, 178, 179, 182, 184, 185, 186, 187, 316, 364, 382, 422, 426, 469, 478], "slurm_step_gpu": 7, "black": [7, 129, 474], "onscreen": 7, "101": 7, "lgl": 7, "libegl": 7, "x11": [7, 475], "xlib": 7, "libx11": 7, "xorg": 7, "attributeerror": [7, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "nonetyp": 7, "glgeterror": 7, "this_dir": 7, "pwd": 7, "ln": 7, "libglut": 7, "sketch": [8, 458], "n_training_step": 8, "datapoint": [8, 83, 478], "n_data_per_train": 8, "no_grad": [8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 272, 277, 293, 294, 297, 298, 328, 330, 334, 394, 396, 399, 400, 401, 402, 463, 464, 465, 475], "loss_fn": [8, 464, 468, 469, 480], "zero_grad": [8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 315, 328, 330, 334, 394, 396, 458, 461, 463, 464, 465, 468, 471, 474, 475, 476], "backpropag": [8, 127, 128, 142, 143, 156, 361, 362, 363, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 397, 468, 475, 476], "differenti": [8, 83, 127, 128, 191, 232, 364, 386, 399, 400, 401, 402, 464, 467, 468, 474, 475, 476], "denomin": 8, "artifact": 8, "numer": [8, 69, 136, 187, 269, 296, 324, 325, 338, 343, 344, 347, 348, 349, 350, 351, 435, 463, 478, 481], "misconcept": 8, "freed": 8, "appear": [8, 11, 36, 59, 84, 85, 107, 114, 115, 132, 185, 190, 457, 476, 478], "compuat": 8, "fix": [8, 41, 156, 255, 362, 364, 380, 384, 462, 471, 476, 481], "retain_graph": [8, 127, 128], "discuss": [8, 9, 469, 474, 475], "inplac": [8, 35, 42, 47, 50, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 350, 394, 395, 396, 461], "forward": [8, 15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 231, 232, 236, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 305, 306, 307, 308, 310, 311, 314, 316, 317, 319, 320, 322, 326, 327, 328, 330, 334, 342, 344, 346, 347, 349, 350, 351, 354, 355, 357, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 394, 396, 397, 399, 400, 401, 402, 403, 453, 457, 464, 476, 480], "submodul": [8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 255, 272, 295, 299, 328, 330, 334, 358, 379, 394, 396], "param": [8, 35, 42, 47, 55, 65, 66, 71, 72, 77, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 209, 216, 220, 221, 225, 232, 234, 242, 243, 249, 253, 259, 261, 263, 270, 272, 287, 289, 305, 306, 307, 323, 328, 330, 334, 342, 347, 350, 353, 379, 389, 393, 394, 396, 399, 400, 401, 402, 403, 461, 465, 471, 474, 475, 476, 477, 480], "grad": [8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 351, 394, 396, 461, 463], "whose": [8, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 65, 66, 71, 72, 73, 74, 77, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 317, 328, 330, 334, 350, 394, 396], "fit": [8, 66, 236, 255, 273, 457, 458, 461], "brax": [8, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 243, 466, 481], "jax": [8, 127, 128, 142, 143, 273], "improperli": 8, "underli": [8, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 379, 464, 466, 468, 470, 476], "tedeiou": 8, "priorit": [8, 62, 78, 106, 107, 364, 365, 366, 368, 369, 370, 377, 382, 384, 386, 387, 461, 462, 469, 480], "amount": [8, 156, 316, 399, 462, 478], "costli": [8, 476], "constitut": [8, 462, 475, 476], "profil": 8, "frequent": [8, 50, 478], "program": [8, 369, 377, 465, 481], "functorch": [8, 10], "incl": 8, "suit": [8, 131, 463, 466, 480, 481], "mujoco_instal": 8, "valueerror": [8, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "bad": 8, "fds_to_keep": 8, "new_shap": 8, "permut": [8, 113, 238, 258, 465, 480, 481], "idea": [9, 382, 458, 464, 467, 474, 475], "introductori": 9, "intro": [9, 463, 464], "dai": [9, 480], "2022": [9, 10, 277, 480], "spin": [9, 130, 131], "hug": [9, 330, 334], "syllabu": 9, "lectur": 9, "awesom": 9, "curat": 9, "succinct": [9, 467], "summari": [9, 236, 269, 270, 461, 462, 463, 464], "reddit": 9, "reagent": 9, "orient": [9, 481], "baselines3": 9, "tf": 9, "bandit": [9, 153], "tensorflow": [9, 303, 304], "kera": 9, "acm": 9, "dopamin": 9, "prototyp": [9, 465, 471], "salina": 9, "tianshou": 9, "eleg": 9, "rlpyt": 9, "rllib": 9, "industri": [9, 480], "grade": 9, "factori": [9, 15, 16, 18, 21, 22, 23, 25, 27, 67, 69, 78, 79, 80, 82, 461], "cherri": 9, "jaxrl": 9, "mbrl": [9, 150, 456], "rlmeta": 9, "light": 9, "elegantrl": 9, "cloud": 9, "mtrl": 9, "baselin": 9, "689": 10, "_torchrl": 10, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 10, "colab": [10, 463, 464, 474, 475], "notebook": [10, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "24": [10, 115, 135, 151, 152, 179, 315, 346, 419, 474], "pip3": [10, 461, 463, 464, 474, 475], "url": [10, 138], "org": [10, 15, 16, 32, 62, 106, 107, 127, 128, 130, 131, 138, 142, 143, 148, 149, 151, 152, 153, 162, 170, 171, 212, 240, 265, 275, 281, 282, 283, 284, 285, 286, 289, 290, 291, 297, 302, 303, 304, 309, 310, 311, 315, 316, 317, 319, 320, 326, 344, 361, 362, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 380, 381, 383, 384, 385, 386, 399, 404, 412, 452, 472, 477], "whl": 10, "u": [10, 293, 294, 297, 298, 476], "upgrad": 10, "lib_version_her": 10, "pyav": 11, "conveni": [11, 212, 463, 474, 475, 476, 478], "power": [11, 462], "knob": 11, "dispos": 11, "clarifi": 11, "behind": [11, 249, 453], "ultim": [11, 296, 324, 325], "ffmpeg": 11, "whatev": [11, 457, 461], "fed": [11, 177, 475, 478], "feed": [11, 240, 267, 379, 394, 456, 461, 474, 475, 478], "suppos": [11, 156, 432, 458, 481], "snippet": [11, 240, 265, 461], "gave": 11, "extrem": [11, 156, 165, 361, 363, 378, 381, 383, 394], "blurri": [11, 465], "stitch": 11, "exp_nam": [11, 419, 420, 421, 424, 425, 426, 447, 462, 470, 471], "my_exp": [11, 470], "pixels_onli": [11, 130, 131, 135, 137, 138, 162, 461, 462, 470, 471, 480, 481], "my_video": [11, 470], "record_env": [11, 470, 471], "codec": 11, "h264": 11, "crf": 11, "preset": 11, "qualiti": [11, 341, 456], "allow_non": 12, "unwrap": [12, 224, 262, 427], "seealso": 12, "timeout": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 156, 192], "close_env": [13, 15, 16, 18, 21, 22, 23, 25, 29], "shutdown": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 160, 166, 209, 461, 462, 478, 480], "implic": [13, 22, 23, 25], "notimplementederror": [13, 22, 23, 25, 84, 461], "subclass": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 35, 36, 39, 42, 47, 65, 66, 72, 77, 85, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 207, 208, 261, 268, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 350, 351, 352, 354, 357, 379, 381, 455, 462, 464, 469, 476, 478], "policy_weight": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29], "worker_id": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "kwarg": [13, 15, 16, 18, 21, 22, 25, 26, 27, 29, 34, 35, 36, 37, 39, 40, 42, 43, 47, 48, 49, 52, 54, 55, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 84, 85, 86, 87, 88, 89, 95, 96, 98, 100, 101, 102, 103, 105, 106, 107, 109, 114, 115, 116, 118, 120, 122, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 199, 200, 206, 207, 209, 216, 240, 242, 251, 255, 260, 261, 262, 264, 266, 267, 269, 271, 272, 274, 276, 278, 279, 280, 282, 283, 284, 285, 288, 291, 292, 295, 296, 299, 300, 301, 302, 305, 306, 307, 312, 316, 325, 327, 328, 329, 330, 331, 333, 334, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 389, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 417, 419, 423, 424, 426, 430, 437, 442, 443, 448, 449, 450, 457, 463, 465, 475], "upload": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29], "transfer": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 351], "fetch": [13, 15, 16, 18, 19, 21, 22, 23, 25, 27, 29, 61, 63, 70, 84, 95, 96, 127, 128, 130, 131, 183, 191, 232, 395, 467, 477, 478], "typeerror": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29], "weight_updat": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 462], "overwritten": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29, 50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 227, 330, 334], "localweightsupdaterbas": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29], "remoteweightsupdaterbas": [13, 15, 16, 18, 21, 22, 23, 25, 27, 29], "get_server_weight": 14, "design": [14, 24, 26, 35, 42, 47, 55, 57, 59, 65, 66, 72, 77, 112, 118, 125, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 212, 230, 241, 260, 262, 270, 272, 328, 330, 334, 342, 361, 362, 363, 364, 369, 370, 371, 372, 373, 374, 377, 378, 379, 381, 382, 383, 384, 387, 394, 396, 397, 453, 455, 461, 462, 463, 464, 466, 467, 468, 473, 474, 475, 476, 478, 480, 481], "date": [14, 17, 129, 211, 422], "datacollectorbas": [14, 15, 17, 19, 20, 23, 24, 26, 30, 347, 351, 439, 442, 443, 447, 453], "all_worker_id": [14, 17, 19, 20, 24, 26, 30], "scope": [14, 17, 19, 20, 24, 26, 30, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 465, 481], "push_weight": [14, 17, 19, 20, 24, 26, 30], "push": [14, 17, 19, 20, 24, 26, 30], "noth": [14, 17, 19, 20, 24, 26, 30, 50, 144, 186, 461, 463], "register_collector": [14, 17, 19, 20, 24, 26, 30], "create_env_fn": [15, 16, 18, 21, 22, 23, 25, 27, 133, 156, 165, 461, 480], "policy_factori": [15, 16, 18, 21, 22, 23, 25, 27, 29], "device_typ": [15, 18, 21, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 240, 265, 267, 279, 280, 281, 282, 283, 284, 285, 291, 300, 305, 306, 308, 309, 314, 317, 350, 434, 445], "env_devic": [15, 16, 18, 21, 22, 23, 25, 27, 462], "create_env_kwarg": [15, 16, 18, 21, 27, 133, 151, 156, 165, 260, 461, 481], "collector_class": [15, 16, 22, 23, 25, 26, 27], "postproc": [15, 16, 18, 21, 22, 23, 25, 27, 29, 55, 245, 462, 478], "explorationtyp": [15, 16, 18, 21, 22, 23, 25, 27, 347, 379, 432, 456, 461, 462, 463, 464, 467, 474, 480], "interactiontyp": [15, 18, 21, 22, 23, 25, 27, 174, 201, 347, 351, 432], "preemptive_threshold": [15, 16, 21], "num_thread": [15, 16, 21, 61, 63, 70, 84, 95, 96, 136, 156, 165, 183, 187, 395], "num_sub_thread": [15, 16, 21, 156, 165], "str": [15, 16, 18, 21, 22, 23, 24, 25, 27, 28, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 100, 106, 107, 109, 120, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 142, 144, 148, 149, 151, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 201, 204, 208, 212, 224, 230, 231, 232, 240, 244, 253, 254, 257, 259, 260, 262, 263, 265, 267, 268, 269, 272, 273, 276, 288, 289, 295, 299, 301, 302, 305, 306, 307, 317, 318, 326, 328, 330, 331, 332, 334, 338, 343, 344, 347, 348, 349, 350, 351, 354, 355, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 387, 390, 394, 395, 396, 397, 398, 399, 400, 401, 402, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 451, 462, 463, 465], "set_trunc": [15, 16, 18, 21, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "use_buff": [15, 16, 18, 156, 165], "extend_buff": [15, 16, 18], "replay_buffer_chunk": 15, "trust_polici": [15, 16, 18, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "compile_polici": [15, 16, 18], "cudagraph_polici": [15, 16, 18], "no_cuda_sync": [15, 16, 18], "datacollector": [15, 16, 18, 21, 27, 29, 55, 381, 463, 469, 478], "recept": 15, "safe": [15, 16, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 107, 114, 183, 274, 316, 323, 324, 338, 343, 344, 347, 348, 349, 350, 351, 353, 395, 456, 480], "sota": [15, 16, 150, 228, 383, 428, 442, 455, 461, 462, 480], "guard": [15, 16], "doc": [15, 16, 80, 138, 141, 142, 143, 153, 162, 426, 457, 462, 474, 475, 478], "env_mak": [15, 16, 18, 27, 67, 126, 447, 481], "2000": [15, 16, 18, 55, 83, 139, 315, 419, 478], "50": [15, 16, 18, 27, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 64, 71, 73, 74, 82, 85, 86, 87, 88, 89, 114, 115, 148, 149, 272, 464, 478], "del": [15, 16, 18, 29, 461, 462, 463, 473, 474, 478, 480, 481], "int64": [15, 16, 18, 29, 31, 33, 34, 38, 43, 44, 50, 51, 52, 53, 54, 59, 60, 61, 63, 64, 65, 70, 71, 75, 78, 80, 83, 84, 94, 95, 96, 106, 114, 126, 129, 132, 136, 144, 147, 148, 149, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 190, 205, 209, 217, 224, 238, 245, 253, 289, 316, 318, 343, 344, 347, 348, 349, 395, 456, 476], "tensordictmodulebas": [15, 16, 18, 21, 22, 23, 25, 27, 42, 65, 77, 211, 327, 328, 330, 334, 343, 346, 348, 394, 464], "undergon": [15, 16, 18, 21, 22, 23, 25, 27, 83], "env_obs_kei": [15, 16, 18, 21, 22, 23, 25, 27], "mustn": [15, 16, 18, 21, 22, 23, 25, 27], "pickl": [15, 16, 18, 21, 22, 23, 25, 27, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 328, 330, 334, 394, 396], "exclus": [15, 16, 18, 21, 22, 23, 25, 27, 29, 69, 78, 79, 90, 91, 107, 114, 115, 189, 209, 225, 227, 293, 295, 297, 299, 303, 304, 343, 344, 348, 349, 385, 386, 387, 399, 400, 401, 402, 403, 426, 451, 456], "lifespan": [15, 16, 18, 21, 22, 23, 25, 29, 462], "divis": [15, 16, 18, 21, 22, 23, 25, 35, 107, 114, 115, 270, 275, 475], "endless": [15, 16, 18, 21, 22, 23, 25, 190], "sit": [15, 16, 18, 21, 22, 23, 25, 27, 439, 462], "cast": [15, 16, 18, 21, 22, 23, 25, 27, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 77, 82, 84, 85, 86, 87, 88, 89, 94, 95, 96, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 142, 143, 144, 151, 152, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 205, 206, 208, 209, 211, 212, 213, 216, 217, 218, 220, 221, 223, 224, 225, 226, 228, 231, 232, 239, 240, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 265, 266, 267, 268, 269, 270, 272, 328, 330, 334, 350, 363, 378, 381, 394, 395, 396, 474, 481], "deriv": [15, 16, 22, 23, 25, 27, 81, 287, 437], "span": [15, 16, 18, 21, 22, 23, 25, 27, 107, 114, 115], "n_step": [15, 16, 18, 21, 22, 23, 25, 27, 55, 272, 346, 462, 463, 474, 475], "mainli": [15, 16, 18, 21, 22, 23, 25, 27, 71, 178, 179, 182, 426, 456, 474, 475, 476], "round": [15, 16, 18, 21, 22, 23, 25, 27, 129, 177], "closest": [15, 16, 18, 21, 22, 23, 25, 27], "boolm": [15, 16, 21], "ratio": [15, 16, 21, 71, 461, 463], "finish": [15, 16, 18, 21, 27, 29, 136, 187, 245, 481], "earli": [15, 16, 21, 55, 136, 187, 253, 480], "safeti": [15, 16, 21, 150, 156, 165, 270], "harm": [15, 16, 21, 156, 165], "add_truncated_kei": [15, 16, 18, 21, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262], "trust": [15, 16, 18, 126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 218, 299], "cudagraphmodul": [15, 16, 18, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "behaviour": [15, 16, 18, 42, 65, 77, 328, 330, 334, 394, 464, 465, 480], "bypass": [15, 16, 18, 467], "isaaclab": [15, 16, 18, 137, 141], "maniskil": [15, 16, 18], "crash": [15, 16, 18, 245], "multiprocessedweightupdat": [15, 16], "ordereddict": [15, 16, 18, 21, 27, 29, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 269, 270, 272, 328, 330, 334, 364, 384, 394, 396], "worker0": [15, 16, 21], "state_dict0": [15, 16, 21], "worker1": [15, 16, 21], "state_dict1": [15, 16, 21], "reset_idx": [15, 16, 21], "static_se": [15, 16, 18, 21, 27, 29, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262], "increment": [15, 16, 18, 21, 29, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187, 236, 378], "env_fn": [15, 16, 18, 21, 29, 133, 449, 450], "env_fn_parallel": [15, 16, 18, 21, 29], "300": [15, 16, 18, 21, 29, 114, 115, 284, 285], "out_se": [15, 16, 18, 21, 29, 481], "irrevers": [15, 16, 21], "pipe": [15, 16, 18, 21, 29, 156], "tqdm": [15, 16, 18, 21, 29, 62, 67, 68, 69, 78, 79, 109, 437, 461, 463, 464, 474, 475, 476], "ale_pi": [15, 16, 18, 21, 29, 465], "10000": [15, 16, 21, 27, 156, 275, 437, 464], "progress": [15, 16, 18, 21, 29, 430, 431, 432, 437, 458, 462, 464, 481], "bar": [15, 16, 18, 21, 29, 100, 102, 122, 342, 430, 431, 432, 437, 458, 462], "pbar": [15, 16, 18, 21, 29, 461, 463, 464, 474, 475, 476], "100_000": [15, 16, 18, 21, 29, 465, 471], "prec_wc": [15, 16, 18, 21, 29], "wc": [15, 16, 18, 21, 29], "write_count": [15, 16, 18, 21, 29, 62, 67, 68, 69, 78, 79, 109], "set_descript": [15, 16, 18, 21, 29, 461, 463, 464, 474, 475, 476], "remote_collector": [17, 27], "max_interv": 17, "leverag": [17, 27, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 461, 475, 481], "_get_server_weight": [17, 20, 24, 26], "_maybe_map_weight": [17, 20, 24, 26], "_sync_weights_with_work": [17, 20, 24, 26], "_skip_upd": 17, "interv": [17, 205, 257, 418, 419, 429, 439, 462, 476], "raycollector": [17, 67, 453], "return_same_td": 18, "interruptor": 18, "cautious": [18, 381], "whole": [18, 35, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 83, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 347, 364, 384, 394, 396, 428, 461, 463], "_interruptor": 18, "outsid": [18, 221, 260, 457, 470, 474, 475, 476], "start_collect": 18, "stop_collect": 18, "preeptiv": 18, "init": [18, 27, 29, 35, 42, 47, 55, 65, 66, 67, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 261, 269, 272, 305, 306, 307, 328, 330, 334, 394, 396, 399, 426, 462, 463], "chunk": [18, 29, 467], "policy_state_dict": [18, 29], "env_state_dict": [18, 29], "256": [18, 29, 94, 148, 149, 230, 286, 462, 463, 465, 474, 475], "weight_gett": 19, "vanillaweightsend": 19, "sender": 19, "weightupdatereceiverbas": 19, "update_weight": [19, 24, 26, 439], "piec": [20, 99, 110, 121, 124, 125, 461, 462, 463, 470, 474, 475, 476, 478], "scheme": [20, 458, 481], "hanld": 20, "unchang": [20, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 222, 240, 255, 261, 262, 265, 267, 272, 292, 328, 330, 334, 350, 394, 396, 419, 434, 461, 478], "__call__": [20, 35, 42, 47, 55, 64, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 351, 394, 396, 458], "proxi": [20, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 70, 73, 74, 82, 84, 85, 86, 87, 88, 89, 95, 96, 183, 304, 312, 347, 395, 457], "weakref": [20, 50, 84], "registr": [20, 462], "exporationtyp": [22, 23, 25], "collector_kwarg": [22, 23, 25, 27], "num_workers_per_collector": [22, 23, 25, 27], "slurm_kwarg": [22, 23, 25], "update_after_each_batch": [22, 23, 25, 27], "max_weight_update_interv": [22, 23, 25, 27], "tcp_port": [22, 23, 25, 28], "respect": [22, 23, 25, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 210, 216, 220, 223, 234, 240, 241, 250, 255, 261, 262, 265, 267, 272, 293, 297, 305, 320, 328, 330, 334, 350, 355, 361, 363, 378, 381, 383, 394, 396, 399, 401, 402, 433, 457, 463, 464, 474, 475], "subnod": [22, 23, 25, 27], "readi": [22, 25, 27, 454, 462, 463, 465, 467, 470, 478, 480], "fashion": [22, 25, 27, 61, 63, 70, 84, 95, 96, 115, 183, 395], "distributed_back": [22, 23], "ucc": [22, 23], "submitit_delai": [22, 28], "former": [22, 23, 25, 31, 35, 42, 47, 62, 65, 66, 69, 72, 77, 78, 79, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357, 461], "whilst": [22, 23, 25], "homonym": [22, 23, 25, 476], "visit": [22, 23, 25, 84, 182], "facebookincub": [22, 23, 25], "tcp": [22, 23, 25, 28], "port": [22, 23, 25, 28, 168, 332], "10003": [22, 23, 25, 28], "distributedweightupdat": 22, "liter": [23, 84, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 189, 190, 330, 334, 337], "update_interv": 23, "frequenc": [23, 315, 461], "restart": 24, "rank": [24, 120, 276, 332, 333], "visible_devic": 25, "tensorpipe_opt": 25, "experiment": [25, 31, 59, 347, 351], "tensorpiperpcbackendopt": 25, "rpcweightupdat": 25, "collector_info": 26, "collector_rref": 26, "ray_init_config": [27, 67], "remote_config": [27, 62, 67, 68, 69, 78, 79, 109], "num_collector": [27, 449, 450, 461, 462], "coordin": [27, 219], "autodetect": 27, "num_cpu": [27, 67], "num_gpu": [27, 67], "1024": [27, 67, 286, 478], "equat": [27, 65, 84, 136, 187, 269, 270, 316, 360, 363, 385, 394, 463, 466, 476], "exce": [27, 478], "indefinit": [27, 93], "rayreplaybuff": [27, 453], "enfoc": 27, "rayweightupdat": 27, "distributed_collector": [27, 67], "add_collector": 27, "local_polici": 27, "stop_remote_collector": 27, "num_job": 28, "tcpport": 28, "submitit_main_conf": 28, "slurm_cpus_per_task": 28, "slurm_gpus_per_nod": 28, "slurm_partit": 28, "timeout_min": 28, "submitit_collection_conf": 28, "delai": [28, 386, 468], "jump": [28, 466], "host": [28, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "satellit": 28, "rendezv": 28, "hang": 28, "forev": 28, "default_config": [28, 281, 286, 314, 342], "default_slurm_conf_main": 28, "default_slurm_conf": 28, "dialog_turns_per_batch": 29, "yield_only_last_step": 29, "yield_completed_trajectori": 29, "total_dialog_turn": 29, "async_env": 29, "flatten_data": 29, "queue": [29, 160, 269, 396, 478, 480], "simplifi": [29, 62, 200, 467, 476, 478], "steps_per_batch": 29, "total_step": 29, "vllm": [29, 30, 185, 329, 330, 331, 332, 333, 334], "vllmwrapper": [29, 185, 330], "mocking_class": [29, 260], "dummystrdataload": 29, "llmenv": [29, 180, 188, 190, 334], "llm_model": 29, "gpt2": [29, 64, 71, 80, 83, 144, 186, 281, 286, 314, 330, 334], "get_token": 29, "pad_token": [29, 64, 80], "eos_token": [29, 64, 181], "from_dataload": [29, 185, 190], "from_text": [29, 177, 185, 190, 330, 334], "group_repeat": [29, 178, 179, 182, 185, 188, 190], "attention_mask": [29, 61, 63, 64, 70, 71, 80, 83, 94, 96, 185, 330, 334], "text": [29, 64, 71, 80, 96, 144, 177, 178, 179, 181, 182, 184, 185, 186, 192, 293, 294, 297, 298, 316, 330, 334, 396, 455, 463], "nontensorstack": [29, 50, 57, 101, 126, 129, 144, 177, 179, 182, 186, 190, 194, 230, 259, 263, 334], "plsgqejeyd": 29, "text_respons": [29, 96, 177, 179, 181, 182, 184, 185, 187, 192, 330, 334, 455], "ec": 29, "tjbjz3perwhz": 29, "tokens_respons": [29, 96, 185, 330, 334], "alia": [29, 35, 42, 47, 55, 62, 65, 66, 67, 68, 69, 72, 77, 78, 79, 84, 100, 101, 102, 103, 109, 116, 118, 122, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 380, 381, 382, 383, 384, 386, 387, 394, 396, 397, 403], "master_address": [30, 332], "master_port": [30, 332], "model_metadata": 30, "vllm_tp_size": 30, "rollout_tensordict": 31, "nestedkei": [31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 65, 70, 73, 74, 75, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 107, 114, 115, 126, 129, 132, 136, 144, 156, 157, 160, 161, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 191, 194, 198, 203, 204, 205, 206, 210, 211, 212, 213, 214, 215, 219, 220, 221, 222, 223, 224, 225, 227, 229, 230, 231, 232, 233, 236, 237, 238, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 265, 269, 270, 272, 274, 278, 289, 292, 316, 318, 342, 346, 351, 366, 395, 396, 397, 417, 419], "as_nest": 31, "x": [31, 42, 55, 65, 66, 69, 71, 72, 77, 115, 144, 186, 230, 232, 258, 263, 273, 275, 277, 278, 280, 289, 291, 293, 294, 295, 297, 298, 299, 300, 302, 305, 306, 327, 328, 330, 334, 343, 347, 348, 357, 360, 394, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 437, 455, 461, 465, 474, 476, 478, 480], "durat": [31, 475], "meta": [31, 61, 63, 70, 82, 84, 95, 96, 134, 138, 183, 361, 363, 378, 381, 383, 395, 458, 463, 474, 475, 478], "aren": [31, 254, 464], "eventu": [31, 317, 464, 476], "recov": [31, 114, 115, 352, 369, 377, 473], "layout": 31, "to_padded_tensor": 31, "nested_tensor": [31, 135, 137], "stride": [31, 35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 279, 280, 282, 283, 291, 305, 328, 330, 334, 394, 396, 462, 474, 480], "jag": 31, "focu": [31, 461, 462, 463, 465, 467, 468, 469, 474], "team": [31, 474, 475, 480], "cat": [31, 50, 190, 355, 362, 364, 365, 377, 382, 384, 386, 387, 474, 478, 480], "arang": [31, 33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 107, 114, 115, 205, 289, 303, 304, 343, 428, 456, 478], "obs_": 31, "trajectory_id": 31, "int32": [31, 35, 36, 50, 79, 85, 114, 142, 143, 154, 155, 167, 197, 346], "data_split": 31, "got": [31, 469], "init_kl_coef": 32, "horizon": [32, 148, 149, 170, 171, 276, 302, 463], "kl": [32, 41, 71, 191, 232, 373, 378], "describ": [32, 61, 63, 70, 82, 84, 95, 96, 161, 183, 213, 323, 324, 366, 395, 422, 457, 461, 463, 474, 475, 476, 481], "ziegler": 32, "et": [32, 276], "relax": [32, 417], "penalti": [32, 71, 189, 375, 378], "strai": [32, 71], "greater": [32, 107, 114, 115, 217, 233, 234, 295, 299, 364, 461, 462], "increas": [32, 98, 212, 256, 277, 316, 474, 475], "pull": [32, 50, 84, 178, 478], "toward": [32, 267], "aggress": 32, "kl_coef": [32, 41, 71], "arxiv": [32, 62, 106, 107, 127, 128, 130, 131, 142, 143, 148, 149, 151, 152, 162, 170, 171, 212, 240, 265, 275, 281, 282, 283, 284, 285, 286, 289, 290, 291, 297, 302, 309, 310, 311, 315, 316, 317, 319, 320, 326, 344, 361, 362, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376, 377, 380, 381, 384, 385, 386, 399, 404, 412, 477], "pdf": [32, 212, 281, 282, 283, 284, 285, 289, 315, 316, 344, 364, 371, 375, 382, 385, 386, 399, 404, 412], "1909": 32, "08593": 32, "lm": 32, "blob": 32, "master": [32, 332, 474, 475], "lm_human_prefer": 32, "train_polici": 32, "kl_valu": 32, "coef": [32, 191, 232, 363, 378, 381], "newest": 32, "int8": [33, 132, 147, 158, 159, 210], "encod": [33, 34, 35, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 73, 74, 82, 85, 86, 87, 88, 89, 127, 128, 132, 135, 136, 137, 138, 141, 142, 143, 151, 152, 154, 155, 162, 168, 169, 187, 205, 222, 311, 312, 315, 319, 330, 334, 360, 462, 463, 464, 467, 476, 478], "null": [33, 36, 37, 39, 40, 42, 48, 49, 57, 58, 62, 73, 74, 78, 82, 85, 86, 87, 88, 89, 106, 107, 177, 185, 210, 230], "denot": [33, 475], "clariti": [33, 50], "assert_is_in": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "cardin": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 84, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 289, 318, 343, 344, 349, 463], "outcom": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 287, 303, 304, 323, 379, 394, 474], "cartesian": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "clear_device_": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "is_in": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 481], "np": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 136, 187, 268, 354, 417, 465, 474, 476], "ndarrai": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 136, 187, 316, 354, 417, 465, 474], "ignore_devic": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "arrai": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 71, 73, 74, 82, 85, 86, 87, 88, 89, 106, 126, 129, 132, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 190, 224, 293, 294, 297, 298, 461, 474], "use_mask": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 158, 159], "erase_memoize_cach": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "memoiz": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 136, 187], "memoize_encod": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "compliant": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "singleton": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 184, 279, 280, 300, 321, 322, 453, 457], "start_dim": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "end_dim": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "classmethod": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 73, 74, 77, 78, 79, 82, 84, 85, 86, 87, 88, 89, 95, 96, 109, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 230, 265, 273, 280, 281, 314, 395], "implements_for_spec": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "torch_funct": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "index_typ": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 57, 58, 73, 74, 82, 85, 86, 87, 88, 89], "tensor_to_index": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "exanpl": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "one_hot": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 289, 304, 318], "categ": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 347], "to_categorical_spec": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "idx_one_hot": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "idx_categ": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "to_categor": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "make_neg_dim": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "convert": [33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 74, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 126, 127, 128, 129, 132, 135, 136, 137, 138, 141, 142, 143, 144, 151, 152, 154, 155, 156, 157, 160, 162, 165, 166, 167, 168, 169, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 216, 220, 223, 240, 255, 261, 262, 265, 267, 269, 270, 272, 328, 330, 334, 350, 360, 379, 394, 395, 396, 461, 462, 463, 476, 478], "shortcut": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 476, 481], "ndimens": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 461], "violat": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 456], "project": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 66, 73, 74, 82, 85, 86, 87, 88, 89, 222, 274, 297, 316, 338, 343, 344, 347, 348, 349, 350, 351, 426, 456, 480, 481], "uniformli": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 108, 379, 394, 481], "normal": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 68, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 236, 269, 270, 274, 275, 279, 280, 296, 300, 303, 304, 324, 325, 347, 351, 363, 364, 378, 381, 396, 432, 435, 451, 456, 458, 464, 467, 475, 481], "drawn": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 255, 292, 347, 351, 463, 474, 475], "set_provisional_n": [33, 34, 38, 43, 51, 52], "temporarili": [33, 34, 38, 43, 51, 52, 98, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 469, 478], "dest": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 77, 82, 85, 86, 87, 88, 89, 240, 265, 267, 350], "to_numpi": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "transformed_in": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89, 262, 323, 451], "check_spec_encod": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "to_one_hot": [33, 34, 38, 43, 51, 52, 53, 54, 59, 60], "hot": [33, 34, 38, 43, 51, 52, 53, 54, 59, 60, 127, 128, 135, 137, 138, 141, 142, 143, 148, 149, 151, 152, 154, 155, 158, 159, 162, 168, 169, 170, 171, 205, 206, 222, 289, 312, 313, 318, 343, 344, 348, 349, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 464], "categ_sampl": [33, 34, 38, 43, 53, 54, 59, 60], "onehot_sampl": [33, 34, 38, 43, 53, 54], "to_one_hot_spec": [33, 34, 38, 43, 51, 52, 53, 54, 59, 60], "categoricalbox": [33, 34, 38, 43, 53, 54, 59, 60, 157], "type_check": [33, 34, 36, 37, 38, 39, 40, 43, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 73, 74, 82, 85, 86, 87, 88, 89], "update_mask": [33, 34, 38, 43, 51, 52, 53, 54, 59, 60], "disabl": [33, 34, 35, 38, 42, 43, 47, 51, 52, 53, 54, 55, 59, 60, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 296, 325, 328, 330, 334, 394, 396, 417, 461, 474, 475], "unmask": [33, 34, 38, 43, 51, 52, 53, 54, 59, 60], "ts": [33, 34, 38, 43, 51, 52, 53, 54, 59, 60], "num_bit": 35, "convert_to_binari": 35, "decim": 35, "1001": 35, "bit": [35, 230, 463, 464, 466, 474, 475, 478], "heavysid": 35, "binary_to_decim": 35, "add_modul": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "fn": [35, 42, 47, 55, 64, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 263, 272, 328, 330, 334, 394, 396, 449, 450], "recurs": [35, 39, 40, 42, 47, 48, 55, 65, 66, 72, 74, 77, 90, 91, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396, 465], "init_weight": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "m": [35, 42, 47, 51, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 222, 272, 278, 328, 330, 334, 351, 394, 396, 462, 476], "fill_": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 462, 464], "net": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 283, 285, 288, 291, 306, 328, 330, 334, 361, 362, 364, 370, 377, 381, 382, 383, 384, 394, 396, 447, 462, 476, 477, 480], "in_featur": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 279, 280, 282, 283, 284, 285, 291, 300, 305, 306, 308, 309, 328, 330, 334, 339, 350, 358, 366, 368, 394, 396, 465, 467, 468], "out_featur": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 150, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 276, 279, 280, 282, 283, 284, 285, 290, 291, 295, 299, 300, 302, 305, 306, 308, 309, 328, 330, 334, 339, 343, 350, 358, 366, 368, 394, 396, 456, 461, 464, 465, 467, 468, 471, 480], "bia": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 230, 240, 255, 260, 261, 262, 265, 267, 272, 275, 279, 280, 282, 283, 284, 285, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 306, 308, 309, 316, 328, 330, 334, 350, 357, 359, 360, 364, 379, 384, 394, 396, 457, 461, 462, 463, 464, 475], "requires_grad": [35, 42, 47, 55, 65, 66, 72, 77, 126, 127, 128, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 260, 262, 272, 315, 328, 330, 334, 351, 364, 384, 394, 396], "bfloat16": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "datatyp": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 478], "member": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396, 419], "xdoctest": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 230, 240, 255, 260, 261, 262, 265, 267, 272, 328, 330, 334, 350, 364, 379, 384, 394, 396], "buf": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "20l": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396], "1l": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396], "5l": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396], "doubl": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 220, 221, 223, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 366, 371, 376, 382, 385, 394, 396, 397, 461, 462, 463, 464, 481], "eval": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 269, 272, 277, 328, 330, 334, 394, 396, 456, 461, 462, 463], "evalu": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 137, 144, 148, 149, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 217, 262, 272, 277, 287, 303, 304, 312, 325, 328, 330, 334, 382, 394, 396, 442, 443, 462, 463, 471], "dropout": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 277, 278, 293, 295, 297, 299, 300, 328, 330, 334, 394, 396, 456, 464], "batchnorm": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 275, 328, 330, 334, 394, 396], "comparison": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 262, 272, 328, 330, 334, 379, 394, 396, 461, 462], "extra_repr": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "recip": [35, 42, 47, 64, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 307, 310, 311, 314, 316, 319, 320, 322, 327, 328, 330, 334, 342, 344, 346, 349, 354, 357], "get_buff": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "get_submodul": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "qualifi": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "referenc": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "resolv": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "someth": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 147, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 454, 462, 463, 476, 481], "get_extra_st": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 328, 330, 334, 394, 396], "set_extra_st": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 328, 330, 334, 394, 396], "picklabl": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 328, 330, 334, 394, 396], "get_paramet": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "net_b": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "net_c": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "conv": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 279, 280, 328, 330, 334, 394, 396, 462], "conv2d": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 280, 282, 283, 291, 305, 328, 330, 334, 394, 396], "kernel_s": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 279, 280, 282, 283, 291, 305, 310, 328, 330, 334, 394, 396, 462, 480], "diagram": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "degre": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 218, 272, 328, 330, 334, 394, 396], "named_modul": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "half": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396, 461], "ipu": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "strict": [35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 364, 384, 394, 395, 396, 465], "descend": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "get_swap_module_params_on_convers": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "persist": [35, 42, 45, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 230, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "preserv": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 350, 364, 384, 394, 396], "missing_kei": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "unexpected_kei": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "namedtupl": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "l": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 293, 297, 328, 330, 334, 394, 396, 398, 463, 476], "idx": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "mtia": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "named_buff": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "remove_dupl": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396], "prepend": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 379, 394, 396, 465], "running_var": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "named_children": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "conv4": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "conv5": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "memo": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "named_paramet": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 232, 272, 328, 330, 331, 334, 379, 394, 396], "register_backward_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "removablehandl": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "favor": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 272, 328, 330, 334, 394, 396, 463], "register_full_backward_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_buff": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "running_mean": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "alongsid": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 455, 470], "num_featur": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 275, 328, 330, 334, 394, 396], "register_forward_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 289, 318, 328, 330, 334, 394, 396], "with_kwarg": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "always_cal": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_module_forward_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "regardless": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 363, 378, 381, 394, 396], "register_forward_pre_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "invok": [35, 42, 47, 55, 65, 66, 68, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "And": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 333, 334, 394, 396, 468], "forward_pr": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_module_forward_pre_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "ordinarili": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "grad_input": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "grad_output": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "technic": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 462, 464, 465, 467], "caller": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_module_full_backward_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_full_backward_pre_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "backward_pr": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_module_full_backward_pre_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_load_state_dict_post_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "incompatible_kei": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "thrown": [35, 42, 47, 55, 65, 66, 72, 73, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 478], "register_load_state_dict_pre_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "local_metadata": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "error_msg": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "noqa": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 141, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "b950": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_modul": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 458], "register_paramet": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_state_dict_post_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "register_state_dict_pre_hook": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "keep_var": [35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 364, 384, 394, 395, 396], "requires_grad_": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 465], "autograd": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396], "freez": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 269, 270, 272, 328, 330, 334, 394, 396], "finetun": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "gan": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "set_submodul": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "share_memori": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 133, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 461], "share_memory_": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396, 480], "destin": [35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 203, 211, 220, 221, 223, 230, 260, 262, 265, 269, 272, 328, 330, 334, 364, 384, 394, 395, 396, 419], "averag": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 269, 270, 272, 316, 328, 330, 334, 364, 372, 373, 384, 394, 396, 435, 461, 463], "shallow": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 364, 384, 394, 396, 464], "detach": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 230, 260, 262, 272, 328, 330, 334, 364, 375, 379, 384, 386, 394, 396, 399, 400, 401, 402, 461], "non_block": [35, 42, 47, 55, 61, 63, 65, 66, 70, 72, 77, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 395, 396, 464], "memory_format": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "channels_last": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "tri": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396, 470], "pin": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "4d": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "ignore_w": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "1913": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "3420": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "5113": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "2325": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "torch_doctest_cuda1": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "gpu1": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "1914": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "5112": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "2324": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "float16": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 294, 298, 328, 330, 334, 350, 394, 396], "cdoubl": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "3741": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "j": [35, 42, 47, 55, 62, 65, 66, 72, 77, 106, 107, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396, 458, 468], "2382": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "5593": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "4443": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "complex128": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "6122": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "1150": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 216, 240, 255, 261, 262, 265, 267, 272, 328, 330, 334, 350, 394, 396], "to_empti": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "dst_type": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "xpu": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "set_to_non": [35, 42, 47, 55, 65, 66, 72, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 190, 191, 192, 193, 194, 272, 328, 330, 334, 394, 396], "upper": [36, 112, 235], "continuousbox": [36, 39, 85, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 197, 230, 233, 255, 263], "provision": 38, "descript": [39, 141, 170, 177, 208, 462, 463], "akin": 39, "unnam": 39, "compositespec": [39, 453, 476, 481], "constraint": [39, 150, 324, 463, 474, 475], "data_cl": 39, "tensorclass": [39, 61, 63, 70, 84, 94, 95, 96, 100, 102, 122, 183, 395], "pixels_spec": 39, "observation_vector_spec": 39, "composite_spec": 39, "observation_vector": [39, 213, 461], "_nodefault": [39, 40, 48, 74], "is_empti": [39, 40, 48, 74, 476], "include_nest": [39, 40, 48, 74], "leaves_onli": [39, 40, 48, 74], "is_leaf": [39, 40, 48, 74], "_compositespecitemsview": [39, 40, 48, 74], "_compositespeckeysview": [39, 40, 48, 74], "reflect": [39, 40, 48, 74, 137, 158, 159, 203, 230, 268, 379, 394, 440, 462, 463, 464, 475], "lock_": [39, 40, 48, 74], "propag": [39, 40, 48, 74, 361, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 399, 400, 401, 402, 463, 474, 475], "succeed": [39, 40, 48, 74, 230, 263], "pop": [39, 40, 48, 74], "keyerror": [39, 40, 48, 74, 178, 179, 182, 262], "extract": [39, 40, 48, 74, 194, 208, 230, 259, 263, 345, 461, 463, 480], "selected_kei": [39, 40, 48, 74, 249, 461], "unlock_": [39, 40, 48, 74], "_compositespecvaluesview": [39, 40, 48, 74], "multipli": [41, 185, 190, 277, 293, 297, 361, 362, 363, 364, 370, 378, 380, 381, 382, 384, 394, 435, 461, 474], "calcul": [41, 71, 179, 245, 293, 361, 363, 368, 378, 381, 383, 386, 394, 399], "reassign": 42, "reward2go": [42, 453], "reward_key_out": 42, "time_dim": [42, 399, 401, 402, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416], "unrol": [42, 372, 404, 405, 408, 409, 410, 411, 412, 413, 414, 415, 416], "discount": [42, 55, 133, 245, 272, 362, 368, 371, 372, 374, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 457, 462, 463, 474, 475], "lastrewardtotraj": 42, "last_reward_to_traj": 42, "new_tensordict": 42, "is_tdmodule_compat": [42, 65, 77, 328, 330, 334, 394], "reset_out_kei": [42, 65, 77, 328, 330, 334, 394], "orign": [42, 65, 77, 328, 330, 334, 394], "mod": [42, 65, 77, 217, 232, 278, 295, 299, 328, 330, 334, 346, 351, 354, 394, 464, 465, 471], "select_out_kei": [42, 65, 77, 328, 330, 334, 361, 362, 364, 365, 369, 370, 377, 381, 382, 384, 386, 387, 394, 465], "reset_parameters_recurs": [42, 65, 77, 328, 330, 334, 379, 394], "relu": [42, 65, 77, 150, 276, 286, 302, 328, 330, 334, 360], "old_param": [42, 65, 77, 328, 330, 334], "bork": [42, 65, 77, 328, 330, 334], "dork": [42, 65, 77, 328, 330, 334], "reset_paramet": [42, 65, 77, 307, 328, 330, 334], "from_modul": [42, 65, 77, 289, 328, 330, 334, 350, 353, 480], "out_keys_sourc": [42, 65, 77, 328, 330, 334, 394], "rubric": [42, 65, 77, 236, 328, 330, 334, 353, 394], "revert": [42, 65, 77, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 328, 330, 334, 394, 467, 478], "seq": [42, 65, 77, 278, 293, 295, 297, 299, 328, 330, 334, 346, 394, 464, 465, 471, 473], "z": [42, 65, 77, 294, 328, 330, 334, 394], "shift_kei": [44, 46, 56, 75], "is_full_kei": [44, 46, 56, 75], "is_ful": [44, 46, 56, 75], "tempfil": [44, 61, 62, 63, 67, 68, 69, 70, 75, 78, 79, 83, 84, 95, 96, 100, 109, 183, 395, 447, 461, 462, 464, 465, 469, 474, 477, 478], "register_save_hook": [44, 62, 67, 68, 69, 75, 78, 79, 109], "temporarydirectori": [44, 61, 62, 63, 67, 68, 69, 70, 75, 78, 79, 83, 84, 95, 96, 109, 183, 395, 461, 462, 464, 465, 469, 474, 477, 478], "tmpdir": [44, 62, 67, 68, 69, 75, 78, 79, 83, 109, 461, 462, 465, 474], "rb_load": [44, 62, 67, 68, 69, 78, 79, 109], "register_load_hook": [44, 62, 67, 68, 69, 78, 79, 109], "filesystem": [45, 478], "ted2nest": [46, 453], "stackedcomposit": [48, 453], "tensordictmap": [50, 453], "observation_kei": [50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "excluded_kei": [50, 225], "consolid": [50, 77, 91, 102], "lazili": [50, 101, 306, 476], "from_tensordict_pair": [50, 77], "querymodul": [50, 77], "get_keys_from_env": 50, "cattensor": [50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 461, 473, 476, 481], "unsqueezetransform": [50, 212, 476, 478], "oracl": 50, "obs_kei": 50, "state_kei": [50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "reset_st": 50, "rollout0": 50, "rollout1": 50, "rollout1b": 50, "collaps": 50, "max_length": [50, 61, 63, 64, 80, 83, 84, 94, 190, 194, 259, 465, 471], "valid_path": [50, 84], "assert_clos": 50, "subtre": [50, 84], "intersect": [50, 273], "Or": [50, 163, 164, 305], "rollout_from_path": [50, 84], "plot": [50, 84, 461, 463, 464, 474, 475, 476], "_nestedkei": [50, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "return_nod": 50, "diverg": [50, 191, 232, 347, 351, 373, 378], "endpoint": 50, "r0": [50, 461], "123": [50, 84], "392": [50, 84], "989": [50, 84], "809": [50, 84], "847": [50, 84], "r1": 50, "235": 50, "td_root": [50, 84], "node_data": [50, 84], "node_id": [50, 84], "nontensordata": [50, 57, 95, 129, 154, 155, 190, 194, 230, 259, 263, 417], "_parent": [50, 84], "0x716eeb78fbf0": 50, "0x": 50, "4341220243998689835": 50, "6745467818783115365": 50, "win": [50, 84], "to_str": [50, 84], "node_format_fn": [50, 84], "indent": [50, 84], "rollouts_data": [50, 84], "456": [50, 84], "359": [50, 84], "3094": [50, 84], "75": [50, 84, 114], "948": [50, 84], "68": [50, 84, 114], "9045": [50, 84], "rollout_data": [50, 84], "nvec": [51, 53], "remove_singleton": 51, "ax": [51, 308, 309, 474], "Not": [51, 52, 69, 127, 128, 142, 260, 295, 299], "neither": [51, 52, 53, 54, 168, 476], "use_regist": [53, 59], "mone_hot": [53, 54], "boxlist": [53, 54], "gamma": [55, 245, 272, 302, 361, 362, 364, 365, 366, 368, 370, 371, 372, 374, 377, 379, 381, 382, 383, 384, 386, 387, 388, 389, 394, 397, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 447, 457, 461, 462, 463, 474, 475, 480], "sutton": [55, 457, 474, 475], "1988": 55, "tempor": [55, 295, 299, 302, 400, 401, 406, 407], "44": [55, 114], "ahead": [55, 272, 481], "bias": [55, 293, 294, 297, 298, 357, 457, 461], "mitig": [55, 212], "multisteptransform": [55, 453], "99": [55, 245, 269, 302, 374, 389, 398, 405, 447, 461, 462, 463, 465, 468, 471, 474, 475, 480], "nontermin": 55, "original_reward": 55, "newli": [55, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "OR": 55, "row": [56, 76, 142, 143, 233], "example_data": [57, 95, 182, 185, 190], "conform": 57, "templat": [57, 95, 178, 179, 182, 193, 420], "randomli": [57, 113, 167, 235, 236, 255, 292, 347, 351, 467, 474, 475, 476, 478], "unidimension": 59, "action_valu": [59, 288, 289, 318, 343, 344, 348, 349, 364, 370, 379, 394, 397, 456, 464, 465, 467, 471], "keepdim": 59, "chosen_action_valu": [59, 317, 318, 326, 348, 349, 397, 456, 464, 467], "priori": 59, "uniqu": [59, 84, 114, 115, 144, 148, 149, 184, 186, 212, 224, 254, 255, 256, 260, 346, 426, 469, 478], "tensor_spec": [59, 161, 204, 206, 369, 370, 381, 383], "one_hot_sampl": [59, 60], "chosen_data": [61, 94], "rewarddata": [61, 94, 453], "rejected_data": [61, 94], "copy_exist": [61, 63, 70, 84, 95, 96, 183, 395], "return_earli": [61, 63, 70, 84, 95, 96, 183, 395], "share_non_tensor": [61, 63, 70, 84, 95, 96, 183, 395], "memmap": [61, 63, 70, 84, 95, 96, 100, 156, 165, 183, 269, 395, 419, 421, 434], "dataclass": [61, 63, 70, 82, 84, 95, 96, 183, 379, 395], "from_dataset": [61, 63, 94], "dataset_nam": [61, 63, 71, 83, 94, 153], "550": [61, 63, 71, 83, 94, 114, 115], "root_dir": [61, 63, 83, 94], "from_disk": [61, 63, 83, 94], "carperai": [61, 63, 71, 83], "openai_summarize_comparison": [61, 63, 83], "load_from_disk": [61, 63, 83, 94], "load_dataset": [61, 63, 83, 94], "92534": 61, "input_id": [61, 63, 64, 70, 71, 80, 83, 94, 144, 185, 186], "end_scor": [61, 70, 71, 94], "sub_data": [61, 63], "from_tensordict": [61, 63, 70, 84, 95, 96, 183, 395], "non_tensordict": [61, 63, 70, 84, 95, 96, 183, 395], "getattr": [61, 63, 70, 84, 95, 96, 183, 395], "load_memmap": [61, 63, 70, 84, 95, 96, 183, 395], "load_": [61, 63, 70, 84, 95, 96, 183, 395], "load_memmap_": [61, 63, 70, 84, 95, 96, 183, 395], "fromkei": [61, 63, 70, 84, 95, 96, 183, 395], "saved_td": [61, 63, 70, 84, 95, 96, 183, 395], "td_load": [61, 63, 70, 84, 95, 96, 183, 395], "fake": [61, 63, 70, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 395, 461, 462, 465], "_subclass": [61, 63, 70, 84, 95, 96, 183, 395], "faketensormod": [61, 63, 70, 84, 95, 96, 183, 395], "faketensor": [61, 63, 70, 84, 95, 96, 183, 395], "from_flatten": [61, 63, 70, 84, 95, 96, 183, 395], "attemptedli": [61, 63, 70, 84, 95, 96, 183, 395], "existsok": [61, 63, 70, 84, 95, 96, 100, 183, 395], "mimic": [61, 63, 70, 84, 95, 96, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 183, 185, 186, 187, 395], "cross": [61, 63, 70, 84, 95, 96, 183, 276, 395], "tensordictfutur": [61, 63, 70, 84, 95, 96, 183, 395], "serialis": [61, 63, 70, 84, 95, 96, 183, 395], "deepli": [61, 63, 70, 84, 95, 96, 183, 395], "memmap_": [61, 63, 70, 84, 95, 96, 183, 269, 395], "memmap_lik": [61, 63, 70, 84, 95, 96, 183, 395], "contentless": [61, 63, 70, 84, 95, 96, 183, 395], "1_000_000": [61, 62, 63, 67, 68, 69, 70, 78, 79, 84, 95, 96, 109, 114, 183, 395, 461, 464, 474], "alloc": [61, 63, 70, 84, 95, 96, 102, 183, 287, 303, 304, 395, 455, 461], "memmap_refresh_": [61, 63, 70, 84, 95, 96, 183, 395], "refresh": [61, 63, 70, 84, 95, 96, 183, 395, 471, 474, 475], "saved_path": [61, 63, 70, 84, 95, 96, 183, 395], "setattr": [61, 63, 70, 84, 95, 96, 183, 395], "tent": [61, 63, 70, 83, 84, 95, 96, 183, 395], "to_tensordict": [61, 63, 70, 84, 95, 96, 183, 395, 464], "retain_non": [61, 63, 70, 84, 95, 96, 183, 395], "discrard": [61, 63, 70, 84, 95, 96, 183, 395], "alpha": [62, 78, 106, 107, 279, 280, 282, 283, 284, 285, 291, 305, 362, 364, 370, 380, 382, 384, 386, 461, 478, 480], "ep": [62, 78, 106, 107, 236, 269, 270, 275, 316, 363, 385, 394, 435, 457, 461, 462, 464, 465, 468, 471], "1e": [62, 78, 106, 107, 236, 269, 270, 275, 287, 290, 323, 461, 462, 463, 475], "08": [62, 78, 106, 107], "pin_memori": [62, 69, 78, 79, 239, 461, 480], "schaul": [62, 106, 107], "quan": [62, 106, 107], "antonogl": [62, 106, 107], "silver": [62, 106, 107], "2015": [62, 106, 107, 217], "ab": [62, 106, 107, 127, 128, 130, 131, 142, 143, 148, 149, 151, 152, 162, 170, 171, 211, 240, 265, 269, 275, 281, 286, 290, 291, 297, 302, 309, 310, 311, 317, 319, 320, 326, 361, 362, 366, 367, 368, 369, 372, 373, 374, 376, 377, 380, 381, 384, 477], "1511": [62, 106, 107, 291], "05952": [62, 106, 107], "expon": [62, 78, 106, 107], "\u03b1": [62, 78, 106, 107], "delta": [62, 78, 106, 107, 293, 297, 323, 347, 351, 453, 457, 474], "1_000": [62, 69, 78, 79, 474, 478], "mini": [62, 69, 78, 79, 475], "decid": [62, 69, 78, 79, 474, 480], "incompat": [62, 69, 78, 79, 383, 478], "drop_last": [62, 69, 78, 79, 113, 115], "notion": [62, 69, 78, 79, 315], "caution": [62, 69, 78, 79, 113, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 481], "codebas": [62, 69, 78, 79, 476], "return_info": [62, 67, 68, 69, 78, 79, 106, 107, 109, 478], "tensordictprioritizedreplaybuff": [62, 453, 480], "_weight": [62, 78, 106, 107], "update_prior": [62, 106, 107, 434, 458, 462, 478, 480], "36278465": 62, "invert": [62, 67, 68, 69, 78, 79, 109, 359, 463], "as_remot": [62, 67, 68, 69, 78, 79, 109], "cl": [62, 67, 68, 69, 78, 79, 109, 462], "quantiti": [62, 67, 68, 69, 78, 79, 109], "reserv": [62, 67, 68, 69, 78, 79, 109, 458], "default_remote_class_config": [62, 67, 68, 69, 78, 79, 109], "randomsampl": [62, 67, 68, 69, 78, 79, 109, 461, 474], "td_error": [62, 67, 68, 69, 78, 79, 109, 364, 365, 366, 368, 369, 370, 371, 377, 379, 382, 384, 386, 387, 394, 397, 461, 478, 480], "update_tensordict_prior": [62, 67, 68, 69, 78, 79, 109, 461, 478, 480], "insert_transform": [62, 67, 68, 69, 78, 79, 109, 178, 179, 182, 207, 262], "insert": [62, 67, 68, 69, 78, 79, 99, 109, 110, 120, 121, 124, 125, 178, 179, 182, 207, 212, 216, 252, 262, 264], "set_sampl": [62, 67, 68, 69, 78, 79, 109], "set_storag": [62, 67, 68, 69, 78, 79, 109], "set_writ": [62, 67, 68, 69, 78, 79, 109], "prompt_rindex": [63, 64, 71], "promptdatatldr": 63, "116722": 63, "prompt": [64, 71, 95, 177, 180, 184, 185, 190, 192, 396, 455], "return_tensordict": [64, 80], "tensodict": [64, 80], "valid_sampl": 64, "eough": 64, "toknen": 64, "meet": 64, "criterion": 64, "autotoken": [64, 80, 83, 95, 177, 178, 179, 181, 182, 189, 192, 330, 334, 455], "from_pretrain": [64, 71, 80, 144, 177, 179, 182, 186, 192, 330, 455], "enough": [64, 478], "inde": [64, 222, 463, 465, 476], "index_kei": [65, 77], "hash_kei": 65, "_hash": 65, "hash_modul": [65, 72, 77], "siphash": [65, 66, 77, 144, 186], "hash_to_int": 65, "hashtoint": 65, "query_modul": [65, 77], "key1": [65, 77, 213, 252, 428, 436, 480], "key2": [65, 77, 213, 252, 428, 436, 480], "write_hash": 65, "n_compon": 66, "dtype_cast": 66, "as_tensor": [66, 72, 465], "init_method": 66, "emb": [66, 464], "sklearn": [66, 153], "byte": [66, 72, 180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396], "builtin": [66, 72], "pythonhashse": [66, 72], "todo": [66, 191, 396], "optiona": 67, "transform_factori": [67, 69, 78, 79], "asyncio": [67, 126], "ray_buff": 67, "object_store_memori": 67, "600": [67, 71], "await": 67, "invoc": 68, "friendli": [68, 461], "include_info": [68, 78, 79], "storagecheckpointerbas": [69, 116], "roundrobinwrit": 69, "_pytre": [69, 478], "tree_map": [69, 478], "assert0": [69, 478], "ref_model": 71, "reward_model": [71, 356], "max_new_token": 71, "score_clip": 71, "kl_schedul": 71, "klcontrollerbas": 71, "num_step": [71, 465], "causal": 71, "sentenc": [71, 181], "frozen": [71, 191, 232, 269, 270], "gpt2rewardmodel": 71, "get_dataload": [71, 453], "promptdata": [71, 453], "gpt2lmheadmodel": 71, "dl": [71, 190], "block_siz": [71, 94], "tensorclass_typ": [71, 94], "openai_summarize_tldr": 71, "config_class": 71, "model_path": 71, "rollout_from_model": 71, "rollout_from_data": 71, "reward_kl": [71, 232], "reward_raw": 71, "sample_log_prob": [71, 232, 339, 340, 341, 347, 351, 353, 381], "create_rollout_td": 71, "log_prob": [71, 96, 191, 287, 303, 304, 312, 315, 325, 330, 334, 351, 364, 457], "log_ratio": 71, "replic": [71, 457], "rindex": 71, "eo": 71, "generation_config": 71, "generationconfig": 71, "ti": [71, 408, 409, 410, 411, 413, 414, 415, 416, 462], "log_probs_gen": 71, "logprobs_of_label": 71, "hash_a": 72, "4669941682990263259": 72, "3778166555168484291": 72, "9122128731510687521": 72, "hash_b": 72, "heterogen": [73, 74, 101, 126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 305, 306, 461, 462], "220": 75, "resembl": 77, "tensormap": 77, "collat": [77, 109, 178, 179, 182], "subtyp": 77, "embedding_storag": 77, "tensor_dict_storag": 77, "new_index": 77, "key3": 77, "retrieve_valu": 77, "storage_constructor": 77, "write_fn": 77, "tensordictstorag": 77, "thumb": [77, 156, 463], "lazydynamicstorag": 77, "fixedstorag": 77, "randomprojectionhash": 77, "priority_kei": [78, 79, 106, 364, 366, 369, 370, 371, 377, 379, 382, 384, 386, 387, 394, 397, 478, 480], "reduct": [78, 106, 107, 120, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 380, 381, 382, 383, 384, 386, 387, 394], "prioritizedreplaybuff": [78, 453, 480], "min": [78, 106, 107, 120, 316, 362, 363, 364, 370, 380, 382, 384, 394, 462, 463], "median": [78, 106, 107, 120, 136, 142, 143, 187, 205, 347, 351], "huggingfac": [80, 184, 345], "co": [80, 184, 224, 476], "pad_trunc": 80, "am": 80, "me": 80, "reassur": 80, "ok": 80, "_encode_memo_dict": 82, "primarili": [82, 241, 467], "educ": 82, "guess": 82, "knowledg": [82, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 468, 470], "tokenizer_fn": 83, "tensordicttoken": [83, 453], "pre_tokenization_hook": 83, "valid_s": 83, "tokenizer_class": 83, "tokenizer_model_nam": 83, "tokein": 83, "elementwis": 83, "vocabulari": [83, 144, 185, 186, 194, 259], "loader": [83, 463], "185068": 83, "dataset_to_tensordict": 83, "data_dir": 83, "batch_dim": [83, 126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 451], "valid_mask_kei": 83, "batch_dimens": 83, "filder": 83, "from_dict": [83, 190], "data_memmap": 83, "ref": 84, "branching_act": 84, "prev_act": 84, "edg": [84, 465], "travers": 84, "breadth": 84, "bf": 84, "fully_expand": 84, "get_vertex_by_hash": 84, "get_vertex_by_id": 84, "is_termin": 84, "make_nod": 84, "node_observ": 84, "bag": 84, "num_children": 84, "num_vertic": 84, "count_repeat": 84, "recustruct": 84, "plotli": 84, "make_label": 84, "visual": [84, 240, 265, 267, 419, 463, 474, 476], "unsupport": 84, "selected_act": 84, "mctsforest": [84, 144, 186, 453], "key_typ": 84, "recurse_through_entri": 91, "recurse_through_stack": 91, "infinit": [94, 148, 149, 170, 171, 270, 469, 478], "block": [94, 99, 125, 141, 182, 192, 455, 456, 461, 464, 465, 468, 469, 474, 478], "pairwisedataset": [94, 453], "contentbas": 95, "tool_cal": 95, "tool_respons": [95, 192, 455], "apply_chat_templ": [95, 177, 192, 455], "autoprocessor": 95, "add_generation_prompt": 95, "chat_templ": [95, 193], "continue_final_messag": 95, "return_tensor": 95, "pt": [95, 421, 458], "return_dict": 95, "chat": [95, 177, 178, 179, 182, 192, 193, 455], "pretrainedtoken": [95, 177, 188, 330, 334], "messag": [95, 455], "default_spec": 95, "set_list_to_stack": [95, 177, 182, 192, 455], "foo": [95, 100, 102, 122, 342, 478, 481], "token_list": 96, "tokens_response_list": 96, "checkpoint_fil": 98, "h5": 98, "h5_kwarg": 98, "iff": 98, "suffix": [98, 432], "h5py": 98, "create_dataset": 98, "consequ": [98, 297, 469], "immut": [99, 126, 129, 132, 136, 144, 156, 160, 165, 166, 177, 178, 179, 182, 185, 186, 187, 243, 262], "scratch_dir": [100, 461, 462, 464, 469, 474, 477, 478], "sent": [100, 102, 122, 269], "mistak": [100, 102, 122], "overewritten": 100, "tensorstoragecheckpoint": 100, "pathlib": [100, 437, 465], "main_ckpt_dir": 100, "rb_memmap": 100, "10_000_000": 100, "myclass": [100, 102, 122], "attach": [100, 101, 102, 103, 116, 118, 122, 462], "entiti": [100, 101, 102, 103, 116, 118, 122, 177], "lazystacktensordict": 101, "heterougen": 101, "linearli": 101, "densifi": 101, "unlimit": [101, 103], "st": 101, "expans": [102, 379, 394], "zero_": [102, 122, 197, 331], "liststoag": 104, "max_capac": [106, 107, 461, 478], "max_priority_within_buff": [106, 107], "data_0": 106, "data_1": 106, "smoothen": 106, "tdrb": 106, "pack": [106, 293, 297, 463, 466, 481], "nd": [106, 107], "1d": [106, 107, 114, 115, 120], "sum_tre": [106, 107], "min_tre": [106, 107], "slice_len": [107, 114, 115, 419], "end_kei": [107, 114, 115], "cache_valu": [107, 114, 115], "closer": [107, 480], "readili": [107, 114, 115, 351], "conjunct": [107, 114, 115, 462], "Will": [107, 114, 151, 419], "buffer0": [107, 114], "immutablewrit": [107, 114], "buffer1": [107, 114], "other_sampl": [107, 114], "shorter": [107, 114, 115], "short": [107, 114, 115, 126, 127, 128, 129, 132, 136, 142, 143, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 297, 298, 462, 463, 466, 467, 475, 478], "Be": [107, 114, 115], "fewer": [107, 114], "tolist": 107, "120110917137936e": 107, "06": [107, 287, 323], "storageensembl": [109, 112], "samplerensembl": 109, "writerensembl": [109, 118], "sample_from_al": [109, 112], "num_buffer_sampl": [109, 112], "ensembl": [109, 112, 118, 119, 125, 350, 382], "forbidden": 109, "0x13a2ef430": 109, "0x13a2f9310": 109, "interpol": [109, 244, 462, 465], "interpolationmod": 109, "bilinear": [109, 244], "0x13a2f9220": 109, "0x13a2f9f70": 109, "0x13a2d9b50": 109, "0x13a2f95b0": 109, "0x128648260": 109, "roundrobin": [110, 121], "buffer_id": [112, 118], "shuffl": [113, 115, 475], "incomplet": [113, 115], "fresh": 113, "haven": [113, 477], "remain": [113, 191, 211, 221, 222, 232, 254, 309, 468], "draw": [113, 292], "use_gpu": [114, 115], "slicesamplerwithoutreplac": [114, 478], "acceler": [114, 115, 136, 187, 474, 475], "reconstruct": [114, 115, 373, 461, 481], "ep_1": [114, 115], "ep_2": [114, 115], "73": 114, "74": 114, "76": 114, "77": 114, "42": [114, 300, 315, 361, 362, 364, 365, 369, 377, 384], "43": 114, "45": 114, "67": [114, 473], "69": 114, "70": 114, "71": 114, "27": [114, 115, 127, 128, 156, 165, 217], "28": [114, 115, 305], "31": [114, 142, 143], "80": [114, 127, 128], "82": 114, "83": 114, "84": [114, 244, 464, 465], "78": 114, "79": 114, "320": [114, 115, 130, 131], "700": [114, 115], "dataid": [114, 115], "available_dataset": [114, 115], "counter": [115, 217, 260, 346, 430, 458, 465], "23": [115, 217, 273], "request": [115, 209, 241], "51": 115, "__len__": 116, "rank_kei": 120, "samplerwithoutreplac": [120, 463, 475, 478], "get_insert_index": 120, "themselv": [126, 277, 462], "dens": [126, 303, 304], "maybe_dens": 126, "min_get": [126, 160, 166], "maker": [126, 451, 462], "sort": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 213, 316], "another_act": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "discretebox": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "mutabl": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "action_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 463, 475], "had": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 467, 469], "all_act": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "any_don": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "loc": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187, 232, 236, 247, 269, 270, 296, 324, 325, 339, 340, 341, 347, 351, 353, 361, 362, 364, 377, 381, 382, 383, 384, 441, 451, 456, 461, 462, 463, 464, 467, 475, 480], "_callabletransform": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 185, 186, 187], "auto_specs_": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "action_spac": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 224, 289, 318, 343, 344, 348, 349, 361, 362, 364, 365, 366, 368, 369, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 464, 465, 467, 471], "check_dtyp": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187], "discrep": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 361, 363, 365, 366, 378, 381, 383, 397], "broken": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187], "rng": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 172, 177, 178, 179, 182, 185, 186, 187, 476], "done_keys_group": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "another_don": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "done_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "empty_cach": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 262], "fake_tensordict": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 462, 465], "envnam": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "full_action_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 474, 475], "full_done_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "full_observation_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "full_reward_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "pipeline_st": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "full_state_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "input_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "is_spec_lock": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "maybe_reset": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "speak": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 218, 351, 461], "observation_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "output_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "register_gym": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 466], "entry_point": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "info_kei": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "reward_threshold": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "nondeterminist": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "max_episode_step": [126, 129, 132, 135, 136, 137, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "order_enforc": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "autoreset": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "disable_env_check": [126, 129, 132, 135, 136, 144, 151, 152, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "apply_api_compat": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "nasium": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 200], "dmcontrolenv": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 419, 453, 461, 466, 473, 481], "dmc": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "cheetah": [126, 129, 130, 131, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 419, 461], "removeemptyspec": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "threshold": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 292, 362, 363, 394, 463], "learnt": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 447], "checker": [126, 129, 132, 135, 136, 144, 151, 152, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "stepapicompat": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "deem": [126, 129, 132, 136, 144, 148, 149, 156, 157, 160, 165, 166, 167, 170, 171, 177, 178, 179, 182, 185, 186, 187], "task_nam": [126, 129, 130, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "envgym": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0855": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0215": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0881": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0412": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "1101": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0080": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0254": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0424": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "veloc": [126, 129, 130, 131, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 474, 475, 476, 481], "9609e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "9776e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "04": [126, 129, 132, 136, 140, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 257, 270], "6347e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "3842e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "5338e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "3064e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0381e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "6656e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "05": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 257, 275, 476], "0204e": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0833": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0275": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0612": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0770": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "1256": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0082": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0186": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0476": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "2221": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "2256": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "5930": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "6937": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "5865": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "5479": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0187": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "6825": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "5224": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0018": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "1005": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0335": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 218], "0268": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0133": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0627": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0074": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0488": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0353": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0075": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0069": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0098": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0058": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0033": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0157": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0004": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 257], "0381": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0452": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "11355747": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "04257728": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "00408397": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "04155852": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0389733": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "01409826": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0978704": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "08808327": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "03970837": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "00535434": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "02353762": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "05116226": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "02788907": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "06848346": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "05154399": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "0371798": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "05128025": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "dydact": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "ant": [126, 127, 128, 129, 132, 136, 139, 141, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 477], "gym_env": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 480], "reset_kei": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 212, 248, 254, 255, 256, 474], "multitask": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "multiag": [126, 129, 132, 136, 144, 147, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 306, 317, 326, 363, 378, 381, 397], "another_reward": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "reward_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "auto_cast_to_devic": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 475], "soon": [126, 129, 132, 136, 144, 156, 157, 158, 159, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "__sort": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "as__": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "categorical_action_encod": [126, 127, 128, 129, 132, 135, 136, 137, 138, 141, 142, 143, 144, 151, 152, 156, 157, 160, 162, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 200, 217, 465], "argmaxmodul": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "argmax": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 289, 318, 344, 349, 465, 467], "n_act": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 232, 361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 468], "ourselv": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 463, 481], "emul": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "epoch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 437, 463, 474, 475], "input_td": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "rollout_td": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "state_spec_unbatch": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "prevail": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 204, 213, 248], "next_tensordict": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203, 209, 213, 225, 226, 227, 239, 242, 243, 249, 252, 265, 269], "precomput": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187], "_stepmdp": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203], "exclude_act": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 203], "minim": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 421, 478], "reset_data": [126, 129, 132, 136, 144, 156, 157, 160, 165, 166, 167, 177, 178, 179, 182, 185, 186, 187, 455, 481], "googl": [127, 128, 148, 149, 154, 155, 182, 184, 275, 463, 464, 474, 475], "convers": [127, 128, 142, 143, 179, 182, 200, 455, 457], "2106": [127, 128, 367, 386], "13281": [127, 128], "frame_skip": [127, 128, 130, 131, 135, 136, 137, 138, 142, 143, 145, 146, 151, 152, 162, 187, 228, 430, 432, 440, 458, 461, 462, 463, 480], "allow_done_after_reset": [127, 128, 130, 131, 132, 135, 137, 138, 141, 142, 143, 151, 152, 154, 155, 162, 168, 169], "toler": [127, 128, 130, 131, 135, 137, 138, 141, 142, 143, 151, 152, 154, 155, 162, 168, 169, 287, 323], "is_avail": [127, 128, 461, 462, 463, 464, 474, 475, 477], "87": [127, 128], "acrobot": [127, 128, 130, 131, 481], "advant": [127, 128, 142, 143], "timer": [127, 128, 136, 142, 143, 187], "timeit": [127, 128, 142, 143, 465], "310": [127, 128], "ms": [127, 128, 142, 143], "268": [127, 128], "433": [127, 128], "213": [127, 128], "8605": [127, 128], "pipelineenv": 128, "get_environ": 128, "san": 129, "fen": [129, 154, 155], "pgn": 129, "legal": 129, "board": [129, 167], "include_san": 129, "algebra": [129, 476], "notat": 129, "include_fen": 129, "forsyth": 129, "edward": 129, "include_pgn": 129, "portabl": [129, 470], "include_legal_mov": 129, "include_hash": 129, "mask_act": 129, "subset": [129, 476, 477], "29275": 129, "rnbqkbnr": [129, 154, 155], "pppppppp": [129, 154, 155], "kqkq": [129, 154, 155], "legal_mov": 129, "219": 129, "5p2": 129, "ppppp1pp": 129, "event": [129, 303, 304, 312, 408, 409, 410, 411, 413, 414, 415, 416, 478], "white": 129, "f4": 129, "96": 129, "kq": 129, "5n2": 129, "rnbqkb1r": 129, "nf3": 129, "na6": 129, "c4": 129, "f6": 129, "h4": 129, "rb8": 129, "na3": 129, "ra": 129, "get_legal_mov": 129, "uci": 129, "dm_control": [130, 131, 461, 473, 481], "2006": [130, 131, 217, 362, 368], "12983": [130, 131], "240": [130, 131, 480], "swingup": [130, 131, 481], "swingup_spars": [130, 131], "ball_in_cup": [130, 131], "catch": [130, 131, 465], "balance_spars": [130, 131], "three_pol": [130, 131], "two_pol": [130, 131], "finger": [130, 131], "turn_easi": [130, 131], "turn_hard": [130, 131], "fish": [130, 131], "upright": [130, 131, 462], "swim": [130, 131], "hopper": [130, 131], "hop": [130, 131], "humanoid": [130, 131, 156, 165, 473], "walk": [130, 131, 156, 165, 462, 473], "run_pure_st": [130, 131], "bring_bal": [130, 131], "bring_peg": [130, 131], "insert_bal": [130, 131], "insert_peg": [130, 131], "point_mass": [130, 131], "reacher": [130, 131], "swimmer": [130, 131], "swimmer6": [130, 131], "swimmer15": [130, 131], "walker": [130, 131], "dog": [130, 131], "trot": [130, 131], "humanoid_cmu": [130, 131], "lqr": [130, 131], "lqr_2_1": [130, 131], "lqr_6_2": [130, 131], "quadrup": [130, 131], "escap": [130, 131], "stacker": [130, 131], "stack_2": [130, 131], "stack_4": [130, 131], "deviceless": 132, "run_type_check": [132, 150], "hint": 132, "counterenv": 132, "creator": [133, 442, 443, 449, 450, 451], "substitut": [133, 254, 269, 467], "vecnorm": [133, 270, 451], "env_creat": [133, 461], "test_env1": 133, "_td": [133, 372], "observation_count": [133, 481], "test_env2": 133, "ps": 133, "p1": 133, "p2": 133, "9934": 133, "make_vari": [133, 260], "variant": [133, 260, 277, 456], "trajcount": 133, "env_creator_pendulum": 133, "env_creator_cartpol": 133, "env_str": 134, "device_map": 134, "registri": [135, 168], "asyncvectorenv": 135, "pixel_observ": [135, 137, 138, 162], "pixelobservationwrapp": [135, 137, 138, 162], "adventur": [135, 137], "airraid": [135, 137, 481], "alien": [135, 137], "time_limit": 135, "timelimit": [135, 148, 149, 170, 171], "default_info_dict_read": [135, 136, 137, 156, 187], "reader": [135, 136, 137, 156, 187, 462], "set_info_dict_read": [135, 136, 137, 156, 187, 466], "info_dict": [135, 136, 137, 156, 187], "gymlikeenv": [135, 137, 187, 453], "auto_register_info_dict": [135, 136, 137, 156, 187], "multibinari": [135, 137], "multidiscret": [135, 137], "rag": [135, 137], "gym_conversion_exampl": [135, 137], "info_dict_read": [136, 156, 187], "ignore_priv": [136, 187], "baseinfodictread": [136, 187], "tensordictprim": [136, 156, 187, 278, 295, 299, 358, 456, 464], "succe": [136, 156, 187], "underscor": [136, 187], "primer": [136, 185, 187, 190, 255, 278, 295, 299, 358, 464], "halfcheetah": [136, 156, 187, 205, 244, 461, 480], "reward_ctrl": [136, 156, 187], "reward_run": [136, 156, 187], "x_posit": [136, 156, 187], "x_veloc": [136, 156, 187], "raise_if_clos": [136, 187], "fast_encod": [136, 187], "memoize_cach": [136, 187], "adaptive_autorang": [136, 187], "4f": [136, 187, 463, 464, 476], "fp": [136, 187, 419, 424, 426], "10141": [136, 187], "5742fp": [136, 187], "10576": [136, 187], "8388fp": [136, 187], "read_act": [136, 187], "read_don": [136, 187], "nonsens": [136, 187], "fallback": [136, 187], "read_ob": [136, 187], "dictat": [136, 187, 233, 347, 351, 381, 461, 476], "read_reward": [136, 187], "hoc": [136, 156, 187, 467], "dict_read": [136, 187], "my_info_kei": [136, 187], "some_env": [136, 187], "vecenv": 137, "vectorenv": 137, "convert_actions_to_numpi": 137, "missing_obs_valu": [137, 268], "vecgymenvtransform": 137, "secur": 138, "habitat3": 138, "ai": [138, 477], "habitatrenderpick": 138, "isaacgym": [139, 140], "isaacgymwrapp": [139, 453], "isaacgymenv": [140, 453], "webpag": 140, "isaac": [140, 141], "essenc": [140, 466], "scripts_isaaclab": 141, "managerbasedrlenv": 141, "app": 141, "applaunch": 141, "argpars": [141, 448, 451], "parser": [141, 181, 448, 451], "argumentpars": 141, "add_app_launcher_arg": 141, "args_cli": 141, "hydra_arg": 141, "parse_known_arg": 141, "app_launch": 141, "isaaclab_task": 141, "f401": 141, "manager_bas": 141, "ant_env_cfg": 141, "antenvcfg": 141, "isaac_lab": 141, "cfg": [141, 440, 441, 442, 443, 444, 445, 446, 447, 448, 451], "instadeepai": [142, 143], "2306": [142, 143, 270], "09884": [142, 143], "snake": [142, 143, 179], "grid": [142, 143, 419], "bodi": [142, 143], "body_st": [142, 143], "fruit_posit": [142, 143], "col": [142, 143], "head_posit": [142, 143], "tail": [142, 143], "game2048": [142, 143], "maze": [142, 143], "cleaner": [142, 143], "cvrp": [142, 143], "multicvrp": [142, 143], "minesweep": [142, 143], "rubikscub": [142, 143], "knapsack": [142, 143], "sudoku": [142, 143], "tsp": [142, 143], "connector": [142, 143], "v2": [142, 143, 163, 164, 390, 408, 409, 410, 411, 413, 414, 415, 416, 464], "mmst": [142, 143], "graphcolor": [142, 143], "partli": [142, 143], "scrambl": [142, 143], "robotwarehous": [142, 143], "tetri": [142, 143], "binpack": [142, 143], "jobshop": [142, 143], "0x1fca91910": 142, "122": [142, 143, 481], "0x1ff9baee0": 142, "134": [142, 143], "0x1ff9ba7c0": 142, "172": [142, 143], "jit": 143, "eager": 143, "tdreset": [143, 272, 473], "whichev": 143, "overview": [144, 186, 463, 465, 468, 474, 475, 480], "vocab_s": [144, 185, 186], "hashing_modul": [144, 186], "text_output": [144, 186], "decod": [144, 186, 198, 310, 330, 334], "batch_decod": [144, 186], "text_kei": [144, 186], "gpt2token": [144, 186], "make_tensordict": [144, 186], "mo": [145, 146], "minecart": [145, 146], "mo_gym": [146, 233], "qualnam": 147, "neural": [147, 158, 159, 279, 280, 313, 315, 321, 350, 399, 456, 462, 463, 464, 467, 474, 475, 476, 481], "group_map": [147, 148, 149, 154, 155, 158, 159, 168, 169, 170, 171, 173, 474], "constructiuon": [147, 158, 159], "premad": [147, 148, 149, 158, 159, 170, 171, 397], "all_in_one_group": [147, 154, 155, 173], "agent_0": [147, 158, 159, 168, 173, 252], "agent_1": [147, 158, 159, 168, 173, 252], "agent_2": [147, 158, 159, 168, 173], "agent_3": [147, 168], "one_group_per_ag": [147, 158, 159], "meltingpot": [148, 149], "2211": [148, 149], "13746": [148, 149], "melt": [148, 149], "pot": [148, 149], "novel": [148, 149, 468], "social": [148, 149], "familiar": [148, 149, 462, 475, 481], "unfamiliar": [148, 149], "broad": [148, 149], "cooper": [148, 149, 474, 475], "decept": [148, 149], "reciproc": [148, 149], "stubborn": [148, 149], "substrat": [148, 149], "ml_collect": 148, "config_dict": 148, "configdict": 148, "categorical_act": [148, 149, 154, 155, 158, 159, 163, 164, 168, 169, 170, 171], "marlgroupmaptyp": [148, 149, 154, 155, 158, 159, 168, 169, 170, 171, 173, 453, 474], "agent_nam": [148, 149, 170, 171, 173], "agent_names_to_indices_map": [148, 149, 170, 171], "env_torchrl": [148, 149], "commons_harvest__open": [148, 149], "rgb": [148, 149], "144": [148, 149], "192": [148, 149], "collective_reward": [148, 149], "ready_to_shoot": [148, 149], "88": [148, 149, 163, 164], "substrate_config": 149, "get_config": 149, "mp_env": 149, "build_from_config": 149, "default_player_rol": 149, "mymbenv": [150, 276, 302], "world_model": [150, 276, 302, 373], "hidden_observ": [150, 276, 302], "mlp": [150, 276, 279, 280, 282, 283, 284, 285, 291, 295, 299, 302, 306, 307, 339, 343, 358, 366, 368, 456, 462, 465, 467, 468, 471, 473, 477, 480], "worldmodelwrapp": [150, 276, 302], "activation_class": [150, 276, 279, 280, 282, 283, 284, 285, 290, 291, 300, 302, 305, 306, 462, 467, 474, 475, 480], "activate_last_lay": [150, 276, 285, 300, 302], "sail": [151, 152], "sg": [151, 152], "2206": [151, 152], "10558": [151, 152], "readthedoc": [151, 154, 155], "en": [151, 154, 155], "python_interfac": 151, "envpoolmixin": 152, "env_bas": 152, "task_id": 152, "env_typ": 152, "gym_reset_return_info": 152, "envpool_env": 152, "www": [153, 303, 304], "fetch_openml": 153, "adult_num": 153, "adult_onehot": 153, "mushroom_num": 153, "mushroom_onehot": 153, "covertyp": 153, "shuttl": 153, "magic": [153, 465, 466], "106": 153, "openspiel": [154, 155], "open_spiel": [154, 155], "game_str": 154, "return_st": [154, 155, 158, 159], "4672": [154, 155], "current_play": [154, 155], "674": 154, "2048": [154, 155], "add_nois": [154, 155], "amazon": [154, 155], "backgammon": [154, 155], "restor": [154, 155], "td_restor": [154, 155], "pyspiel": 155, "load_gam": 155, "new_initial_st": 155, "3009": 155, "my_env_fun": [156, 165], "custom_attribute_list": [156, 165], "custom_attribut": [156, 165], "custom_method_list": [156, 165], "custom_method": [156, 165], "deploi": [156, 165, 209, 465], "slight": [156, 165, 462], "share_individual_td": [156, 165], "shared_memori": [156, 165], "policy_proof": [156, 165], "ll": [156, 165, 217, 293, 294, 297, 298, 461, 462, 463, 464, 466, 467, 468, 469, 471, 475, 481], "hidden": [156, 165, 211, 282, 290, 293, 294, 295, 297, 298, 299, 310, 311, 319, 320, 339, 340, 341, 342, 350, 353, 363, 378, 381, 456, 464, 473, 480], "serial_for_singl": [156, 165, 462], "circular": [156, 165, 461], "list_of_kwarg": [156, 165], "com_veloc": [156, 165], "head_height": [156, 165], "joint_angl": [156, 165], "torso_vert": [156, 165], "idl": 156, "batched_pipe_timeout": 156, "stringent": [156, 463, 474, 475], "penv": [156, 260], "env_fix": 156, "influenc": 156, "myenv": [156, 209, 220, 223], "update_kwarg": [156, 165], "th": [157, 227, 264, 293, 297, 476], "thdot": [157, 476], "max_spe": [157, 476], "max_torqu": [157, 476], "gen_param": [157, 476], "gravit": [157, 476], "torqu": [157, 476], "pettingzoo": [158, 159, 474, 475], "pet": [158, 159], "zoo": [158, 159], "__": [158, 159], "aecenv": [158, 159], "dead": [158, 159], "done_on_ani": [158, 159, 474], "compulsori": [158, 159], "adversary_0": [158, 159], "adversari": [158, 159, 375, 474], "sisl": 158, "multiwalker_v9": 158, "aec": [158, 159], "n_piston": [158, 159], "pistonball_v6": [158, 159], "piston": [158, 159], "piston_0": [158, 159], "piston_1": [158, 159], "piston_20": [158, 159], "tictactoe_v3": [158, 159], "player": [158, 159, 167], "player_1": [158, 159], "player_2": [158, 159], "butterfli": 159, "parallel_env": [159, 461, 480, 481], "_setup": [160, 166], "async_reset_send": [160, 166], "async_reset_recv": [160, 166], "cube": 161, "roboh": 162, "expos": [162, 220, 223, 352, 462], "vikashplu": 162, "wiki": 162, "2310": 162, "06828": 162, "from_depth": 162, "smacv2": [163, 164], "starcraft": [163, 164], "challeng": [163, 164, 466, 476, 477], "10gen_terran": [163, 164], "10gen_zerg": [163, 164], "10gen_protoss": [163, 164], "3m": [163, 164], "8m": [163, 164], "25m": [163, 164], "5m_vs_6m": [163, 164], "8m_vs_9m": [163, 164], "10m_vs_11m": [163, 164], "27m_vs_30m": [163, 164], "mmm": [163, 164], "mmm2": [163, 164], "2s3z": [163, 164], "3s5z": [163, 164], "3s5z_vs_3s6z": [163, 164], "3s_vs_3z": [163, 164], "3s_vs_4z": [163, 164], "3s_vs_5z": [163, 164], "1c3s5z": [163, 164], "2m_vs_1z": [163, 164], "corridor": [163, 164], "6h_vs_8z": [163, 164], "2s_vs_1sc": [163, 164], "so_many_banel": [163, 164], "bane_vs_ban": [163, 164], "2c_vs_64zg": [163, 164], "old": [163, 164, 270, 378, 481], "smac": [163, 164], "map_nam": [163, 164], "176": [163, 164], "battle_won": [163, 164], "dead_al": [163, 164], "dead_enemi": [163, 164], "episode_limit": [163, 164], "322": [163, 164], "procedur": [163, 164], "distribution_config": [163, 164], "n_unit": [163, 164], "n_enemi": [163, 164], "team_gen": [163, 164], "dist_typ": [163, 164], "weighted_team": [163, 164], "unit_typ": [163, 164], "marin": [163, 164], "maraud": [163, 164], "medivac": [163, 164], "exception_unit_typ": [163, 164], "start_posit": [163, 164], "surrounded_and_reflect": [163, 164], "map_x": [163, 164], "map_i": [163, 164], "capability_config": [163, 164], "131": [163, 164], "starcraft2env": 164, "tic": 167, "tac": 167, "toe": 167, "single_play": 167, "player1": 167, "desired_batch_s": 167, "player0": 167, "uniti": [168, 169], "ml": [168, 169], "technolog": [168, 169], "llapi": [168, 169], "mlagents_env": [168, 169], "unityenviron": [168, 169], "file_nam": 168, "registered_nam": 168, "nor": 168, "localhost": [168, 332], "connect": 168, "3dball": 168, "group_0": 168, "vectorsensor_size8": 168, "continuous_act": [168, 170, 171, 417, 474, 475], "agent_10": 168, "agent_11": 168, "agent_4": 168, "agent_5": 168, "agent_6": 168, "agent_7": 168, "agent_8": 168, "agent_9": 168, "group_reward": 168, "proroklab": [170, 171], "vectorizedmultiagentsimul": [170, 171], "2207": [170, 171], "03530": [170, 171], "basescenario": 170, "defaultt": 170, "chosen": [170, 171, 254, 255, 317, 318, 326, 349, 419, 456, 470], "sparsiti": 170, "unbatched_action_spec": [170, 171], "unbatched_observation_spec": [170, 171], "unbatched_reward_spec": [170, 171], "het_spec": [170, 171], "het_specs_map": [170, 171], "flock": [170, 171, 417], "agent_collision_rew": [170, 171], "agent_distance_rew": [170, 171], "ca": 173, "environment4": 173, "get_group_map": 173, "sumbodul": 176, "histori": [177, 178, 179, 182, 185, 192, 453, 455], "assist": [177, 179, 182, 192, 455, 464], "answer": [177, 179, 181, 182], "hopefulli": [177, 462], "system_prompt": [177, 192, 455], "apply_templ": [177, 178, 179, 182, 192], "pars": [177, 181, 193, 455, 478], "template_kwarg": [177, 178, 179, 182], "system_rol": [177, 455], "user_rol": [177, 455], "datasetchatenv": [177, 455], "gsm8kenv": [177, 178, 181, 188, 455], "ifevalenv": [177, 178], "pprint": [177, 182, 455], "qwen": [177, 179, 182, 192, 455], "qwen2": [177, 179, 182, 192, 455], "3b": [177, 179, 182, 192], "im_start": [177, 179, 182, 192, 455], "ni": 177, "im_end": [177, 179, 192, 455], "td_action": 177, "td_next": 177, "nthi": 177, "rlvr": 178, "verifi": 178, "batch_size_dl": [178, 179, 182, 188], "thin": [178, 187, 329, 457], "chatenv": [178, 187, 192, 455], "bucket": 178, "dataloadingprim": [178, 185, 255, 455], "set_missing_toler": [178, 179, 182, 262], "gsm8k": [179, 180, 188], "compute_reward": [179, 182], "question": [179, 182, 478, 480], "adam": [179, 315, 324, 461, 462, 463, 464, 465, 468, 471, 474, 475, 476], "bought": 179, "sandwich": 179, "he": 179, "paid": 179, "breed": 179, "mari": 179, "saw": [179, 470, 476, 478], "reward_answ": [179, 181], "reward_contain": [179, 181], "reward_right": [179, 181], "reward_think": [179, 181], "snak": 179, "transformthatmeasuresbyt": [180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396], "bytes_in_td": [180, 181, 184, 190, 191, 192, 193, 194, 206, 208, 209, 211, 212, 213, 216, 217, 218, 221, 224, 225, 226, 228, 231, 232, 239, 241, 242, 243, 245, 248, 249, 252, 253, 254, 255, 256, 257, 259, 260, 261, 265, 266, 268, 269, 272, 396], "transform_done_spec": [180, 181, 184, 190, 191, 192, 193, 194, 221, 252, 259, 261, 263, 272, 396], "transform_env_batch_s": [180, 181, 184, 190, 191, 192, 193, 194, 209, 216, 261, 272, 396], "transform_env_devic": [180, 181, 184, 190, 191, 192, 193, 194, 216, 221, 261, 272, 396], "transform_full_done_spec": [180, 181, 184, 190, 191, 192, 193, 194, 209, 216, 220, 221, 225, 232, 234, 242, 243, 249, 253, 259, 261, 263, 270, 272, 396], "make_gsm8k_env": [181, 455], "asssoci": 181, "extract_tag": 181, "xml": 181, "ifev": [182, 184], "nyou": 182, "instruction_id_list": [182, 184], "detectable_cont": 182, "number_placehold": 182, "num_highlight": 182, "num_": 182, "respond": 182, "plan": [182, 276, 301, 302], "week": 182, "europ": 182, "trip": 182, "london": 182, "pari": 182, "rome": 182, "cap": [182, 463, 478], "restaur": 182, "prompt_level_strict_acc": 183, "inst_level_strict_acc": 183, "prompt_level_loose_acc": 183, "inst_level_loose_acc": 183, "instruction_ids_kei": 184, "prompt_kei": [184, 396], "keyword_args_kei": 184, "id_kei": 184, "response_column": 184, "score_kei": 184, "ifeval_scor": 184, "aggregate_reward": 184, "ifevalscoredata": 184, "scorer": 184, "IF": 184, "column": 184, "langdetect": 184, "nltk": 184, "immutabledict": 184, "cot": 185, "token_kei": 185, "str_kei": 185, "attention_kei": 185, "assign_reward": 185, "has_attent": 185, "assign_don": 185, "batchless": 185, "eos_token_id": 185, "pretrainedtokenizerbas": [185, 194, 259], "stack_method": [185, 190], "as_nested_tensor": [185, 190], "as_padded_tensor": [185, 190], "data_kei": 185, "bert": [185, 194, 259], "uncas": [185, 194, 259], "tokens_in": 185, "tokens_out": 185, "mlgym": [187, 189], "get_library_nam": 187, "prisonersdilemma": 189, "reward_wrong_format": 189, "mlgymenv": 189, "wrongli": 189, "mappabl": 190, "maybe_dense_stack": 190, "unrel": 190, "endless_dataload": 190, "set_capture_non_tensor_stack": 190, "dummydataload": 190, "generate_random_str": 190, "ascii_lowercas": 190, "__iter__": 190, "__next__": 190, "zxwvupirska": 190, "stringa": 190, "zxwvupirsk": 190, "roll": 190, "init_st": 190, "nngcmflsana": 190, "vrrbnhzpmga": 190, "nngcmflsan": 190, "vrrb": 190, "dummytensordataload": 190, "generate_random_tensor": 190, "pad_tensor": 190, "padding_length": 190, "data_spec": 190, "log_prob_kei": [191, 232, 351, 457], "add_to_reward": 191, "pi_curr": [191, 232], "pi_0": [191, 232], "overfit": [191, 232], "probabilist": [191, 232, 347, 361, 381, 453, 463, 480], "get_dist": [191, 232, 351, 352], "kl_penalti": 191, "ref_log_prob": 191, "formula": [191, 232, 296, 324, 325, 361, 363, 378, 381, 394, 457, 463], "tool_nam": 192, "nprint": 192, "successfulli": [192, 455], "use_raw_nontensor": [194, 230, 259, 263], "additional_token": [194, 259], "skip_special_token": [194, 259], "add_special_token": [194, 259], "return_attention_mask": [194, 259], "missing_toler": [194, 259], "call_before_reset": [194, 259], "test_input_spec": [194, 263], "list_of_tensordict": [195, 196], "unsqueeze_null_shap": 197, "dynamic_shap": 197, "model_bas": [198, 199, 276, 302], "model_based_env": [198, 372], "dreamerenv": [198, 372, 453], "model_based_env_ev": 198, "spec_typ": 200, "convert_specnam": 200, "remap_state_to_observ": 200, "spectyp": 200, "unus": 200, "probabilistictdmodul": [201, 300, 347, 351, 398, 432], "keep_oth": [203, 476], "exclude_reward": 203, "exclude_don": 203, "next_": 203, "write_full_fals": 204, "_terminated_or_trunc": 204, "num_interv": 205, "out_action_kei": 205, "samplingstrategi": 205, "optino": 205, "intenum": 205, "action_disc": 205, "masker": 206, "maskedenv": 206, "ones_lik": [206, 303], "scatter": 206, "fill_float": 208, "fill_int": 208, "fill_bool": 208, "someenvclass": 208, "autoresetenv": 208, "fooenv": 208, "sign": [208, 250, 399, 474], "envtyp": 208, "reshape_fn": [209, 465], "reset_func": 209, "env_kwarg": [209, 449, 450, 461], "accompani": [209, 253], "tensordict_batch_s": 209, "tensordict_reset": [209, 476], "biner": 210, "burn_in": 211, "burn": 211, "burnt": 211, "gru_modul": [211, 295, 358], "input_s": [211, 255, 293, 294, 295, 297, 298, 299, 358, 464, 465], "hidden_s": [211, 255, 293, 294, 295, 297, 298, 299, 358, 464, 465], "default_recurrent_mod": [211, 295, 299], "burn_in_transform": 211, "gru": [211, 255, 294, 295, 358, 465], "num_lay": [211, 293, 295, 297, 299, 310, 311, 358, 465], "is_init": [211, 231, 295, 299, 316, 346, 358, 399, 464, 465], "86": 211, "3008": 211, "0344": 211, "padding_valu": [212, 303, 304], "as_invers": 212, "movement": 212, "1312": 212, "5602": 212, "consumpt": [212, 453], "pictur": 212, "pixels_trsf": [212, 478], "grayscal": [212, 462, 464, 465, 478, 481], "data_exclud": [212, 478], "make_rb_transform_and_sampl": 212, "sampler_kwarg": 212, "redund": [212, 464], "del_kei": [213, 252, 265, 473, 476], "unsqueeze_if_oor": 213, "observation_posit": 213, "observation_veloc": 213, "delet": [213, 252, 426], "crop": [214, 241, 419], "center": [214, 315, 419], "width": [214, 219, 244], "height": [214, 219, 244], "squar": [214, 219, 296, 324, 325, 419, 455], "scalar": [215, 246, 274, 283, 285, 292, 308, 309, 316, 357, 361, 362, 363, 369, 370, 371, 372, 373, 374, 376, 377, 378, 379, 381, 382, 383, 384, 385, 387, 394, 397, 399, 400, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 456, 462, 468, 476], "rewardsc": [216, 262, 461, 462, 464], "rewardclip": 216, "transformed_env": [216, 262, 466], "condition": 217, "switch": [217, 262, 270, 296, 325, 417], "met": [217, 218, 360, 474, 476], "unalt": 217, "criteria": 217, "policy_switch": 217, "cond": [217, 218], "step_count_kei": [217, 218, 253], "step_count_tot": 217, "step_count_main": 217, "0322": 217, "1540": 217, "0111": 217, "3190": 217, "0299": 217, "1544": 217, "0181": 217, "3280": 217, "0276": 217, "1550": 217, "0255": 217, "3414": 217, "0253": 217, "1558": 217, "0334": 217, "3596": 217, "0230": 217, "1569": 217, "0422": 217, "3828": 217, "0206": 217, "1582": 217, "0519": 217, "4117": 217, "1598": 217, "0629": 217, "4469": 217, "0156": 217, "1617": 217, "0753": 217, "4891": 217, "0130": 217, "1639": 217, "0895": 217, "5394": 217, "0104": 217, "1665": 217, "1058": 217, "5987": 217, "0076": 217, "1696": 217, "1246": 217, "6685": 217, "0047": 217, "1732": 217, "1463": 217, "7504": 217, "0016": 217, "1774": 217, "1715": 217, "8459": 217, "0020": 217, "0150": 217, "1884": 217, "6117": 217, "0017": 217, "2071": 217, "3838": 217, "0105": 217, "2115": 217, "5110": 217, "25": [217, 461], "altogeth": 218, "exectu": 218, "palliat": [218, 467], "inner_count": 218, "middle_env": 218, "middle_count": 218, "auto_unwrap": [218, 262, 427], "9670": 218, "2546": 218, "9669": 218, "9802": 218, "1981": 218, "1601": 218, "9926": 218, "1214": 218, "5556": 218, "9994": 218, "7622": 218, "9984": 218, "0561": 218, "7933": 218, "9895": 218, "1445": 218, "7779": 218, "dtype_in": 220, "dtype_out": 220, "scan": [220, 223, 352, 353], "resp": [220, 223], "not_transform": [220, 223], "orig_devic": 221, "unspecifi": 221, "num_actions_effect": 222, "max_act": 222, "include_forward": 222, "num_act": [222, 280, 370, 465, 467], "action_out": 222, "eol_kei": 224, "lives_kei": 224, "eol_attribut": 224, "breakout": 224, "210": [224, 238], "160": [224, 238], "eol_transform": 224, "eol": 224, "dqnloss": [224, 361, 362, 364, 365, 368, 370, 371, 372, 376, 377, 379, 381, 382, 383, 384, 385, 386, 387, 388, 394, 397, 444, 453, 457, 462, 464, 465, 471], "register_kei": 224, "loss_or_advantag": 224, "lossmodul": [224, 437, 446, 447, 453, 457], "valueestimatorbas": [224, 379, 394, 453], "finit": [226, 315, 467, 478], "first_dim": 227, "last_dim": 227, "allow_positive_dim": [227, 252, 264], "frameskip": 227, "repeatedli": [228, 463, 475], "hash_fn": 230, "repertoir": 230, "reproducible_hash": 230, "unarytransform": 230, "observation_str": 230, "tobyt": [230, 263], "observation_hash": 230, "x08": 230, "x8b": 230, "xbexav": 230, "xbf": 230, "x00": 230, "xee": 230, "xb5": 230, "x17": 230, "x8f": 230, "xbe": [230, 263], "x88": 230, "xccu": 230, "xc0vr": 230, "get_input_from_hash": 230, "hash_tensor": 230, "init_kei": [231, 346], "tracker": 231, "normalparamextractor": [232, 339, 340, 341, 347, 353, 361, 362, 364, 370, 377, 381, 382, 383, 384, 386, 387, 456, 463, 467, 475, 480], "probabilisticactor": [232, 339, 340, 341, 342, 361, 362, 364, 367, 369, 370, 377, 380, 381, 382, 383, 384, 386, 387, 456, 461, 463, 467, 474, 475], "tanhnorm": [232, 339, 340, 341, 347, 353, 361, 362, 364, 377, 381, 382, 383, 384, 386, 387, 453, 463, 475, 480], "return_log_prob": [232, 330, 334, 339, 340, 341, 347, 351, 353, 383, 456, 463, 467, 474, 475, 480], "apply_": 232, "copy_": [232, 461], "mogymwrapp": [233, 453], "mo_env": 233, "sea": 233, "treasur": 233, "so_env": 233, "stack_reward": 234, "stack_observ": 234, "auto_batch_size_": 234, "macro": [234, 346], "noop": 235, "trial": 235, "standard_norm": [236, 247, 269, 270, 461, 462, 464], "affin": [236, 247, 269, 270], "layer": [236, 269, 275, 279, 280, 282, 283, 288, 290, 293, 294, 295, 297, 298, 299, 300, 305, 306, 308, 309, 310, 311, 321, 322, 336, 345, 354, 456, 462, 463, 464, 465, 467, 474, 477], "epsilon": [236, 274, 292, 316, 385, 435, 462, 463, 464, 467], "recover": 236, "set_default_tensor_typ": 236, "doubletensor": 236, "isclos": 236, "next_ob": [236, 399, 400, 401, 402, 480], "init_stat": [236, 461, 462, 463, 464], "3752e": 236, "5087e": 236, "9294e": 236, "9636": 236, "5608": 236, "6408": 236, "num_it": [236, 462, 463], "reduce_dim": [236, 461, 462, 463, 464], "cat_dim": [236, 461, 462, 463, 464], "keep_dim": [236, 346, 462, 464], "statist": [236, 269, 270, 275, 383, 451, 461, 462, 463, 481], "gaussian": [236, 255, 274, 276, 302, 308, 309, 314, 463, 465, 474], "empir": [236, 276, 302, 347, 351, 461, 463, 475], "3d": [236, 279], "reorder": 238, "in_keys_in": [238, 264], "channel": [238, 258, 305, 310, 311, 462], "r3m": [240, 477], "resnet": [240, 265, 267], "ego4d": [240, 265, 267], "univers": [240, 265, 267, 466], "suraj": [240, 265], "nair": [240, 265], "aravind": [240, 265], "rajeswaran": [240, 265], "vikash": [240, 265, 267], "kumar": [240, 265, 267], "chelsea": [240, 265], "finn": [240, 265], "abhinav": [240, 265], "gupta": [240, 265], "2203": [240, 265, 302, 477], "12601": [240, 265, 477], "_init": [240, 265, 461], "resnet50": [240, 267, 477], "model_nam": [240, 265, 267, 331, 422], "resnet34": 240, "resnet18": 240, "r3m_vec": [240, 477], "stack_imag": [240, 267], "tread": [240, 267], "hub": [240, 267, 466], "resnet50_weight": [240, 267], "imagenet1k_v1": [240, 267], "download_path": [240, 267], "tensor_pixels_kei": [240, 267], "sub_seq_len": 241, "sample_dim": [241, 461], "hesit": 241, "robust": [241, 275], "mix": [241, 317, 326, 397, 461, 474, 475], "improp": 241, "dummyenv": 242, "another_oth": 242, "other_reward": 242, "create_copi": 243, "stuff": [243, 469], "newnam": 243, "r2g": 245, "reward_to_go": 245, "bernoulli_": 245, "9010": 245, "9404": [245, 405], "9701": [245, 405], "9900": [245, 405], "0000": [245, 256, 257, 292, 315, 354, 405], "clamp_min": 246, "clamp_max": 246, "clip_min": 246, "clip_max": 246, "episode_": 248, "reward1": 248, "reward2": 248, "episode_reward": [248, 474, 475], "keep_reward": 249, "keep_don": 249, "logical_or": 250, "in_key_inv": 252, "unstack": 252, "update_don": 253, "disjunct": 253, "recognis": 253, "target_return": 254, "default_valu": [255, 358], "expand_spec": 255, "single_default_valu": 255, "call_before_env_reset": 255, "unit": [255, 276, 290, 293, 294, 310, 311, 319, 320, 463], "scala": 255, "mykei": 255, "__unless": 255, "exists__": 255, "get_primers_from_modul": [255, 278, 295, 299, 453], "recurrent_st": [255, 295, 299, 358, 464], "10th": 256, "0216": 256, "1149": 256, "1990": 256, "2749": 256, "3281": 256, "9290": 256, "3702": 256, "8978": 256, "time_kei": 257, "elaps": [257, 470], "monitor": [257, 466], "expend": 257, "_polici": 257, "time_reset": 257, "time_polici": 257, "time_step": [257, 298, 346], "0882": 257, "0002": 257, "5797e": 257, "6289e": 257, "7990e": 257, "0824e": 257, "0837e": 257, "6056e": 257, "2016e": 257, "1062e": 257, "7009e": 257, "from_int": 258, "shape_toler": 258, "ri": 258, "traj_count": 260, "traj": 260, "countingenv": 260, "make_env_c0": 260, "make_env_c1": 260, "set_contain": 261, "reset_par": 261, "smoothli": [262, 275], "add_1": 262, "cache_spec": 262, "inv_fn": 263, "unari": 263, "durin": 263, "ommit": 263, "observation_trsf": 263, "xbc": 263, "x7f": 263, "x859": 263, "x81": 263, "x9a": 263, "xbd": 263, "xb8t8": 263, "test_output_spec": 263, "danger": 264, "vc1": 265, "vc1_vec": 265, "untrain": 265, "make_noload_model": 265, "vip": [266, 267, 477], "implicit": [267, 369, 377, 478], "jason": 267, "ma": 267, "shagun": 267, "sodhani": 267, "dinesh": 267, "jayaraman": 267, "osbert": 267, "bastani": 267, "ami": 267, "zhang": 267, "vip_vec": 267, "final_nam": 268, "sb3": 268, "terminal_obs_read": 268, "vecnormv2": 269, "new_api": [269, 270], "to_observation_norm": [269, 270], "frozen_copi": [269, 270], "shared_td": 269, "race": 269, "decai": [269, 270, 274, 292, 385, 435, 461, 462, 464, 481], "underflow": [269, 435], "build_td_for_shared_vecnorm": 269, "memmori": 269, "td_share": 269, "v": [269, 293, 294, 297, 298, 339, 369, 377, 384, 461, 462], "unfreez": [269, 270], "observationnorm": [269, 270, 451, 461, 462, 463, 464, 480], "train_env": 269, "eval_env": 269, "9999": 270, "0001": [270, 290], "shared_data": 270, "reduce_batch_dim": 270, "varianc": [270, 275, 276, 277, 296, 324, 325, 457, 461, 463, 475], "vs": [270, 273], "weigh": 270, "_cast_int_to_float": 270, "env_trsf": 270, "observation_norm": 270, "reward_norm": [270, 435], "unnorm": [270, 303, 304, 312], "7967": 270, "1238": 270, "5911": 270, "5275": 270, "8585": 270, "5028": 270, "2505": 270, "3169": [270, 354], "1332": 270, "1235": 270, "6596e": 270, "3072e": 270, "9170e": 270, "9255e": 270, "9131e": 270, "4671e": 270, "3760e": 270, "2058e": 270, "3484e": 270, "6185e": 270, "1456": 270, "1862": 270, "2053": 270, "2605": 270, "4046": 270, "5185": 270, "8023": 270, "1364": 270, "6183": 270, "5406": 270, "0920": 270, "1492": 270, "2702": 270, "3917": 270, "5001": 270, "7947": 270, "0160": 270, "3347": 270, "9082": 270, "9679": 270, "2199": 270, "2918": 270, "1668": 270, "2083": 270, "4981": 270, "5046": 270, "7950": 270, "9791": 270, "1484": 270, "4182": 270, "2201": 270, "0403": 270, "5206": 270, "7791": 270, "8282": 270, "2279": 270, "2907": 270, "4929": 270, "7793": 270, "8626": 270, "1832": 270, "local_env": 270, "testifi": 270, "4307": 270, "9613": 270, "state_dim": [271, 281, 286, 314, 319, 320, 342], "action_dim": [271, 281, 282, 284, 286, 314, 342, 461, 473], "gsde": [271, 382, 451], "gsdemodul": 271, "rb_transform": 272, "resist": 272, "insensit": 272, "sensit": [272, 462, 464], "_orig": 272, "95": [272, 302, 389, 463, 464], "window": [272, 346, 474, 478, 480], "module_nam": [273, 379, 394], "from_vers": 273, "to_vers": 273, "class_method": 273, "import_modul": 273, "get_class_that_defined_method": 273, "module_set": 273, "setters_dict": 273, "setter": 273, "setter_dict": 273, "po": 274, "sigma_init": [274, 474], "sigma_end": [274, 474], "annealing_num_step": [274, 292, 316, 461, 462, 464, 465, 467, 471, 474], "sigma": [274, 293, 294, 296, 297, 298, 316, 324, 325, 463, 474], "omiss": [274, 292, 316], "momentum": 275, "max_r": 275, "max_d": 275, "warmup_step": 275, "batchrenorm": 275, "1702": 275, "03275": 275, "corenet": 275, "enhanc": 275, "warmup": 275, "phase": [275, 277, 475, 478], "outlier": 275, "period": 275, "warm": 275, "renorm": 275, "entropi": [276, 312, 361, 362, 363, 364, 369, 370, 377, 378, 380, 381, 382, 384, 386, 387, 394, 395, 475], "botev": 276, "2013": 276, "cem": 276, "k": [276, 278, 293, 294, 297, 298, 330, 334], "maximis": [276, 282, 284, 302, 462, 463, 475], "modelbasedenv": [276, 302], "planning_horizon": [276, 302], "mpc": [276, 301, 302], "num_candid": [276, 302], "candid": [276, 302], "top_k": [276, 302], "modelbasedenvbas": [276, 301, 302, 453], "safemodul": [276, 301, 339, 341, 351, 361, 362, 364, 369, 370, 377, 381, 382, 383, 384, 386, 387, 442, 443, 447, 453, 480], "hausknecht": 277, "wagen": 277, "reus": [277, 282, 426], "consistentdropoutmodul": [277, 456], "capit": 277, "conceptu": 277, "devianc": 277, "set_exploration_typ": [277, 379, 432, 453, 456, 463, 464, 465, 467, 474, 480], "_main_async_collector": 277, "asyncdatacollector": [277, 453], "ditto": 277, "consistentdropout": 278, "input_shap": 278, "batcht": 278, "make_tensordict_prim": [278, 295, 299, 464], "input_dtyp": 278, "get_default_dtyp": [278, 435], "mask_6127171760": 278, "env0": [278, 481], "num_cel": [279, 280, 282, 283, 284, 285, 290, 291, 295, 299, 300, 305, 306, 339, 358, 462, 463, 464, 465, 467, 468, 471, 474, 475, 480], "elu": [279, 280, 282, 283, 284, 285, 290, 291, 305, 462, 480], "activation_kwarg": [279, 280, 300], "norm_class": [279, 280, 282, 283, 300], "norm_kwarg": [279, 280, 300], "bias_last_lay": [279, 280, 282, 283, 284, 285, 291, 300], "aggregator_class": [279, 280, 282, 283, 462, 464, 480], "squashdim": [279, 280, 282, 291, 305, 480], "aggregator_kwarg": [279, 280, 282, 283, 462, 464], "squeeze_output": [279, 280, 282, 283, 462, 464], "convolut": [279, 280, 282, 283, 305, 321, 465, 467], "cell": [279, 280, 293, 294, 295, 297, 298, 299, 300, 305, 306, 463, 465, 466, 467, 468, 469, 470, 471], "kernel": [279, 280, 305], "cnet": [279, 280], "conv3d": 279, "rectangular": [279, 280], "lazyconv2d": [280, 282, 283, 291, 305], "default_atari_dqn": [280, 465], "semin": 280, "transformer_config": [281, 314, 342], "decisiontransform": [281, 314], "dtconfig": [281, 286, 314], "2202": [281, 286, 380], "05607": [281, 286, 380], "return_to_go": [281, 286, 314, 342], "conv_net_kwarg": [282, 283], "mlp_net_kwarg": [282, 283, 284], "use_avg_pool": [282, 283], "WITH": [282, 283, 284, 285, 316, 385], "1509": [282, 283, 284, 285, 302, 316, 366, 376, 385], "02971": [282, 283, 284, 285, 316, 385], "convnet": [282, 283, 291, 305, 464, 465, 467, 480], "ndims_in": 282, "avgpool": [282, 283], "lazylinear": [282, 283, 284, 285, 291, 300, 456, 463, 467, 476, 477], "2304": 282, "adaptiveavgpool2d": [283, 462, 464], "output_s": [283, 462, 464], "squeeze2dlay": 283, "400": [284, 285, 475], "mlp_net_kwargs_net1": 285, "mlp_net_kwargs_net2": 285, "mlp1": 285, "mlp2": 285, "desdescrib": 286, "n_embd": 286, "n_layer": [286, 293, 297], "n_head": 286, "n_inner": 286, "n_posit": 286, "resid_pdrop": 286, "attn_pdrop": 286, "gpt2config": 286, "atol": [287, 323], "rtol": [287, 323], "batch_shap": [287, 312, 323], "event_shap": [287, 323], "absolut": [287, 323, 461], "_instanc": 287, "densiti": [287, 303, 304, 312, 325], "mass": [287, 303, 304, 312, 325, 476], "rsampl": [287, 304, 312, 351], "sample_shap": [287, 303, 304, 312], "softmax": [288, 304, 312, 343, 344], "var_num": [289, 318, 343, 344, 349], "action_value_kei": [289, 318, 343, 344, 348, 349, 364, 379, 394, 397], "action_mask_kei": [289, 292, 318, 343, 344, 348, 349], "1707": [289, 344, 371, 381], "06887": [289, 344, 371], "mult": [289, 306, 318, 343, 344, 348, 349], "tensordict_modul": [289, 293, 294, 297, 298, 318, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 361, 362, 364, 365, 369, 370, 377, 381, 382, 383, 384, 386, 387, 456], "nbin": [289, 343, 456], "customdistributionalqv": 289, "log_softmax": [289, 343], "qvalue_actor": [289, 318, 343, 348, 456], "to_modul": [289, 350, 353, 461, 480], "std_bia": 290, "std_min_val": 290, "belief": [290, 310, 319, 320], "1912": [290, 372, 373, 374], "01603": [290, 372, 373, 374], "softplu": [290, 357, 359, 360], "out_features_valu": 291, "cnn_kwarg": [291, 462], "mlp_kwarg": [291, 462], "duel": 291, "cnn": [291, 305, 462, 465, 467, 480], "06581": 291, "512": 291, "greedi": [292, 318, 344, 349, 462, 464, 465, 467], "eps_init": [292, 316, 462, 464, 465, 467, 471], "eps_end": [292, 316, 462], "explorative_polici": [292, 316], "9055": 292, "9277": 292, "6295": 292, "2532": 292, "grad_fn": [292, 338, 351], "addbackward0": 292, "batch_first": [293, 297, 464], "bidirect": [293, 297, 464], "cudnn": [293, 294, 295, 297, 298, 299, 464, 465], "rnn": [293, 294, 295, 297, 298, 299, 337, 370, 384, 399, 464, 465, 467], "device_count": [293, 294, 297, 298, 481], "n_in": [293, 294, 297, 298], "n_out": [293, 294, 297, 298], "h0": [293, 294, 297, 298], "h1": [293, 294, 297, 298], "vectoris": [293, 294, 297, 298], "call_gru": [293, 294], "h_out": [293, 294, 297, 298], "batched_cal": [293, 294, 297, 298], "gate": [293, 294, 297], "r_t": 293, "w_": [293, 294, 297, 298], "ir": [293, 294], "x_t": [293, 297], "b_": [293, 294, 297, 298], "hr": [293, 294, 297], "h_": [293, 294, 297], "z_t": 293, "iz": [293, 294], "hz": [293, 294], "n_t": 293, "odot": [293, 294, 297, 298], "hn": [293, 294, 297], "h_t": [293, 297], "sigmoid": [293, 294, 297, 298], "hadamard": [293, 294, 297, 298], "multilay": [293, 297], "_t": [293, 297, 475, 476], "ge": [293, 297], "bernoulli": [293, 297], "b_ih": [293, 294, 297, 298, 299], "b_hh": [293, 294, 297, 298, 299], "h_0": [293, 297, 298], "pack_padded_sequ": [293, 297], "pack_sequ": [293, 297], "num": [293, 297, 471], "_layer": [293, 297], "_size": [293, 294, 297, 298], "h_n": [293, 297], "packedsequ": [293, 297], "weight_ih_l": [293, 297], "learnabl": [293, 294, 297, 298], "w_ir": 293, "w_iz": 293, "w_in": 293, "num_direct": [293, 297], "weight_hh_l": [293, 297], "w_hr": 293, "w_hz": 293, "w_hn": 293, "bias_ih_l": [293, 297], "b_ir": 293, "b_iz": 293, "b_in": 293, "bias_hh_l": [293, 297], "b_hr": 293, "b_hz": 293, "b_hn": 293, "mathcal": [293, 294, 297, 298], "sqrt": [293, 294, 297, 298, 316], "frac": [293, 294, 297, 298, 463], "seq_len": [293, 297], "subtli": 293, "matrix": [293, 297, 308, 309], "hx": [293, 294, 297, 298], "lstmcell": [294, 299, 465], "gru_cel": 294, "weight_ih": [294, 298], "weight_hh": [294, 298], "bias_ih": [294, 298], "bias_hh": [294, 298], "rocm": [294, 298], "embedd": [295, 299], "grucel": [295, 350], "python_bas": [295, 299], "custom_kei": [295, 299], "hasn": [295, 299], "set_recurrent_mod": [295, 299, 464], "recurrent_mod": [295, 299, 337], "rs": [295, 461], "gru_module_train": 295, "policy_train": 295, "traj_td": 295, "make_cudnn_bas": [295, 299], "make_python_bas": [295, 299, 465], "supplementari": [295, 299, 463, 481], "That": [295, 299, 463, 474], "dealt": [295, 299], "poorli": [295, 299], "meth": [295, 299, 379, 476], "data_collector": [295, 299, 462], "upscal": [296, 324, 325], "tanh_loc": [296, 324, 325], "event_dim": [296, 323, 324], "poor": [296, 324, 325], "explos": [296, 324, 325], "proj_siz": 297, "c0": [297, 298], "c1": [297, 298], "call_lstm": [297, 298], "c_out": [297, 298], "i_t": 297, "ii": [297, 298], "hi": [297, 298], "f_t": 297, "hf": [297, 298], "g_t": 297, "ig": [297, 298], "hg": [297, 298], "o_t": 297, "ho": [297, 298], "c_t": 297, "c_": 297, "1402": 297, "1128": 297, "c_0": [297, 298], "proj": 297, "c_n": 297, "w_ii": 297, "w_if": 297, "w_ig": 297, "w_io": 297, "w_hi": 297, "w_hf": 297, "w_hg": 297, "w_ho": 297, "b_ii": 297, "b_if": 297, "b_ig": 297, "b_io": 297, "b_hi": 297, "b_hf": 297, "b_hg": 297, "b_ho": 297, "weight_hr_l": 297, "_revers": 297, "analog": [297, 467], "cn": 297, "lstm_cell": 298, "h_1": 298, "c_1": 298, "cx": 298, "recurrent_state_h": 299, "recurrent_state_c": 299, "triplet": [299, 348, 349], "lstm_modul": 299, "rs_h": 299, "rs_c": 299, "single_bias_last_lay": 300, "layer_class": 300, "layer_kwarg": 300, "perceptron": [300, 467], "noisylinear": [300, 308, 453, 462], "noisylazylinear": [300, 453], "mpcplanner": 301, "tensordict_out": [301, 328, 330, 334, 481], "mppi": 302, "covari": 302, "william": [302, 383], "aldrich": 302, "theodor": 302, "01149": 302, "hansen": 302, "wang": 302, "su": 302, "04955": 302, "valueoper": [302, 339, 340, 341, 361, 362, 363, 364, 365, 370, 377, 378, 381, 382, 383, 384, 386, 387, 447, 456, 461, 463, 468], "tdlambdaestim": [302, 453, 461], "value_net": [302, 366, 368, 383, 399, 400, 401, 402, 463, 465, 467, 468, 471], "adv": 302, "lmbda": [302, 389, 399, 402, 404, 410, 411, 412, 415, 416, 457, 461, 463, 475], "value_network": [302, 365, 366, 368, 369, 371, 377, 384, 399, 400, 401, 402, 457, 461, 463, 465, 468, 471, 474], "temperatur": [302, 330, 334, 362, 369, 377], "neg_inf": [303, 304], "inf": [303, 304], "use_cross_entropi": 303, "api_doc": [303, 304], "tf_agent": [303, 304], "sparse_mask": [303, 304], "cross_entropi": 303, "1203": [303, 304], "0928": [303, 304], "0831": [303, 304], "1972": [303, 304], "grad_method": [304, 312], "reparamgradientstrategi": [304, 312], "passthrough": [304, 312], "relaxedonehot": [304, 312], "sample_non_valid": 304, "zeros_lik": [304, 476], "share_param": [305, 306, 307, 474, 475], "use_td_param": [305, 306, 307], "get_stateful_net": [305, 306, 307, 379, 394, 456, 457], "from_stateful_net": [305, 306, 307, 379, 394, 457], "homogen": [305, 306, 474, 475], "tensordictparam": [305, 306, 351], "_empty_net": [305, 306], "roughli": [305, 306, 480], "agent_network": [305, 306], "modulelist": [305, 306], "2592": 305, "decentr": 305, "n_agent_input": [306, 307, 474, 475], "n_agent_output": [306, 307, 474, 475], "toech": 306, "centalis": 306, "shown": [306, 456, 465, 473, 474, 475, 478], "agent_dim": 307, "vmap_random": [307, 379, 394, 457], "stateful_net": [307, 379, 394], "Such": [307, 379, 394], "multiagentmlp": [307, 474, 475], "snet": 307, "hasattr": [307, 461], "kaiming_normal_": 307, "std_init": [308, 309], "initialize_paramet": 308, "isol": [308, 379, 394, 455, 465], "1706": [309, 326], "10295v3": 309, "induc": [309, 351], "aid": 309, "1803": [310, 311, 317], "10122": [310, 311], "rnn_hidden": 310, "latent": 311, "ordin": [313, 453], "parametris": [313, 315], "inres": 314, "mu": [314, 316, 463], "impos": [315, 456], "proxim": [315, 381, 463, 475], "atom": 315, "tang": 315, "agraw": 315, "2020": 315, "1901": 315, "10500": 315, "discretis": 315, "num_atom": 315, "num_sampl": 315, "middl": 315, "lr": [315, 461, 462, 463, 464, 471, 474, 475, 476], "optimis": [315, 474, 475], "minimis": 315, "penalis": 315, "0308": 315, "1586": 315, "4727": 315, "2260": 315, "1120": 315, "histogram": 315, "return_typ": 315, "hist": [315, 478], "158": 315, "478": 315, "228": 315, "112": 315, "bin_edg": 315, "8000": 315, "6000": 315, "4000": 315, "ornstein": [316, 461, 465], "uhlenbeck": [316, 461, 465], "ou": [316, 461], "correl": 316, "noise_t": 316, "noise_": 316, "theta": [316, 463, 476], "sigma_t": 316, "sigma_": 316, "anneal": [316, 462, 467, 474], "ou_prev_nois": 316, "ou_step": 316, "x0": 316, "sigma_min": 316, "n_steps_ann": 316, "is_init_kei": 316, "_ou_prev_nois": 316, "_ou_step": 316, "state_shap": [317, 397], "mixing_embed_dim": [317, 397], "qmix": [317, 474, 475], "mixer": [317, 326, 397], "monoton": 317, "hyper": 317, "11485": 317, "qmixerloss": [317, 326], "qmix_vdn": [317, 326], "vdn": [317, 326], "hidden_dim": [319, 320], "scale_lb": [319, 320], "posterior": [319, 373], "rssm": [319, 320, 373], "1811": [319, 320], "04551": [319, 320], "obs_embed": 319, "rnn_hidden_dim": 320, "dream": 320, "safe_tanh": 324, "tanhtransform": 324, "overflow": [324, 338, 343, 344, 347, 348, 349, 350, 351], "get_mod": [324, 351], "decomposit": 326, "05296": 326, "hide": [327, 463, 474, 475], "satisfi": [327, 456], "vmap_dim": 327, "lam": 327, "sample_in": 327, "sample_in_td": 327, "vm": 327, "probabilistictensordictsequenti": [328, 352, 361, 363, 378, 381, 383, 394, 442, 443, 457, 480], "placement": 329, "tokenization_util": [330, 334], "generate_kwarg": [330, 334], "aspect": [330, 334, 462, 468], "tokenizer_kwarg": [330, 334], "pad_output": [330, 334], "conserv": [330, 334, 362, 368], "automodelforcausallm": 330, "input_data": [330, 334], "hello": [330, 334], "output_data": [330, 334], "make_ray_work": 331, "train_model": 331, "inference_serv": 331, "collective_rpc": 331, "update_weight_broadcast": 331, "model_update_group": 331, "src": 331, "current_stream": 331, "world_siz": 332, "statelessprocessgroup": 332, "plane": 332, "pyncclcommun": 332, "vllmparameterserv": 333, "tp": 333, "tp_size": 333, "check_weights_chang": 333, "transformerswrapp": 334, "llmdata": [334, 453], "translat": [338, 347], "character": [338, 343, 347, 348, 350, 478], "td_modul": [338, 339, 340, 341, 347, 350, 351, 353, 355, 467, 480], "3635": 338, "0340": 338, "1476": 338, "3911": 338, "1664": 338, "5455": 338, "2247": 338, "4583": 338, "2916": 338, "2160": 338, "5337": 338, "5193": 338, "addmmbackward0": 338, "actorvalueoper": [339, 363, 378, 381, 456, 467], "get_policy_oper": [339, 340, 341, 363, 378, 381, 456], "standalon": [339, 340, 341, 465, 467], "tdmodul": [339, 340, 341, 447], "get_critic_oper": 339, "common_oper": [339, 341], "policy_oper": [339, 340, 341], "value_oper": [339, 340, 341], "module_hidden": [339, 341], "td_module_hidden": [339, 341], "module_act": [339, 341], "td_module_act": [339, 340, 341], "module_valu": [339, 340, 341], "td_module_valu": [339, 340, 341], "state_action_valu": [339, 355, 362, 364, 369, 377, 384, 398, 447, 456, 461, 474, 480], "td_clone": [339, 340, 341], "tensordictmodulewrapp": [339, 442, 443, 447], "get_policy_head": [339, 340, 341], "safesequenti": [339, 340, 341, 397], "head": [339, 341, 351, 358, 363, 378, 381, 453], "get_value_head": [339, 340, 341], "get_value_oper": [339, 340, 341, 363, 378, 381], "action_modul": 340, "actorcriticoper": [341, 456, 467], "actorcriticwrapp": [341, 456, 461], "inferec": 342, "set_tensor_kei": 342, "dt_inference_wrapp": 342, "baz": 342, "inference_context": 342, "obs_dim": 342, "tanhdelta": [342, 453, 461, 474], "dtactor": 342, "actor_modul": [342, 480], "dist_class": 342, "dist_kwarg": 342, "distribution_kwarg": [342, 347, 351, 463, 474, 475], "inference_actor": 342, "sequence_length": 342, "mask_context": 342, "out_act": 342, "qvaluemodul": [343, 348, 397, 464, 465, 467, 471], "distributionaldqnnet": 343, "make_log_softmax": 343, "my_action_valu": [344, 349], "chanc": 344, "lmheadmodel": 345, "actor_head": [345, 363, 378, 381], "base_model": 345, "lm_head": 345, "lookahead": 346, "reshape_cat": 346, "actor_bas": 346, "obs_cat": 346, "obs_cat_reshap": 346, "action_orig": 346, "multistepenvwrapp": 346, "alter": [346, 379, 455, 456], "ego": 346, "default_interaction_typ": [347, 351, 467], "interaction_typ": [347, 351], "set_interaction_typ": [347, 351], "compositedistribut": [347, 351, 361, 381, 457, 467], "distribution_map": [347, 351], "name_map": [347, 351], "cache_dist": [347, 351], "n_empirical_estim": [347, 351], "compound": [347, 467], "chose": 349, "functionalmodul": 350, "functionalmodulewithbuff": 350, "td_fmodul": 350, "td_function": 350, "td_state": 350, "params_repeat": 350, "td_vmap": [350, 353], "random_sampl": [350, 351], "suppli": 351, "paliat": 351, "get_median": 351, "get_mean": 351, "sample_key_nam": 351, "_log_prob": 351, "composite_lp_aggreg": 351, "clampbackward0": 351, "anihil": 351, "partial_toler": [352, 353, 473], "AND": [352, 353, 364], "tensordictsequ": 353, "safeprobabilisticmodul": [353, 456], "spec1": 353, "net1": 353, "module1": 353, "td_module1": 353, "spec2": 353, "module2": 353, "td_module2": 353, "boundari": [354, 463, 465, 474, 475], "resolut": 354, "9944": 354, "9991": 354, "3020": 354, "2299": 354, "5418": 354, "2989": 354, "6849": 354, "2690": 354, "9649": 354, "5686": 354, "8602": 354, "0315": 354, "8455": 354, "6027": 354, "4746": 354, "7843": 354, "7782": 354, "2111": 354, "5115": 354, "4687": 354, "5760": 354, "custommodul": 355, "imaginari": 356, "imagin": 356, "transition_model": 356, "get_reward_oper": 356, "get_transition_model_oper": 356, "min_val": [357, 360], "_bia": 357, "surject": 360, "expln": 360, "biased_softplu": [360, 453], "biased_softplus_": 360, "syntax": [360, 461], "add_custom_map": 360, "1602": 361, "01783v2": 361, "actor_network": [361, 362, 363, 364, 365, 367, 369, 370, 377, 378, 380, 381, 382, 383, 384, 386, 387, 394, 457, 461, 463, 468, 474, 475], "critic_network": [361, 363, 378, 381, 383, 463, 475], "entropy_bonu": [361, 363, 378, 381, 394, 463], "favour": [361, 363, 378, 381, 394], "samples_mc_entropi": [361, 363, 378, 380, 381, 394], "entropy_coef": [361, 363, 378, 381, 394, 463, 475], "critic_coef": [361, 363, 378, 381, 394, 463], "loss_critic_typ": [361, 363, 378, 381, 383, 463], "l1": [361, 363, 365, 366, 370, 378, 381, 382, 383, 386, 387, 390, 397, 456, 461], "l2": [361, 363, 365, 366, 367, 368, 370, 373, 374, 378, 381, 382, 383, 386, 387, 390, 397, 461, 474], "smooth_l1": [361, 362, 363, 364, 365, 366, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387, 390, 397, 463], "separate_loss": [361, 363, 364, 365, 369, 370, 377, 378, 381, 382, 383, 384, 386, 387], "advantage_kei": [361, 363, 378, 381, 383, 394, 396, 399, 400, 401, 402], "value_target_kei": [361, 363, 378, 381, 383, 399, 400, 401, 402], "value_target": [361, 363, 378, 381, 383, 399, 400, 401, 402, 463, 475], "ddp": [361, 363, 378, 381, 383], "fsdp": [361, 363, 378, 381, 383], "divid": [361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 377, 378, 380, 381, 382, 383, 384, 386, 387, 394, 440, 461, 474, 475, 476], "clip_valu": [361, 363, 378, 381, 383, 394], "loss_crit": [361, 381, 394, 463, 475], "loss_entropi": [361, 381, 395, 463, 475], "loss_object": [361, 381, 395, 463, 475], "next_reward": [361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 399, 400, 401, 402], "next_don": [361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 399, 400, 401, 402], "next_termin": [361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 399, 400, 401, 402], "loss_obj": 361, "next_observ": [361, 362, 364, 365, 366, 368, 369, 370, 377, 381, 382, 383, 384, 386, 387, 473], "sacloss": [361, 376, 385, 453], "default_kei": [361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 380, 381, 382, 383, 384, 386, 387, 394, 397, 403], "_acceptedkei": [361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 377, 379, 380, 381, 382, 383, 384, 386, 387, 394, 397, 403], "fraction": 361, "make_value_estim": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 388, 394, 397, 457, 461, 462, 474, 475, 480], "value_typ": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 389, 394, 397, 461], "valueestim": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 389, 394, 397, 453, 457, 461, 474, 475], "hyperparam": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 461], "enum": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 389, 394, 397, 461], "default_value_estim": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 461, 480], "default_value_kwarg": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 453, 461], "dqn_loss": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 388, 394, 397], "td1": [361, 362, 364, 365, 366, 368, 370, 371, 372, 377, 379, 381, 382, 383, 384, 386, 387, 394, 397, 461], "04779": [362, 368], "qvalue_network": [362, 364, 369, 370, 377, 382, 384, 386, 387], "unti": [362, 364, 377, 382, 384, 386, 387], "loss_funct": [362, 364, 365, 366, 367, 368, 369, 370, 377, 382, 384, 386, 387, 390, 397, 461, 474], "alpha_init": [362, 364, 370, 380, 382, 384], "min_alpha": [362, 364, 370, 380, 382, 384], "max_alpha": [362, 364, 370, 380, 382, 384], "fixed_alpha": [362, 364, 370, 380, 382, 384], "target_entropi": [362, 364, 370, 380, 382, 384], "prod": [362, 364, 380, 384], "delay_actor": [362, 365, 384, 386, 387], "delay_qvalu": [362, 370, 382, 384, 386, 387], "min_q_weight": 362, "max_q_backup": 362, "backup": 362, "deterministic_backup": 362, "num_random": 362, "with_lagrang": 362, "lagrang": 362, "lagrange_thresh": 362, "deactivate_vmap": [362, 364, 370, 377, 382, 384, 386, 387, 399, 400, 401, 402], "valueclass": [362, 364, 365, 370, 382, 384, 386, 387], "qvalu": [362, 364, 369, 370, 377, 382, 384, 386, 387], "loss_actor": [362, 364, 365, 369, 370, 377, 382, 383, 384, 386, 387, 433, 461, 474], "loss_actor_bc": 362, "loss_alpha": [362, 364, 370, 382, 384], "loss_cql": [362, 368], "loss_qvalu": [362, 364, 368, 369, 370, 377, 382, 384, 386, 387], "loss_alpha_prim": 362, "clip_epsilon": [363, 394, 463, 475], "head_nam": [363, 378, 381], "normalize_advantag": [363, 378, 381, 475], "normalize_advantage_exclude_dim": [363, 378, 381], "multiobject": [363, 378, 381], "value_kei": [363, 378, 381, 399, 400, 401, 402, 461], "somemodul": [363, 378, 381], "someactor": [363, 378, 381], "value_head": [363, 378, 381], "somevalu": [363, 378, 381], "loss_modul": [363, 376, 378, 379, 381, 385, 394, 437, 446, 447, 457, 458, 461, 462, 463, 474, 475, 478], "IN": 364, "FOR": 364, "simplic": [364, 462, 463, 469, 477, 478, 480], "openreview": [364, 382], "pczqttstix": 364, "qvalue_loss": [364, 386], "actor_loss": [364, 386], "alpha_loss": 364, "num_qvalue_net": [364, 369, 370, 377, 382, 384, 386, 387], "maybe_init_target_entropi": 364, "fault_toler": 364, "target_entropy_buff": 364, "delay_valu": [365, 366, 368, 371, 383, 384, 397, 462, 464, 465, 471, 474], "loss_valu": [365, 369, 377, 383, 384, 461, 463, 474, 475], "pred_valu": [365, 368, 386, 387, 461], "pred_value_max": [365, 461], "target_valu": [365, 368, 382, 386, 387, 398, 457, 461], "target_value_max": [365, 461], "qvalueactor": [366, 368, 397, 462, 464], "double_dqn": 366, "06461": [366, 376], "mult_one_hot": [366, 369, 370, 397], "loss_val": [366, 368, 457, 461, 463, 464, 465, 468, 469, 471, 474, 475, 478], "01345": 367, "distanc": [368, 378, 390, 398, 399, 475], "dcql_loss": 368, "2110": [369, 377], "06169": [369, 377], "expectil": [369, 377], "tau": [369, 377, 385, 461, 462, 474], "antmaz": [369, 377], "sticht": [369, 377], "onehotcategor": [369, 370, 453], "target_entropy_weight": 370, "skip_done_st": [370, 384], "disctount": 371, "distributionalqvalueactor": [371, 456], "input_tensordict": [371, 461], "actor_model": 372, "value_model": [372, 374], "imagination_horizon": 372, "discount_loss": [372, 374], "lambda_kl": 373, "lambda_reco": 373, "lambda_reward": 373, "reco_loss": 373, "reward_loss": 373, "free_nat": 373, "nat": 373, "delayed_clamp": 373, "global_averag": 373, "value_loss": 374, "fake_data": 374, "1606": 375, "03476": 375, "discriminator_network": 375, "use_grad_penalti": 375, "gp_lambda": 375, "discrimin": 375, "ddpgloss": [376, 385, 447, 453, 461, 468, 474, 480], "td3loss": [376, 385, 453], "value_network_update_interv": 376, "qvalueclass": 377, "loss_value_diff": 377, "diff": 377, "old_polici": 378, "new_polici": 378, "apart": [378, 475], "dtarg": 378, "samples_mc_kl": 378, "analyt": 378, "decrement": 378, "loss_": [379, 433, 457, 461, 468], "equip": [379, 464, 465, 467], "gh": 379, "_forward_value_estimator_kei": 379, "value_estim": [379, 394, 399, 400, 401, 402, 403, 457, 461, 475], "myloss": 379, "action2": 379, "augment": [379, 455, 469, 471, 478], "deterministic_sampling_mod": 379, "convert_to_funct": [379, 394, 461], "expand_dim": [379, 394], "create_target_param": [379, 394, 461], "compare_against": [379, 394, 461], "_param": [379, 394], "resampl": [379, 394], "_target_param": [379, 394], "network_nam": [379, 394], "blend": [379, 394], "add_random_modul": [379, 394, 457], "flavor": [381, 461, 474, 475, 480], "clipppoloss": [381, 453, 463, 475], "klpenppoloss": [381, 453], "06347": 381, "gae": [381, 453, 457, 461, 463, 475], "ppo_loss": 381, "tdlambda": [381, 389, 457, 461], "base_lay": 381, "randn_lik": 381, "samplelogprob": 381, "ay8zfzm0tdd": 382, "sub_sample_len": 382, "subsampl": [382, 428, 458], "action_log_prob_actor": 382, "state_action_value_actor": [382, 386, 387], "connectionist": 383, "1992": 383, "doi": 383, "1007": 383, "bf00992696": 383, "actor_net": [383, 461, 463], "1801": 384, "01290": 384, "applic": [384, 397, 466, 467, 476], "1812": 384, "05905": 384, "redqloss": [385, 453], "math": 385, "theta_t": [385, 476], "theta_": [385, 476], "polyak": 385, "minimalist": 386, "06860": 386, "policy_nois": [386, 387], "noise_clip": [386, 387], "td3_bc": 386, "bc_loss": 386, "lmbd": 386, "td0": [388, 461, 474], "strict_shap": 390, "view_a": 390, "grpolossoutput": [394, 396], "clip_fract": 395, "kl_approx": 395, "ess": 395, "loss_kl_to_ref": 395, "kl_to_ref": 395, "grpo_siz": 396, "rewards_kei": 396, "hit": 396, "qmixer": [397, 453], "local_valu": 397, "visibl": [397, 475], "acceptedkei": 397, "global_valu": 397, "penultim": 397, "local_value_network": 397, "mixer_network": 397, "value_modul": [397, 463, 480], "qnet": [397, 461], "next_val_kei": 398, "pred_next_v": 398, "mse": 398, "q_valu": 398, "n_steps_to_next": 398, "value_next_st": 398, "1506": [399, 404, 412], "02438": [399, 404, 412], "exponenti": [399, 400, 401, 402, 404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 435], "average_ga": [399, 463], "skip_exist": [399, 400, 401, 402], "get_default_devic": [399, 400, 401, 402, 403], "auto_reset_env": 399, "next_valu": [399, 400, 401, 402, 403], "gradient_mod": 399, "value_error": [399, 400, 401, 402, 403], "marker": [399, 461], "trajecotri": 399, "fair": 399, "target_param": [399, 400, 401, 402, 403, 461, 475], "98": [399, 400, 401, 402], "94": [399, 402], "unpack": [399, 400, 401, 402], "tensor_kei": [399, 400, 401, 402, 403], "aka": [400, 462, 474], "average_reward": [400, 401, 402], "tdestim": [400, 401, 403], "infti": 401, "valuefunctionbas": 403, "old_stat": [404, 406, 408, 410, 412, 413, 415], "new_stat": [404, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416], "rolling_gamma": [408, 409, 410, 411, 413, 414, 415, 416], "g1": [408, 409, 410, 411, 413, 414, 415, 416], "g2": [408, 409, 410, 411, 413, 414, 415, 416], "g3": [408, 409, 410, 411, 413, 414, 415, 416], "g4": [408, 409, 410, 411, 413, 414, 415, 416], "v3": [408, 409, 410, 411, 413, 414, 415, 416], "preproc": [417, 465, 474], "as_non_tensor": [417, 474], "render_method": 417, "pass_tensordict": 417, "syntact": 417, "sugar": 417, "out_file_bas": 418, "skip_reset": 418, "center_crop": 419, "make_grid": 419, "log_video": 419, "csv": [419, 421, 423, 462, 470, 471], "wandb": [419, 423, 426, 470, 480], "tensorboard": [419, 423, 425, 470, 480], "log_dir": [419, 420, 421, 423, 425, 426, 462, 471], "cheetah_video": 419, "run_video": 419, "openxexperiencereplai": 419, "sec": [419, 476], "video_fp": [419, 421, 424], "cmu_stretch": 419, "run_video_0": 419, "cur_dir": 421, "csv_log": 421, "add_video": 421, "video_": 421, "experiment_nam": [422, 423], "uuid": [422, 462, 481], "logger_typ": 423, "logger_nam": 423, "mlflow": [423, 424], "wandb_kwarg": 423, "mlflow_kwarg": 423, "tracking_uri": 424, "uri": 424, "datastor": 424, "tb_log": 425, "tensoarboard": 425, "td_log": 425, "save_dir": 426, "resum": 426, "uncategor": 426, "my_funct": 427, "sub_traj_len": 428, "min_sub_traj_len": 428, "register_op": [428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 458, 462], "process_optim_batch": [428, 434, 435, 458], "td_out": [428, 436], "_process_optim_batch_hook": [428, 458], "batch_subsampl": 428, "clear_cuda": 429, "pre_optim_step": [429, 458], "log_pbar": [430, 431, 432, 435, 458, 462], "count_fram": 430, "pre_steps_log": [430, 431, 458], "count_frames_log": 430, "lognam": 431, "r_train": 431, "log_reward": [431, 462], "record_interv": [432, 461, 462], "record_fram": [432, 440, 461, 462], "policy_explor": [432, 447, 461, 462, 465, 467, 471], "log_kei": [432, 462], "underestim": 432, "r_evalu": [432, 461], "loss_compon": 433, "appl": 433, "optimizer_hook": 433, "flatten_tensordict": [434, 462], "max_dim": 434, "rb_trainer": 434, "batch_process": [434, 435, 436, 458], "post_loss": [434, 458], "999": [435, 462], "jitter": 435, "finfo": 435, "default_dtyp": 435, "update_reward_stat": 435, "normalize_reward": 435, "make_train": [436, 453], "_process_batch_hook": [436, 458], "select_kei": [436, 458], "versatil": [437, 466], "optim_steps_per_batch": [437, 458, 462], "clip_grad_norm": 437, "clip_norm": 437, "progress_bar": 437, "save_trainer_interv": 437, "log_interv": [437, 462], "save_trainer_fil": [437, 458], "load_from_fil": [437, 458], "update_weights_interv": [439, 462], "post_step": [439, 458, 462], "dictconfig": [440, 441, 442, 443, 445, 446, 447, 448, 451], "unknowingli": 440, "annealing_fram": [440, 461], "init_env_step": [440, 441, 461], "proof_environ": [441, 461], "sta": 441, "ot": 441, "actor_model_explor": [442, 443, 461], "make_env_kwarg": [442, 443], "targetnetupdat": [444, 446, 447], "replayargsconfig": 445, "target_net_updat": [447, 461, 462], "constitu": 447, "egreedywrapp": 447, "env_proof": 447, "obs_spec": 447, "net_valu": 447, "dir": [447, 458, 462], "gettempdir": 447, "namespac": [448, 451], "transformed_env_constructor": [448, 453], "num_env_per_collector": [449, 450], "video_tag": 451, "norm_obs_onli": 451, "use_env_cr": 451, "custom_env_mak": 451, "custom_env": 451, "return_transformed_env": 451, "action_dim_gsd": 451, "state_dim_gsd": 451, "obs_norm_state_dict": 451, "weightupdat": 453, "distributedsyncdatacollector": 453, "submitit_delayed_launch": 453, "remotetensordictreplaybuff": 453, "rational": 453, "footnot": 453, "binarydiscretetensorspec": 453, "boundedtensorspec": 453, "discretetensorspec": 453, "lazystackedcompositespec": 453, "lazystackedtensorspec": 453, "multidiscretetensorspec": 453, "multionehotdiscretetensorspec": 453, "nontensorspec": 453, "onehotdiscretetensorspec": 453, "unboundedcontinuoustensorspec": 453, "unboundeddiscretetensorspec": 453, "prompttensordicttoken": 453, "rolloutfrommodel": 453, "tokenizeddatasetload": 453, "create_infinite_iter": 453, "constantklcontrol": 453, "adaptiveklcontrol": 453, "densifyreward": 453, "h5combin": 453, "h5split": 453, "nested2t": 453, "check_no_exclusive_kei": 453, "consolidate_spec": 453, "contains_lazy_spec": 453, "envmetadata": 453, "chessenv": 453, "tictactoeenv": 453, "llmhashingenv": 453, "check_marl_group": 453, "get_available_librari": 453, "terminated_or_trunc": 453, "dreamerdecod": 453, "braxwrapp": 453, "dmcontrolwrapp": 453, "isaaclabwrapp": 453, "jumanjiwrapp": 453, "meltingpotenv": 453, "meltingpotwrapp": 453, "mogymenv": 453, "multithreadedenvwrapp": 453, "openmlenv": 453, "openspielwrapp": 453, "openspielenv": 453, "pettingzooenv": [453, 474], "robohiveenv": 453, "smacv2env": 453, "smacv2wrapp": 453, "unitymlagentsenv": 453, "unitymlagentswrapp": 453, "vmaswrapp": 453, "register_gym_spec_convers": 453, "vllmupdat": 453, "llmcollector": [453, 455], "qvaluehook": 453, "distributionalqvaluehook": 453, "reset_nois": 453, "cemplann": 453, "mpcplannerbas": 453, "mppiplann": 453, "independentnorm": 453, "truncatednorm": 453, "maskedonehotcategor": 453, "onehotordin": 453, "inv_softplu": 453, "vmapmodul": 453, "distributionaldqnloss": [453, 462], "discretesacloss": 453, "crossqloss": 453, "iqlloss": 453, "discreteiqlloss": 453, "cqlloss": 453, "discretecqlloss": 453, "gailloss": 453, "dtloss": 453, "onlinedtloss": 453, "td3bcloss": 453, "ppoloss": 453, "a2closs": 453, "reinforceloss": 453, "dreameractorloss": 453, "dreamermodelloss": 453, "dreamervalueloss": 453, "td0estim": [453, 461], "td1estim": [453, 461], "td0_return_estim": 453, "td0_advantage_estim": 453, "td1_return_estim": 453, "vec_td1_return_estim": 453, "td1_advantage_estim": 453, "vec_td1_advantage_estim": 453, "td_lambda_return_estim": 453, "vec_td_lambda_return_estim": 453, "td_lambda_advantage_estim": 453, "vec_td_lambda_advantage_estim": 453, "generalized_advantage_estim": 453, "vec_generalized_advantage_estim": 453, "hardupd": [453, 461, 468], "softupd": [453, 461, 462, 464, 465, 468, 471, 474], "distance_loss": [453, 461], "group_optim": 453, "hold_out_net": 453, "hold_out_param": [453, 461], "batchsubsampl": [453, 458], "clearcudacach": 453, "countframeslog": 453, "logscalar": [453, 458, 462], "optimizerhook": [453, 462], "logvalidationreward": [453, 458, 461, 462], "replaybuffertrain": [453, 458, 462], "rewardnorm": 453, "selectkei": [453, 458], "trainerhookbas": [453, 458, 462], "updateweight": [453, 458, 462], "make_collector_offpolici": 453, "make_collector_onpolici": 453, "make_dqn_loss": 453, "make_replay_buff": [453, 461], "make_target_updat": 453, "parallel_env_constructor": [453, 461], "sync_async_collector": 453, "sync_sync_collector": 453, "correct_for_frame_skip": 453, "get_stats_random_rollout": 453, "mlflowlogg": 453, "get_logg": 453, "generate_exp_nam": 453, "journei": 454, "textbook": 454, "highlight": [454, 474], "ever": [454, 475], "bump": 454, "benefit": [454, 466, 474, 475, 478], "pr": 454, "fundament": [455, 469], "templatetransform": 455, "pythoninterpret": 455, "klrewardtransform": 455, "grpoloss": 455, "simpler": [455, 462, 466], "make_mlgym": 455, "7b": 455, "step_data": 455, "s_": 455, "unifi": [455, 481], "ground": [456, 461, 476], "recycl": [456, 478], "noisier": 456, "Their": [456, 474, 475], "sd": [456, 481], "prob_modul": 456, "uncertainti": 456, "soften": 456, "backbon": [456, 464, 467, 473, 480], "make_actor": 456, "make_valu": 456, "shared_param": 456, "make_common": 456, "reusabl": [457, 461, 478], "swappabl": [457, 461], "characterist": [457, 461, 476], "trainabl": [457, 461, 468, 477], "smth": [457, 461], "metric": [457, 461], "plenti": [457, 465], "amort": [457, 462, 463], "told": [457, 463], "pseudo": [457, 469, 476], "buri": 457, "str_valu": 457, "nutshel": [457, 461], "barto": [457, 474, 475], "chapter": [457, 470], "value_net_loss": 457, "pow": [457, 461], "room": 457, "signifi": [457, 474, 475], "underperform": 457, "intric": [457, 467], "set_composite_lp_aggreg": [457, 475], "action_td": 457, "action0": 457, "f0": 457, "action1": 457, "f1": 457, "f2": 457, "f3": 457, "action0_log_prob": 457, "action1_log_prob": 457, "inferior": 457, "multivari": 457, "dirichlet": 457, "prev_log_prob": 457, "new_log_prob": 457, "log_weight": 457, "appreci": [457, 466], "multihead": 457, "believ": 458, "substanti": 458, "_pre_steps_log_hook": 458, "_pre_optim_hook": 458, "sub_batch": 458, "_post_loss_hook": 458, "_post_optim_hook": 458, "post_optim": [458, 462], "_post_optim_log": 458, "post_optim_log": 458, "_post_steps_hook": 458, "_post_steps_log_hook": 458, "post_steps_log": 458, "logginghook": 458, "logging_hook": 458, "save_dict": 458, "some_valu": 458, "torchsnapshot": 458, "ckpt_backend": 458, "filepath": 458, "save_train": 458, "000": [460, 479], "galleri": [460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "mem": [460, 479], "mb": [460, 479], "coding_ddpg": [460, 461, 479], "coding_dqn": [460, 462, 479], "coding_ppo": [460, 463, 479], "dqn_with_rnn": [460, 464, 479], "multi_task": [460, 473, 479], "multiagent_competitive_ddpg": [460, 474, 479], "multiagent_ppo": [460, 475, 479], "pretrained_model": [460, 477, 479], "rb_tutori": [460, 478, 479], "torchrl_demo": [460, 479, 480], "torchrl_env": [460, 479, 481], "author": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 474, 475, 476, 478, 481], "vincent": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 476, 478, 481], "moen": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 476, 478, 481], "assembl": 461, "focus": [461, 468], "maxim": [461, 468, 476], "transpar": [461, 464], "bash": 461, "is_fork": [461, 462, 463, 464, 474, 475, 477], "get_start_method": [461, 462, 463, 464, 474, 475, 477], "collector_devic": 461, "loss_dict": 461, "modal": 461, "oblivi": [461, 463, 478], "elementari": 461, "didact": [461, 465], "dilut": 461, "pessimist": [461, 462, 463], "target_actor_network_param": 461, "actor_in_kei": 461, "actor_crit": 461, "compromis": 461, "hp": 461, "_value_estim": 461, "elif": [461, 462], "unknown": 461, "_loss_actor": 461, "td_copi": 461, "actor_network_param": [461, 474], "value_network_param": [461, 474], "_loss_valu": 461, "pred_val": 461, "target_value_network_param": 461, "glue": 461, "_forward": 461, "remaind": 461, "env_librari": 461, "env_task": 461, "env_arg": [461, 462], "torchr": 461, "rescal": 461, "presum": 461, "make_transformed_env": 461, "reward_sc": 461, "env_per_collector": 461, "transform_state_dict": 461, "make_t_env": 461, "cheat": 461, "10m": 461, "cautiou": 461, "magnitud": [461, 474], "thousand": [461, 464], "get_env_stat": 461, "proof_env": 461, "5000": [461, 465, 471], "recal": [461, 463, 478], "ddpgmlpactor": 461, "ddpgmlpqnet": 461, "materi": 461, "ornsteinuhlenbeckprocessmodul": [461, 467], "make_ddpg_actor": 461, "q_net": 461, "tight": 461, "10_000": [461, 463], "traj_len": [461, 464], "make_record": 461, "recorder_obj": 461, "pick": [461, 462, 467], "buffer_s": [461, 462], "random_crop_len": 461, "prb": 461, "buffer_scratch_dir": [461, 462, 464, 469, 477], "dataflow": 461, "ceil_div": 461, "utd": [461, 464], "update_to_data": 461, "realiz": 461, "_must_": 461, "001": [461, 476], "outdat": 461, "trick": [461, 462], "despit": 461, "optimizer_actor": 461, "weight_decai": [461, 462], "optimizer_valu": 461, "total_collection_step": 461, "rewards_ev": 461, "collected_fram": 461, "numel": [461, 463, 464, 465, 471, 474, 477, 478], "current_fram": [461, 474], "sampled_tensordict": 461, "gn1": 461, "clip_grad_norm_": [461, 463, 474, 475, 476], "gn2": 461, "gn": [461, 476], "td_record": 461, "rn": 461, "2f": 461, "mention": [461, 464, 478, 481], "matplotlib": [461, 463, 464, 465, 474, 475, 476, 478, 481], "pyplot": [461, 463, 464, 465, 474, 475, 476, 478, 481], "plt": [461, 463, 464, 465, 474, 475, 476, 478, 481], "zip": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "legend": [461, 474], "xlabel": [461, 464, 475, 476], "ylabel": [461, 475], "tight_layout": 461, "takeawai": [461, 462, 465], "distpatch": 461, "jupyt": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "ipynb": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 473, 474, 475, 476, 477, 478, 480, 481], "sphinx": [461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481], "road": 462, "highest": [462, 467], "prerequisit": [462, 464], "lookup": 462, "cart": 462, "pole": 462, "un": 462, "actuat": 462, "frictionless": 462, "duelingcnndqnet": 462, "egreedymodul": [462, 464, 465, 467, 471], "is_notebook": 462, "shell": 462, "get_ipython": 462, "__class__": 462, "zmqinteractiveshel": 462, "qtconsol": 462, "terminalinteractiveshel": 462, "ipython": [462, 475, 476], "nameerror": [462, 474], "umbrella": 462, "misplac": 462, "misus": 462, "orchestr": [462, 468, 470], "five": 462, "64x64": 462, "motion": [462, 476], "obs_norm_sd": 462, "mp_context": 462, "get_norm_stat": 462, "test_env": 462, "mathbb": 462, "rightarrow": 462, "make_model": 462, "dummy_env": 462, "init_bia": 462, "exploration_modul": [462, 464, 465, 467, 471], "eps_greedy_v": 462, "eps_greedy_val_env": 462, "actor_explor": 462, "get_replay_buff": 462, "n_optim": [462, 468, 469], "parametriz": 462, "get_collector": 462, "bunch": 462, "ubiquit": [462, 466], "get_loss_modul": 462, "target_updat": [462, 474], "995": 462, "variat": 462, "2e": [462, 476], "wd": 462, "upd": 462, "harder": [462, 480], "5_000": 462, "500000": 462, "100000": 462, "005": [462, 474], "mandatori": [462, 463, 475, 476], "fairer": 462, "budget": 462, "dqn_exp_": 462, "uuid1": [462, 481], "cumbersom": 462, "buffer_hook": 462, "aliv": 462, "total_reward": 462, "print_csv_files_in_fold": 462, "folder_path": 462, "csv_file": 462, "output_str": 462, "dirpath": 462, "endswith": 462, "strip": 462, "qvaluenetwork": 462, "accuraci": 462, "fanci": [462, 469], "demonstr": [463, 465, 469, 474, 475, 476, 478, 481], "talk": 463, "six": 463, "sophist": [463, 475], "invent": 463, "theta_k": 463, "pi_": 463, "exceed": 463, "discourag": [463, 476], "indispens": 463, "analyz": 463, "lingua": 463, "franca": 463, "defaultdict": [463, 476], "3e": [463, 464, 474, 475], "max_grad_norm": [463, 474, 475], "sub_batch_s": 463, "num_epoch": [463, 475], "entropy_ep": [463, 475], "charact": [463, 465], "inverteddoublependulum": 463, "transmit": 463, "stai": 463, "confid": [463, 474, 475], "ran": 463, "f_": 463, "mu_": 463, "difficulti": [463, 481], "d_ob": 463, "d_action": 463, "policy_modul": [463, 474, 475], "briefli": [463, 474, 475], "refil": [463, 475], "easiest": [463, 468, 474, 475], "mathemat": [463, 474, 475], "tradeoff": [463, 475], "advantage_modul": 463, "lr_schedul": [463, 476], "cosineannealinglr": [463, 476], "eval_str": 463, "tensordict_data": [463, 475], "data_view": [463, 475], "subdata": [463, 474, 475], "cum_reward_str": 463, "stepcount_str": 463, "param_group": [463, 474], "lr_str": 463, "eval_rollout": 463, "nice": [463, 466, 469], "figsiz": [463, 476], "subplot": [463, 474, 476, 481], "titl": [463, 464, 465, 475, 476], "84x84": [464, 465], "accessori": 464, "stamp": 464, "n_cell": 464, "customiz": 464, "wouldn": 464, "qval": 464, "stoch_polici": 464, "opportun": [464, 474], "uniniti": 464, "again": [464, 465, 466, 467, 469, 475, 477, 478, 481], "strongli": 464, "million": 464, "sake": [464, 477, 478], "20_000": [464, 476], "longest": 464, "npai": 464, "action_spread": 464, "strong": 465, "impress": 465, "arduino": 465, "raspberri": 465, "pi": [465, 474, 475, 476], "alon": 465, "examplifi": 465, "ship": 465, "stick": 465, "nearest": 465, "value_mlp": [465, 471], "init_rand_step": [465, 471], "total_count": [465, 471], "total_episod": [465, 471], "t0": [465, 471], "screen": [465, 474], "color": [465, 474], "unblock": 465, "policy_transform": 465, "fake_td": 465, "exported_polici": 465, "div": 465, "graph_modul": 465, "print_read": 465, "group0": 465, "group0_agent0_ob": 465, "collid": [465, 475], "group0_agent0": 465, "agent0_ob": 465, "comma": 465, "digress": 465, "exported_stochastic_polici": 465, "trace": 465, "batchsizetransform": 465, "hidden0": 465, "hidden1": 465, "recurrent_polici": 465, "fake_ob": 465, "fake_hidden0": 465, "fake_hidden1": 465, "fake_is_init": 465, "exported_recurrent_polici": 465, "platform": [465, 480], "aoti": 465, "_inductor": 465, "aoti_compile_and_packag": 465, "aoti_load_packag": 465, "pt2": 465, "pkg_path": 465, "package_path": 465, "compiled_modul": 465, "onnxruntim": 465, "showcas": [465, 476], "web": 465, "explain": [465, 477], "tensorrt": 465, "android": 465, "aleinterfac": 465, "rom": 465, "loadrom": 465, "reset_gam": 465, "screen_ob": 465, "getscreenrgb": 465, "tick_param": 465, "bottom": 465, "labelleft": 465, "labelbottom": 465, "imshow": [465, 481], "dynamo_export": 465, "onnx_policy_export": 465, "onnx_file_path": 465, "ort_sess": 465, "inferencesess": 465, "cpuexecutionprovid": 465, "onnxruntime_input": 465, "get_input": 465, "onnx_polici": 465, "lightweight": [465, 470], "onnxruntime_output": 465, "topic": [466, 467, 468], "straight": 466, "backtrack": 466, "reset_with_act": 466, "stepped_data": 466, "spatial": 466, "useless": 466, "policyless": 466, "examin": [466, 474], "tackl": 467, "delv": 467, "extractor": 467, "additivegaussianmodul": [467, 474], "exploration_polici": [467, 474], "greedili": 467, "2d": [467, 474, 475], "innov": [467, 468], "rollout_explor": 467, "sole": 468, "supervis": [468, 469, 478, 481], "n_collect": 468, "get_next_batch": 468, "concis": 468, "ddpg_loss": 468, "total_loss": 468, "prove": 468, "reliev": 468, "concern": 468, "accustom": 469, "surprisingli": 469, "art": [469, 474, 475], "countless": 469, "yourself": [469, 474, 475], "everywher": 470, "log_scalar": 470, "my_scalar": 470, "excess": 470, "lesson": 471, "voluntarili": 471, "torchrl_logg": 471, "training_loop": 471, "video_record": 471, "arbitrarili": 471, "t1": 471, "conclud": [471, 477], "tutorials_python": 472, "tutorials_jupyt": 472, "env1_obs_kei": 473, "observation_stand": 473, "env2_obs_kei": 473, "observation_walk": 473, "tdreset1": 473, "tdreset2": 473, "lazy_stack": 473, "policy_common": 473, "policy_stand": 473, "policy_walk": 473, "But": 473, "env1_mak": 473, "env2_mak": 473, "_single_task": 473, "td_rollout": 473, "matteo": [474, 475], "bettini": [474, 475], "benchmarl": [474, 475], "simple_tag": 474, "maddpg": [474, 475], "multiagentparticleenviron": 474, "mpe": 474, "centralis": [474, 475], "tie": [474, 475], "iddpg": [474, 475], "richard": 474, "andrew": 474, "mit": 474, "press": 474, "2018": 474, "mathbf": [474, 475], "decentralis": [474, 475], "literatur": [474, 475], "overcom": [474, 475], "stationari": [474, 475], "establish": 474, "gui": [474, 475], "is_sphinx": 474, "__sphinx_build__": 474, "n_iter": [474, 475, 476], "evad": 474, "iteration_when_stop_training_evad": 474, "memory_s": 474, "n_optimiser_step": 474, "train_batch_s": 474, "polyak_tau": 474, "chaser": 474, "red": 474, "circl": [474, 475], "green": 474, "touch": [474, 476], "penal": [474, 475], "obstacl": 474, "drag": [474, 475], "elast": [474, 475], "collis": [474, 475], "imped": 474, "n_chaser": 474, "n_evad": 474, "n_obstacl": 474, "use_vma": 474, "simple_tag_v3": 474, "num_good": 474, "num_adversari": 474, "num_obstacl": 474, "max_cycl": 474, "num_vmas_env": [474, 475], "num_good_ag": 474, "num_landmark": 474, "four": [474, 475, 476], "n_agents_in_that_group": 474, "stress": [474, 475], "paramount": [474, 475], "n_rollout_step": [474, 475], "evolut": [474, 475], "group_nam": 474, "n_agents_in_group": 474, "minor": 474, "agents_exploration_polici": 474, "utilis": [474, 475], "n_obs_per_ag": [474, 475], "n_actions_per_ag": [474, 475], "share_parameters_polici": [474, 475], "policy_net": [474, 475], "_agent": 474, "grant": [474, 475], "converg": [474, 475], "share_parameters_crit": [474, 475], "obs_act": 474, "cat_modul": 474, "critic_modul": 474, "fantast": [474, 475], "reset_td": 474, "interfer": 474, "subject": [474, 476], "flatten_kei": 474, "process_batch": 474, "group_shap": 474, "get_item_shap": [474, 475], "nested_done_kei": 474, "nested_terminated_kei": 474, "desc": [474, 475], "episode_reward_mean_": 474, "episode_reward_mean_map": 474, "train_group_map": 474, "group_batch": 474, "_group": 474, "loss_nam": 474, "episode_reward_mean": [474, 475], "fig": [474, 478], "set_ylabel": 474, "axvlin": 474, "orang": 474, "set_xlabel": 474, "video_logg": 474, "vmas_log": 474, "env_with_rend": 474, "vmas_rend": 474, "print_log_dir": 474, "profici": [474, 475], "lidar": 475, "sensor": 475, "mappo": 475, "ippo": 475, "analys": 475, "visualis": 475, "vmas_devic": 475, "6_000": 475, "minibatch_s": 475, "generalis": 475, "simd": 475, "warp": 475, "todai": 475, "surround": 475, "dot": [475, 476], "scenario_nam": 475, "critic_net": 475, "minibatch": 475, "episode_reward_mean_list": 475, "critic_network_param": 475, "target_critic_network_param": 475, "xvfb": 475, "pyvirtualdisplai": 475, "1400": 475, "900": 475, "pil": 475, "rendering_callback": 475, "fromarrai": 475, "gif": 475, "save_al": 475, "append_imag": 475, "freeli": 476, "broader": 476, "wider": 476, "acquaint": 476, "avenu": 476, "_apply_to_composit": 476, "default_x": 476, "default_i": 476, "upward": 476, "angular": 476, "sin": 476, "rad": 476, "angl": 476, "deleg": 476, "new_th": 476, "new_thdot": 476, "g_forc": 476, "angle_norm": 476, "albeit": 476, "high_th": 476, "high_thdot": 476, "low_th": 476, "low_thdot": 476, "trivial": 476, "irrelev": 476, "_make_spec": 476, "td_param": 476, "render_fp": 476, "random_": 476, "_make_step": 476, "staticmethod": 476, "skeleton": 476, "unitari": 476, "sine": 476, "cosin": 476, "sintransform": 476, "costransform": 476, "t_sin": 476, "t_co": 476, "cat_transform": 476, "simple_rollout": 476, "unexplor": 476, "init_td": 476, "traj_return": 476, "last_reward": 476, "is_ipython": 476, "inlin": 476, "get_backend": 476, "ion": 476, "gcf": 476, "clear_output": 476, "r3mtransform": 477, "embodi": 477, "env_transform": [477, 481], "wiser": 477, "batteri": 478, "gc": 478, "buffer_list": 478, "lowest": 478, "medium": 478, "buffer_lazytensor": 478, "tempdir": 478, "buffer_lazymemmap": 478, "fullest": 478, "mydata": 478, "buffer_lazi": 478, "_i": 478, "artifici": 478, "hamper": 478, "she": 478, "proport": 478, "reappear": 478, "unfold": 478, "problemat": 478, "4th": 478, "prioritizedslicesampl": 478, "tensordictmaxvaluewrit": 478, "demo": 480, "icml": 480, "vmoen": 480, "fb": 480, "invest": 480, "media": 480, "predominantli": 480, "data2": 480, "sub_key1": 480, "scturctur": 480, "data_stack": 480, "data_sampl": 480, "_sampler": 480, "_sum_tre": 480, "modulenotfounderror": 480, "noopresetenv": [480, 481], "backbone_modul": 480, "params_expand": 480, "exec_sequ": 480, "tensordict_exp": 480, "base_modul": 480, "tensordicts_prealloc": 480, "tensordicts_stack": 480, "tensordict_rollout": [480, 481], "automatical": 480, "60": 480, "particularili": 480, "concatmodul": 480, "loss_td": 480, "contributor": 480, "curiou": 480, "nascent": 480, "unsupervis": 481, "_build_env": 481, "deserv": 481, "__episode__": 481, "__trajectory__": 481, "void": 481, "reproduct": 481, "tensordict_tprim": 481, "wrapper1": 481, "wrapper2": 481, "obviou": 481, "truth": 481, "env_transformed_bi": 481, "stanc": 481, "transformeddistribut": 481, "base_dist": 481, "concat": 481, "mofidi": 481, "transformedenviron": 481, "moderet": 481, "computation": 481, "incom": 481, "amongst": 481, "has_cuda": 481, "convention": 481, "markovian": 481, "bar_": 481, "get_someth": 481, "aargh": 481, "is_clos": 481, "foo_list": 481, "121": 481, "evolv": 481, "steadi": 481, "approx": 481, "absor": 481, "_extra_st": 481}, "objects": {"torchrl": [[12, 0, 1, "", "auto_unwrap_transformed_env"], [273, 0, 1, "", "implement_for"], [427, 0, 1, "", "set_auto_unwrap_transformed_env"]], "torchrl.collectors": [[13, 0, 1, "", "DataCollectorBase"], [14, 0, 1, "", "MultiProcessedWeightUpdater"], [15, 0, 1, "", "MultiSyncDataCollector"], [16, 0, 1, "", "MultiaSyncDataCollector"], [17, 0, 1, "", "RayWeightUpdater"], [18, 0, 1, "", "SyncDataCollector"], [19, 0, 1, "", "VanillaWeightUpdater"], [20, 0, 1, "", "WeightUpdaterBase"], [21, 0, 1, "", "aSyncDataCollector"]], "torchrl.collectors.DataCollectorBase": [[13, 1, 1, "", "async_shutdown"], [13, 1, 1, "", "pause"], [13, 1, 1, "", "start"], [13, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.MultiProcessedWeightUpdater": [[14, 1, 1, "", "all_worker_ids"], [14, 2, 1, "", "collector"], [14, 1, 1, "", "push_weights"], [14, 1, 1, "", "register_collector"]], "torchrl.collectors.MultiSyncDataCollector": [[15, 1, 1, "", "async_shutdown"], [15, 1, 1, "", "load_state_dict"], [15, 1, 1, "", "pause"], [15, 1, 1, "", "reset"], [15, 1, 1, "", "set_seed"], [15, 1, 1, "", "shutdown"], [15, 1, 1, "", "start"], [15, 1, 1, "", "state_dict"], [15, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.MultiaSyncDataCollector": [[16, 1, 1, "", "async_shutdown"], [16, 1, 1, "", "load_state_dict"], [16, 1, 1, "", "pause"], [16, 1, 1, "", "reset"], [16, 1, 1, "", "set_seed"], [16, 1, 1, "", "shutdown"], [16, 1, 1, "", "start"], [16, 1, 1, "", "state_dict"], [16, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.RayWeightUpdater": [[17, 1, 1, "", "_get_server_weights"], [17, 1, 1, "", "_maybe_map_weights"], [17, 1, 1, "", "_skip_update"], [17, 1, 1, "", "_sync_weights_with_worker"], [17, 1, 1, "id0", "all_worker_ids"], [17, 2, 1, "", "collector"], [17, 1, 1, "", "push_weights"], [17, 1, 1, "", "register_collector"]], "torchrl.collectors.SyncDataCollector": [[18, 1, 1, "", "async_shutdown"], [18, 1, 1, "", "iterator"], [18, 1, 1, "", "load_state_dict"], [18, 1, 1, "", "pause"], [18, 1, 1, "", "reset"], [18, 1, 1, "", "rollout"], [18, 1, 1, "", "set_seed"], [18, 1, 1, "", "shutdown"], [18, 1, 1, "", "start"], [18, 1, 1, "", "state_dict"], [18, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.VanillaWeightUpdater": [[19, 1, 1, "", "all_worker_ids"], [19, 2, 1, "", "collector"], [19, 1, 1, "", "push_weights"], [19, 1, 1, "", "register_collector"]], "torchrl.collectors.WeightUpdaterBase": [[20, 1, 1, "", "all_worker_ids"], [20, 2, 1, "", "collector"], [20, 1, 1, "id0", "push_weights"], [20, 1, 1, "id1", "register_collector"]], "torchrl.collectors.aSyncDataCollector": [[21, 1, 1, "", "async_shutdown"], [21, 1, 1, "", "load_state_dict"], [21, 1, 1, "", "pause"], [21, 1, 1, "", "reset"], [21, 1, 1, "", "set_seed"], [21, 1, 1, "", "shutdown"], [21, 1, 1, "", "start"], [21, 1, 1, "", "state_dict"], [21, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed": [[22, 0, 1, "", "DistributedDataCollector"], [23, 0, 1, "", "DistributedSyncDataCollector"], [24, 0, 1, "", "DistributedWeightUpdater"], [25, 0, 1, "", "RPCDataCollector"], [26, 0, 1, "", "RPCWeightUpdater"], [27, 0, 1, "", "RayCollector"], [28, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedDataCollector": [[22, 1, 1, "", "async_shutdown"], [22, 1, 1, "", "pause"], [22, 1, 1, "", "start"], [22, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[23, 1, 1, "", "async_shutdown"], [23, 1, 1, "", "pause"], [23, 1, 1, "", "start"], [23, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedWeightUpdater": [[24, 1, 1, "", "_get_server_weights"], [24, 1, 1, "", "_maybe_map_weights"], [24, 1, 1, "", "_sync_weights_with_worker"], [24, 1, 1, "id0", "all_worker_ids"], [24, 2, 1, "", "collector"], [24, 1, 1, "", "push_weights"], [24, 1, 1, "", "register_collector"], [24, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RPCDataCollector": [[25, 1, 1, "", "async_shutdown"], [25, 1, 1, "", "pause"], [25, 1, 1, "", "start"], [25, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RPCWeightUpdater": [[26, 1, 1, "", "_get_server_weights"], [26, 1, 1, "", "_maybe_map_weights"], [26, 1, 1, "", "_sync_weights_with_worker"], [26, 1, 1, "id0", "all_worker_ids"], [26, 2, 1, "", "collector"], [26, 1, 1, "", "push_weights"], [26, 1, 1, "", "register_collector"], [26, 1, 1, "", "update_weights"]], "torchrl.collectors.distributed.RayCollector": [[27, 1, 1, "", "add_collectors"], [27, 1, 1, "", "async_shutdown"], [27, 1, 1, "", "load_state_dict"], [27, 1, 1, "", "local_policy"], [27, 1, 1, "", "pause"], [27, 2, 1, "", "remote_collectors"], [27, 1, 1, "", "set_seed"], [27, 1, 1, "", "shutdown"], [27, 1, 1, "", "start"], [27, 1, 1, "", "state_dict"], [27, 1, 1, "", "stop_remote_collectors"], [27, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.llm": [[29, 0, 1, "", "LLMCollector"], [30, 0, 1, "", "vLLMUpdater"]], "torchrl.collectors.llm.LLMCollector": [[29, 1, 1, "", "async_shutdown"], [29, 2, 1, "", "dialog_turns_per_batch"], [29, 1, 1, "", "iterator"], [29, 1, 1, "", "load_state_dict"], [29, 1, 1, "", "pause"], [29, 1, 1, "", "reset"], [29, 2, 1, "", "rollout"], [29, 1, 1, "", "set_seed"], [29, 1, 1, "", "shutdown"], [29, 1, 1, "", "start"], [29, 1, 1, "", "state_dict"], [29, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.llm.vLLMUpdater": [[30, 1, 1, "", "all_worker_ids"], [30, 2, 1, "", "collector"], [30, 1, 1, "", "push_weights"], [30, 1, 1, "", "register_collector"]], "torchrl.collectors.utils": [[31, 3, 1, "", "split_trajectories"]], "torchrl.data": [[32, 0, 1, "", "AdaptiveKLController"], [33, 0, 1, "", "Binary"], [34, 0, 1, "", "BinaryDiscreteTensorSpec"], [35, 0, 1, "", "BinaryToDecimal"], [36, 0, 1, "", "Bounded"], [37, 0, 1, "", "BoundedTensorSpec"], [38, 0, 1, "", "Categorical"], [39, 0, 1, "", "Composite"], [40, 0, 1, "", "CompositeSpec"], [41, 0, 1, "", "ConstantKLController"], [42, 0, 1, "", "DensifyReward"], [43, 0, 1, "", "DiscreteTensorSpec"], [44, 0, 1, "", "Flat2TED"], [45, 0, 1, "", "H5Combine"], [46, 0, 1, "", "H5Split"], [47, 0, 1, "", "HashToInt"], [48, 0, 1, "", "LazyStackedCompositeSpec"], [49, 0, 1, "", "LazyStackedTensorSpec"], [50, 0, 1, "", "MCTSForest"], [51, 0, 1, "", "MultiCategorical"], [52, 0, 1, "", "MultiDiscreteTensorSpec"], [53, 0, 1, "", "MultiOneHot"], [54, 0, 1, "", "MultiOneHotDiscreteTensorSpec"], [55, 0, 1, "", "MultiStep"], [56, 0, 1, "", "Nested2TED"], [57, 0, 1, "", "NonTensor"], [58, 0, 1, "", "NonTensorSpec"], [59, 0, 1, "", "OneHot"], [60, 0, 1, "", "OneHotDiscreteTensorSpec"], [61, 0, 1, "", "PairwiseDataset"], [62, 0, 1, "", "PrioritizedReplayBuffer"], [63, 0, 1, "", "PromptData"], [64, 0, 1, "", "PromptTensorDictTokenizer"], [65, 0, 1, "", "QueryModule"], [66, 0, 1, "", "RandomProjectionHash"], [67, 0, 1, "", "RayReplayBuffer"], [68, 0, 1, "", "RemoteTensorDictReplayBuffer"], [69, 0, 1, "", "ReplayBuffer"], [70, 0, 1, "", "RewardData"], [71, 0, 1, "", "RolloutFromModel"], [72, 0, 1, "", "SipHash"], [73, 0, 1, "", "Stacked"], [74, 0, 1, "", "StackedComposite"], [75, 0, 1, "", "TED2Flat"], [76, 0, 1, "", "TED2Nested"], [77, 0, 1, "", "TensorDictMap"], [78, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [79, 0, 1, "", "TensorDictReplayBuffer"], [80, 0, 1, "", "TensorDictTokenizer"], [81, 0, 1, "", "TensorMap"], [82, 0, 1, "", "TensorSpec"], [83, 0, 1, "", "TokenizedDatasetLoader"], [84, 0, 1, "", "Tree"], [85, 0, 1, "", "Unbounded"], [86, 0, 1, "", "UnboundedContinuous"], [87, 0, 1, "", "UnboundedContinuousTensorSpec"], [88, 0, 1, "", "UnboundedDiscrete"], [89, 0, 1, "", "UnboundedDiscreteTensorSpec"], [90, 0, 1, "", "check_no_exclusive_keys"], [91, 0, 1, "", "consolidate_spec"], [92, 0, 1, "", "contains_lazy_spec"], [93, 0, 1, "", "create_infinite_iterator"], [94, 0, 1, "", "get_dataloader"]], "torchrl.data.AdaptiveKLController": [[32, 1, 1, "", "update"]], "torchrl.data.Binary": [[33, 1, 1, "", "assert_is_in"], [33, 1, 1, "", "cardinality"], [33, 1, 1, "", "clear_device_"], [33, 1, 1, "", "clone"], [33, 1, 1, "", "contains"], [33, 1, 1, "", "cpu"], [33, 1, 1, "", "cuda"], [33, 4, 1, "", "device"], [33, 1, 1, "", "encode"], [33, 1, 1, "", "enumerate"], [33, 1, 1, "", "erase_memoize_cache"], [33, 1, 1, "", "expand"], [33, 1, 1, "", "flatten"], [33, 1, 1, "", "implements_for_spec"], [33, 1, 1, "", "index"], [33, 1, 1, "", "is_in"], [33, 1, 1, "", "make_neg_dim"], [33, 1, 1, "", "memoize_encode"], [33, 2, 1, "", "ndim"], [33, 1, 1, "", "ndimension"], [33, 1, 1, "", "one"], [33, 1, 1, "", "ones"], [33, 1, 1, "", "project"], [33, 1, 1, "", "rand"], [33, 1, 1, "", "reshape"], [33, 1, 1, "", "sample"], [33, 1, 1, "", "set_provisional_n"], [33, 1, 1, "", "squeeze"], [33, 1, 1, "", "to"], [33, 1, 1, "", "to_categorical"], [33, 1, 1, "", "to_categorical_spec"], [33, 1, 1, "", "to_numpy"], [33, 1, 1, "", "to_one_hot"], [33, 1, 1, "", "to_one_hot_spec"], [33, 1, 1, "", "type_check"], [33, 1, 1, "", "unflatten"], [33, 1, 1, "", "unsqueeze"], [33, 1, 1, "", "update_mask"], [33, 1, 1, "", "view"], [33, 1, 1, "", "zero"], [33, 1, 1, "", "zeros"]], "torchrl.data.BinaryDiscreteTensorSpec": [[34, 1, 1, "", "assert_is_in"], [34, 1, 1, "", "cardinality"], [34, 1, 1, "", "clear_device_"], [34, 1, 1, "", "clone"], [34, 1, 1, "", "contains"], [34, 1, 1, "", "cpu"], [34, 1, 1, "", "cuda"], [34, 4, 1, "", "device"], [34, 1, 1, "", "encode"], [34, 1, 1, "", "enumerate"], [34, 1, 1, "", "erase_memoize_cache"], [34, 1, 1, "", "expand"], [34, 1, 1, "", "flatten"], [34, 1, 1, "", "implements_for_spec"], [34, 1, 1, "", "index"], [34, 1, 1, "", "is_in"], [34, 1, 1, "", "make_neg_dim"], [34, 1, 1, "", "memoize_encode"], [34, 2, 1, "", "ndim"], [34, 1, 1, "", "ndimension"], [34, 1, 1, "", "one"], [34, 1, 1, "", "ones"], [34, 1, 1, "", "project"], [34, 1, 1, "", "rand"], [34, 1, 1, "", "reshape"], [34, 1, 1, "", "sample"], [34, 1, 1, "", "set_provisional_n"], [34, 1, 1, "", "squeeze"], [34, 1, 1, "", "to"], [34, 1, 1, "", "to_categorical"], [34, 1, 1, "", "to_categorical_spec"], [34, 1, 1, "", "to_numpy"], [34, 1, 1, "", "to_one_hot"], [34, 1, 1, "", "to_one_hot_spec"], [34, 1, 1, "", "type_check"], [34, 1, 1, "", "unflatten"], [34, 1, 1, "", "unsqueeze"], [34, 1, 1, "", "update_mask"], [34, 1, 1, "", "view"], [34, 1, 1, "", "zero"], [34, 1, 1, "", "zeros"]], "torchrl.data.BinaryToDecimal": [[35, 1, 1, "", "add_module"], [35, 1, 1, "", "apply"], [35, 1, 1, "", "bfloat16"], [35, 1, 1, "", "buffers"], [35, 1, 1, "", "children"], [35, 1, 1, "", "compile"], [35, 1, 1, "", "cpu"], [35, 1, 1, "", "cuda"], [35, 1, 1, "", "double"], [35, 1, 1, "", "eval"], [35, 1, 1, "", "extra_repr"], [35, 1, 1, "", "float"], [35, 1, 1, "", "forward"], [35, 1, 1, "", "get_buffer"], [35, 1, 1, "", "get_extra_state"], [35, 1, 1, "", "get_parameter"], [35, 1, 1, "", "get_submodule"], [35, 1, 1, "", "half"], [35, 1, 1, "", "ipu"], [35, 1, 1, "", "load_state_dict"], [35, 1, 1, "", "modules"], [35, 1, 1, "", "mtia"], [35, 1, 1, "", "named_buffers"], [35, 1, 1, "", "named_children"], [35, 1, 1, "", "named_modules"], [35, 1, 1, "", "named_parameters"], [35, 1, 1, "", "parameters"], [35, 1, 1, "", "register_backward_hook"], [35, 1, 1, "", "register_buffer"], [35, 1, 1, "", "register_forward_hook"], [35, 1, 1, "", "register_forward_pre_hook"], [35, 1, 1, "", "register_full_backward_hook"], [35, 1, 1, "", "register_full_backward_pre_hook"], [35, 1, 1, "", "register_load_state_dict_post_hook"], [35, 1, 1, "", "register_load_state_dict_pre_hook"], [35, 1, 1, "", "register_module"], [35, 1, 1, "", "register_parameter"], [35, 1, 1, "", "register_state_dict_post_hook"], [35, 1, 1, "", "register_state_dict_pre_hook"], [35, 1, 1, "", "requires_grad_"], [35, 1, 1, "", "set_extra_state"], [35, 1, 1, "", "set_submodule"], [35, 1, 1, "", "share_memory"], [35, 1, 1, "", "state_dict"], [35, 1, 1, "", "to"], [35, 1, 1, "", "to_empty"], [35, 1, 1, "", "train"], [35, 1, 1, "", "type"], [35, 1, 1, "", "xpu"], [35, 1, 1, "", "zero_grad"]], "torchrl.data.Bounded": [[36, 1, 1, "", "assert_is_in"], [36, 1, 1, "", "cardinality"], [36, 1, 1, "", "clear_device_"], [36, 1, 1, "", "clone"], [36, 1, 1, "", "contains"], [36, 1, 1, "", "cpu"], [36, 1, 1, "", "cuda"], [36, 2, 1, "", "device"], [36, 1, 1, "", "encode"], [36, 1, 1, "", "enumerate"], [36, 1, 1, "", "erase_memoize_cache"], [36, 1, 1, "", "expand"], [36, 1, 1, "", "flatten"], [36, 1, 1, "", "implements_for_spec"], [36, 1, 1, "", "index"], [36, 1, 1, "", "is_in"], [36, 1, 1, "", "make_neg_dim"], [36, 1, 1, "", "memoize_encode"], [36, 2, 1, "", "ndim"], [36, 1, 1, "", "ndimension"], [36, 1, 1, "", "one"], [36, 1, 1, "", "ones"], [36, 1, 1, "", "project"], [36, 1, 1, "", "rand"], [36, 1, 1, "", "reshape"], [36, 1, 1, "", "sample"], [36, 1, 1, "", "squeeze"], [36, 1, 1, "", "to"], [36, 1, 1, "", "to_numpy"], [36, 1, 1, "", "type_check"], [36, 1, 1, "", "unflatten"], [36, 1, 1, "", "unsqueeze"], [36, 1, 1, "", "view"], [36, 1, 1, "", "zero"], [36, 1, 1, "", "zeros"]], "torchrl.data.BoundedTensorSpec": [[37, 1, 1, "", "assert_is_in"], [37, 1, 1, "", "cardinality"], [37, 1, 1, "", "clear_device_"], [37, 1, 1, "", "clone"], [37, 1, 1, "", "contains"], [37, 1, 1, "", "cpu"], [37, 1, 1, "", "cuda"], [37, 2, 1, "", "device"], [37, 1, 1, "", "encode"], [37, 1, 1, "", "enumerate"], [37, 1, 1, "", "erase_memoize_cache"], [37, 1, 1, "", "expand"], [37, 1, 1, "", "flatten"], [37, 1, 1, "", "implements_for_spec"], [37, 1, 1, "", "index"], [37, 1, 1, "", "is_in"], [37, 1, 1, "", "make_neg_dim"], [37, 1, 1, "", "memoize_encode"], [37, 2, 1, "", "ndim"], [37, 1, 1, "", "ndimension"], [37, 1, 1, "", "one"], [37, 1, 1, "", "ones"], [37, 1, 1, "", "project"], [37, 1, 1, "", "rand"], [37, 1, 1, "", "reshape"], [37, 1, 1, "", "sample"], [37, 1, 1, "", "squeeze"], [37, 1, 1, "", "to"], [37, 1, 1, "", "to_numpy"], [37, 1, 1, "", "type_check"], [37, 1, 1, "", "unflatten"], [37, 1, 1, "", "unsqueeze"], [37, 1, 1, "", "view"], [37, 1, 1, "", "zero"], [37, 1, 1, "", "zeros"]], "torchrl.data.Categorical": [[38, 1, 1, "", "assert_is_in"], [38, 1, 1, "", "cardinality"], [38, 1, 1, "", "clear_device_"], [38, 1, 1, "", "clone"], [38, 1, 1, "", "contains"], [38, 1, 1, "", "cpu"], [38, 1, 1, "", "cuda"], [38, 4, 1, "", "device"], [38, 1, 1, "", "encode"], [38, 1, 1, "", "enumerate"], [38, 1, 1, "", "erase_memoize_cache"], [38, 1, 1, "", "expand"], [38, 1, 1, "", "flatten"], [38, 1, 1, "", "implements_for_spec"], [38, 1, 1, "", "index"], [38, 1, 1, "", "is_in"], [38, 1, 1, "", "make_neg_dim"], [38, 1, 1, "", "memoize_encode"], [38, 2, 1, "", "ndim"], [38, 1, 1, "", "ndimension"], [38, 1, 1, "", "one"], [38, 1, 1, "", "ones"], [38, 1, 1, "", "project"], [38, 1, 1, "", "rand"], [38, 1, 1, "", "reshape"], [38, 1, 1, "", "sample"], [38, 1, 1, "", "set_provisional_n"], [38, 1, 1, "", "squeeze"], [38, 1, 1, "", "to"], [38, 1, 1, "", "to_categorical"], [38, 1, 1, "", "to_categorical_spec"], [38, 1, 1, "", "to_numpy"], [38, 1, 1, "", "to_one_hot"], [38, 1, 1, "", "to_one_hot_spec"], [38, 1, 1, "", "type_check"], [38, 1, 1, "", "unflatten"], [38, 1, 1, "", "unsqueeze"], [38, 1, 1, "", "update_mask"], [38, 1, 1, "", "view"], [38, 1, 1, "", "zero"], [38, 1, 1, "", "zeros"]], "torchrl.data.Composite": [[39, 1, 1, "", "assert_is_in"], [39, 1, 1, "", "cardinality"], [39, 1, 1, "", "clear_device_"], [39, 1, 1, "", "clone"], [39, 1, 1, "", "contains"], [39, 1, 1, "", "cpu"], [39, 1, 1, "", "cuda"], [39, 2, 1, "", "device"], [39, 1, 1, "", "empty"], [39, 1, 1, "", "encode"], [39, 1, 1, "", "enumerate"], [39, 1, 1, "", "erase_memoize_cache"], [39, 1, 1, "", "expand"], [39, 1, 1, "", "flatten"], [39, 1, 1, "", "get"], [39, 1, 1, "", "implements_for_spec"], [39, 1, 1, "", "index"], [39, 1, 1, "", "is_empty"], [39, 1, 1, "", "is_in"], [39, 1, 1, "", "items"], [39, 1, 1, "", "keys"], [39, 1, 1, "", "lock_"], [39, 1, 1, "", "make_neg_dim"], [39, 1, 1, "", "memoize_encode"], [39, 2, 1, "", "ndim"], [39, 1, 1, "", "ndimension"], [39, 1, 1, "", "one"], [39, 1, 1, "", "ones"], [39, 1, 1, "", "pop"], [39, 1, 1, "", "project"], [39, 1, 1, "", "rand"], [39, 1, 1, "", "reshape"], [39, 1, 1, "", "sample"], [39, 1, 1, "", "separates"], [39, 1, 1, "", "set"], [39, 1, 1, "", "squeeze"], [39, 1, 1, "", "to"], [39, 1, 1, "", "to_numpy"], [39, 1, 1, "", "type_check"], [39, 1, 1, "", "unflatten"], [39, 1, 1, "", "unlock_"], [39, 1, 1, "", "unsqueeze"], [39, 1, 1, "", "values"], [39, 1, 1, "", "view"], [39, 1, 1, "", "zero"], [39, 1, 1, "", "zeros"]], "torchrl.data.CompositeSpec": [[40, 1, 1, "", "assert_is_in"], [40, 1, 1, "", "cardinality"], [40, 1, 1, "", "clear_device_"], [40, 1, 1, "", "clone"], [40, 1, 1, "", "contains"], [40, 1, 1, "", "cpu"], [40, 1, 1, "", "cuda"], [40, 2, 1, "", "device"], [40, 1, 1, "", "empty"], [40, 1, 1, "", "encode"], [40, 1, 1, "", "enumerate"], [40, 1, 1, "", "erase_memoize_cache"], [40, 1, 1, "", "expand"], [40, 1, 1, "", "flatten"], [40, 1, 1, "", "get"], [40, 1, 1, "", "implements_for_spec"], [40, 1, 1, "", "index"], [40, 1, 1, "", "is_empty"], [40, 1, 1, "", "is_in"], [40, 1, 1, "", "items"], [40, 1, 1, "", "keys"], [40, 1, 1, "", "lock_"], [40, 1, 1, "", "make_neg_dim"], [40, 1, 1, "", "memoize_encode"], [40, 2, 1, "", "ndim"], [40, 1, 1, "", "ndimension"], [40, 1, 1, "", "one"], [40, 1, 1, "", "ones"], [40, 1, 1, "", "pop"], [40, 1, 1, "", "project"], [40, 1, 1, "", "rand"], [40, 1, 1, "", "reshape"], [40, 1, 1, "", "sample"], [40, 1, 1, "", "separates"], [40, 1, 1, "", "set"], [40, 1, 1, "", "squeeze"], [40, 1, 1, "", "to"], [40, 1, 1, "", "to_numpy"], [40, 1, 1, "", "type_check"], [40, 1, 1, "", "unflatten"], [40, 1, 1, "", "unlock_"], [40, 1, 1, "", "unsqueeze"], [40, 1, 1, "", "values"], [40, 1, 1, "", "view"], [40, 1, 1, "", "zero"], [40, 1, 1, "", "zeros"]], "torchrl.data.DensifyReward": [[42, 1, 1, "", "add_module"], [42, 1, 1, "", "apply"], [42, 1, 1, "", "bfloat16"], [42, 1, 1, "", "buffers"], [42, 1, 1, "", "children"], [42, 1, 1, "", "compile"], [42, 1, 1, "", "cpu"], [42, 1, 1, "", "cuda"], [42, 1, 1, "", "double"], [42, 1, 1, "", "eval"], [42, 1, 1, "", "extra_repr"], [42, 1, 1, "", "float"], [42, 1, 1, "", "forward"], [42, 1, 1, "", "get_buffer"], [42, 1, 1, "", "get_extra_state"], [42, 1, 1, "", "get_parameter"], [42, 1, 1, "", "get_submodule"], [42, 1, 1, "", "half"], [42, 1, 1, "", "ipu"], [42, 1, 1, "", "is_tdmodule_compatible"], [42, 1, 1, "", "load_state_dict"], [42, 1, 1, "", "modules"], [42, 1, 1, "", "mtia"], [42, 1, 1, "", "named_buffers"], [42, 1, 1, "", "named_children"], [42, 1, 1, "", "named_modules"], [42, 1, 1, "", "named_parameters"], [42, 1, 1, "", "parameters"], [42, 1, 1, "", "register_backward_hook"], [42, 1, 1, "", "register_buffer"], [42, 1, 1, "", "register_forward_hook"], [42, 1, 1, "", "register_forward_pre_hook"], [42, 1, 1, "", "register_full_backward_hook"], [42, 1, 1, "", "register_full_backward_pre_hook"], [42, 1, 1, "", "register_load_state_dict_post_hook"], [42, 1, 1, "", "register_load_state_dict_pre_hook"], [42, 1, 1, "", "register_module"], [42, 1, 1, "", "register_parameter"], [42, 1, 1, "", "register_state_dict_post_hook"], [42, 1, 1, "", "register_state_dict_pre_hook"], [42, 1, 1, "", "requires_grad_"], [42, 1, 1, "", "reset_out_keys"], [42, 1, 1, "", "reset_parameters_recursive"], [42, 1, 1, "", "select_out_keys"], [42, 1, 1, "", "set_extra_state"], [42, 1, 1, "", "set_submodule"], [42, 1, 1, "", "share_memory"], [42, 1, 1, "", "state_dict"], [42, 1, 1, "", "to"], [42, 1, 1, "", "to_empty"], [42, 1, 1, "", "train"], [42, 1, 1, "", "type"], [42, 1, 1, "", "xpu"], [42, 1, 1, "", "zero_grad"]], "torchrl.data.DiscreteTensorSpec": [[43, 1, 1, "", "assert_is_in"], [43, 1, 1, "", "cardinality"], [43, 1, 1, "", "clear_device_"], [43, 1, 1, "", "clone"], [43, 1, 1, "", "contains"], [43, 1, 1, "", "cpu"], [43, 1, 1, "", "cuda"], [43, 4, 1, "", "device"], [43, 1, 1, "", "encode"], [43, 1, 1, "", "enumerate"], [43, 1, 1, "", "erase_memoize_cache"], [43, 1, 1, "", "expand"], [43, 1, 1, "", "flatten"], [43, 1, 1, "", "implements_for_spec"], [43, 1, 1, "", "index"], [43, 1, 1, "", "is_in"], [43, 1, 1, "", "make_neg_dim"], [43, 1, 1, "", "memoize_encode"], [43, 2, 1, "", "ndim"], [43, 1, 1, "", "ndimension"], [43, 1, 1, "", "one"], [43, 1, 1, "", "ones"], [43, 1, 1, "", "project"], [43, 1, 1, "", "rand"], [43, 1, 1, "", "reshape"], [43, 1, 1, "", "sample"], [43, 1, 1, "", "set_provisional_n"], [43, 1, 1, "", "squeeze"], [43, 1, 1, "", "to"], [43, 1, 1, "", "to_categorical"], [43, 1, 1, "", "to_categorical_spec"], [43, 1, 1, "", "to_numpy"], [43, 1, 1, "", "to_one_hot"], [43, 1, 1, "", "to_one_hot_spec"], [43, 1, 1, "", "type_check"], [43, 1, 1, "", "unflatten"], [43, 1, 1, "", "unsqueeze"], [43, 1, 1, "", "update_mask"], [43, 1, 1, "", "view"], [43, 1, 1, "", "zero"], [43, 1, 1, "", "zeros"]], "torchrl.data.HashToInt": [[47, 1, 1, "", "add_module"], [47, 1, 1, "", "apply"], [47, 1, 1, "", "bfloat16"], [47, 1, 1, "", "buffers"], [47, 1, 1, "", "children"], [47, 1, 1, "", "compile"], [47, 1, 1, "", "cpu"], [47, 1, 1, "", "cuda"], [47, 1, 1, "", "double"], [47, 1, 1, "", "eval"], [47, 1, 1, "", "extra_repr"], [47, 1, 1, "", "float"], [47, 1, 1, "", "forward"], [47, 1, 1, "", "get_buffer"], [47, 1, 1, "", "get_extra_state"], [47, 1, 1, "", "get_parameter"], [47, 1, 1, "", "get_submodule"], [47, 1, 1, "", "half"], [47, 1, 1, "", "ipu"], [47, 1, 1, "", "load_state_dict"], [47, 1, 1, "", "modules"], [47, 1, 1, "", "mtia"], [47, 1, 1, "", "named_buffers"], [47, 1, 1, "", "named_children"], [47, 1, 1, "", "named_modules"], [47, 1, 1, "", "named_parameters"], [47, 1, 1, "", "parameters"], [47, 1, 1, "", "register_backward_hook"], [47, 1, 1, "", "register_buffer"], [47, 1, 1, "", "register_forward_hook"], [47, 1, 1, "", "register_forward_pre_hook"], [47, 1, 1, "", "register_full_backward_hook"], [47, 1, 1, "", "register_full_backward_pre_hook"], [47, 1, 1, "", "register_load_state_dict_post_hook"], [47, 1, 1, "", "register_load_state_dict_pre_hook"], [47, 1, 1, "", "register_module"], [47, 1, 1, "", "register_parameter"], [47, 1, 1, "", "register_state_dict_post_hook"], [47, 1, 1, "", "register_state_dict_pre_hook"], [47, 1, 1, "", "requires_grad_"], [47, 1, 1, "", "set_extra_state"], [47, 1, 1, "", "set_submodule"], [47, 1, 1, "", "share_memory"], [47, 1, 1, "", "state_dict"], [47, 1, 1, "", "to"], [47, 1, 1, "", "to_empty"], [47, 1, 1, "", "train"], [47, 1, 1, "", "type"], [47, 1, 1, "", "xpu"], [47, 1, 1, "", "zero_grad"]], "torchrl.data.LazyStackedCompositeSpec": [[48, 1, 1, "", "assert_is_in"], [48, 1, 1, "", "cardinality"], [48, 1, 1, "", "clear_device_"], [48, 1, 1, "", "clone"], [48, 1, 1, "", "contains"], [48, 1, 1, "", "cpu"], [48, 1, 1, "", "cuda"], [48, 2, 1, "", "device"], [48, 1, 1, "", "empty"], [48, 1, 1, "", "encode"], [48, 1, 1, "", "enumerate"], [48, 1, 1, "", "erase_memoize_cache"], [48, 1, 1, "", "expand"], [48, 1, 1, "", "flatten"], [48, 1, 1, "", "get"], [48, 1, 1, "", "implements_for_spec"], [48, 1, 1, "", "index"], [48, 1, 1, "", "is_empty"], [48, 1, 1, "", "is_in"], [48, 1, 1, "", "items"], [48, 1, 1, "", "keys"], [48, 1, 1, "", "lock_"], [48, 1, 1, "", "make_neg_dim"], [48, 1, 1, "", "memoize_encode"], [48, 2, 1, "", "ndim"], [48, 1, 1, "", "ndimension"], [48, 1, 1, "", "one"], [48, 1, 1, "", "ones"], [48, 1, 1, "", "pop"], [48, 1, 1, "", "project"], [48, 1, 1, "", "rand"], [48, 1, 1, "", "reshape"], [48, 1, 1, "", "sample"], [48, 1, 1, "", "separates"], [48, 1, 1, "", "set"], [48, 1, 1, "", "squeeze"], [48, 1, 1, "", "to"], [48, 1, 1, "", "to_numpy"], [48, 1, 1, "", "type_check"], [48, 1, 1, "", "unflatten"], [48, 1, 1, "", "unlock_"], [48, 1, 1, "", "unsqueeze"], [48, 1, 1, "", "values"], [48, 1, 1, "", "view"], [48, 1, 1, "", "zero"], [48, 1, 1, "", "zeros"]], "torchrl.data.LazyStackedTensorSpec": [[49, 1, 1, "", "assert_is_in"], [49, 1, 1, "", "cardinality"], [49, 1, 1, "", "clear_device_"], [49, 1, 1, "", "clone"], [49, 1, 1, "", "contains"], [49, 1, 1, "", "cpu"], [49, 1, 1, "", "cuda"], [49, 2, 1, "", "device"], [49, 1, 1, "", "encode"], [49, 1, 1, "", "enumerate"], [49, 1, 1, "", "erase_memoize_cache"], [49, 1, 1, "", "expand"], [49, 1, 1, "", "flatten"], [49, 1, 1, "", "implements_for_spec"], [49, 1, 1, "", "index"], [49, 1, 1, "", "is_in"], [49, 1, 1, "", "make_neg_dim"], [49, 1, 1, "", "memoize_encode"], [49, 2, 1, "", "ndim"], [49, 1, 1, "", "ndimension"], [49, 1, 1, "", "one"], [49, 1, 1, "", "ones"], [49, 1, 1, "", "project"], [49, 1, 1, "", "rand"], [49, 1, 1, "", "reshape"], [49, 1, 1, "", "sample"], [49, 1, 1, "", "squeeze"], [49, 1, 1, "", "to"], [49, 1, 1, "", "to_numpy"], [49, 1, 1, "", "type_check"], [49, 1, 1, "", "unflatten"], [49, 1, 1, "", "unsqueeze"], [49, 1, 1, "", "view"], [49, 1, 1, "", "zero"], [49, 1, 1, "", "zeros"]], "torchrl.data.MCTSForest": [[50, 2, 1, "", "action_keys"], [50, 2, 1, "", "done_keys"], [50, 1, 1, "", "extend"], [50, 1, 1, "", "get_keys_from_env"], [50, 2, 1, "", "observation_keys"], [50, 2, 1, "", "reward_keys"], [50, 1, 1, "", "to_string"]], "torchrl.data.MultiCategorical": [[51, 1, 1, "", "assert_is_in"], [51, 1, 1, "", "cardinality"], [51, 1, 1, "", "clear_device_"], [51, 1, 1, "", "clone"], [51, 1, 1, "", "contains"], [51, 1, 1, "", "cpu"], [51, 1, 1, "", "cuda"], [51, 4, 1, "", "device"], [51, 1, 1, "", "encode"], [51, 1, 1, "", "enumerate"], [51, 1, 1, "", "erase_memoize_cache"], [51, 1, 1, "", "expand"], [51, 1, 1, "", "flatten"], [51, 1, 1, "", "implements_for_spec"], [51, 1, 1, "", "index"], [51, 1, 1, "", "is_in"], [51, 1, 1, "", "make_neg_dim"], [51, 1, 1, "", "memoize_encode"], [51, 2, 1, "", "ndim"], [51, 1, 1, "", "ndimension"], [51, 1, 1, "", "one"], [51, 1, 1, "", "ones"], [51, 1, 1, "", "project"], [51, 1, 1, "", "rand"], [51, 1, 1, "", "reshape"], [51, 1, 1, "", "sample"], [51, 1, 1, "", "set_provisional_n"], [51, 1, 1, "", "squeeze"], [51, 1, 1, "", "to"], [51, 1, 1, "", "to_categorical"], [51, 1, 1, "", "to_categorical_spec"], [51, 1, 1, "", "to_numpy"], [51, 1, 1, "", "to_one_hot"], [51, 1, 1, "", "to_one_hot_spec"], [51, 1, 1, "", "type_check"], [51, 1, 1, "", "unflatten"], [51, 1, 1, "", "unsqueeze"], [51, 1, 1, "", "update_mask"], [51, 1, 1, "", "view"], [51, 1, 1, "", "zero"], [51, 1, 1, "", "zeros"]], "torchrl.data.MultiDiscreteTensorSpec": [[52, 1, 1, "", "assert_is_in"], [52, 1, 1, "", "cardinality"], [52, 1, 1, "", "clear_device_"], [52, 1, 1, "", "clone"], [52, 1, 1, "", "contains"], [52, 1, 1, "", "cpu"], [52, 1, 1, "", "cuda"], [52, 4, 1, "", "device"], [52, 1, 1, "", "encode"], [52, 1, 1, "", "enumerate"], [52, 1, 1, "", "erase_memoize_cache"], [52, 1, 1, "", "expand"], [52, 1, 1, "", "flatten"], [52, 1, 1, "", "implements_for_spec"], [52, 1, 1, "", "index"], [52, 1, 1, "", "is_in"], [52, 1, 1, "", "make_neg_dim"], [52, 1, 1, "", "memoize_encode"], [52, 2, 1, "", "ndim"], [52, 1, 1, "", "ndimension"], [52, 1, 1, "", "one"], [52, 1, 1, "", "ones"], [52, 1, 1, "", "project"], [52, 1, 1, "", "rand"], [52, 1, 1, "", "reshape"], [52, 1, 1, "", "sample"], [52, 1, 1, "", "set_provisional_n"], [52, 1, 1, "", "squeeze"], [52, 1, 1, "", "to"], [52, 1, 1, "", "to_categorical"], [52, 1, 1, "", "to_categorical_spec"], [52, 1, 1, "", "to_numpy"], [52, 1, 1, "", "to_one_hot"], [52, 1, 1, "", "to_one_hot_spec"], [52, 1, 1, "", "type_check"], [52, 1, 1, "", "unflatten"], [52, 1, 1, "", "unsqueeze"], [52, 1, 1, "", "update_mask"], [52, 1, 1, "", "view"], [52, 1, 1, "", "zero"], [52, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHot": [[53, 1, 1, "", "assert_is_in"], [53, 1, 1, "", "cardinality"], [53, 1, 1, "", "clear_device_"], [53, 1, 1, "", "clone"], [53, 1, 1, "", "contains"], [53, 1, 1, "", "cpu"], [53, 1, 1, "", "cuda"], [53, 4, 1, "", "device"], [53, 1, 1, "", "encode"], [53, 1, 1, "", "enumerate"], [53, 1, 1, "", "erase_memoize_cache"], [53, 1, 1, "", "expand"], [53, 1, 1, "", "flatten"], [53, 1, 1, "", "implements_for_spec"], [53, 1, 1, "", "index"], [53, 1, 1, "", "is_in"], [53, 1, 1, "", "make_neg_dim"], [53, 1, 1, "", "memoize_encode"], [53, 2, 1, "", "ndim"], [53, 1, 1, "", "ndimension"], [53, 1, 1, "", "one"], [53, 1, 1, "", "ones"], [53, 1, 1, "", "project"], [53, 1, 1, "", "rand"], [53, 1, 1, "", "reshape"], [53, 1, 1, "", "sample"], [53, 1, 1, "", "squeeze"], [53, 1, 1, "", "to"], [53, 1, 1, "", "to_categorical"], [53, 1, 1, "", "to_categorical_spec"], [53, 1, 1, "", "to_numpy"], [53, 1, 1, "", "to_one_hot"], [53, 1, 1, "", "to_one_hot_spec"], [53, 1, 1, "", "type_check"], [53, 1, 1, "", "unflatten"], [53, 1, 1, "", "unsqueeze"], [53, 1, 1, "", "update_mask"], [53, 1, 1, "", "view"], [53, 1, 1, "", "zero"], [53, 1, 1, "", "zeros"]], "torchrl.data.MultiOneHotDiscreteTensorSpec": [[54, 1, 1, "", "assert_is_in"], [54, 1, 1, "", "cardinality"], [54, 1, 1, "", "clear_device_"], [54, 1, 1, "", "clone"], [54, 1, 1, "", "contains"], [54, 1, 1, "", "cpu"], [54, 1, 1, "", "cuda"], [54, 4, 1, "", "device"], [54, 1, 1, "", "encode"], [54, 1, 1, "", "enumerate"], [54, 1, 1, "", "erase_memoize_cache"], [54, 1, 1, "", "expand"], [54, 1, 1, "", "flatten"], [54, 1, 1, "", "implements_for_spec"], [54, 1, 1, "", "index"], [54, 1, 1, "", "is_in"], [54, 1, 1, "", "make_neg_dim"], [54, 1, 1, "", "memoize_encode"], [54, 2, 1, "", "ndim"], [54, 1, 1, "", "ndimension"], [54, 1, 1, "", "one"], [54, 1, 1, "", "ones"], [54, 1, 1, "", "project"], [54, 1, 1, "", "rand"], [54, 1, 1, "", "reshape"], [54, 1, 1, "", "sample"], [54, 1, 1, "", "squeeze"], [54, 1, 1, "", "to"], [54, 1, 1, "", "to_categorical"], [54, 1, 1, "", "to_categorical_spec"], [54, 1, 1, "", "to_numpy"], [54, 1, 1, "", "to_one_hot"], [54, 1, 1, "", "to_one_hot_spec"], [54, 1, 1, "", "type_check"], [54, 1, 1, "", "unflatten"], [54, 1, 1, "", "unsqueeze"], [54, 1, 1, "", "update_mask"], [54, 1, 1, "", "view"], [54, 1, 1, "", "zero"], [54, 1, 1, "", "zeros"]], "torchrl.data.MultiStep": [[55, 1, 1, "", "add_module"], [55, 1, 1, "", "apply"], [55, 1, 1, "", "bfloat16"], [55, 1, 1, "", "buffers"], [55, 1, 1, "", "children"], [55, 1, 1, "", "compile"], [55, 1, 1, "", "cpu"], [55, 1, 1, "", "cuda"], [55, 1, 1, "", "double"], [55, 1, 1, "", "eval"], [55, 1, 1, "", "extra_repr"], [55, 1, 1, "", "float"], [55, 1, 1, "", "forward"], [55, 1, 1, "", "get_buffer"], [55, 1, 1, "", "get_extra_state"], [55, 1, 1, "", "get_parameter"], [55, 1, 1, "", "get_submodule"], [55, 1, 1, "", "half"], [55, 1, 1, "", "ipu"], [55, 1, 1, "", "load_state_dict"], [55, 1, 1, "", "modules"], [55, 1, 1, "", "mtia"], [55, 1, 1, "", "named_buffers"], [55, 1, 1, "", "named_children"], [55, 1, 1, "", "named_modules"], [55, 1, 1, "", "named_parameters"], [55, 1, 1, "", "parameters"], [55, 1, 1, "", "register_backward_hook"], [55, 1, 1, "", "register_buffer"], [55, 1, 1, "", "register_forward_hook"], [55, 1, 1, "", "register_forward_pre_hook"], [55, 1, 1, "", "register_full_backward_hook"], [55, 1, 1, "", "register_full_backward_pre_hook"], [55, 1, 1, "", "register_load_state_dict_post_hook"], [55, 1, 1, "", "register_load_state_dict_pre_hook"], [55, 1, 1, "", "register_module"], [55, 1, 1, "", "register_parameter"], [55, 1, 1, "", "register_state_dict_post_hook"], [55, 1, 1, "", "register_state_dict_pre_hook"], [55, 1, 1, "", "requires_grad_"], [55, 1, 1, "", "set_extra_state"], [55, 1, 1, "", "set_submodule"], [55, 1, 1, "", "share_memory"], [55, 1, 1, "", "state_dict"], [55, 1, 1, "", "to"], [55, 1, 1, "", "to_empty"], [55, 1, 1, "", "train"], [55, 1, 1, "", "type"], [55, 1, 1, "", "xpu"], [55, 1, 1, "", "zero_grad"]], "torchrl.data.NonTensor": [[57, 1, 1, "", "assert_is_in"], [57, 1, 1, "", "cardinality"], [57, 1, 1, "", "clear_device_"], [57, 1, 1, "", "clone"], [57, 1, 1, "", "contains"], [57, 1, 1, "", "cpu"], [57, 1, 1, "", "cuda"], [57, 2, 1, "", "device"], [57, 1, 1, "", "encode"], [57, 1, 1, "", "enumerate"], [57, 1, 1, "", "erase_memoize_cache"], [57, 1, 1, "", "expand"], [57, 1, 1, "", "flatten"], [57, 1, 1, "", "implements_for_spec"], [57, 1, 1, "", "index"], [57, 1, 1, "", "is_in"], [57, 1, 1, "", "make_neg_dim"], [57, 1, 1, "", "memoize_encode"], [57, 2, 1, "", "ndim"], [57, 1, 1, "", "ndimension"], [57, 1, 1, "", "one"], [57, 1, 1, "", "ones"], [57, 1, 1, "", "project"], [57, 1, 1, "", "rand"], [57, 1, 1, "", "reshape"], [57, 1, 1, "", "sample"], [57, 1, 1, "", "squeeze"], [57, 1, 1, "", "to"], [57, 1, 1, "", "to_numpy"], [57, 1, 1, "", "type_check"], [57, 1, 1, "", "unflatten"], [57, 1, 1, "", "unsqueeze"], [57, 1, 1, "", "view"], [57, 1, 1, "", "zero"], [57, 1, 1, "", "zeros"]], "torchrl.data.NonTensorSpec": [[58, 1, 1, "", "assert_is_in"], [58, 1, 1, "", "cardinality"], [58, 1, 1, "", "clear_device_"], [58, 1, 1, "", "clone"], [58, 1, 1, "", "contains"], [58, 1, 1, "", "cpu"], [58, 1, 1, "", "cuda"], [58, 2, 1, "", "device"], [58, 1, 1, "", "encode"], [58, 1, 1, "", "enumerate"], [58, 1, 1, "", "erase_memoize_cache"], [58, 1, 1, "", "expand"], [58, 1, 1, "", "flatten"], [58, 1, 1, "", "implements_for_spec"], [58, 1, 1, "", "index"], [58, 1, 1, "", "is_in"], [58, 1, 1, "", "make_neg_dim"], [58, 1, 1, "", "memoize_encode"], [58, 2, 1, "", "ndim"], [58, 1, 1, "", "ndimension"], [58, 1, 1, "", "one"], [58, 1, 1, "", "ones"], [58, 1, 1, "", "project"], [58, 1, 1, "", "rand"], [58, 1, 1, "", "reshape"], [58, 1, 1, "", "sample"], [58, 1, 1, "", "squeeze"], [58, 1, 1, "", "to"], [58, 1, 1, "", "to_numpy"], [58, 1, 1, "", "type_check"], [58, 1, 1, "", "unflatten"], [58, 1, 1, "", "unsqueeze"], [58, 1, 1, "", "view"], [58, 1, 1, "", "zero"], [58, 1, 1, "", "zeros"]], "torchrl.data.OneHot": [[59, 1, 1, "", "assert_is_in"], [59, 1, 1, "", "cardinality"], [59, 1, 1, "", "clear_device_"], [59, 1, 1, "", "clone"], [59, 1, 1, "", "contains"], [59, 1, 1, "", "cpu"], [59, 1, 1, "", "cuda"], [59, 4, 1, "", "device"], [59, 1, 1, "", "encode"], [59, 1, 1, "", "enumerate"], [59, 1, 1, "", "erase_memoize_cache"], [59, 1, 1, "", "expand"], [59, 1, 1, "", "flatten"], [59, 1, 1, "", "implements_for_spec"], [59, 1, 1, "", "index"], [59, 1, 1, "", "is_in"], [59, 1, 1, "", "make_neg_dim"], [59, 1, 1, "", "memoize_encode"], [59, 2, 1, "", "ndim"], [59, 1, 1, "", "ndimension"], [59, 1, 1, "", "one"], [59, 1, 1, "", "ones"], [59, 1, 1, "", "project"], [59, 1, 1, "", "rand"], [59, 1, 1, "", "reshape"], [59, 1, 1, "", "sample"], [59, 1, 1, "", "squeeze"], [59, 1, 1, "", "to"], [59, 1, 1, "", "to_categorical"], [59, 1, 1, "", "to_categorical_spec"], [59, 1, 1, "", "to_numpy"], [59, 1, 1, "", "to_one_hot"], [59, 1, 1, "", "to_one_hot_spec"], [59, 1, 1, "", "type_check"], [59, 1, 1, "", "unflatten"], [59, 1, 1, "", "unsqueeze"], [59, 1, 1, "", "update_mask"], [59, 1, 1, "", "view"], [59, 1, 1, "", "zero"], [59, 1, 1, "", "zeros"]], "torchrl.data.OneHotDiscreteTensorSpec": [[60, 1, 1, "", "assert_is_in"], [60, 1, 1, "", "cardinality"], [60, 1, 1, "", "clear_device_"], [60, 1, 1, "", "clone"], [60, 1, 1, "", "contains"], [60, 1, 1, "", "cpu"], [60, 1, 1, "", "cuda"], [60, 4, 1, "", "device"], [60, 1, 1, "", "encode"], [60, 1, 1, "", "enumerate"], [60, 1, 1, "", "erase_memoize_cache"], [60, 1, 1, "", "expand"], [60, 1, 1, "", "flatten"], [60, 1, 1, "", "implements_for_spec"], [60, 1, 1, "", "index"], [60, 1, 1, "", "is_in"], [60, 1, 1, "", "make_neg_dim"], [60, 1, 1, "", "memoize_encode"], [60, 2, 1, "", "ndim"], [60, 1, 1, "", "ndimension"], [60, 1, 1, "", "one"], [60, 1, 1, "", "ones"], [60, 1, 1, "", "project"], [60, 1, 1, "", "rand"], [60, 1, 1, "", "reshape"], [60, 1, 1, "", "sample"], [60, 1, 1, "", "squeeze"], [60, 1, 1, "", "to"], [60, 1, 1, "", "to_categorical"], [60, 1, 1, "", "to_categorical_spec"], [60, 1, 1, "", "to_numpy"], [60, 1, 1, "", "to_one_hot"], [60, 1, 1, "", "to_one_hot_spec"], [60, 1, 1, "", "type_check"], [60, 1, 1, "", "unflatten"], [60, 1, 1, "", "unsqueeze"], [60, 1, 1, "", "update_mask"], [60, 1, 1, "", "view"], [60, 1, 1, "", "zero"], [60, 1, 1, "", "zeros"]], "torchrl.data.PairwiseDataset": [[61, 2, 1, "", "device"], [61, 1, 1, "", "dumps"], [61, 1, 1, "", "fields"], [61, 1, 1, "", "from_dataset"], [61, 1, 1, "", "from_tensordict"], [61, 1, 1, "", "get"], [61, 1, 1, "", "load"], [61, 1, 1, "", "load_"], [61, 1, 1, "", "load_memmap"], [61, 1, 1, "", "load_state_dict"], [61, 1, 1, "", "memmap"], [61, 1, 1, "", "memmap_"], [61, 1, 1, "", "memmap_like"], [61, 1, 1, "", "memmap_refresh_"], [61, 1, 1, "", "save"], [61, 1, 1, "", "set"], [61, 1, 1, "", "state_dict"], [61, 1, 1, "", "to_tensordict"], [61, 1, 1, "", "unbind"]], "torchrl.data.PrioritizedReplayBuffer": [[62, 1, 1, "", "add"], [62, 1, 1, "", "append_transform"], [62, 1, 1, "", "as_remote"], [62, 1, 1, "", "dump"], [62, 1, 1, "", "dumps"], [62, 1, 1, "", "empty"], [62, 1, 1, "", "extend"], [62, 1, 1, "", "insert_transform"], [62, 1, 1, "", "load"], [62, 1, 1, "", "loads"], [62, 1, 1, "", "register_load_hook"], [62, 1, 1, "", "register_save_hook"], [62, 1, 1, "", "sample"], [62, 2, 1, "", "sampler"], [62, 1, 1, "", "save"], [62, 1, 1, "", "set_sampler"], [62, 1, 1, "", "set_storage"], [62, 1, 1, "", "set_writer"], [62, 2, 1, "", "storage"], [62, 2, 1, "", "write_count"], [62, 2, 1, "", "writer"]], "torchrl.data.PromptData": [[63, 2, 1, "", "device"], [63, 1, 1, "", "dumps"], [63, 1, 1, "", "fields"], [63, 1, 1, "", "from_dataset"], [63, 1, 1, "", "from_tensordict"], [63, 1, 1, "", "get"], [63, 1, 1, "", "load"], [63, 1, 1, "", "load_"], [63, 1, 1, "", "load_memmap"], [63, 1, 1, "", "load_state_dict"], [63, 1, 1, "", "memmap"], [63, 1, 1, "", "memmap_"], [63, 1, 1, "", "memmap_like"], [63, 1, 1, "", "memmap_refresh_"], [63, 1, 1, "", "save"], [63, 1, 1, "", "set"], [63, 1, 1, "", "state_dict"], [63, 1, 1, "", "to_tensordict"], [63, 1, 1, "", "unbind"]], "torchrl.data.QueryModule": [[65, 1, 1, "", "add_module"], [65, 1, 1, "", "apply"], [65, 1, 1, "", "bfloat16"], [65, 1, 1, "", "buffers"], [65, 1, 1, "", "children"], [65, 1, 1, "", "compile"], [65, 1, 1, "", "cpu"], [65, 1, 1, "", "cuda"], [65, 1, 1, "", "double"], [65, 1, 1, "", "eval"], [65, 1, 1, "", "extra_repr"], [65, 1, 1, "", "float"], [65, 1, 1, "", "forward"], [65, 1, 1, "", "get_buffer"], [65, 1, 1, "", "get_extra_state"], [65, 1, 1, "", "get_parameter"], [65, 1, 1, "", "get_submodule"], [65, 1, 1, "", "half"], [65, 1, 1, "", "ipu"], [65, 1, 1, "", "is_tdmodule_compatible"], [65, 1, 1, "", "load_state_dict"], [65, 1, 1, "", "modules"], [65, 1, 1, "", "mtia"], [65, 1, 1, "", "named_buffers"], [65, 1, 1, "", "named_children"], [65, 1, 1, "", "named_modules"], [65, 1, 1, "", "named_parameters"], [65, 1, 1, "", "parameters"], [65, 1, 1, "", "register_backward_hook"], [65, 1, 1, "", "register_buffer"], [65, 1, 1, "", "register_forward_hook"], [65, 1, 1, "", "register_forward_pre_hook"], [65, 1, 1, "", "register_full_backward_hook"], [65, 1, 1, "", "register_full_backward_pre_hook"], [65, 1, 1, "", "register_load_state_dict_post_hook"], [65, 1, 1, "", "register_load_state_dict_pre_hook"], [65, 1, 1, "", "register_module"], [65, 1, 1, "", "register_parameter"], [65, 1, 1, "", "register_state_dict_post_hook"], [65, 1, 1, "", "register_state_dict_pre_hook"], [65, 1, 1, "", "requires_grad_"], [65, 1, 1, "", "reset_out_keys"], [65, 1, 1, "", "reset_parameters_recursive"], [65, 1, 1, "", "select_out_keys"], [65, 1, 1, "", "set_extra_state"], [65, 1, 1, "", "set_submodule"], [65, 1, 1, "", "share_memory"], [65, 1, 1, "", "state_dict"], [65, 1, 1, "", "to"], [65, 1, 1, "", "to_empty"], [65, 1, 1, "", "train"], [65, 1, 1, "", "type"], [65, 1, 1, "", "xpu"], [65, 1, 1, "", "zero_grad"]], "torchrl.data.RandomProjectionHash": [[66, 1, 1, "", "add_module"], [66, 1, 1, "", "apply"], [66, 1, 1, "", "bfloat16"], [66, 1, 1, "", "buffers"], [66, 1, 1, "", "children"], [66, 1, 1, "", "compile"], [66, 1, 1, "", "cpu"], [66, 1, 1, "", "cuda"], [66, 1, 1, "", "double"], [66, 1, 1, "", "eval"], [66, 1, 1, "", "extra_repr"], [66, 1, 1, "", "fit"], [66, 1, 1, "", "float"], [66, 1, 1, "", "forward"], [66, 1, 1, "", "get_buffer"], [66, 1, 1, "", "get_extra_state"], [66, 1, 1, "", "get_parameter"], [66, 1, 1, "", "get_submodule"], [66, 1, 1, "", "half"], [66, 1, 1, "", "ipu"], [66, 1, 1, "", "load_state_dict"], [66, 1, 1, "", "modules"], [66, 1, 1, "", "mtia"], [66, 1, 1, "", "named_buffers"], [66, 1, 1, "", "named_children"], [66, 1, 1, "", "named_modules"], [66, 1, 1, "", "named_parameters"], [66, 1, 1, "", "parameters"], [66, 1, 1, "", "register_backward_hook"], [66, 1, 1, "", "register_buffer"], [66, 1, 1, "", "register_forward_hook"], [66, 1, 1, "", "register_forward_pre_hook"], [66, 1, 1, "", "register_full_backward_hook"], [66, 1, 1, "", "register_full_backward_pre_hook"], [66, 1, 1, "", "register_load_state_dict_post_hook"], [66, 1, 1, "", "register_load_state_dict_pre_hook"], [66, 1, 1, "", "register_module"], [66, 1, 1, "", "register_parameter"], [66, 1, 1, "", "register_state_dict_post_hook"], [66, 1, 1, "", "register_state_dict_pre_hook"], [66, 1, 1, "", "requires_grad_"], [66, 1, 1, "", "set_extra_state"], [66, 1, 1, "", "set_submodule"], [66, 1, 1, "", "share_memory"], [66, 1, 1, "", "state_dict"], [66, 1, 1, "", "to"], [66, 1, 1, "", "to_empty"], [66, 1, 1, "", "train"], [66, 1, 1, "", "type"], [66, 1, 1, "", "xpu"], [66, 1, 1, "", "zero_grad"]], "torchrl.data.RayReplayBuffer": [[67, 1, 1, "", "add"], [67, 1, 1, "", "append_transform"], [67, 1, 1, "", "as_remote"], [67, 1, 1, "", "dump"], [67, 1, 1, "", "dumps"], [67, 1, 1, "", "empty"], [67, 1, 1, "", "extend"], [67, 1, 1, "", "insert_transform"], [67, 1, 1, "", "load"], [67, 1, 1, "", "loads"], [67, 1, 1, "", "register_load_hook"], [67, 1, 1, "", "register_save_hook"], [67, 1, 1, "", "sample"], [67, 2, 1, "", "sampler"], [67, 1, 1, "", "save"], [67, 1, 1, "", "set_sampler"], [67, 1, 1, "", "set_storage"], [67, 1, 1, "", "set_writer"], [67, 2, 1, "", "storage"], [67, 2, 1, "", "write_count"], [67, 2, 1, "", "writer"]], "torchrl.data.RemoteTensorDictReplayBuffer": [[68, 1, 1, "", "add"], [68, 1, 1, "", "append_transform"], [68, 1, 1, "", "as_remote"], [68, 1, 1, "", "dump"], [68, 1, 1, "", "dumps"], [68, 1, 1, "", "empty"], [68, 1, 1, "", "extend"], [68, 1, 1, "", "insert_transform"], [68, 1, 1, "", "load"], [68, 1, 1, "", "loads"], [68, 1, 1, "", "register_load_hook"], [68, 1, 1, "", "register_save_hook"], [68, 1, 1, "", "sample"], [68, 2, 1, "", "sampler"], [68, 1, 1, "", "save"], [68, 1, 1, "", "set_sampler"], [68, 1, 1, "", "set_storage"], [68, 1, 1, "", "set_writer"], [68, 2, 1, "", "storage"], [68, 2, 1, "", "write_count"], [68, 2, 1, "", "writer"]], "torchrl.data.ReplayBuffer": [[69, 1, 1, "", "add"], [69, 1, 1, "", "append_transform"], [69, 1, 1, "", "as_remote"], [69, 1, 1, "", "dump"], [69, 1, 1, "", "dumps"], [69, 1, 1, "", "empty"], [69, 1, 1, "", "extend"], [69, 1, 1, "", "insert_transform"], [69, 1, 1, "", "load"], [69, 1, 1, "", "loads"], [69, 1, 1, "", "register_load_hook"], [69, 1, 1, "", "register_save_hook"], [69, 1, 1, "", "sample"], [69, 2, 1, "", "sampler"], [69, 1, 1, "", "save"], [69, 1, 1, "", "set_sampler"], [69, 1, 1, "", "set_storage"], [69, 1, 1, "", "set_writer"], [69, 2, 1, "", "storage"], [69, 2, 1, "", "write_count"], [69, 2, 1, "", "writer"]], "torchrl.data.RewardData": [[70, 2, 1, "", "device"], [70, 1, 1, "", "dumps"], [70, 1, 1, "", "fields"], [70, 1, 1, "", "from_tensordict"], [70, 1, 1, "", "get"], [70, 1, 1, "", "load"], [70, 1, 1, "", "load_"], [70, 1, 1, "", "load_memmap"], [70, 1, 1, "", "load_state_dict"], [70, 1, 1, "", "memmap"], [70, 1, 1, "", "memmap_"], [70, 1, 1, "", "memmap_like"], [70, 1, 1, "", "memmap_refresh_"], [70, 1, 1, "", "save"], [70, 1, 1, "", "set"], [70, 1, 1, "", "state_dict"], [70, 1, 1, "", "to_tensordict"], [70, 1, 1, "", "unbind"]], "torchrl.data.RolloutFromModel": [[71, 1, 1, "", "create_rollout_td"], [71, 1, 1, "", "generate"], [71, 1, 1, "", "logprobs_of_labels"]], "torchrl.data.SipHash": [[72, 1, 1, "", "add_module"], [72, 1, 1, "", "apply"], [72, 1, 1, "", "bfloat16"], [72, 1, 1, "", "buffers"], [72, 1, 1, "", "children"], [72, 1, 1, "", "compile"], [72, 1, 1, "", "cpu"], [72, 1, 1, "", "cuda"], [72, 1, 1, "", "double"], [72, 1, 1, "", "eval"], [72, 1, 1, "", "extra_repr"], [72, 1, 1, "", "float"], [72, 1, 1, "", "forward"], [72, 1, 1, "", "get_buffer"], [72, 1, 1, "", "get_extra_state"], [72, 1, 1, "", "get_parameter"], [72, 1, 1, "", "get_submodule"], [72, 1, 1, "", "half"], [72, 1, 1, "", "ipu"], [72, 1, 1, "", "load_state_dict"], [72, 1, 1, "", "modules"], [72, 1, 1, "", "mtia"], [72, 1, 1, "", "named_buffers"], [72, 1, 1, "", "named_children"], [72, 1, 1, "", "named_modules"], [72, 1, 1, "", "named_parameters"], [72, 1, 1, "", "parameters"], [72, 1, 1, "", "register_backward_hook"], [72, 1, 1, "", "register_buffer"], [72, 1, 1, "", "register_forward_hook"], [72, 1, 1, "", "register_forward_pre_hook"], [72, 1, 1, "", "register_full_backward_hook"], [72, 1, 1, "", "register_full_backward_pre_hook"], [72, 1, 1, "", "register_load_state_dict_post_hook"], [72, 1, 1, "", "register_load_state_dict_pre_hook"], [72, 1, 1, "", "register_module"], [72, 1, 1, "", "register_parameter"], [72, 1, 1, "", "register_state_dict_post_hook"], [72, 1, 1, "", "register_state_dict_pre_hook"], [72, 1, 1, "", "requires_grad_"], [72, 1, 1, "", "set_extra_state"], [72, 1, 1, "", "set_submodule"], [72, 1, 1, "", "share_memory"], [72, 1, 1, "", "state_dict"], [72, 1, 1, "", "to"], [72, 1, 1, "", "to_empty"], [72, 1, 1, "", "train"], [72, 1, 1, "", "type"], [72, 1, 1, "", "xpu"], [72, 1, 1, "", "zero_grad"]], "torchrl.data.Stacked": [[73, 1, 1, "", "assert_is_in"], [73, 1, 1, "", "cardinality"], [73, 1, 1, "", "clear_device_"], [73, 1, 1, "", "clone"], [73, 1, 1, "", "contains"], [73, 1, 1, "", "cpu"], [73, 1, 1, "", "cuda"], [73, 2, 1, "", "device"], [73, 1, 1, "", "encode"], [73, 1, 1, "", "enumerate"], [73, 1, 1, "", "erase_memoize_cache"], [73, 1, 1, "", "expand"], [73, 1, 1, "", "flatten"], [73, 1, 1, "", "implements_for_spec"], [73, 1, 1, "", "index"], [73, 1, 1, "", "is_in"], [73, 1, 1, "", "make_neg_dim"], [73, 1, 1, "", "memoize_encode"], [73, 2, 1, "", "ndim"], [73, 1, 1, "", "ndimension"], [73, 1, 1, "", "one"], [73, 1, 1, "", "ones"], [73, 1, 1, "", "project"], [73, 1, 1, "", "rand"], [73, 1, 1, "", "reshape"], [73, 1, 1, "", "sample"], [73, 1, 1, "", "squeeze"], [73, 1, 1, "", "to"], [73, 1, 1, "", "to_numpy"], [73, 1, 1, "", "type_check"], [73, 1, 1, "", "unflatten"], [73, 1, 1, "", "unsqueeze"], [73, 1, 1, "", "view"], [73, 1, 1, "", "zero"], [73, 1, 1, "", "zeros"]], "torchrl.data.StackedComposite": [[74, 1, 1, "", "assert_is_in"], [74, 1, 1, "", "cardinality"], [74, 1, 1, "", "clear_device_"], [74, 1, 1, "", "clone"], [74, 1, 1, "", "contains"], [74, 1, 1, "", "cpu"], [74, 1, 1, "", "cuda"], [74, 2, 1, "", "device"], [74, 1, 1, "", "empty"], [74, 1, 1, "", "encode"], [74, 1, 1, "", "enumerate"], [74, 1, 1, "", "erase_memoize_cache"], [74, 1, 1, "", "expand"], [74, 1, 1, "", "flatten"], [74, 1, 1, "", "get"], [74, 1, 1, "", "implements_for_spec"], [74, 1, 1, "", "index"], [74, 1, 1, "", "is_empty"], [74, 1, 1, "", "is_in"], [74, 1, 1, "", "items"], [74, 1, 1, "", "keys"], [74, 1, 1, "", "lock_"], [74, 1, 1, "", "make_neg_dim"], [74, 1, 1, "", "memoize_encode"], [74, 2, 1, "", "ndim"], [74, 1, 1, "", "ndimension"], [74, 1, 1, "", "one"], [74, 1, 1, "", "ones"], [74, 1, 1, "", "pop"], [74, 1, 1, "", "project"], [74, 1, 1, "", "rand"], [74, 1, 1, "", "reshape"], [74, 1, 1, "", "sample"], [74, 1, 1, "", "separates"], [74, 1, 1, "", "set"], [74, 1, 1, "", "squeeze"], [74, 1, 1, "", "to"], [74, 1, 1, "", "to_numpy"], [74, 1, 1, "", "type_check"], [74, 1, 1, "", "unflatten"], [74, 1, 1, "", "unlock_"], [74, 1, 1, "", "unsqueeze"], [74, 1, 1, "", "values"], [74, 1, 1, "", "view"], [74, 1, 1, "", "zero"], [74, 1, 1, "", "zeros"]], "torchrl.data.TensorDictMap": [[77, 1, 1, "", "add_module"], [77, 1, 1, "", "apply"], [77, 1, 1, "", "bfloat16"], [77, 1, 1, "", "buffers"], [77, 1, 1, "", "children"], [77, 1, 1, "", "compile"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 1, 1, "", "double"], [77, 1, 1, "", "eval"], [77, 1, 1, "", "extra_repr"], [77, 1, 1, "", "float"], [77, 1, 1, "", "forward"], [77, 1, 1, "", "from_tensordict_pair"], [77, 1, 1, "", "get_buffer"], [77, 1, 1, "", "get_extra_state"], [77, 1, 1, "", "get_parameter"], [77, 1, 1, "", "get_submodule"], [77, 1, 1, "", "half"], [77, 1, 1, "", "ipu"], [77, 1, 1, "", "is_tdmodule_compatible"], [77, 1, 1, "", "load_state_dict"], [77, 1, 1, "", "modules"], [77, 1, 1, "", "mtia"], [77, 1, 1, "", "named_buffers"], [77, 1, 1, "", "named_children"], [77, 1, 1, "", "named_modules"], [77, 1, 1, "", "named_parameters"], [77, 1, 1, "", "parameters"], [77, 1, 1, "", "register_backward_hook"], [77, 1, 1, "", "register_buffer"], [77, 1, 1, "", "register_forward_hook"], [77, 1, 1, "", "register_forward_pre_hook"], [77, 1, 1, "", "register_full_backward_hook"], [77, 1, 1, "", "register_full_backward_pre_hook"], [77, 1, 1, "", "register_load_state_dict_post_hook"], [77, 1, 1, "", "register_load_state_dict_pre_hook"], [77, 1, 1, "", "register_module"], [77, 1, 1, "", "register_parameter"], [77, 1, 1, "", "register_state_dict_post_hook"], [77, 1, 1, "", "register_state_dict_pre_hook"], [77, 1, 1, "", "requires_grad_"], [77, 1, 1, "", "reset_out_keys"], [77, 1, 1, "", "reset_parameters_recursive"], [77, 1, 1, "", "select_out_keys"], [77, 1, 1, "", "set_extra_state"], [77, 1, 1, "", "set_submodule"], [77, 1, 1, "", "share_memory"], [77, 1, 1, "", "state_dict"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_empty"], [77, 1, 1, "", "train"], [77, 1, 1, "", "type"], [77, 1, 1, "", "xpu"], [77, 1, 1, "", "zero_grad"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[78, 1, 1, "", "add"], [78, 1, 1, "", "append_transform"], [78, 1, 1, "", "as_remote"], [78, 1, 1, "", "dump"], [78, 1, 1, "", "dumps"], [78, 1, 1, "", "empty"], [78, 1, 1, "", "extend"], [78, 1, 1, "", "insert_transform"], [78, 1, 1, "", "load"], [78, 1, 1, "", "loads"], [78, 1, 1, "", "register_load_hook"], [78, 1, 1, "", "register_save_hook"], [78, 1, 1, "", "sample"], [78, 2, 1, "", "sampler"], [78, 1, 1, "", "save"], [78, 1, 1, "", "set_sampler"], [78, 1, 1, "", "set_storage"], [78, 1, 1, "", "set_writer"], [78, 2, 1, "", "storage"], [78, 2, 1, "", "write_count"], [78, 2, 1, "", "writer"]], "torchrl.data.TensorDictReplayBuffer": [[79, 1, 1, "", "add"], [79, 1, 1, "", "append_transform"], [79, 1, 1, "", "as_remote"], [79, 1, 1, "", "dump"], [79, 1, 1, "", "dumps"], [79, 1, 1, "", "empty"], [79, 1, 1, "", "extend"], [79, 1, 1, "", "insert_transform"], [79, 1, 1, "", "load"], [79, 1, 1, "", "loads"], [79, 1, 1, "", "register_load_hook"], [79, 1, 1, "", "register_save_hook"], [79, 1, 1, "", "sample"], [79, 2, 1, "", "sampler"], [79, 1, 1, "", "save"], [79, 1, 1, "", "set_sampler"], [79, 1, 1, "", "set_storage"], [79, 1, 1, "", "set_writer"], [79, 2, 1, "", "storage"], [79, 2, 1, "", "write_count"], [79, 2, 1, "", "writer"]], "torchrl.data.TensorSpec": [[82, 1, 1, "", "assert_is_in"], [82, 1, 1, "", "cardinality"], [82, 1, 1, "", "clear_device_"], [82, 1, 1, "", "clone"], [82, 1, 1, "", "contains"], [82, 1, 1, "", "cpu"], [82, 1, 1, "", "cuda"], [82, 2, 1, "", "device"], [82, 1, 1, "", "encode"], [82, 1, 1, "", "enumerate"], [82, 1, 1, "", "erase_memoize_cache"], [82, 1, 1, "", "expand"], [82, 1, 1, "", "flatten"], [82, 1, 1, "", "implements_for_spec"], [82, 1, 1, "", "index"], [82, 1, 1, "", "is_in"], [82, 1, 1, "", "make_neg_dim"], [82, 1, 1, "", "memoize_encode"], [82, 2, 1, "", "ndim"], [82, 1, 1, "", "ndimension"], [82, 1, 1, "", "one"], [82, 1, 1, "", "ones"], [82, 1, 1, "", "project"], [82, 1, 1, "", "rand"], [82, 1, 1, "", "reshape"], [82, 1, 1, "", "sample"], [82, 1, 1, "", "squeeze"], [82, 1, 1, "", "to"], [82, 1, 1, "", "to_numpy"], [82, 1, 1, "", "type_check"], [82, 1, 1, "", "unflatten"], [82, 1, 1, "", "unsqueeze"], [82, 1, 1, "", "view"], [82, 1, 1, "", "zero"], [82, 1, 1, "", "zeros"]], "torchrl.data.TokenizedDatasetLoader": [[83, 1, 1, "", "dataset_to_tensordict"], [83, 1, 1, "", "load"]], "torchrl.data.Tree": [[84, 2, 1, "", "branching_action"], [84, 2, 1, "", "device"], [84, 1, 1, "", "dumps"], [84, 1, 1, "", "edges"], [84, 1, 1, "", "fields"], [84, 1, 1, "", "from_tensordict"], [84, 2, 1, "", "full_action_spec"], [84, 2, 1, "", "full_done_spec"], [84, 2, 1, "", "full_observation_spec"], [84, 2, 1, "", "full_reward_spec"], [84, 2, 1, "", "full_state_spec"], [84, 1, 1, "", "fully_expanded"], [84, 1, 1, "", "get"], [84, 1, 1, "", "get_vertex_by_hash"], [84, 1, 1, "", "get_vertex_by_id"], [84, 2, 1, "", "is_terminal"], [84, 1, 1, "", "load"], [84, 1, 1, "", "load_"], [84, 1, 1, "", "load_memmap"], [84, 1, 1, "", "load_state_dict"], [84, 1, 1, "", "make_node"], [84, 1, 1, "", "max_length"], [84, 1, 1, "", "memmap"], [84, 1, 1, "", "memmap_"], [84, 1, 1, "", "memmap_like"], [84, 1, 1, "", "memmap_refresh_"], [84, 2, 1, "", "node_observation"], [84, 2, 1, "", "node_observations"], [84, 2, 1, "", "num_children"], [84, 1, 1, "", "num_vertices"], [84, 2, 1, "", "parent"], [84, 1, 1, "", "plot"], [84, 2, 1, "", "prev_action"], [84, 1, 1, "", "rollout_from_path"], [84, 1, 1, "", "save"], [84, 2, 1, "", "selected_actions"], [84, 1, 1, "", "set"], [84, 1, 1, "", "state_dict"], [84, 1, 1, "", "to_string"], [84, 1, 1, "", "to_tensordict"], [84, 1, 1, "", "unbind"], [84, 1, 1, "", "valid_paths"], [84, 1, 1, "", "vertices"], [84, 2, 1, "", "visits"]], "torchrl.data.Unbounded": [[85, 1, 1, "", "assert_is_in"], [85, 1, 1, "", "cardinality"], [85, 1, 1, "", "clear_device_"], [85, 1, 1, "", "clone"], [85, 1, 1, "", "contains"], [85, 1, 1, "", "cpu"], [85, 1, 1, "", "cuda"], [85, 2, 1, "", "device"], [85, 1, 1, "", "encode"], [85, 1, 1, "", "enumerate"], [85, 1, 1, "", "erase_memoize_cache"], [85, 1, 1, "", "expand"], [85, 1, 1, "", "flatten"], [85, 1, 1, "", "implements_for_spec"], [85, 1, 1, "", "index"], [85, 1, 1, "", "is_in"], [85, 1, 1, "", "make_neg_dim"], [85, 1, 1, "", "memoize_encode"], [85, 2, 1, "", "ndim"], [85, 1, 1, "", "ndimension"], [85, 1, 1, "", "one"], [85, 1, 1, "", "ones"], [85, 1, 1, "", "project"], [85, 1, 1, "", "rand"], [85, 1, 1, "", "reshape"], [85, 1, 1, "", "sample"], [85, 1, 1, "", "squeeze"], [85, 1, 1, "", "to"], [85, 1, 1, "", "to_numpy"], [85, 1, 1, "", "type_check"], [85, 1, 1, "", "unflatten"], [85, 1, 1, "", "unsqueeze"], [85, 1, 1, "", "view"], [85, 1, 1, "", "zero"], [85, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuous": [[86, 1, 1, "", "assert_is_in"], [86, 1, 1, "", "cardinality"], [86, 1, 1, "", "clear_device_"], [86, 1, 1, "", "clone"], [86, 1, 1, "", "contains"], [86, 1, 1, "", "cpu"], [86, 1, 1, "", "cuda"], [86, 2, 1, "", "device"], [86, 1, 1, "", "encode"], [86, 1, 1, "", "enumerate"], [86, 1, 1, "", "erase_memoize_cache"], [86, 1, 1, "", "expand"], [86, 1, 1, "", "flatten"], [86, 1, 1, "", "implements_for_spec"], [86, 1, 1, "", "index"], [86, 1, 1, "", "is_in"], [86, 1, 1, "", "make_neg_dim"], [86, 1, 1, "", "memoize_encode"], [86, 2, 1, "", "ndim"], [86, 1, 1, "", "ndimension"], [86, 1, 1, "", "one"], [86, 1, 1, "", "ones"], [86, 1, 1, "", "project"], [86, 1, 1, "", "rand"], [86, 1, 1, "", "reshape"], [86, 1, 1, "", "sample"], [86, 1, 1, "", "squeeze"], [86, 1, 1, "", "to"], [86, 1, 1, "", "to_numpy"], [86, 1, 1, "", "type_check"], [86, 1, 1, "", "unflatten"], [86, 1, 1, "", "unsqueeze"], [86, 1, 1, "", "view"], [86, 1, 1, "", "zero"], [86, 1, 1, "", "zeros"]], "torchrl.data.UnboundedContinuousTensorSpec": [[87, 1, 1, "", "assert_is_in"], [87, 1, 1, "", "cardinality"], [87, 1, 1, "", "clear_device_"], [87, 1, 1, "", "clone"], [87, 1, 1, "", "contains"], [87, 1, 1, "", "cpu"], [87, 1, 1, "", "cuda"], [87, 2, 1, "", "device"], [87, 1, 1, "", "encode"], [87, 1, 1, "", "enumerate"], [87, 1, 1, "", "erase_memoize_cache"], [87, 1, 1, "", "expand"], [87, 1, 1, "", "flatten"], [87, 1, 1, "", "implements_for_spec"], [87, 1, 1, "", "index"], [87, 1, 1, "", "is_in"], [87, 1, 1, "", "make_neg_dim"], [87, 1, 1, "", "memoize_encode"], [87, 2, 1, "", "ndim"], [87, 1, 1, "", "ndimension"], [87, 1, 1, "", "one"], [87, 1, 1, "", "ones"], [87, 1, 1, "", "project"], [87, 1, 1, "", "rand"], [87, 1, 1, "", "reshape"], [87, 1, 1, "", "sample"], [87, 1, 1, "", "squeeze"], [87, 1, 1, "", "to"], [87, 1, 1, "", "to_numpy"], [87, 1, 1, "", "type_check"], [87, 1, 1, "", "unflatten"], [87, 1, 1, "", "unsqueeze"], [87, 1, 1, "", "view"], [87, 1, 1, "", "zero"], [87, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscrete": [[88, 1, 1, "", "assert_is_in"], [88, 1, 1, "", "cardinality"], [88, 1, 1, "", "clear_device_"], [88, 1, 1, "", "clone"], [88, 1, 1, "", "contains"], [88, 1, 1, "", "cpu"], [88, 1, 1, "", "cuda"], [88, 2, 1, "", "device"], [88, 1, 1, "", "encode"], [88, 1, 1, "", "enumerate"], [88, 1, 1, "", "erase_memoize_cache"], [88, 1, 1, "", "expand"], [88, 1, 1, "", "flatten"], [88, 1, 1, "", "implements_for_spec"], [88, 1, 1, "", "index"], [88, 1, 1, "", "is_in"], [88, 1, 1, "", "make_neg_dim"], [88, 1, 1, "", "memoize_encode"], [88, 2, 1, "", "ndim"], [88, 1, 1, "", "ndimension"], [88, 1, 1, "", "one"], [88, 1, 1, "", "ones"], [88, 1, 1, "", "project"], [88, 1, 1, "", "rand"], [88, 1, 1, "", "reshape"], [88, 1, 1, "", "sample"], [88, 1, 1, "", "squeeze"], [88, 1, 1, "", "to"], [88, 1, 1, "", "to_numpy"], [88, 1, 1, "", "type_check"], [88, 1, 1, "", "unflatten"], [88, 1, 1, "", "unsqueeze"], [88, 1, 1, "", "view"], [88, 1, 1, "", "zero"], [88, 1, 1, "", "zeros"]], "torchrl.data.UnboundedDiscreteTensorSpec": [[89, 1, 1, "", "assert_is_in"], [89, 1, 1, "", "cardinality"], [89, 1, 1, "", "clear_device_"], [89, 1, 1, "", "clone"], [89, 1, 1, "", "contains"], [89, 1, 1, "", "cpu"], [89, 1, 1, "", "cuda"], [89, 2, 1, "", "device"], [89, 1, 1, "", "encode"], [89, 1, 1, "", "enumerate"], [89, 1, 1, "", "erase_memoize_cache"], [89, 1, 1, "", "expand"], [89, 1, 1, "", "flatten"], [89, 1, 1, "", "implements_for_spec"], [89, 1, 1, "", "index"], [89, 1, 1, "", "is_in"], [89, 1, 1, "", "make_neg_dim"], [89, 1, 1, "", "memoize_encode"], [89, 2, 1, "", "ndim"], [89, 1, 1, "", "ndimension"], [89, 1, 1, "", "one"], [89, 1, 1, "", "ones"], [89, 1, 1, "", "project"], [89, 1, 1, "", "rand"], [89, 1, 1, "", "reshape"], [89, 1, 1, "", "sample"], [89, 1, 1, "", "squeeze"], [89, 1, 1, "", "to"], [89, 1, 1, "", "to_numpy"], [89, 1, 1, "", "type_check"], [89, 1, 1, "", "unflatten"], [89, 1, 1, "", "unsqueeze"], [89, 1, 1, "", "view"], [89, 1, 1, "", "zero"], [89, 1, 1, "", "zeros"]], "torchrl.data.llm": [[95, 0, 1, "", "History"], [96, 0, 1, "", "LLMData"]], "torchrl.data.llm.History": [[95, 1, 1, "", "append"], [95, 1, 1, "", "apply_chat_template"], [95, 1, 1, "", "default_spec"], [95, 2, 1, "", "device"], [95, 1, 1, "", "dumps"], [95, 1, 1, "", "fields"], [95, 1, 1, "", "from_tensordict"], [95, 1, 1, "", "get"], [95, 1, 1, "", "load"], [95, 1, 1, "", "load_"], [95, 1, 1, "", "load_memmap"], [95, 1, 1, "", "load_state_dict"], [95, 1, 1, "", "memmap"], [95, 1, 1, "", "memmap_"], [95, 1, 1, "", "memmap_like"], [95, 1, 1, "", "memmap_refresh_"], [95, 1, 1, "", "save"], [95, 1, 1, "", "set"], [95, 1, 1, "", "state_dict"], [95, 1, 1, "", "to_tensordict"], [95, 1, 1, "", "unbind"]], "torchrl.data.llm.LLMData": [[96, 2, 1, "", "device"], [96, 1, 1, "", "dumps"], [96, 1, 1, "", "fields"], [96, 1, 1, "", "from_tensordict"], [96, 1, 1, "", "get"], [96, 1, 1, "", "load"], [96, 1, 1, "", "load_"], [96, 1, 1, "", "load_memmap"], [96, 1, 1, "", "load_state_dict"], [96, 1, 1, "", "memmap"], [96, 1, 1, "", "memmap_"], [96, 1, 1, "", "memmap_like"], [96, 1, 1, "", "memmap_refresh_"], [96, 1, 1, "", "save"], [96, 1, 1, "", "set"], [96, 1, 1, "", "state_dict"], [96, 1, 1, "", "to_tensordict"], [96, 1, 1, "", "unbind"]], "torchrl.data.replay_buffers": [[97, 0, 1, "", "FlatStorageCheckpointer"], [98, 0, 1, "", "H5StorageCheckpointer"], [99, 0, 1, "", "ImmutableDatasetWriter"], [100, 0, 1, "", "LazyMemmapStorage"], [101, 0, 1, "", "LazyStackStorage"], [102, 0, 1, "", "LazyTensorStorage"], [103, 0, 1, "", "ListStorage"], [104, 0, 1, "", "ListStorageCheckpointer"], [105, 0, 1, "", "NestedStorageCheckpointer"], [106, 0, 1, "", "PrioritizedSampler"], [107, 0, 1, "", "PrioritizedSliceSampler"], [108, 0, 1, "", "RandomSampler"], [109, 0, 1, "", "ReplayBufferEnsemble"], [110, 0, 1, "", "RoundRobinWriter"], [111, 0, 1, "", "Sampler"], [112, 0, 1, "", "SamplerEnsemble"], [113, 0, 1, "", "SamplerWithoutReplacement"], [114, 0, 1, "", "SliceSampler"], [115, 0, 1, "", "SliceSamplerWithoutReplacement"], [116, 0, 1, "", "Storage"], [117, 0, 1, "", "StorageCheckpointerBase"], [118, 0, 1, "", "StorageEnsemble"], [119, 0, 1, "", "StorageEnsembleCheckpointer"], [120, 0, 1, "", "TensorDictMaxValueWriter"], [121, 0, 1, "", "TensorDictRoundRobinWriter"], [122, 0, 1, "", "TensorStorage"], [123, 0, 1, "", "TensorStorageCheckpointer"], [124, 0, 1, "", "Writer"], [125, 0, 1, "", "WriterEnsemble"]], "torchrl.data.replay_buffers.ImmutableDatasetWriter": [[99, 1, 1, "", "add"], [99, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[100, 1, 1, "", "attach"], [100, 1, 1, "", "dump"], [100, 1, 1, "", "load"], [100, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyStackStorage": [[101, 1, 1, "", "attach"], [101, 1, 1, "", "dump"], [101, 1, 1, "", "load"], [101, 1, 1, "", "save"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[102, 1, 1, "", "attach"], [102, 1, 1, "", "dump"], [102, 1, 1, "", "load"], [102, 1, 1, "", "save"]], "torchrl.data.replay_buffers.ListStorage": [[103, 1, 1, "", "attach"], [103, 1, 1, "", "dump"], [103, 1, 1, "", "load"], [103, 1, 1, "", "save"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[106, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.PrioritizedSliceSampler": [[107, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.ReplayBufferEnsemble": [[109, 1, 1, "", "add"], [109, 1, 1, "", "append_transform"], [109, 1, 1, "", "as_remote"], [109, 1, 1, "", "dump"], [109, 1, 1, "", "dumps"], [109, 1, 1, "", "empty"], [109, 1, 1, "", "extend"], [109, 1, 1, "", "insert_transform"], [109, 1, 1, "", "load"], [109, 1, 1, "", "loads"], [109, 1, 1, "", "register_load_hook"], [109, 1, 1, "", "register_save_hook"], [109, 1, 1, "", "sample"], [109, 2, 1, "", "sampler"], [109, 1, 1, "", "save"], [109, 1, 1, "", "set_sampler"], [109, 1, 1, "", "set_storage"], [109, 1, 1, "", "set_writer"], [109, 2, 1, "", "storage"], [109, 2, 1, "", "write_count"], [109, 2, 1, "", "writer"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[110, 1, 1, "", "add"], [110, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[116, 1, 1, "", "attach"], [116, 1, 1, "", "dump"], [116, 1, 1, "", "load"], [116, 1, 1, "", "save"]], "torchrl.data.replay_buffers.StorageEnsemble": [[118, 1, 1, "", "attach"], [118, 1, 1, "", "dump"], [118, 1, 1, "", "load"], [118, 1, 1, "", "save"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[120, 1, 1, "", "add"], [120, 1, 1, "", "extend"], [120, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[121, 1, 1, "", "add"], [121, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[122, 1, 1, "", "attach"], [122, 1, 1, "", "dump"], [122, 1, 1, "", "load"], [122, 1, 1, "", "save"]], "torchrl.data.replay_buffers.Writer": [[124, 1, 1, "", "add"], [124, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.WriterEnsemble": [[125, 1, 1, "", "add"], [125, 1, 1, "", "extend"]], "torchrl.envs": [[126, 0, 1, "", "AsyncEnvPool"], [127, 3, 1, "", "BraxEnv"], [128, 3, 1, "", "BraxWrapper"], [129, 0, 1, "", "ChessEnv"], [130, 3, 1, "", "DMControlEnv"], [131, 3, 1, "", "DMControlWrapper"], [132, 0, 1, "", "EnvBase"], [133, 0, 1, "", "EnvCreator"], [134, 0, 1, "", "EnvMetaData"], [135, 3, 1, "", "GymEnv"], [136, 0, 1, "", "GymLikeEnv"], [137, 3, 1, "", "GymWrapper"], [138, 3, 1, "", "HabitatEnv"], [139, 3, 1, "", "IsaacGymEnv"], [140, 3, 1, "", "IsaacGymWrapper"], [141, 3, 1, "", "IsaacLabWrapper"], [142, 3, 1, "", "JumanjiEnv"], [143, 3, 1, "", "JumanjiWrapper"], [144, 0, 1, "", "LLMHashingEnv"], [145, 3, 1, "", "MOGymEnv"], [146, 3, 1, "", "MOGymWrapper"], [147, 3, 1, "", "MarlGroupMapType"], [148, 3, 1, "", "MeltingpotEnv"], [149, 3, 1, "", "MeltingpotWrapper"], [150, 3, 1, "", "ModelBasedEnvBase"], [151, 3, 1, "", "MultiThreadedEnv"], [152, 3, 1, "", "MultiThreadedEnvWrapper"], [153, 3, 1, "", "OpenMLEnv"], [154, 3, 1, "", "OpenSpielEnv"], [155, 3, 1, "", "OpenSpielWrapper"], [156, 0, 1, "", "ParallelEnv"], [157, 0, 1, "", "PendulumEnv"], [158, 3, 1, "", "PettingZooEnv"], [159, 3, 1, "", "PettingZooWrapper"], [160, 0, 1, "", "ProcessorAsyncEnvPool"], [161, 3, 1, "", "RandomPolicy"], [162, 3, 1, "", "RoboHiveEnv"], [163, 3, 1, "", "SMACv2Env"], [164, 3, 1, "", "SMACv2Wrapper"], [165, 0, 1, "", "SerialEnv"], [166, 0, 1, "", "ThreadingAsyncEnvPool"], [167, 0, 1, "", "TicTacToeEnv"], [168, 3, 1, "", "UnityMLAgentsEnv"], [169, 3, 1, "", "UnityMLAgentsWrapper"], [170, 3, 1, "", "VmasEnv"], [171, 3, 1, "", "VmasWrapper"], [172, 3, 1, "", "check_env_specs"], [173, 3, 1, "", "check_marl_grouping"], [174, 3, 1, "", "exploration_type"], [175, 3, 1, "", "get_available_libraries"], [176, 3, 1, "", "gym_backend"], [197, 3, 1, "", "make_composite_from_td"], [150, 1, 1, "", "rand_step"], [200, 3, 1, "", "register_gym_spec_conversion"], [150, 1, 1, "", "reset"], [150, 1, 1, "", "rollout"], [201, 3, 1, "", "set_exploration_type"], [202, 3, 1, "", "set_gym_backend"], [150, 1, 1, "", "set_seed"], [150, 1, 1, "", "step"], [203, 3, 1, "", "step_mdp"], [204, 3, 1, "", "terminated_or_truncated"]], "torchrl.envs.AsyncEnvPool": [[126, 2, 1, "", "action_key"], [126, 2, 1, "", "action_keys"], [126, 2, 1, "", "action_spec"], [126, 2, 1, "", "action_spec_unbatched"], [126, 1, 1, "", "add_module"], [126, 1, 1, "", "add_truncated_keys"], [126, 1, 1, "", "all_actions"], [126, 1, 1, "", "any_done"], [126, 1, 1, "", "append_transform"], [126, 1, 1, "", "apply"], [126, 1, 1, "", "auto_specs_"], [126, 2, 1, "", "batch_dims"], [126, 2, 1, "", "batch_locked"], [126, 2, 1, "", "batch_size"], [126, 1, 1, "", "bfloat16"], [126, 1, 1, "", "buffers"], [126, 1, 1, "", "cardinality"], [126, 1, 1, "", "check_env_specs"], [126, 1, 1, "", "children"], [126, 1, 1, "", "compile"], [126, 1, 1, "", "cpu"], [126, 1, 1, "", "cuda"], [126, 2, 1, "", "done_key"], [126, 2, 1, "", "done_keys"], [126, 2, 1, "", "done_keys_groups"], [126, 2, 1, "", "done_spec"], [126, 2, 1, "", "done_spec_unbatched"], [126, 1, 1, "", "double"], [126, 1, 1, "", "empty_cache"], [126, 1, 1, "", "eval"], [126, 1, 1, "", "extra_repr"], [126, 1, 1, "", "fake_tensordict"], [126, 1, 1, "", "float"], [126, 1, 1, "", "forward"], [126, 2, 1, "", "full_action_spec"], [126, 2, 1, "", "full_action_spec_unbatched"], [126, 2, 1, "", "full_done_spec"], [126, 2, 1, "", "full_done_spec_unbatched"], [126, 2, 1, "", "full_observation_spec_unbatched"], [126, 2, 1, "", "full_reward_spec"], [126, 2, 1, "", "full_reward_spec_unbatched"], [126, 2, 1, "", "full_state_spec"], [126, 2, 1, "", "full_state_spec_unbatched"], [126, 1, 1, "", "get_buffer"], [126, 1, 1, "", "get_extra_state"], [126, 1, 1, "", "get_parameter"], [126, 1, 1, "", "get_submodule"], [126, 1, 1, "", "half"], [126, 2, 1, "", "input_spec"], [126, 2, 1, "", "input_spec_unbatched"], [126, 1, 1, "", "ipu"], [126, 2, 1, "", "is_spec_locked"], [126, 1, 1, "", "load_state_dict"], [126, 1, 1, "", "maybe_reset"], [126, 1, 1, "", "modules"], [126, 1, 1, "", "mtia"], [126, 1, 1, "", "named_buffers"], [126, 1, 1, "", "named_children"], [126, 1, 1, "", "named_modules"], [126, 1, 1, "", "named_parameters"], [126, 2, 1, "", "observation_keys"], [126, 2, 1, "", "observation_spec"], [126, 2, 1, "", "observation_spec_unbatched"], [126, 2, 1, "", "output_spec"], [126, 2, 1, "", "output_spec_unbatched"], [126, 1, 1, "", "parameters"], [126, 1, 1, "", "rand_action"], [126, 1, 1, "", "rand_step"], [126, 1, 1, "", "register_backward_hook"], [126, 1, 1, "", "register_buffer"], [126, 1, 1, "", "register_forward_hook"], [126, 1, 1, "", "register_forward_pre_hook"], [126, 1, 1, "", "register_full_backward_hook"], [126, 1, 1, "", "register_full_backward_pre_hook"], [126, 1, 1, "", "register_gym"], [126, 1, 1, "", "register_load_state_dict_post_hook"], [126, 1, 1, "", "register_load_state_dict_pre_hook"], [126, 1, 1, "", "register_module"], [126, 1, 1, "", "register_parameter"], [126, 1, 1, "", "register_state_dict_post_hook"], [126, 1, 1, "", "register_state_dict_pre_hook"], [126, 1, 1, "", "requires_grad_"], [126, 1, 1, "", "reset"], [126, 2, 1, "", "reset_keys"], [126, 2, 1, "", "reward_key"], [126, 2, 1, "", "reward_keys"], [126, 2, 1, "", "reward_spec"], [126, 2, 1, "", "reward_spec_unbatched"], [126, 1, 1, "", "rollout"], [126, 1, 1, "", "set_extra_state"], [126, 1, 1, "", "set_seed"], [126, 1, 1, "", "set_spec_lock_"], [126, 1, 1, "", "set_submodule"], [126, 2, 1, "", "shape"], [126, 1, 1, "", "share_memory"], [126, 2, 1, "", "specs"], [126, 1, 1, "", "state_dict"], [126, 2, 1, "", "state_keys"], [126, 2, 1, "", "state_spec"], [126, 2, 1, "", "state_spec_unbatched"], [126, 1, 1, "", "step"], [126, 1, 1, "", "step_and_maybe_reset"], [126, 1, 1, "", "step_mdp"], [126, 1, 1, "", "to"], [126, 1, 1, "", "to_empty"], [126, 1, 1, "", "train"], [126, 1, 1, "", "type"], [126, 1, 1, "", "xpu"], [126, 1, 1, "", "zero_grad"]], "torchrl.envs.ChessEnv": [[129, 2, 1, "", "action_key"], [129, 2, 1, "", "action_keys"], [129, 2, 1, "", "action_spec"], [129, 2, 1, "", "action_spec_unbatched"], [129, 1, 1, "", "add_module"], [129, 1, 1, "", "add_truncated_keys"], [129, 1, 1, "", "all_actions"], [129, 1, 1, "", "any_done"], [129, 1, 1, "", "append_transform"], [129, 1, 1, "", "apply"], [129, 1, 1, "", "auto_specs_"], [129, 2, 1, "", "batch_dims"], [129, 2, 1, "", "batch_locked"], [129, 2, 1, "", "batch_size"], [129, 1, 1, "", "bfloat16"], [129, 1, 1, "", "buffers"], [129, 1, 1, "", "cardinality"], [129, 1, 1, "", "check_env_specs"], [129, 1, 1, "", "children"], [129, 1, 1, "", "compile"], [129, 1, 1, "", "cpu"], [129, 1, 1, "", "cuda"], [129, 2, 1, "", "done_key"], [129, 2, 1, "", "done_keys"], [129, 2, 1, "", "done_keys_groups"], [129, 2, 1, "", "done_spec"], [129, 2, 1, "", "done_spec_unbatched"], [129, 1, 1, "", "double"], [129, 1, 1, "", "empty_cache"], [129, 1, 1, "", "eval"], [129, 1, 1, "", "extra_repr"], [129, 1, 1, "", "fake_tensordict"], [129, 1, 1, "", "float"], [129, 1, 1, "", "forward"], [129, 2, 1, "", "full_action_spec"], [129, 2, 1, "", "full_action_spec_unbatched"], [129, 2, 1, "", "full_done_spec"], [129, 2, 1, "", "full_done_spec_unbatched"], [129, 2, 1, "", "full_observation_spec_unbatched"], [129, 2, 1, "", "full_reward_spec"], [129, 2, 1, "", "full_reward_spec_unbatched"], [129, 2, 1, "", "full_state_spec"], [129, 2, 1, "", "full_state_spec_unbatched"], [129, 1, 1, "", "get_buffer"], [129, 1, 1, "", "get_extra_state"], [129, 1, 1, "", "get_legal_moves"], [129, 1, 1, "", "get_parameter"], [129, 1, 1, "", "get_submodule"], [129, 1, 1, "", "half"], [129, 2, 1, "", "input_spec"], [129, 2, 1, "", "input_spec_unbatched"], [129, 1, 1, "", "ipu"], [129, 2, 1, "", "is_spec_locked"], [129, 1, 1, "", "load_state_dict"], [129, 1, 1, "", "maybe_reset"], [129, 1, 1, "", "modules"], [129, 1, 1, "", "mtia"], [129, 1, 1, "", "named_buffers"], [129, 1, 1, "", "named_children"], [129, 1, 1, "", "named_modules"], [129, 1, 1, "", "named_parameters"], [129, 2, 1, "", "observation_keys"], [129, 2, 1, "", "observation_spec"], [129, 2, 1, "", "observation_spec_unbatched"], [129, 2, 1, "", "output_spec"], [129, 2, 1, "", "output_spec_unbatched"], [129, 1, 1, "", "parameters"], [129, 1, 1, "", "rand_action"], [129, 1, 1, "", "rand_step"], [129, 1, 1, "", "register_backward_hook"], [129, 1, 1, "", "register_buffer"], [129, 1, 1, "", "register_forward_hook"], [129, 1, 1, "", "register_forward_pre_hook"], [129, 1, 1, "", "register_full_backward_hook"], [129, 1, 1, "", "register_full_backward_pre_hook"], [129, 1, 1, "", "register_gym"], [129, 1, 1, "", "register_load_state_dict_post_hook"], [129, 1, 1, "", "register_load_state_dict_pre_hook"], [129, 1, 1, "", "register_module"], [129, 1, 1, "", "register_parameter"], [129, 1, 1, "", "register_state_dict_post_hook"], [129, 1, 1, "", "register_state_dict_pre_hook"], [129, 1, 1, "", "requires_grad_"], [129, 1, 1, "", "reset"], [129, 2, 1, "", "reset_keys"], [129, 2, 1, "", "reward_key"], [129, 2, 1, "", "reward_keys"], [129, 2, 1, "", "reward_spec"], [129, 2, 1, "", "reward_spec_unbatched"], [129, 1, 1, "", "rollout"], [129, 1, 1, "", "set_extra_state"], [129, 1, 1, "", "set_seed"], [129, 1, 1, "", "set_spec_lock_"], [129, 1, 1, "", "set_submodule"], [129, 2, 1, "", "shape"], [129, 1, 1, "", "share_memory"], [129, 2, 1, "", "specs"], [129, 1, 1, "", "state_dict"], [129, 2, 1, "", "state_keys"], [129, 2, 1, "", "state_spec"], [129, 2, 1, "", "state_spec_unbatched"], [129, 1, 1, "", "step"], [129, 1, 1, "", "step_and_maybe_reset"], [129, 1, 1, "", "step_mdp"], [129, 1, 1, "", "to"], [129, 1, 1, "", "to_empty"], [129, 1, 1, "", "train"], [129, 1, 1, "", "type"], [129, 1, 1, "", "xpu"], [129, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvBase": [[132, 2, 1, "", "action_key"], [132, 2, 1, "", "action_keys"], [132, 2, 1, "", "action_spec"], [132, 2, 1, "", "action_spec_unbatched"], [132, 1, 1, "", "add_module"], [132, 1, 1, "", "add_truncated_keys"], [132, 1, 1, "", "all_actions"], [132, 1, 1, "", "any_done"], [132, 1, 1, "", "append_transform"], [132, 1, 1, "", "apply"], [132, 1, 1, "", "auto_specs_"], [132, 2, 1, "", "batch_dims"], [132, 2, 1, "", "batch_locked"], [132, 2, 1, "", "batch_size"], [132, 1, 1, "", "bfloat16"], [132, 1, 1, "", "buffers"], [132, 1, 1, "", "cardinality"], [132, 1, 1, "", "check_env_specs"], [132, 1, 1, "", "children"], [132, 1, 1, "", "compile"], [132, 1, 1, "", "cpu"], [132, 1, 1, "", "cuda"], [132, 2, 1, "", "done_key"], [132, 2, 1, "", "done_keys"], [132, 2, 1, "", "done_keys_groups"], [132, 2, 1, "", "done_spec"], [132, 2, 1, "", "done_spec_unbatched"], [132, 1, 1, "", "double"], [132, 1, 1, "", "empty_cache"], [132, 1, 1, "", "eval"], [132, 1, 1, "", "extra_repr"], [132, 1, 1, "", "fake_tensordict"], [132, 1, 1, "", "float"], [132, 1, 1, "", "forward"], [132, 2, 1, "", "full_action_spec"], [132, 2, 1, "", "full_action_spec_unbatched"], [132, 2, 1, "", "full_done_spec"], [132, 2, 1, "", "full_done_spec_unbatched"], [132, 2, 1, "", "full_observation_spec_unbatched"], [132, 2, 1, "", "full_reward_spec"], [132, 2, 1, "", "full_reward_spec_unbatched"], [132, 2, 1, "", "full_state_spec"], [132, 2, 1, "", "full_state_spec_unbatched"], [132, 1, 1, "", "get_buffer"], [132, 1, 1, "", "get_extra_state"], [132, 1, 1, "", "get_parameter"], [132, 1, 1, "", "get_submodule"], [132, 1, 1, "", "half"], [132, 2, 1, "", "input_spec"], [132, 2, 1, "", "input_spec_unbatched"], [132, 1, 1, "", "ipu"], [132, 2, 1, "", "is_spec_locked"], [132, 1, 1, "", "load_state_dict"], [132, 1, 1, "", "maybe_reset"], [132, 1, 1, "", "modules"], [132, 1, 1, "", "mtia"], [132, 1, 1, "", "named_buffers"], [132, 1, 1, "", "named_children"], [132, 1, 1, "", "named_modules"], [132, 1, 1, "", "named_parameters"], [132, 2, 1, "", "observation_keys"], [132, 2, 1, "", "observation_spec"], [132, 2, 1, "", "observation_spec_unbatched"], [132, 2, 1, "", "output_spec"], [132, 2, 1, "", "output_spec_unbatched"], [132, 1, 1, "", "parameters"], [132, 1, 1, "", "rand_action"], [132, 1, 1, "id0", "rand_step"], [132, 1, 1, "", "register_backward_hook"], [132, 1, 1, "", "register_buffer"], [132, 1, 1, "", "register_forward_hook"], [132, 1, 1, "", "register_forward_pre_hook"], [132, 1, 1, "", "register_full_backward_hook"], [132, 1, 1, "", "register_full_backward_pre_hook"], [132, 1, 1, "", "register_gym"], [132, 1, 1, "", "register_load_state_dict_post_hook"], [132, 1, 1, "", "register_load_state_dict_pre_hook"], [132, 1, 1, "", "register_module"], [132, 1, 1, "", "register_parameter"], [132, 1, 1, "", "register_state_dict_post_hook"], [132, 1, 1, "", "register_state_dict_pre_hook"], [132, 1, 1, "", "requires_grad_"], [132, 1, 1, "id1", "reset"], [132, 2, 1, "", "reset_keys"], [132, 2, 1, "", "reward_key"], [132, 2, 1, "", "reward_keys"], [132, 2, 1, "", "reward_spec"], [132, 2, 1, "", "reward_spec_unbatched"], [132, 1, 1, "id2", "rollout"], [132, 1, 1, "", "set_extra_state"], [132, 1, 1, "id3", "set_seed"], [132, 1, 1, "", "set_spec_lock_"], [132, 1, 1, "", "set_submodule"], [132, 2, 1, "", "shape"], [132, 1, 1, "", "share_memory"], [132, 2, 1, "", "specs"], [132, 1, 1, "", "state_dict"], [132, 2, 1, "", "state_keys"], [132, 2, 1, "", "state_spec"], [132, 2, 1, "", "state_spec_unbatched"], [132, 1, 1, "id4", "step"], [132, 1, 1, "", "step_and_maybe_reset"], [132, 1, 1, "", "step_mdp"], [132, 1, 1, "", "to"], [132, 1, 1, "", "to_empty"], [132, 1, 1, "", "train"], [132, 1, 1, "", "type"], [132, 1, 1, "", "xpu"], [132, 1, 1, "", "zero_grad"]], "torchrl.envs.EnvCreator": [[133, 1, 1, "", "make_variant"]], "torchrl.envs.GymLikeEnv": [[136, 2, 1, "", "action_key"], [136, 2, 1, "", "action_keys"], [136, 2, 1, "", "action_spec"], [136, 2, 1, "", "action_spec_unbatched"], [136, 1, 1, "", "add_module"], [136, 1, 1, "", "add_truncated_keys"], [136, 1, 1, "", "all_actions"], [136, 1, 1, "", "any_done"], [136, 1, 1, "", "append_transform"], [136, 1, 1, "", "apply"], [136, 1, 1, "", "auto_register_info_dict"], [136, 1, 1, "", "auto_specs_"], [136, 2, 1, "", "batch_dims"], [136, 2, 1, "", "batch_locked"], [136, 2, 1, "", "batch_size"], [136, 1, 1, "", "bfloat16"], [136, 1, 1, "", "buffers"], [136, 1, 1, "", "cardinality"], [136, 1, 1, "", "check_env_specs"], [136, 1, 1, "", "children"], [136, 1, 1, "", "close"], [136, 1, 1, "", "compile"], [136, 1, 1, "", "cpu"], [136, 1, 1, "", "cuda"], [136, 2, 1, "", "done_key"], [136, 2, 1, "", "done_keys"], [136, 2, 1, "", "done_keys_groups"], [136, 2, 1, "", "done_spec"], [136, 2, 1, "", "done_spec_unbatched"], [136, 1, 1, "", "double"], [136, 1, 1, "", "empty_cache"], [136, 1, 1, "", "eval"], [136, 1, 1, "", "extra_repr"], [136, 1, 1, "", "fake_tensordict"], [136, 1, 1, "", "fast_encoding"], [136, 1, 1, "", "float"], [136, 1, 1, "", "forward"], [136, 2, 1, "", "full_action_spec"], [136, 2, 1, "", "full_action_spec_unbatched"], [136, 2, 1, "", "full_done_spec"], [136, 2, 1, "", "full_done_spec_unbatched"], [136, 2, 1, "", "full_observation_spec_unbatched"], [136, 2, 1, "", "full_reward_spec"], [136, 2, 1, "", "full_reward_spec_unbatched"], [136, 2, 1, "", "full_state_spec"], [136, 2, 1, "", "full_state_spec_unbatched"], [136, 1, 1, "", "get_buffer"], [136, 1, 1, "", "get_extra_state"], [136, 1, 1, "", "get_parameter"], [136, 1, 1, "", "get_submodule"], [136, 1, 1, "", "half"], [136, 2, 1, "", "input_spec"], [136, 2, 1, "", "input_spec_unbatched"], [136, 1, 1, "", "ipu"], [136, 2, 1, "", "is_spec_locked"], [136, 1, 1, "", "load_state_dict"], [136, 1, 1, "", "maybe_reset"], [136, 1, 1, "", "modules"], [136, 1, 1, "", "mtia"], [136, 1, 1, "", "named_buffers"], [136, 1, 1, "", "named_children"], [136, 1, 1, "", "named_modules"], [136, 1, 1, "", "named_parameters"], [136, 2, 1, "", "observation_keys"], [136, 2, 1, "", "observation_spec"], [136, 2, 1, "", "observation_spec_unbatched"], [136, 2, 1, "", "output_spec"], [136, 2, 1, "", "output_spec_unbatched"], [136, 1, 1, "", "parameters"], [136, 1, 1, "", "rand_action"], [136, 1, 1, "", "rand_step"], [136, 1, 1, "", "read_action"], [136, 1, 1, "", "read_done"], [136, 1, 1, "", "read_obs"], [136, 1, 1, "", "read_reward"], [136, 1, 1, "", "register_backward_hook"], [136, 1, 1, "", "register_buffer"], [136, 1, 1, "", "register_forward_hook"], [136, 1, 1, "", "register_forward_pre_hook"], [136, 1, 1, "", "register_full_backward_hook"], [136, 1, 1, "", "register_full_backward_pre_hook"], [136, 1, 1, "", "register_gym"], [136, 1, 1, "", "register_load_state_dict_post_hook"], [136, 1, 1, "", "register_load_state_dict_pre_hook"], [136, 1, 1, "", "register_module"], [136, 1, 1, "", "register_parameter"], [136, 1, 1, "", "register_state_dict_post_hook"], [136, 1, 1, "", "register_state_dict_pre_hook"], [136, 1, 1, "", "requires_grad_"], [136, 1, 1, "", "reset"], [136, 2, 1, "", "reset_keys"], [136, 2, 1, "", "reward_key"], [136, 2, 1, "", "reward_keys"], [136, 2, 1, "", "reward_spec"], [136, 2, 1, "", "reward_spec_unbatched"], [136, 1, 1, "", "rollout"], [136, 1, 1, "", "set_extra_state"], [136, 1, 1, "", "set_info_dict_reader"], [136, 1, 1, "", "set_seed"], [136, 1, 1, "", "set_spec_lock_"], [136, 1, 1, "", "set_submodule"], [136, 2, 1, "", "shape"], [136, 1, 1, "", "share_memory"], [136, 2, 1, "", "specs"], [136, 1, 1, "", "state_dict"], [136, 2, 1, "", "state_keys"], [136, 2, 1, "", "state_spec"], [136, 2, 1, "", "state_spec_unbatched"], [136, 1, 1, "", "step"], [136, 1, 1, "", "step_and_maybe_reset"], [136, 1, 1, "", "step_mdp"], [136, 1, 1, "", "to"], [136, 1, 1, "", "to_empty"], [136, 1, 1, "", "train"], [136, 1, 1, "", "type"], [136, 1, 1, "", "xpu"], [136, 1, 1, "", "zero_grad"]], "torchrl.envs.LLMHashingEnv": [[144, 2, 1, "", "action_key"], [144, 2, 1, "", "action_keys"], [144, 2, 1, "", "action_spec"], [144, 2, 1, "", "action_spec_unbatched"], [144, 1, 1, "", "add_module"], [144, 1, 1, "", "add_truncated_keys"], [144, 1, 1, "", "all_actions"], [144, 1, 1, "", "any_done"], [144, 1, 1, "", "append_transform"], [144, 1, 1, "", "apply"], [144, 1, 1, "", "auto_specs_"], [144, 2, 1, "", "batch_dims"], [144, 2, 1, "", "batch_locked"], [144, 2, 1, "", "batch_size"], [144, 1, 1, "", "bfloat16"], [144, 1, 1, "", "buffers"], [144, 1, 1, "", "cardinality"], [144, 1, 1, "", "check_env_specs"], [144, 1, 1, "", "children"], [144, 1, 1, "", "compile"], [144, 1, 1, "", "cpu"], [144, 1, 1, "", "cuda"], [144, 2, 1, "", "done_key"], [144, 2, 1, "", "done_keys"], [144, 2, 1, "", "done_keys_groups"], [144, 2, 1, "", "done_spec"], [144, 2, 1, "", "done_spec_unbatched"], [144, 1, 1, "", "double"], [144, 1, 1, "", "empty_cache"], [144, 1, 1, "", "eval"], [144, 1, 1, "", "extra_repr"], [144, 1, 1, "", "fake_tensordict"], [144, 1, 1, "", "float"], [144, 1, 1, "", "forward"], [144, 2, 1, "", "full_action_spec"], [144, 2, 1, "", "full_action_spec_unbatched"], [144, 2, 1, "", "full_done_spec"], [144, 2, 1, "", "full_done_spec_unbatched"], [144, 2, 1, "", "full_observation_spec_unbatched"], [144, 2, 1, "", "full_reward_spec"], [144, 2, 1, "", "full_reward_spec_unbatched"], [144, 2, 1, "", "full_state_spec"], [144, 2, 1, "", "full_state_spec_unbatched"], [144, 1, 1, "", "get_buffer"], [144, 1, 1, "", "get_extra_state"], [144, 1, 1, "", "get_parameter"], [144, 1, 1, "", "get_submodule"], [144, 1, 1, "", "half"], [144, 2, 1, "", "input_spec"], [144, 2, 1, "", "input_spec_unbatched"], [144, 1, 1, "", "ipu"], [144, 2, 1, "", "is_spec_locked"], [144, 1, 1, "", "load_state_dict"], [144, 1, 1, "", "make_tensordict"], [144, 1, 1, "", "maybe_reset"], [144, 1, 1, "", "modules"], [144, 1, 1, "", "mtia"], [144, 1, 1, "", "named_buffers"], [144, 1, 1, "", "named_children"], [144, 1, 1, "", "named_modules"], [144, 1, 1, "", "named_parameters"], [144, 2, 1, "", "observation_keys"], [144, 2, 1, "", "observation_spec"], [144, 2, 1, "", "observation_spec_unbatched"], [144, 2, 1, "", "output_spec"], [144, 2, 1, "", "output_spec_unbatched"], [144, 1, 1, "", "parameters"], [144, 1, 1, "", "rand_action"], [144, 1, 1, "", "rand_step"], [144, 1, 1, "", "register_backward_hook"], [144, 1, 1, "", "register_buffer"], [144, 1, 1, "", "register_forward_hook"], [144, 1, 1, "", "register_forward_pre_hook"], [144, 1, 1, "", "register_full_backward_hook"], [144, 1, 1, "", "register_full_backward_pre_hook"], [144, 1, 1, "", "register_gym"], [144, 1, 1, "", "register_load_state_dict_post_hook"], [144, 1, 1, "", "register_load_state_dict_pre_hook"], [144, 1, 1, "", "register_module"], [144, 1, 1, "", "register_parameter"], [144, 1, 1, "", "register_state_dict_post_hook"], [144, 1, 1, "", "register_state_dict_pre_hook"], [144, 1, 1, "", "requires_grad_"], [144, 1, 1, "", "reset"], [144, 2, 1, "", "reset_keys"], [144, 2, 1, "", "reward_key"], [144, 2, 1, "", "reward_keys"], [144, 2, 1, "", "reward_spec"], [144, 2, 1, "", "reward_spec_unbatched"], [144, 1, 1, "", "rollout"], [144, 1, 1, "", "set_extra_state"], [144, 1, 1, "", "set_seed"], [144, 1, 1, "", "set_spec_lock_"], [144, 1, 1, "", "set_submodule"], [144, 2, 1, "", "shape"], [144, 1, 1, "", "share_memory"], [144, 2, 1, "", "specs"], [144, 1, 1, "", "state_dict"], [144, 2, 1, "", "state_keys"], [144, 2, 1, "", "state_spec"], [144, 2, 1, "", "state_spec_unbatched"], [144, 1, 1, "", "step"], [144, 1, 1, "", "step_and_maybe_reset"], [144, 1, 1, "", "step_mdp"], [144, 1, 1, "", "to"], [144, 1, 1, "", "to_empty"], [144, 1, 1, "", "train"], [144, 1, 1, "", "type"], [144, 1, 1, "", "xpu"], [144, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[156, 2, 1, "", "action_key"], [156, 2, 1, "", "action_keys"], [156, 2, 1, "", "action_spec"], [156, 2, 1, "", "action_spec_unbatched"], [156, 1, 1, "", "add_module"], [156, 1, 1, "", "add_truncated_keys"], [156, 1, 1, "", "all_actions"], [156, 1, 1, "", "any_done"], [156, 1, 1, "", "append_transform"], [156, 1, 1, "", "apply"], [156, 1, 1, "", "auto_specs_"], [156, 2, 1, "", "batch_dims"], [156, 2, 1, "", "batch_locked"], [156, 2, 1, "", "batch_size"], [156, 1, 1, "", "bfloat16"], [156, 1, 1, "", "buffers"], [156, 1, 1, "", "cardinality"], [156, 1, 1, "", "check_env_specs"], [156, 1, 1, "", "children"], [156, 1, 1, "", "compile"], [156, 1, 1, "", "cpu"], [156, 1, 1, "", "cuda"], [156, 2, 1, "", "done_key"], [156, 2, 1, "", "done_keys"], [156, 2, 1, "", "done_keys_groups"], [156, 2, 1, "", "done_spec"], [156, 2, 1, "", "done_spec_unbatched"], [156, 1, 1, "", "double"], [156, 1, 1, "", "empty_cache"], [156, 1, 1, "", "eval"], [156, 1, 1, "", "extra_repr"], [156, 1, 1, "", "fake_tensordict"], [156, 1, 1, "", "float"], [156, 1, 1, "", "forward"], [156, 2, 1, "", "full_action_spec"], [156, 2, 1, "", "full_action_spec_unbatched"], [156, 2, 1, "", "full_done_spec"], [156, 2, 1, "", "full_done_spec_unbatched"], [156, 2, 1, "", "full_observation_spec_unbatched"], [156, 2, 1, "", "full_reward_spec"], [156, 2, 1, "", "full_reward_spec_unbatched"], [156, 2, 1, "", "full_state_spec"], [156, 2, 1, "", "full_state_spec_unbatched"], [156, 1, 1, "", "get_buffer"], [156, 1, 1, "", "get_extra_state"], [156, 1, 1, "", "get_parameter"], [156, 1, 1, "", "get_submodule"], [156, 1, 1, "", "half"], [156, 2, 1, "", "input_spec"], [156, 2, 1, "", "input_spec_unbatched"], [156, 1, 1, "", "ipu"], [156, 2, 1, "", "is_spec_locked"], [156, 1, 1, "", "load_state_dict"], [156, 1, 1, "", "maybe_reset"], [156, 1, 1, "", "modules"], [156, 1, 1, "", "mtia"], [156, 1, 1, "", "named_buffers"], [156, 1, 1, "", "named_children"], [156, 1, 1, "", "named_modules"], [156, 1, 1, "", "named_parameters"], [156, 2, 1, "", "observation_keys"], [156, 2, 1, "", "observation_spec"], [156, 2, 1, "", "observation_spec_unbatched"], [156, 2, 1, "", "output_spec"], [156, 2, 1, "", "output_spec_unbatched"], [156, 1, 1, "", "parameters"], [156, 1, 1, "", "rand_action"], [156, 1, 1, "", "rand_step"], [156, 1, 1, "", "register_backward_hook"], [156, 1, 1, "", "register_buffer"], [156, 1, 1, "", "register_forward_hook"], [156, 1, 1, "", "register_forward_pre_hook"], [156, 1, 1, "", "register_full_backward_hook"], [156, 1, 1, "", "register_full_backward_pre_hook"], [156, 1, 1, "", "register_gym"], [156, 1, 1, "", "register_load_state_dict_post_hook"], [156, 1, 1, "", "register_load_state_dict_pre_hook"], [156, 1, 1, "", "register_module"], [156, 1, 1, "", "register_parameter"], [156, 1, 1, "", "register_state_dict_post_hook"], [156, 1, 1, "", "register_state_dict_pre_hook"], [156, 1, 1, "", "requires_grad_"], [156, 1, 1, "", "reset"], [156, 2, 1, "", "reset_keys"], [156, 2, 1, "", "reward_key"], [156, 2, 1, "", "reward_keys"], [156, 2, 1, "", "reward_spec"], [156, 2, 1, "", "reward_spec_unbatched"], [156, 1, 1, "", "rollout"], [156, 1, 1, "", "set_extra_state"], [156, 1, 1, "", "set_seed"], [156, 1, 1, "", "set_spec_lock_"], [156, 1, 1, "", "set_submodule"], [156, 2, 1, "", "shape"], [156, 1, 1, "", "share_memory"], [156, 2, 1, "", "specs"], [156, 1, 1, "", "state_dict"], [156, 2, 1, "", "state_keys"], [156, 2, 1, "", "state_spec"], [156, 2, 1, "", "state_spec_unbatched"], [156, 1, 1, "", "step"], [156, 1, 1, "", "step_and_maybe_reset"], [156, 1, 1, "", "step_mdp"], [156, 1, 1, "", "to"], [156, 1, 1, "", "to_empty"], [156, 1, 1, "", "train"], [156, 1, 1, "", "type"], [156, 1, 1, "", "update_kwargs"], [156, 1, 1, "", "xpu"], [156, 1, 1, "", "zero_grad"]], "torchrl.envs.PendulumEnv": [[157, 2, 1, "", "action_key"], [157, 2, 1, "", "action_keys"], [157, 2, 1, "", "action_spec"], [157, 2, 1, "", "action_spec_unbatched"], [157, 1, 1, "", "add_module"], [157, 1, 1, "", "add_truncated_keys"], [157, 1, 1, "", "all_actions"], [157, 1, 1, "", "any_done"], [157, 1, 1, "", "append_transform"], [157, 1, 1, "", "apply"], [157, 1, 1, "", "auto_specs_"], [157, 2, 1, "", "batch_dims"], [157, 2, 1, "", "batch_size"], [157, 1, 1, "", "bfloat16"], [157, 1, 1, "", "buffers"], [157, 1, 1, "", "cardinality"], [157, 1, 1, "", "check_env_specs"], [157, 1, 1, "", "children"], [157, 1, 1, "", "compile"], [157, 1, 1, "", "cpu"], [157, 1, 1, "", "cuda"], [157, 2, 1, "", "done_key"], [157, 2, 1, "", "done_keys"], [157, 2, 1, "", "done_keys_groups"], [157, 2, 1, "", "done_spec"], [157, 2, 1, "", "done_spec_unbatched"], [157, 1, 1, "", "double"], [157, 1, 1, "", "empty_cache"], [157, 1, 1, "", "eval"], [157, 1, 1, "", "extra_repr"], [157, 1, 1, "", "fake_tensordict"], [157, 1, 1, "", "float"], [157, 1, 1, "", "forward"], [157, 2, 1, "", "full_action_spec"], [157, 2, 1, "", "full_action_spec_unbatched"], [157, 2, 1, "", "full_done_spec"], [157, 2, 1, "", "full_done_spec_unbatched"], [157, 2, 1, "", "full_observation_spec_unbatched"], [157, 2, 1, "", "full_reward_spec"], [157, 2, 1, "", "full_reward_spec_unbatched"], [157, 2, 1, "", "full_state_spec"], [157, 2, 1, "", "full_state_spec_unbatched"], [157, 1, 1, "", "gen_params"], [157, 1, 1, "", "get_buffer"], [157, 1, 1, "", "get_extra_state"], [157, 1, 1, "", "get_parameter"], [157, 1, 1, "", "get_submodule"], [157, 1, 1, "", "half"], [157, 2, 1, "", "input_spec"], [157, 2, 1, "", "input_spec_unbatched"], [157, 1, 1, "", "ipu"], [157, 2, 1, "", "is_spec_locked"], [157, 1, 1, "", "load_state_dict"], [157, 1, 1, "", "maybe_reset"], [157, 1, 1, "", "modules"], [157, 1, 1, "", "mtia"], [157, 1, 1, "", "named_buffers"], [157, 1, 1, "", "named_children"], [157, 1, 1, "", "named_modules"], [157, 1, 1, "", "named_parameters"], [157, 2, 1, "", "observation_keys"], [157, 2, 1, "", "observation_spec"], [157, 2, 1, "", "observation_spec_unbatched"], [157, 2, 1, "", "output_spec"], [157, 2, 1, "", "output_spec_unbatched"], [157, 1, 1, "", "parameters"], [157, 1, 1, "", "rand_action"], [157, 1, 1, "", "rand_step"], [157, 1, 1, "", "register_backward_hook"], [157, 1, 1, "", "register_buffer"], [157, 1, 1, "", "register_forward_hook"], [157, 1, 1, "", "register_forward_pre_hook"], [157, 1, 1, "", "register_full_backward_hook"], [157, 1, 1, "", "register_full_backward_pre_hook"], [157, 1, 1, "", "register_gym"], [157, 1, 1, "", "register_load_state_dict_post_hook"], [157, 1, 1, "", "register_load_state_dict_pre_hook"], [157, 1, 1, "", "register_module"], [157, 1, 1, "", "register_parameter"], [157, 1, 1, "", "register_state_dict_post_hook"], [157, 1, 1, "", "register_state_dict_pre_hook"], [157, 1, 1, "", "requires_grad_"], [157, 1, 1, "", "reset"], [157, 2, 1, "", "reset_keys"], [157, 2, 1, "", "reward_key"], [157, 2, 1, "", "reward_keys"], [157, 2, 1, "", "reward_spec"], [157, 2, 1, "", "reward_spec_unbatched"], [157, 1, 1, "", "rollout"], [157, 1, 1, "", "set_extra_state"], [157, 1, 1, "", "set_seed"], [157, 1, 1, "", "set_spec_lock_"], [157, 1, 1, "", "set_submodule"], [157, 2, 1, "", "shape"], [157, 1, 1, "", "share_memory"], [157, 2, 1, "", "specs"], [157, 1, 1, "", "state_dict"], [157, 2, 1, "", "state_keys"], [157, 2, 1, "", "state_spec"], [157, 2, 1, "", "state_spec_unbatched"], [157, 1, 1, "", "step"], [157, 1, 1, "", "step_and_maybe_reset"], [157, 1, 1, "", "step_mdp"], [157, 1, 1, "", "to"], [157, 1, 1, "", "to_empty"], [157, 1, 1, "", "train"], [157, 1, 1, "", "type"], [157, 1, 1, "", "xpu"], [157, 1, 1, "", "zero_grad"]], "torchrl.envs.ProcessorAsyncEnvPool": [[160, 1, 1, "", "_setup"], [160, 2, 1, "", "action_key"], [160, 2, 1, "", "action_keys"], [160, 2, 1, "", "action_spec"], [160, 2, 1, "", "action_spec_unbatched"], [160, 1, 1, "", "add_module"], [160, 1, 1, "", "add_truncated_keys"], [160, 1, 1, "", "all_actions"], [160, 1, 1, "", "any_done"], [160, 1, 1, "", "append_transform"], [160, 1, 1, "", "apply"], [160, 1, 1, "", "async_reset_recv"], [160, 1, 1, "", "async_reset_send"], [160, 1, 1, "", "async_step_recv"], [160, 1, 1, "", "async_step_send"], [160, 1, 1, "", "auto_specs_"], [160, 2, 1, "", "batch_dims"], [160, 2, 1, "", "batch_locked"], [160, 2, 1, "", "batch_size"], [160, 1, 1, "", "bfloat16"], [160, 1, 1, "", "buffers"], [160, 1, 1, "", "cardinality"], [160, 1, 1, "", "check_env_specs"], [160, 1, 1, "", "children"], [160, 1, 1, "", "compile"], [160, 1, 1, "", "cpu"], [160, 1, 1, "", "cuda"], [160, 2, 1, "", "done_key"], [160, 2, 1, "", "done_keys"], [160, 2, 1, "", "done_keys_groups"], [160, 2, 1, "", "done_spec"], [160, 2, 1, "", "done_spec_unbatched"], [160, 1, 1, "", "double"], [160, 1, 1, "", "empty_cache"], [160, 1, 1, "", "eval"], [160, 1, 1, "", "extra_repr"], [160, 1, 1, "", "fake_tensordict"], [160, 1, 1, "", "float"], [160, 1, 1, "", "forward"], [160, 2, 1, "", "full_action_spec"], [160, 2, 1, "", "full_action_spec_unbatched"], [160, 2, 1, "", "full_done_spec"], [160, 2, 1, "", "full_done_spec_unbatched"], [160, 2, 1, "", "full_observation_spec_unbatched"], [160, 2, 1, "", "full_reward_spec"], [160, 2, 1, "", "full_reward_spec_unbatched"], [160, 2, 1, "", "full_state_spec"], [160, 2, 1, "", "full_state_spec_unbatched"], [160, 1, 1, "", "get_buffer"], [160, 1, 1, "", "get_extra_state"], [160, 1, 1, "", "get_parameter"], [160, 1, 1, "", "get_submodule"], [160, 1, 1, "", "half"], [160, 2, 1, "", "input_spec"], [160, 2, 1, "", "input_spec_unbatched"], [160, 1, 1, "", "ipu"], [160, 2, 1, "", "is_spec_locked"], [160, 1, 1, "", "load_state_dict"], [160, 1, 1, "", "maybe_reset"], [160, 1, 1, "", "modules"], [160, 1, 1, "", "mtia"], [160, 1, 1, "", "named_buffers"], [160, 1, 1, "", "named_children"], [160, 1, 1, "", "named_modules"], [160, 1, 1, "", "named_parameters"], [160, 2, 1, "", "observation_keys"], [160, 2, 1, "", "observation_spec"], [160, 2, 1, "", "observation_spec_unbatched"], [160, 2, 1, "", "output_spec"], [160, 2, 1, "", "output_spec_unbatched"], [160, 1, 1, "", "parameters"], [160, 1, 1, "", "rand_action"], [160, 1, 1, "", "rand_step"], [160, 1, 1, "", "register_backward_hook"], [160, 1, 1, "", "register_buffer"], [160, 1, 1, "", "register_forward_hook"], [160, 1, 1, "", "register_forward_pre_hook"], [160, 1, 1, "", "register_full_backward_hook"], [160, 1, 1, "", "register_full_backward_pre_hook"], [160, 1, 1, "", "register_gym"], [160, 1, 1, "", "register_load_state_dict_post_hook"], [160, 1, 1, "", "register_load_state_dict_pre_hook"], [160, 1, 1, "", "register_module"], [160, 1, 1, "", "register_parameter"], [160, 1, 1, "", "register_state_dict_post_hook"], [160, 1, 1, "", "register_state_dict_pre_hook"], [160, 1, 1, "", "requires_grad_"], [160, 1, 1, "", "reset"], [160, 2, 1, "", "reset_keys"], [160, 2, 1, "", "reward_key"], [160, 2, 1, "", "reward_keys"], [160, 2, 1, "", "reward_spec"], [160, 2, 1, "", "reward_spec_unbatched"], [160, 1, 1, "", "rollout"], [160, 1, 1, "", "set_extra_state"], [160, 1, 1, "", "set_seed"], [160, 1, 1, "", "set_spec_lock_"], [160, 1, 1, "", "set_submodule"], [160, 2, 1, "", "shape"], [160, 1, 1, "", "share_memory"], [160, 1, 1, "", "shutdown"], [160, 2, 1, "", "specs"], [160, 1, 1, "", "state_dict"], [160, 2, 1, "", "state_keys"], [160, 2, 1, "", "state_spec"], [160, 2, 1, "", "state_spec_unbatched"], [160, 1, 1, "", "step"], [160, 1, 1, "", "step_and_maybe_reset"], [160, 1, 1, "", "step_mdp"], [160, 1, 1, "", "to"], [160, 1, 1, "", "to_empty"], [160, 1, 1, "", "train"], [160, 1, 1, "", "type"], [160, 1, 1, "", "xpu"], [160, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[165, 2, 1, "", "action_key"], [165, 2, 1, "", "action_keys"], [165, 2, 1, "", "action_spec"], [165, 2, 1, "", "action_spec_unbatched"], [165, 1, 1, "", "add_module"], [165, 1, 1, "", "add_truncated_keys"], [165, 1, 1, "", "all_actions"], [165, 1, 1, "", "any_done"], [165, 1, 1, "", "append_transform"], [165, 1, 1, "", "apply"], [165, 1, 1, "", "auto_specs_"], [165, 2, 1, "", "batch_dims"], [165, 2, 1, "", "batch_locked"], [165, 2, 1, "", "batch_size"], [165, 1, 1, "", "bfloat16"], [165, 1, 1, "", "buffers"], [165, 1, 1, "", "cardinality"], [165, 1, 1, "", "check_env_specs"], [165, 1, 1, "", "children"], [165, 1, 1, "", "compile"], [165, 1, 1, "", "cpu"], [165, 1, 1, "", "cuda"], [165, 2, 1, "", "done_key"], [165, 2, 1, "", "done_keys"], [165, 2, 1, "", "done_keys_groups"], [165, 2, 1, "", "done_spec"], [165, 2, 1, "", "done_spec_unbatched"], [165, 1, 1, "", "double"], [165, 1, 1, "", "empty_cache"], [165, 1, 1, "", "eval"], [165, 1, 1, "", "extra_repr"], [165, 1, 1, "", "fake_tensordict"], [165, 1, 1, "", "float"], [165, 1, 1, "", "forward"], [165, 2, 1, "", "full_action_spec"], [165, 2, 1, "", "full_action_spec_unbatched"], [165, 2, 1, "", "full_done_spec"], [165, 2, 1, "", "full_done_spec_unbatched"], [165, 2, 1, "", "full_observation_spec_unbatched"], [165, 2, 1, "", "full_reward_spec"], [165, 2, 1, "", "full_reward_spec_unbatched"], [165, 2, 1, "", "full_state_spec"], [165, 2, 1, "", "full_state_spec_unbatched"], [165, 1, 1, "", "get_buffer"], [165, 1, 1, "", "get_extra_state"], [165, 1, 1, "", "get_parameter"], [165, 1, 1, "", "get_submodule"], [165, 1, 1, "", "half"], [165, 2, 1, "", "input_spec"], [165, 2, 1, "", "input_spec_unbatched"], [165, 1, 1, "", "ipu"], [165, 2, 1, "", "is_spec_locked"], [165, 1, 1, "", "load_state_dict"], [165, 1, 1, "", "maybe_reset"], [165, 1, 1, "", "modules"], [165, 1, 1, "", "mtia"], [165, 1, 1, "", "named_buffers"], [165, 1, 1, "", "named_children"], [165, 1, 1, "", "named_modules"], [165, 1, 1, "", "named_parameters"], [165, 2, 1, "", "observation_keys"], [165, 2, 1, "", "observation_spec"], [165, 2, 1, "", "observation_spec_unbatched"], [165, 2, 1, "", "output_spec"], [165, 2, 1, "", "output_spec_unbatched"], [165, 1, 1, "", "parameters"], [165, 1, 1, "", "rand_action"], [165, 1, 1, "", "rand_step"], [165, 1, 1, "", "register_backward_hook"], [165, 1, 1, "", "register_buffer"], [165, 1, 1, "", "register_forward_hook"], [165, 1, 1, "", "register_forward_pre_hook"], [165, 1, 1, "", "register_full_backward_hook"], [165, 1, 1, "", "register_full_backward_pre_hook"], [165, 1, 1, "", "register_gym"], [165, 1, 1, "", "register_load_state_dict_post_hook"], [165, 1, 1, "", "register_load_state_dict_pre_hook"], [165, 1, 1, "", "register_module"], [165, 1, 1, "", "register_parameter"], [165, 1, 1, "", "register_state_dict_post_hook"], [165, 1, 1, "", "register_state_dict_pre_hook"], [165, 1, 1, "", "requires_grad_"], [165, 1, 1, "", "reset"], [165, 2, 1, "", "reset_keys"], [165, 2, 1, "", "reward_key"], [165, 2, 1, "", "reward_keys"], [165, 2, 1, "", "reward_spec"], [165, 2, 1, "", "reward_spec_unbatched"], [165, 1, 1, "", "rollout"], [165, 1, 1, "", "set_extra_state"], [165, 1, 1, "", "set_seed"], [165, 1, 1, "", "set_spec_lock_"], [165, 1, 1, "", "set_submodule"], [165, 2, 1, "", "shape"], [165, 1, 1, "", "share_memory"], [165, 2, 1, "", "specs"], [165, 1, 1, "", "state_dict"], [165, 2, 1, "", "state_keys"], [165, 2, 1, "", "state_spec"], [165, 2, 1, "", "state_spec_unbatched"], [165, 1, 1, "", "step"], [165, 1, 1, "", "step_and_maybe_reset"], [165, 1, 1, "", "step_mdp"], [165, 1, 1, "", "to"], [165, 1, 1, "", "to_empty"], [165, 1, 1, "", "train"], [165, 1, 1, "", "type"], [165, 1, 1, "", "update_kwargs"], [165, 1, 1, "", "xpu"], [165, 1, 1, "", "zero_grad"]], "torchrl.envs.ThreadingAsyncEnvPool": [[166, 1, 1, "", "_setup"], [166, 2, 1, "", "action_key"], [166, 2, 1, "", "action_keys"], [166, 2, 1, "", "action_spec"], [166, 2, 1, "", "action_spec_unbatched"], [166, 1, 1, "", "add_module"], [166, 1, 1, "", "add_truncated_keys"], [166, 1, 1, "", "all_actions"], [166, 1, 1, "", "any_done"], [166, 1, 1, "", "append_transform"], [166, 1, 1, "", "apply"], [166, 1, 1, "", "async_reset_recv"], [166, 1, 1, "", "async_reset_send"], [166, 1, 1, "", "async_step_recv"], [166, 1, 1, "", "async_step_send"], [166, 1, 1, "", "auto_specs_"], [166, 2, 1, "", "batch_dims"], [166, 2, 1, "", "batch_locked"], [166, 2, 1, "", "batch_size"], [166, 1, 1, "", "bfloat16"], [166, 1, 1, "", "buffers"], [166, 1, 1, "", "cardinality"], [166, 1, 1, "", "check_env_specs"], [166, 1, 1, "", "children"], [166, 1, 1, "", "compile"], [166, 1, 1, "", "cpu"], [166, 1, 1, "", "cuda"], [166, 2, 1, "", "done_key"], [166, 2, 1, "", "done_keys"], [166, 2, 1, "", "done_keys_groups"], [166, 2, 1, "", "done_spec"], [166, 2, 1, "", "done_spec_unbatched"], [166, 1, 1, "", "double"], [166, 1, 1, "", "empty_cache"], [166, 1, 1, "", "eval"], [166, 1, 1, "", "extra_repr"], [166, 1, 1, "", "fake_tensordict"], [166, 1, 1, "", "float"], [166, 1, 1, "", "forward"], [166, 2, 1, "", "full_action_spec"], [166, 2, 1, "", "full_action_spec_unbatched"], [166, 2, 1, "", "full_done_spec"], [166, 2, 1, "", "full_done_spec_unbatched"], [166, 2, 1, "", "full_observation_spec_unbatched"], [166, 2, 1, "", "full_reward_spec"], [166, 2, 1, "", "full_reward_spec_unbatched"], [166, 2, 1, "", "full_state_spec"], [166, 2, 1, "", "full_state_spec_unbatched"], [166, 1, 1, "", "get_buffer"], [166, 1, 1, "", "get_extra_state"], [166, 1, 1, "", "get_parameter"], [166, 1, 1, "", "get_submodule"], [166, 1, 1, "", "half"], [166, 2, 1, "", "input_spec"], [166, 2, 1, "", "input_spec_unbatched"], [166, 1, 1, "", "ipu"], [166, 2, 1, "", "is_spec_locked"], [166, 1, 1, "", "load_state_dict"], [166, 1, 1, "", "maybe_reset"], [166, 1, 1, "", "modules"], [166, 1, 1, "", "mtia"], [166, 1, 1, "", "named_buffers"], [166, 1, 1, "", "named_children"], [166, 1, 1, "", "named_modules"], [166, 1, 1, "", "named_parameters"], [166, 2, 1, "", "observation_keys"], [166, 2, 1, "", "observation_spec"], [166, 2, 1, "", "observation_spec_unbatched"], [166, 2, 1, "", "output_spec"], [166, 2, 1, "", "output_spec_unbatched"], [166, 1, 1, "", "parameters"], [166, 1, 1, "", "rand_action"], [166, 1, 1, "", "rand_step"], [166, 1, 1, "", "register_backward_hook"], [166, 1, 1, "", "register_buffer"], [166, 1, 1, "", "register_forward_hook"], [166, 1, 1, "", "register_forward_pre_hook"], [166, 1, 1, "", "register_full_backward_hook"], [166, 1, 1, "", "register_full_backward_pre_hook"], [166, 1, 1, "", "register_gym"], [166, 1, 1, "", "register_load_state_dict_post_hook"], [166, 1, 1, "", "register_load_state_dict_pre_hook"], [166, 1, 1, "", "register_module"], [166, 1, 1, "", "register_parameter"], [166, 1, 1, "", "register_state_dict_post_hook"], [166, 1, 1, "", "register_state_dict_pre_hook"], [166, 1, 1, "", "requires_grad_"], [166, 1, 1, "", "reset"], [166, 2, 1, "", "reset_keys"], [166, 2, 1, "", "reward_key"], [166, 2, 1, "", "reward_keys"], [166, 2, 1, "", "reward_spec"], [166, 2, 1, "", "reward_spec_unbatched"], [166, 1, 1, "", "rollout"], [166, 1, 1, "", "set_extra_state"], [166, 1, 1, "", "set_seed"], [166, 1, 1, "", "set_spec_lock_"], [166, 1, 1, "", "set_submodule"], [166, 2, 1, "", "shape"], [166, 1, 1, "", "share_memory"], [166, 1, 1, "", "shutdown"], [166, 2, 1, "", "specs"], [166, 1, 1, "", "state_dict"], [166, 2, 1, "", "state_keys"], [166, 2, 1, "", "state_spec"], [166, 2, 1, "", "state_spec_unbatched"], [166, 1, 1, "", "step"], [166, 1, 1, "", "step_and_maybe_reset"], [166, 1, 1, "", "step_mdp"], [166, 1, 1, "", "to"], [166, 1, 1, "", "to_empty"], [166, 1, 1, "", "train"], [166, 1, 1, "", "type"], [166, 1, 1, "", "xpu"], [166, 1, 1, "", "zero_grad"]], "torchrl.envs.TicTacToeEnv": [[167, 2, 1, "", "action_key"], [167, 2, 1, "", "action_keys"], [167, 2, 1, "", "action_spec"], [167, 2, 1, "", "action_spec_unbatched"], [167, 1, 1, "", "add_module"], [167, 1, 1, "", "add_truncated_keys"], [167, 1, 1, "", "all_actions"], [167, 1, 1, "", "any_done"], [167, 1, 1, "", "append_transform"], [167, 1, 1, "", "apply"], [167, 1, 1, "", "auto_specs_"], [167, 2, 1, "", "batch_dims"], [167, 2, 1, "", "batch_size"], [167, 1, 1, "", "bfloat16"], [167, 1, 1, "", "buffers"], [167, 1, 1, "", "cardinality"], [167, 1, 1, "", "check_env_specs"], [167, 1, 1, "", "children"], [167, 1, 1, "", "compile"], [167, 1, 1, "", "cpu"], [167, 1, 1, "", "cuda"], [167, 2, 1, "", "done_key"], [167, 2, 1, "", "done_keys"], [167, 2, 1, "", "done_keys_groups"], [167, 2, 1, "", "done_spec"], [167, 2, 1, "", "done_spec_unbatched"], [167, 1, 1, "", "double"], [167, 1, 1, "", "empty_cache"], [167, 1, 1, "", "eval"], [167, 1, 1, "", "extra_repr"], [167, 1, 1, "", "fake_tensordict"], [167, 1, 1, "", "float"], [167, 1, 1, "", "forward"], [167, 2, 1, "", "full_action_spec"], [167, 2, 1, "", "full_action_spec_unbatched"], [167, 2, 1, "", "full_done_spec"], [167, 2, 1, "", "full_done_spec_unbatched"], [167, 2, 1, "", "full_observation_spec_unbatched"], [167, 2, 1, "", "full_reward_spec"], [167, 2, 1, "", "full_reward_spec_unbatched"], [167, 2, 1, "", "full_state_spec"], [167, 2, 1, "", "full_state_spec_unbatched"], [167, 1, 1, "", "get_buffer"], [167, 1, 1, "", "get_extra_state"], [167, 1, 1, "", "get_parameter"], [167, 1, 1, "", "get_submodule"], [167, 1, 1, "", "half"], [167, 2, 1, "", "input_spec"], [167, 2, 1, "", "input_spec_unbatched"], [167, 1, 1, "", "ipu"], [167, 2, 1, "", "is_spec_locked"], [167, 1, 1, "", "load_state_dict"], [167, 1, 1, "", "maybe_reset"], [167, 1, 1, "", "modules"], [167, 1, 1, "", "mtia"], [167, 1, 1, "", "named_buffers"], [167, 1, 1, "", "named_children"], [167, 1, 1, "", "named_modules"], [167, 1, 1, "", "named_parameters"], [167, 2, 1, "", "observation_keys"], [167, 2, 1, "", "observation_spec"], [167, 2, 1, "", "observation_spec_unbatched"], [167, 2, 1, "", "output_spec"], [167, 2, 1, "", "output_spec_unbatched"], [167, 1, 1, "", "parameters"], [167, 1, 1, "", "rand_action"], [167, 1, 1, "", "rand_step"], [167, 1, 1, "", "register_backward_hook"], [167, 1, 1, "", "register_buffer"], [167, 1, 1, "", "register_forward_hook"], [167, 1, 1, "", "register_forward_pre_hook"], [167, 1, 1, "", "register_full_backward_hook"], [167, 1, 1, "", "register_full_backward_pre_hook"], [167, 1, 1, "", "register_gym"], [167, 1, 1, "", "register_load_state_dict_post_hook"], [167, 1, 1, "", "register_load_state_dict_pre_hook"], [167, 1, 1, "", "register_module"], [167, 1, 1, "", "register_parameter"], [167, 1, 1, "", "register_state_dict_post_hook"], [167, 1, 1, "", "register_state_dict_pre_hook"], [167, 1, 1, "", "requires_grad_"], [167, 1, 1, "", "reset"], [167, 2, 1, "", "reset_keys"], [167, 2, 1, "", "reward_key"], [167, 2, 1, "", "reward_keys"], [167, 2, 1, "", "reward_spec"], [167, 2, 1, "", "reward_spec_unbatched"], [167, 1, 1, "", "rollout"], [167, 1, 1, "", "set_extra_state"], [167, 1, 1, "", "set_seed"], [167, 1, 1, "", "set_spec_lock_"], [167, 1, 1, "", "set_submodule"], [167, 2, 1, "", "shape"], [167, 1, 1, "", "share_memory"], [167, 2, 1, "", "specs"], [167, 1, 1, "", "state_dict"], [167, 2, 1, "", "state_keys"], [167, 2, 1, "", "state_spec"], [167, 2, 1, "", "state_spec_unbatched"], [167, 1, 1, "", "step"], [167, 1, 1, "", "step_and_maybe_reset"], [167, 1, 1, "", "step_mdp"], [167, 1, 1, "", "to"], [167, 1, 1, "", "to_empty"], [167, 1, 1, "", "train"], [167, 1, 1, "", "type"], [167, 1, 1, "", "xpu"], [167, 1, 1, "", "zero_grad"]], "torchrl.envs.llm": [[177, 0, 1, "", "ChatEnv"], [178, 0, 1, "", "DatasetChatEnv"], [179, 0, 1, "", "GSM8KEnv"], [180, 0, 1, "", "GSM8KPrepareQuestion"], [181, 0, 1, "", "GSM8KRewardParser"], [182, 0, 1, "", "IFEvalEnv"], [183, 0, 1, "", "IFEvalScoreData"], [184, 0, 1, "", "IfEvalScorer"], [185, 0, 1, "", "LLMEnv"], [186, 0, 1, "", "LLMHashingEnv"], [187, 0, 1, "", "MLGymWrapper"], [188, 0, 1, "", "make_gsm8k_env"], [189, 0, 1, "", "make_mlgym"]], "torchrl.envs.llm.ChatEnv": [[177, 2, 1, "", "action_key"], [177, 2, 1, "", "action_keys"], [177, 2, 1, "", "action_spec"], [177, 2, 1, "", "action_spec_unbatched"], [177, 1, 1, "", "add_module"], [177, 1, 1, "", "add_truncated_keys"], [177, 1, 1, "", "all_actions"], [177, 1, 1, "", "any_done"], [177, 1, 1, "", "append_transform"], [177, 1, 1, "", "apply"], [177, 1, 1, "", "auto_specs_"], [177, 2, 1, "", "batch_dims"], [177, 2, 1, "", "batch_locked"], [177, 2, 1, "", "batch_size"], [177, 1, 1, "", "bfloat16"], [177, 1, 1, "", "buffers"], [177, 1, 1, "", "cardinality"], [177, 1, 1, "", "check_env_specs"], [177, 1, 1, "", "children"], [177, 1, 1, "", "compile"], [177, 1, 1, "", "cpu"], [177, 1, 1, "", "cuda"], [177, 2, 1, "", "done_key"], [177, 2, 1, "", "done_keys"], [177, 2, 1, "", "done_keys_groups"], [177, 2, 1, "", "done_spec"], [177, 2, 1, "", "done_spec_unbatched"], [177, 1, 1, "", "double"], [177, 1, 1, "", "empty_cache"], [177, 1, 1, "", "eval"], [177, 1, 1, "", "extra_repr"], [177, 1, 1, "", "fake_tensordict"], [177, 1, 1, "", "float"], [177, 1, 1, "", "forward"], [177, 2, 1, "", "full_action_spec"], [177, 2, 1, "", "full_action_spec_unbatched"], [177, 2, 1, "", "full_done_spec"], [177, 2, 1, "", "full_done_spec_unbatched"], [177, 2, 1, "", "full_observation_spec_unbatched"], [177, 2, 1, "", "full_reward_spec"], [177, 2, 1, "", "full_reward_spec_unbatched"], [177, 2, 1, "", "full_state_spec"], [177, 2, 1, "", "full_state_spec_unbatched"], [177, 1, 1, "", "get_buffer"], [177, 1, 1, "", "get_extra_state"], [177, 1, 1, "", "get_parameter"], [177, 1, 1, "", "get_submodule"], [177, 1, 1, "", "half"], [177, 2, 1, "", "input_spec"], [177, 2, 1, "", "input_spec_unbatched"], [177, 1, 1, "", "ipu"], [177, 2, 1, "", "is_spec_locked"], [177, 1, 1, "", "load_state_dict"], [177, 1, 1, "", "maybe_reset"], [177, 1, 1, "", "modules"], [177, 1, 1, "", "mtia"], [177, 1, 1, "", "named_buffers"], [177, 1, 1, "", "named_children"], [177, 1, 1, "", "named_modules"], [177, 1, 1, "", "named_parameters"], [177, 2, 1, "", "observation_keys"], [177, 2, 1, "", "observation_spec"], [177, 2, 1, "", "observation_spec_unbatched"], [177, 2, 1, "", "output_spec"], [177, 2, 1, "", "output_spec_unbatched"], [177, 1, 1, "", "parameters"], [177, 1, 1, "", "rand_action"], [177, 1, 1, "", "rand_step"], [177, 1, 1, "", "register_backward_hook"], [177, 1, 1, "", "register_buffer"], [177, 1, 1, "", "register_forward_hook"], [177, 1, 1, "", "register_forward_pre_hook"], [177, 1, 1, "", "register_full_backward_hook"], [177, 1, 1, "", "register_full_backward_pre_hook"], [177, 1, 1, "", "register_gym"], [177, 1, 1, "", "register_load_state_dict_post_hook"], [177, 1, 1, "", "register_load_state_dict_pre_hook"], [177, 1, 1, "", "register_module"], [177, 1, 1, "", "register_parameter"], [177, 1, 1, "", "register_state_dict_post_hook"], [177, 1, 1, "", "register_state_dict_pre_hook"], [177, 1, 1, "", "requires_grad_"], [177, 1, 1, "id0", "reset"], [177, 2, 1, "", "reset_keys"], [177, 2, 1, "", "reward_key"], [177, 2, 1, "", "reward_keys"], [177, 2, 1, "", "reward_spec"], [177, 2, 1, "", "reward_spec_unbatched"], [177, 1, 1, "", "rollout"], [177, 1, 1, "", "set_extra_state"], [177, 1, 1, "", "set_seed"], [177, 1, 1, "", "set_spec_lock_"], [177, 1, 1, "", "set_submodule"], [177, 2, 1, "", "shape"], [177, 1, 1, "", "share_memory"], [177, 2, 1, "", "specs"], [177, 1, 1, "", "state_dict"], [177, 2, 1, "", "state_keys"], [177, 2, 1, "", "state_spec"], [177, 2, 1, "", "state_spec_unbatched"], [177, 1, 1, "id1", "step"], [177, 1, 1, "", "step_and_maybe_reset"], [177, 1, 1, "", "step_mdp"], [177, 1, 1, "", "to"], [177, 1, 1, "", "to_empty"], [177, 1, 1, "", "train"], [177, 1, 1, "", "type"], [177, 1, 1, "", "xpu"], [177, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.DatasetChatEnv": [[178, 2, 1, "", "action_key"], [178, 2, 1, "", "action_keys"], [178, 2, 1, "", "action_spec"], [178, 2, 1, "", "action_spec_unbatched"], [178, 1, 1, "", "add_module"], [178, 1, 1, "", "add_truncated_keys"], [178, 1, 1, "", "all_actions"], [178, 1, 1, "", "any_done"], [178, 1, 1, "", "append_transform"], [178, 1, 1, "", "apply"], [178, 1, 1, "", "auto_specs_"], [178, 2, 1, "", "batch_dims"], [178, 2, 1, "", "batch_locked"], [178, 2, 1, "", "batch_size"], [178, 1, 1, "", "bfloat16"], [178, 1, 1, "", "buffers"], [178, 1, 1, "", "cardinality"], [178, 1, 1, "", "check_env_specs"], [178, 1, 1, "", "children"], [178, 1, 1, "", "compile"], [178, 1, 1, "", "cpu"], [178, 1, 1, "", "cuda"], [178, 2, 1, "", "done_key"], [178, 2, 1, "", "done_keys"], [178, 2, 1, "", "done_keys_groups"], [178, 2, 1, "", "done_spec"], [178, 2, 1, "", "done_spec_unbatched"], [178, 1, 1, "", "double"], [178, 1, 1, "", "empty_cache"], [178, 1, 1, "", "eval"], [178, 1, 1, "", "extra_repr"], [178, 1, 1, "", "fake_tensordict"], [178, 1, 1, "", "float"], [178, 1, 1, "", "forward"], [178, 2, 1, "", "full_action_spec"], [178, 2, 1, "", "full_action_spec_unbatched"], [178, 2, 1, "", "full_done_spec"], [178, 2, 1, "", "full_done_spec_unbatched"], [178, 2, 1, "", "full_observation_spec_unbatched"], [178, 2, 1, "", "full_reward_spec"], [178, 2, 1, "", "full_reward_spec_unbatched"], [178, 2, 1, "", "full_state_spec"], [178, 2, 1, "", "full_state_spec_unbatched"], [178, 1, 1, "", "get_buffer"], [178, 1, 1, "", "get_extra_state"], [178, 1, 1, "", "get_parameter"], [178, 1, 1, "", "get_submodule"], [178, 1, 1, "", "half"], [178, 2, 1, "", "input_spec"], [178, 2, 1, "", "input_spec_unbatched"], [178, 1, 1, "", "insert_transform"], [178, 1, 1, "", "ipu"], [178, 2, 1, "", "is_spec_locked"], [178, 1, 1, "", "load_state_dict"], [178, 1, 1, "", "maybe_reset"], [178, 1, 1, "", "modules"], [178, 1, 1, "", "mtia"], [178, 1, 1, "", "named_buffers"], [178, 1, 1, "", "named_children"], [178, 1, 1, "", "named_modules"], [178, 1, 1, "", "named_parameters"], [178, 2, 1, "", "observation_keys"], [178, 2, 1, "", "observation_spec"], [178, 2, 1, "", "observation_spec_unbatched"], [178, 2, 1, "", "output_spec"], [178, 2, 1, "", "output_spec_unbatched"], [178, 1, 1, "", "parameters"], [178, 1, 1, "", "rand_action"], [178, 1, 1, "", "rand_step"], [178, 1, 1, "", "register_backward_hook"], [178, 1, 1, "", "register_buffer"], [178, 1, 1, "", "register_forward_hook"], [178, 1, 1, "", "register_forward_pre_hook"], [178, 1, 1, "", "register_full_backward_hook"], [178, 1, 1, "", "register_full_backward_pre_hook"], [178, 1, 1, "", "register_gym"], [178, 1, 1, "", "register_load_state_dict_post_hook"], [178, 1, 1, "", "register_load_state_dict_pre_hook"], [178, 1, 1, "", "register_module"], [178, 1, 1, "", "register_parameter"], [178, 1, 1, "", "register_state_dict_post_hook"], [178, 1, 1, "", "register_state_dict_pre_hook"], [178, 1, 1, "", "requires_grad_"], [178, 1, 1, "", "reset"], [178, 2, 1, "", "reset_keys"], [178, 2, 1, "", "reward_key"], [178, 2, 1, "", "reward_keys"], [178, 2, 1, "", "reward_spec"], [178, 2, 1, "", "reward_spec_unbatched"], [178, 1, 1, "", "rollout"], [178, 1, 1, "", "set_extra_state"], [178, 1, 1, "", "set_missing_tolerance"], [178, 1, 1, "", "set_seed"], [178, 1, 1, "", "set_spec_lock_"], [178, 1, 1, "", "set_submodule"], [178, 2, 1, "", "shape"], [178, 1, 1, "", "share_memory"], [178, 2, 1, "", "specs"], [178, 1, 1, "", "state_dict"], [178, 2, 1, "", "state_keys"], [178, 2, 1, "", "state_spec"], [178, 2, 1, "", "state_spec_unbatched"], [178, 1, 1, "", "step"], [178, 1, 1, "", "step_and_maybe_reset"], [178, 1, 1, "", "step_mdp"], [178, 1, 1, "", "to"], [178, 1, 1, "", "to_empty"], [178, 1, 1, "", "train"], [178, 1, 1, "", "type"], [178, 1, 1, "", "xpu"], [178, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KEnv": [[179, 2, 1, "", "action_key"], [179, 2, 1, "", "action_keys"], [179, 2, 1, "", "action_spec"], [179, 2, 1, "", "action_spec_unbatched"], [179, 1, 1, "", "add_module"], [179, 1, 1, "", "add_truncated_keys"], [179, 1, 1, "", "all_actions"], [179, 1, 1, "", "any_done"], [179, 1, 1, "", "append_transform"], [179, 1, 1, "", "apply"], [179, 1, 1, "", "auto_specs_"], [179, 2, 1, "", "batch_dims"], [179, 2, 1, "", "batch_locked"], [179, 2, 1, "", "batch_size"], [179, 1, 1, "", "bfloat16"], [179, 1, 1, "", "buffers"], [179, 1, 1, "", "cardinality"], [179, 1, 1, "", "check_env_specs"], [179, 1, 1, "", "children"], [179, 1, 1, "", "compile"], [179, 1, 1, "", "cpu"], [179, 1, 1, "", "cuda"], [179, 2, 1, "", "done_key"], [179, 2, 1, "", "done_keys"], [179, 2, 1, "", "done_keys_groups"], [179, 2, 1, "", "done_spec"], [179, 2, 1, "", "done_spec_unbatched"], [179, 1, 1, "", "double"], [179, 1, 1, "", "empty_cache"], [179, 1, 1, "", "eval"], [179, 1, 1, "", "extra_repr"], [179, 1, 1, "", "fake_tensordict"], [179, 1, 1, "", "float"], [179, 1, 1, "", "forward"], [179, 2, 1, "", "full_action_spec"], [179, 2, 1, "", "full_action_spec_unbatched"], [179, 2, 1, "", "full_done_spec"], [179, 2, 1, "", "full_done_spec_unbatched"], [179, 2, 1, "", "full_observation_spec_unbatched"], [179, 2, 1, "", "full_reward_spec"], [179, 2, 1, "", "full_reward_spec_unbatched"], [179, 2, 1, "", "full_state_spec"], [179, 2, 1, "", "full_state_spec_unbatched"], [179, 1, 1, "", "get_buffer"], [179, 1, 1, "", "get_extra_state"], [179, 1, 1, "", "get_parameter"], [179, 1, 1, "", "get_submodule"], [179, 1, 1, "", "half"], [179, 2, 1, "", "input_spec"], [179, 2, 1, "", "input_spec_unbatched"], [179, 1, 1, "", "insert_transform"], [179, 1, 1, "", "ipu"], [179, 2, 1, "", "is_spec_locked"], [179, 1, 1, "", "load_state_dict"], [179, 1, 1, "", "maybe_reset"], [179, 1, 1, "", "modules"], [179, 1, 1, "", "mtia"], [179, 1, 1, "", "named_buffers"], [179, 1, 1, "", "named_children"], [179, 1, 1, "", "named_modules"], [179, 1, 1, "", "named_parameters"], [179, 2, 1, "", "observation_keys"], [179, 2, 1, "", "observation_spec"], [179, 2, 1, "", "observation_spec_unbatched"], [179, 2, 1, "", "output_spec"], [179, 2, 1, "", "output_spec_unbatched"], [179, 1, 1, "", "parameters"], [179, 1, 1, "", "rand_action"], [179, 1, 1, "", "rand_step"], [179, 1, 1, "", "register_backward_hook"], [179, 1, 1, "", "register_buffer"], [179, 1, 1, "", "register_forward_hook"], [179, 1, 1, "", "register_forward_pre_hook"], [179, 1, 1, "", "register_full_backward_hook"], [179, 1, 1, "", "register_full_backward_pre_hook"], [179, 1, 1, "", "register_gym"], [179, 1, 1, "", "register_load_state_dict_post_hook"], [179, 1, 1, "", "register_load_state_dict_pre_hook"], [179, 1, 1, "", "register_module"], [179, 1, 1, "", "register_parameter"], [179, 1, 1, "", "register_state_dict_post_hook"], [179, 1, 1, "", "register_state_dict_pre_hook"], [179, 1, 1, "", "requires_grad_"], [179, 1, 1, "", "reset"], [179, 2, 1, "", "reset_keys"], [179, 2, 1, "", "reward_key"], [179, 2, 1, "", "reward_keys"], [179, 2, 1, "", "reward_spec"], [179, 2, 1, "", "reward_spec_unbatched"], [179, 1, 1, "", "rollout"], [179, 1, 1, "", "set_extra_state"], [179, 1, 1, "", "set_missing_tolerance"], [179, 1, 1, "", "set_seed"], [179, 1, 1, "", "set_spec_lock_"], [179, 1, 1, "", "set_submodule"], [179, 2, 1, "", "shape"], [179, 1, 1, "", "share_memory"], [179, 2, 1, "", "specs"], [179, 1, 1, "", "state_dict"], [179, 2, 1, "", "state_keys"], [179, 2, 1, "", "state_spec"], [179, 2, 1, "", "state_spec_unbatched"], [179, 1, 1, "", "step"], [179, 1, 1, "", "step_and_maybe_reset"], [179, 1, 1, "", "step_mdp"], [179, 1, 1, "", "to"], [179, 1, 1, "", "to_empty"], [179, 1, 1, "", "train"], [179, 1, 1, "", "type"], [179, 1, 1, "", "xpu"], [179, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KPrepareQuestion": [[180, 1, 1, "", "add_module"], [180, 1, 1, "", "apply"], [180, 1, 1, "", "bfloat16"], [180, 1, 1, "", "buffers"], [180, 1, 1, "", "children"], [180, 1, 1, "", "close"], [180, 1, 1, "", "compile"], [180, 2, 1, "", "container"], [180, 1, 1, "", "cpu"], [180, 1, 1, "", "cuda"], [180, 1, 1, "", "double"], [180, 1, 1, "", "eval"], [180, 1, 1, "", "extra_repr"], [180, 1, 1, "", "float"], [180, 1, 1, "", "forward"], [180, 1, 1, "", "get_buffer"], [180, 1, 1, "", "get_extra_state"], [180, 1, 1, "", "get_parameter"], [180, 1, 1, "", "get_submodule"], [180, 1, 1, "", "half"], [180, 1, 1, "", "init"], [180, 1, 1, "", "inv"], [180, 1, 1, "", "ipu"], [180, 1, 1, "", "load_state_dict"], [180, 1, 1, "", "modules"], [180, 1, 1, "", "mtia"], [180, 1, 1, "", "named_buffers"], [180, 1, 1, "", "named_children"], [180, 1, 1, "", "named_modules"], [180, 1, 1, "", "named_parameters"], [180, 1, 1, "", "parameters"], [180, 2, 1, "", "parent"], [180, 1, 1, "", "register_backward_hook"], [180, 1, 1, "", "register_buffer"], [180, 1, 1, "", "register_forward_hook"], [180, 1, 1, "", "register_forward_pre_hook"], [180, 1, 1, "", "register_full_backward_hook"], [180, 1, 1, "", "register_full_backward_pre_hook"], [180, 1, 1, "", "register_load_state_dict_post_hook"], [180, 1, 1, "", "register_load_state_dict_pre_hook"], [180, 1, 1, "", "register_module"], [180, 1, 1, "", "register_parameter"], [180, 1, 1, "", "register_state_dict_post_hook"], [180, 1, 1, "", "register_state_dict_pre_hook"], [180, 1, 1, "", "requires_grad_"], [180, 1, 1, "", "set_extra_state"], [180, 1, 1, "", "set_submodule"], [180, 1, 1, "", "share_memory"], [180, 1, 1, "", "state_dict"], [180, 1, 1, "", "to"], [180, 1, 1, "", "to_empty"], [180, 1, 1, "", "train"], [180, 1, 1, "", "transform_action_spec"], [180, 1, 1, "", "transform_done_spec"], [180, 1, 1, "", "transform_env_batch_size"], [180, 1, 1, "", "transform_env_device"], [180, 1, 1, "", "transform_input_spec"], [180, 1, 1, "", "transform_observation_spec"], [180, 1, 1, "", "transform_output_spec"], [180, 1, 1, "", "transform_reward_spec"], [180, 1, 1, "", "transform_state_spec"], [180, 1, 1, "", "type"], [180, 1, 1, "", "xpu"], [180, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.GSM8KRewardParser": [[181, 1, 1, "", "add_module"], [181, 1, 1, "", "apply"], [181, 1, 1, "", "bfloat16"], [181, 1, 1, "", "buffers"], [181, 1, 1, "", "children"], [181, 1, 1, "", "close"], [181, 1, 1, "", "compile"], [181, 2, 1, "", "container"], [181, 1, 1, "", "cpu"], [181, 1, 1, "", "cuda"], [181, 1, 1, "", "double"], [181, 1, 1, "", "eval"], [181, 1, 1, "", "extra_repr"], [181, 1, 1, "", "extract_tags"], [181, 1, 1, "", "float"], [181, 1, 1, "", "forward"], [181, 1, 1, "", "get_buffer"], [181, 1, 1, "", "get_extra_state"], [181, 1, 1, "", "get_parameter"], [181, 1, 1, "", "get_submodule"], [181, 1, 1, "", "half"], [181, 1, 1, "", "init"], [181, 1, 1, "", "inv"], [181, 1, 1, "", "ipu"], [181, 1, 1, "", "load_state_dict"], [181, 1, 1, "", "modules"], [181, 1, 1, "", "mtia"], [181, 1, 1, "", "named_buffers"], [181, 1, 1, "", "named_children"], [181, 1, 1, "", "named_modules"], [181, 1, 1, "", "named_parameters"], [181, 1, 1, "", "parameters"], [181, 2, 1, "", "parent"], [181, 1, 1, "", "register_backward_hook"], [181, 1, 1, "", "register_buffer"], [181, 1, 1, "", "register_forward_hook"], [181, 1, 1, "", "register_forward_pre_hook"], [181, 1, 1, "", "register_full_backward_hook"], [181, 1, 1, "", "register_full_backward_pre_hook"], [181, 1, 1, "", "register_load_state_dict_post_hook"], [181, 1, 1, "", "register_load_state_dict_pre_hook"], [181, 1, 1, "", "register_module"], [181, 1, 1, "", "register_parameter"], [181, 1, 1, "", "register_state_dict_post_hook"], [181, 1, 1, "", "register_state_dict_pre_hook"], [181, 1, 1, "", "requires_grad_"], [181, 1, 1, "", "set_extra_state"], [181, 1, 1, "", "set_submodule"], [181, 1, 1, "", "share_memory"], [181, 1, 1, "", "state_dict"], [181, 1, 1, "", "to"], [181, 1, 1, "", "to_empty"], [181, 1, 1, "", "train"], [181, 1, 1, "", "transform_action_spec"], [181, 1, 1, "", "transform_done_spec"], [181, 1, 1, "", "transform_env_batch_size"], [181, 1, 1, "", "transform_env_device"], [181, 1, 1, "", "transform_input_spec"], [181, 1, 1, "", "transform_observation_spec"], [181, 1, 1, "", "transform_output_spec"], [181, 1, 1, "", "transform_reward_spec"], [181, 1, 1, "", "transform_state_spec"], [181, 1, 1, "", "type"], [181, 1, 1, "", "xpu"], [181, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalEnv": [[182, 2, 1, "", "action_key"], [182, 2, 1, "", "action_keys"], [182, 2, 1, "", "action_spec"], [182, 2, 1, "", "action_spec_unbatched"], [182, 1, 1, "", "add_module"], [182, 1, 1, "", "add_truncated_keys"], [182, 1, 1, "", "all_actions"], [182, 1, 1, "", "any_done"], [182, 1, 1, "", "append_transform"], [182, 1, 1, "", "apply"], [182, 1, 1, "", "auto_specs_"], [182, 2, 1, "", "batch_dims"], [182, 2, 1, "", "batch_locked"], [182, 2, 1, "", "batch_size"], [182, 1, 1, "", "bfloat16"], [182, 1, 1, "", "buffers"], [182, 1, 1, "", "cardinality"], [182, 1, 1, "", "check_env_specs"], [182, 1, 1, "", "children"], [182, 1, 1, "", "compile"], [182, 1, 1, "", "cpu"], [182, 1, 1, "", "cuda"], [182, 2, 1, "", "done_key"], [182, 2, 1, "", "done_keys"], [182, 2, 1, "", "done_keys_groups"], [182, 2, 1, "", "done_spec"], [182, 2, 1, "", "done_spec_unbatched"], [182, 1, 1, "", "double"], [182, 1, 1, "", "empty_cache"], [182, 1, 1, "", "eval"], [182, 1, 1, "", "extra_repr"], [182, 1, 1, "", "fake_tensordict"], [182, 1, 1, "", "float"], [182, 1, 1, "", "forward"], [182, 2, 1, "", "full_action_spec"], [182, 2, 1, "", "full_action_spec_unbatched"], [182, 2, 1, "", "full_done_spec"], [182, 2, 1, "", "full_done_spec_unbatched"], [182, 2, 1, "", "full_observation_spec_unbatched"], [182, 2, 1, "", "full_reward_spec"], [182, 2, 1, "", "full_reward_spec_unbatched"], [182, 2, 1, "", "full_state_spec"], [182, 2, 1, "", "full_state_spec_unbatched"], [182, 1, 1, "", "get_buffer"], [182, 1, 1, "", "get_extra_state"], [182, 1, 1, "", "get_parameter"], [182, 1, 1, "", "get_submodule"], [182, 1, 1, "", "half"], [182, 2, 1, "", "input_spec"], [182, 2, 1, "", "input_spec_unbatched"], [182, 1, 1, "", "insert_transform"], [182, 1, 1, "", "ipu"], [182, 2, 1, "", "is_spec_locked"], [182, 1, 1, "", "load_state_dict"], [182, 1, 1, "", "maybe_reset"], [182, 1, 1, "", "modules"], [182, 1, 1, "", "mtia"], [182, 1, 1, "", "named_buffers"], [182, 1, 1, "", "named_children"], [182, 1, 1, "", "named_modules"], [182, 1, 1, "", "named_parameters"], [182, 2, 1, "", "observation_keys"], [182, 2, 1, "", "observation_spec"], [182, 2, 1, "", "observation_spec_unbatched"], [182, 2, 1, "", "output_spec"], [182, 2, 1, "", "output_spec_unbatched"], [182, 1, 1, "", "parameters"], [182, 1, 1, "", "rand_action"], [182, 1, 1, "", "rand_step"], [182, 1, 1, "", "register_backward_hook"], [182, 1, 1, "", "register_buffer"], [182, 1, 1, "", "register_forward_hook"], [182, 1, 1, "", "register_forward_pre_hook"], [182, 1, 1, "", "register_full_backward_hook"], [182, 1, 1, "", "register_full_backward_pre_hook"], [182, 1, 1, "", "register_gym"], [182, 1, 1, "", "register_load_state_dict_post_hook"], [182, 1, 1, "", "register_load_state_dict_pre_hook"], [182, 1, 1, "", "register_module"], [182, 1, 1, "", "register_parameter"], [182, 1, 1, "", "register_state_dict_post_hook"], [182, 1, 1, "", "register_state_dict_pre_hook"], [182, 1, 1, "", "requires_grad_"], [182, 1, 1, "", "reset"], [182, 2, 1, "", "reset_keys"], [182, 2, 1, "", "reward_key"], [182, 2, 1, "", "reward_keys"], [182, 2, 1, "", "reward_spec"], [182, 2, 1, "", "reward_spec_unbatched"], [182, 1, 1, "", "rollout"], [182, 1, 1, "", "set_extra_state"], [182, 1, 1, "", "set_missing_tolerance"], [182, 1, 1, "", "set_seed"], [182, 1, 1, "", "set_spec_lock_"], [182, 1, 1, "", "set_submodule"], [182, 2, 1, "", "shape"], [182, 1, 1, "", "share_memory"], [182, 2, 1, "", "specs"], [182, 1, 1, "", "state_dict"], [182, 2, 1, "", "state_keys"], [182, 2, 1, "", "state_spec"], [182, 2, 1, "", "state_spec_unbatched"], [182, 1, 1, "", "step"], [182, 1, 1, "", "step_and_maybe_reset"], [182, 1, 1, "", "step_mdp"], [182, 1, 1, "", "to"], [182, 1, 1, "", "to_empty"], [182, 1, 1, "", "train"], [182, 1, 1, "", "type"], [182, 1, 1, "", "xpu"], [182, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.IFEvalScoreData": [[183, 2, 1, "", "device"], [183, 1, 1, "", "dumps"], [183, 1, 1, "", "fields"], [183, 1, 1, "", "from_tensordict"], [183, 1, 1, "", "get"], [183, 1, 1, "", "load"], [183, 1, 1, "", "load_"], [183, 1, 1, "", "load_memmap"], [183, 1, 1, "", "load_state_dict"], [183, 1, 1, "", "memmap"], [183, 1, 1, "", "memmap_"], [183, 1, 1, "", "memmap_like"], [183, 1, 1, "", "memmap_refresh_"], [183, 1, 1, "", "save"], [183, 1, 1, "", "set"], [183, 1, 1, "", "state_dict"], [183, 1, 1, "", "to_tensordict"], [183, 1, 1, "", "unbind"]], "torchrl.envs.llm.IfEvalScorer": [[184, 1, 1, "", "add_module"], [184, 1, 1, "", "apply"], [184, 1, 1, "", "bfloat16"], [184, 1, 1, "", "buffers"], [184, 1, 1, "", "children"], [184, 1, 1, "", "close"], [184, 1, 1, "", "compile"], [184, 2, 1, "", "container"], [184, 1, 1, "", "cpu"], [184, 1, 1, "", "cuda"], [184, 1, 1, "", "double"], [184, 1, 1, "", "eval"], [184, 1, 1, "", "extra_repr"], [184, 1, 1, "", "float"], [184, 1, 1, "", "forward"], [184, 1, 1, "", "get_buffer"], [184, 1, 1, "", "get_extra_state"], [184, 1, 1, "", "get_parameter"], [184, 1, 1, "", "get_submodule"], [184, 1, 1, "", "half"], [184, 1, 1, "", "init"], [184, 1, 1, "", "inv"], [184, 1, 1, "", "ipu"], [184, 1, 1, "", "load_state_dict"], [184, 1, 1, "", "modules"], [184, 1, 1, "", "mtia"], [184, 1, 1, "", "named_buffers"], [184, 1, 1, "", "named_children"], [184, 1, 1, "", "named_modules"], [184, 1, 1, "", "named_parameters"], [184, 1, 1, "", "parameters"], [184, 2, 1, "", "parent"], [184, 1, 1, "", "register_backward_hook"], [184, 1, 1, "", "register_buffer"], [184, 1, 1, "", "register_forward_hook"], [184, 1, 1, "", "register_forward_pre_hook"], [184, 1, 1, "", "register_full_backward_hook"], [184, 1, 1, "", "register_full_backward_pre_hook"], [184, 1, 1, "", "register_load_state_dict_post_hook"], [184, 1, 1, "", "register_load_state_dict_pre_hook"], [184, 1, 1, "", "register_module"], [184, 1, 1, "", "register_parameter"], [184, 1, 1, "", "register_state_dict_post_hook"], [184, 1, 1, "", "register_state_dict_pre_hook"], [184, 1, 1, "", "requires_grad_"], [184, 1, 1, "", "set_extra_state"], [184, 1, 1, "", "set_submodule"], [184, 1, 1, "", "share_memory"], [184, 1, 1, "", "state_dict"], [184, 1, 1, "", "to"], [184, 1, 1, "", "to_empty"], [184, 1, 1, "", "train"], [184, 1, 1, "", "transform_action_spec"], [184, 1, 1, "", "transform_done_spec"], [184, 1, 1, "", "transform_env_batch_size"], [184, 1, 1, "", "transform_env_device"], [184, 1, 1, "", "transform_input_spec"], [184, 1, 1, "", "transform_observation_spec"], [184, 1, 1, "", "transform_output_spec"], [184, 1, 1, "", "transform_reward_spec"], [184, 1, 1, "", "transform_state_spec"], [184, 1, 1, "", "type"], [184, 1, 1, "", "xpu"], [184, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMEnv": [[185, 2, 1, "", "action_key"], [185, 2, 1, "", "action_keys"], [185, 2, 1, "", "action_spec"], [185, 2, 1, "", "action_spec_unbatched"], [185, 1, 1, "", "add_module"], [185, 1, 1, "", "add_truncated_keys"], [185, 1, 1, "", "all_actions"], [185, 1, 1, "", "any_done"], [185, 1, 1, "", "append_transform"], [185, 1, 1, "", "apply"], [185, 1, 1, "", "auto_specs_"], [185, 2, 1, "", "batch_dims"], [185, 2, 1, "", "batch_locked"], [185, 2, 1, "", "batch_size"], [185, 1, 1, "", "bfloat16"], [185, 1, 1, "", "buffers"], [185, 1, 1, "", "cardinality"], [185, 1, 1, "", "check_env_specs"], [185, 1, 1, "", "children"], [185, 1, 1, "", "compile"], [185, 1, 1, "", "cpu"], [185, 1, 1, "", "cuda"], [185, 2, 1, "", "done_key"], [185, 2, 1, "", "done_keys"], [185, 2, 1, "", "done_keys_groups"], [185, 2, 1, "", "done_spec"], [185, 2, 1, "", "done_spec_unbatched"], [185, 1, 1, "", "double"], [185, 1, 1, "", "empty_cache"], [185, 1, 1, "", "eval"], [185, 1, 1, "", "extra_repr"], [185, 1, 1, "", "fake_tensordict"], [185, 1, 1, "", "float"], [185, 1, 1, "", "forward"], [185, 1, 1, "id0", "from_dataloader"], [185, 2, 1, "", "full_action_spec"], [185, 2, 1, "", "full_action_spec_unbatched"], [185, 2, 1, "", "full_done_spec"], [185, 2, 1, "", "full_done_spec_unbatched"], [185, 2, 1, "", "full_observation_spec_unbatched"], [185, 2, 1, "", "full_reward_spec"], [185, 2, 1, "", "full_reward_spec_unbatched"], [185, 2, 1, "", "full_state_spec"], [185, 2, 1, "", "full_state_spec_unbatched"], [185, 1, 1, "", "get_buffer"], [185, 1, 1, "", "get_extra_state"], [185, 1, 1, "", "get_parameter"], [185, 1, 1, "", "get_submodule"], [185, 1, 1, "", "half"], [185, 2, 1, "", "input_spec"], [185, 2, 1, "", "input_spec_unbatched"], [185, 1, 1, "", "ipu"], [185, 2, 1, "", "is_spec_locked"], [185, 1, 1, "", "load_state_dict"], [185, 1, 1, "", "maybe_reset"], [185, 1, 1, "", "modules"], [185, 1, 1, "", "mtia"], [185, 1, 1, "", "named_buffers"], [185, 1, 1, "", "named_children"], [185, 1, 1, "", "named_modules"], [185, 1, 1, "", "named_parameters"], [185, 2, 1, "", "observation_keys"], [185, 2, 1, "", "observation_spec"], [185, 2, 1, "", "observation_spec_unbatched"], [185, 2, 1, "", "output_spec"], [185, 2, 1, "", "output_spec_unbatched"], [185, 1, 1, "", "parameters"], [185, 1, 1, "", "rand_action"], [185, 1, 1, "", "rand_step"], [185, 1, 1, "", "register_backward_hook"], [185, 1, 1, "", "register_buffer"], [185, 1, 1, "", "register_forward_hook"], [185, 1, 1, "", "register_forward_pre_hook"], [185, 1, 1, "", "register_full_backward_hook"], [185, 1, 1, "", "register_full_backward_pre_hook"], [185, 1, 1, "", "register_gym"], [185, 1, 1, "", "register_load_state_dict_post_hook"], [185, 1, 1, "", "register_load_state_dict_pre_hook"], [185, 1, 1, "", "register_module"], [185, 1, 1, "", "register_parameter"], [185, 1, 1, "", "register_state_dict_post_hook"], [185, 1, 1, "", "register_state_dict_pre_hook"], [185, 1, 1, "", "requires_grad_"], [185, 1, 1, "", "reset"], [185, 2, 1, "", "reset_keys"], [185, 2, 1, "", "reward_key"], [185, 2, 1, "", "reward_keys"], [185, 2, 1, "", "reward_spec"], [185, 2, 1, "", "reward_spec_unbatched"], [185, 1, 1, "", "rollout"], [185, 1, 1, "", "set_extra_state"], [185, 1, 1, "", "set_seed"], [185, 1, 1, "", "set_spec_lock_"], [185, 1, 1, "", "set_submodule"], [185, 2, 1, "", "shape"], [185, 1, 1, "", "share_memory"], [185, 2, 1, "", "specs"], [185, 1, 1, "", "state_dict"], [185, 2, 1, "", "state_keys"], [185, 2, 1, "", "state_spec"], [185, 2, 1, "", "state_spec_unbatched"], [185, 1, 1, "", "step"], [185, 1, 1, "", "step_and_maybe_reset"], [185, 1, 1, "", "step_mdp"], [185, 1, 1, "", "to"], [185, 1, 1, "", "to_empty"], [185, 1, 1, "", "train"], [185, 1, 1, "", "type"], [185, 1, 1, "", "xpu"], [185, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.LLMHashingEnv": [[186, 2, 1, "", "action_key"], [186, 2, 1, "", "action_keys"], [186, 2, 1, "", "action_spec"], [186, 2, 1, "", "action_spec_unbatched"], [186, 1, 1, "", "add_module"], [186, 1, 1, "", "add_truncated_keys"], [186, 1, 1, "", "all_actions"], [186, 1, 1, "", "any_done"], [186, 1, 1, "", "append_transform"], [186, 1, 1, "", "apply"], [186, 1, 1, "", "auto_specs_"], [186, 2, 1, "", "batch_dims"], [186, 2, 1, "", "batch_locked"], [186, 2, 1, "", "batch_size"], [186, 1, 1, "", "bfloat16"], [186, 1, 1, "", "buffers"], [186, 1, 1, "", "cardinality"], [186, 1, 1, "", "check_env_specs"], [186, 1, 1, "", "children"], [186, 1, 1, "", "compile"], [186, 1, 1, "", "cpu"], [186, 1, 1, "", "cuda"], [186, 2, 1, "", "done_key"], [186, 2, 1, "", "done_keys"], [186, 2, 1, "", "done_keys_groups"], [186, 2, 1, "", "done_spec"], [186, 2, 1, "", "done_spec_unbatched"], [186, 1, 1, "", "double"], [186, 1, 1, "", "empty_cache"], [186, 1, 1, "", "eval"], [186, 1, 1, "", "extra_repr"], [186, 1, 1, "", "fake_tensordict"], [186, 1, 1, "", "float"], [186, 1, 1, "", "forward"], [186, 2, 1, "", "full_action_spec"], [186, 2, 1, "", "full_action_spec_unbatched"], [186, 2, 1, "", "full_done_spec"], [186, 2, 1, "", "full_done_spec_unbatched"], [186, 2, 1, "", "full_observation_spec_unbatched"], [186, 2, 1, "", "full_reward_spec"], [186, 2, 1, "", "full_reward_spec_unbatched"], [186, 2, 1, "", "full_state_spec"], [186, 2, 1, "", "full_state_spec_unbatched"], [186, 1, 1, "", "get_buffer"], [186, 1, 1, "", "get_extra_state"], [186, 1, 1, "", "get_parameter"], [186, 1, 1, "", "get_submodule"], [186, 1, 1, "", "half"], [186, 2, 1, "", "input_spec"], [186, 2, 1, "", "input_spec_unbatched"], [186, 1, 1, "", "ipu"], [186, 2, 1, "", "is_spec_locked"], [186, 1, 1, "", "load_state_dict"], [186, 1, 1, "", "make_tensordict"], [186, 1, 1, "", "maybe_reset"], [186, 1, 1, "", "modules"], [186, 1, 1, "", "mtia"], [186, 1, 1, "", "named_buffers"], [186, 1, 1, "", "named_children"], [186, 1, 1, "", "named_modules"], [186, 1, 1, "", "named_parameters"], [186, 2, 1, "", "observation_keys"], [186, 2, 1, "", "observation_spec"], [186, 2, 1, "", "observation_spec_unbatched"], [186, 2, 1, "", "output_spec"], [186, 2, 1, "", "output_spec_unbatched"], [186, 1, 1, "", "parameters"], [186, 1, 1, "", "rand_action"], [186, 1, 1, "", "rand_step"], [186, 1, 1, "", "register_backward_hook"], [186, 1, 1, "", "register_buffer"], [186, 1, 1, "", "register_forward_hook"], [186, 1, 1, "", "register_forward_pre_hook"], [186, 1, 1, "", "register_full_backward_hook"], [186, 1, 1, "", "register_full_backward_pre_hook"], [186, 1, 1, "", "register_gym"], [186, 1, 1, "", "register_load_state_dict_post_hook"], [186, 1, 1, "", "register_load_state_dict_pre_hook"], [186, 1, 1, "", "register_module"], [186, 1, 1, "", "register_parameter"], [186, 1, 1, "", "register_state_dict_post_hook"], [186, 1, 1, "", "register_state_dict_pre_hook"], [186, 1, 1, "", "requires_grad_"], [186, 1, 1, "", "reset"], [186, 2, 1, "", "reset_keys"], [186, 2, 1, "", "reward_key"], [186, 2, 1, "", "reward_keys"], [186, 2, 1, "", "reward_spec"], [186, 2, 1, "", "reward_spec_unbatched"], [186, 1, 1, "", "rollout"], [186, 1, 1, "", "set_extra_state"], [186, 1, 1, "", "set_seed"], [186, 1, 1, "", "set_spec_lock_"], [186, 1, 1, "", "set_submodule"], [186, 2, 1, "", "shape"], [186, 1, 1, "", "share_memory"], [186, 2, 1, "", "specs"], [186, 1, 1, "", "state_dict"], [186, 2, 1, "", "state_keys"], [186, 2, 1, "", "state_spec"], [186, 2, 1, "", "state_spec_unbatched"], [186, 1, 1, "", "step"], [186, 1, 1, "", "step_and_maybe_reset"], [186, 1, 1, "", "step_mdp"], [186, 1, 1, "", "to"], [186, 1, 1, "", "to_empty"], [186, 1, 1, "", "train"], [186, 1, 1, "", "type"], [186, 1, 1, "", "xpu"], [186, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.MLGymWrapper": [[187, 2, 1, "", "action_key"], [187, 2, 1, "", "action_keys"], [187, 2, 1, "", "action_spec"], [187, 2, 1, "", "action_spec_unbatched"], [187, 1, 1, "", "add_module"], [187, 1, 1, "", "add_truncated_keys"], [187, 1, 1, "", "all_actions"], [187, 1, 1, "", "any_done"], [187, 1, 1, "", "append_transform"], [187, 1, 1, "", "apply"], [187, 1, 1, "", "auto_register_info_dict"], [187, 1, 1, "", "auto_specs_"], [187, 2, 1, "", "batch_dims"], [187, 2, 1, "", "batch_locked"], [187, 2, 1, "", "batch_size"], [187, 1, 1, "", "bfloat16"], [187, 1, 1, "", "buffers"], [187, 1, 1, "", "cardinality"], [187, 1, 1, "", "check_env_specs"], [187, 1, 1, "", "children"], [187, 1, 1, "", "close"], [187, 1, 1, "", "compile"], [187, 1, 1, "", "cpu"], [187, 1, 1, "", "cuda"], [187, 2, 1, "", "done_key"], [187, 2, 1, "", "done_keys"], [187, 2, 1, "", "done_keys_groups"], [187, 2, 1, "", "done_spec"], [187, 2, 1, "", "done_spec_unbatched"], [187, 1, 1, "", "double"], [187, 1, 1, "", "empty_cache"], [187, 1, 1, "", "eval"], [187, 1, 1, "", "extra_repr"], [187, 1, 1, "", "fake_tensordict"], [187, 1, 1, "", "fast_encoding"], [187, 1, 1, "", "float"], [187, 1, 1, "", "forward"], [187, 2, 1, "", "full_action_spec"], [187, 2, 1, "", "full_action_spec_unbatched"], [187, 2, 1, "", "full_done_spec"], [187, 2, 1, "", "full_done_spec_unbatched"], [187, 2, 1, "", "full_observation_spec_unbatched"], [187, 2, 1, "", "full_reward_spec"], [187, 2, 1, "", "full_reward_spec_unbatched"], [187, 2, 1, "", "full_state_spec"], [187, 2, 1, "", "full_state_spec_unbatched"], [187, 1, 1, "", "get_buffer"], [187, 1, 1, "", "get_extra_state"], [187, 1, 1, "", "get_library_name"], [187, 1, 1, "", "get_parameter"], [187, 1, 1, "", "get_submodule"], [187, 1, 1, "", "half"], [187, 2, 1, "", "input_spec"], [187, 2, 1, "", "input_spec_unbatched"], [187, 1, 1, "", "ipu"], [187, 2, 1, "", "is_spec_locked"], [187, 1, 1, "", "load_state_dict"], [187, 1, 1, "", "maybe_reset"], [187, 1, 1, "", "modules"], [187, 1, 1, "", "mtia"], [187, 1, 1, "", "named_buffers"], [187, 1, 1, "", "named_children"], [187, 1, 1, "", "named_modules"], [187, 1, 1, "", "named_parameters"], [187, 2, 1, "", "observation_keys"], [187, 2, 1, "", "observation_spec"], [187, 2, 1, "", "observation_spec_unbatched"], [187, 2, 1, "", "output_spec"], [187, 2, 1, "", "output_spec_unbatched"], [187, 1, 1, "", "parameters"], [187, 1, 1, "", "rand_action"], [187, 1, 1, "", "rand_step"], [187, 1, 1, "", "read_action"], [187, 1, 1, "", "read_done"], [187, 1, 1, "", "read_obs"], [187, 1, 1, "", "read_reward"], [187, 1, 1, "", "register_backward_hook"], [187, 1, 1, "", "register_buffer"], [187, 1, 1, "", "register_forward_hook"], [187, 1, 1, "", "register_forward_pre_hook"], [187, 1, 1, "", "register_full_backward_hook"], [187, 1, 1, "", "register_full_backward_pre_hook"], [187, 1, 1, "", "register_gym"], [187, 1, 1, "", "register_load_state_dict_post_hook"], [187, 1, 1, "", "register_load_state_dict_pre_hook"], [187, 1, 1, "", "register_module"], [187, 1, 1, "", "register_parameter"], [187, 1, 1, "", "register_state_dict_post_hook"], [187, 1, 1, "", "register_state_dict_pre_hook"], [187, 1, 1, "", "requires_grad_"], [187, 1, 1, "", "reset"], [187, 2, 1, "", "reset_keys"], [187, 2, 1, "", "reward_key"], [187, 2, 1, "", "reward_keys"], [187, 2, 1, "", "reward_spec"], [187, 2, 1, "", "reward_spec_unbatched"], [187, 1, 1, "", "rollout"], [187, 1, 1, "", "set_extra_state"], [187, 1, 1, "", "set_info_dict_reader"], [187, 1, 1, "", "set_seed"], [187, 1, 1, "", "set_spec_lock_"], [187, 1, 1, "", "set_submodule"], [187, 2, 1, "", "shape"], [187, 1, 1, "", "share_memory"], [187, 2, 1, "", "specs"], [187, 1, 1, "", "state_dict"], [187, 2, 1, "", "state_keys"], [187, 2, 1, "", "state_spec"], [187, 2, 1, "", "state_spec_unbatched"], [187, 1, 1, "", "step"], [187, 1, 1, "", "step_and_maybe_reset"], [187, 1, 1, "", "step_mdp"], [187, 1, 1, "", "to"], [187, 1, 1, "", "to_empty"], [187, 1, 1, "", "train"], [187, 1, 1, "", "type"], [187, 1, 1, "", "xpu"], [187, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms": [[190, 0, 1, "", "DataLoadingPrimer"], [191, 0, 1, "", "KLRewardTransform"], [192, 0, 1, "", "PythonInterpreter"], [193, 0, 1, "", "TemplateTransform"], [194, 0, 1, "", "Tokenizer"], [195, 0, 1, "", "as_nested_tensor"], [196, 0, 1, "", "as_padded_tensor"]], "torchrl.envs.llm.transforms.DataLoadingPrimer": [[190, 1, 1, "", "add_module"], [190, 1, 1, "", "apply"], [190, 1, 1, "", "bfloat16"], [190, 1, 1, "", "buffers"], [190, 1, 1, "", "children"], [190, 1, 1, "", "close"], [190, 1, 1, "", "compile"], [190, 2, 1, "", "container"], [190, 1, 1, "", "cpu"], [190, 1, 1, "", "cuda"], [190, 1, 1, "", "double"], [190, 1, 1, "", "eval"], [190, 1, 1, "", "extra_repr"], [190, 1, 1, "", "float"], [190, 1, 1, "", "forward"], [190, 1, 1, "", "get_buffer"], [190, 1, 1, "", "get_extra_state"], [190, 1, 1, "", "get_parameter"], [190, 1, 1, "", "get_submodule"], [190, 1, 1, "", "half"], [190, 1, 1, "", "init"], [190, 1, 1, "", "inv"], [190, 1, 1, "", "ipu"], [190, 1, 1, "", "load_state_dict"], [190, 1, 1, "", "modules"], [190, 1, 1, "", "mtia"], [190, 1, 1, "", "named_buffers"], [190, 1, 1, "", "named_children"], [190, 1, 1, "", "named_modules"], [190, 1, 1, "", "named_parameters"], [190, 1, 1, "", "parameters"], [190, 2, 1, "", "parent"], [190, 1, 1, "", "register_backward_hook"], [190, 1, 1, "", "register_buffer"], [190, 1, 1, "", "register_forward_hook"], [190, 1, 1, "", "register_forward_pre_hook"], [190, 1, 1, "", "register_full_backward_hook"], [190, 1, 1, "", "register_full_backward_pre_hook"], [190, 1, 1, "", "register_load_state_dict_post_hook"], [190, 1, 1, "", "register_load_state_dict_pre_hook"], [190, 1, 1, "", "register_module"], [190, 1, 1, "", "register_parameter"], [190, 1, 1, "", "register_state_dict_post_hook"], [190, 1, 1, "", "register_state_dict_pre_hook"], [190, 1, 1, "", "requires_grad_"], [190, 1, 1, "", "set_extra_state"], [190, 1, 1, "", "set_submodule"], [190, 1, 1, "", "share_memory"], [190, 1, 1, "", "state_dict"], [190, 1, 1, "", "to"], [190, 1, 1, "", "to_empty"], [190, 1, 1, "", "train"], [190, 1, 1, "", "transform_action_spec"], [190, 1, 1, "", "transform_done_spec"], [190, 1, 1, "", "transform_env_batch_size"], [190, 1, 1, "", "transform_env_device"], [190, 1, 1, "", "transform_input_spec"], [190, 1, 1, "", "transform_observation_spec"], [190, 1, 1, "", "transform_output_spec"], [190, 1, 1, "", "transform_reward_spec"], [190, 1, 1, "", "transform_state_spec"], [190, 1, 1, "", "type"], [190, 1, 1, "", "xpu"], [190, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.KLRewardTransform": [[191, 1, 1, "", "add_module"], [191, 1, 1, "", "apply"], [191, 1, 1, "", "bfloat16"], [191, 1, 1, "", "buffers"], [191, 1, 1, "", "children"], [191, 1, 1, "", "close"], [191, 1, 1, "", "compile"], [191, 2, 1, "", "container"], [191, 1, 1, "", "cpu"], [191, 1, 1, "", "cuda"], [191, 1, 1, "", "double"], [191, 1, 1, "", "eval"], [191, 1, 1, "", "extra_repr"], [191, 1, 1, "", "float"], [191, 1, 1, "", "forward"], [191, 1, 1, "", "get_buffer"], [191, 1, 1, "", "get_extra_state"], [191, 1, 1, "", "get_parameter"], [191, 1, 1, "", "get_submodule"], [191, 1, 1, "", "half"], [191, 1, 1, "", "init"], [191, 1, 1, "", "inv"], [191, 1, 1, "", "ipu"], [191, 1, 1, "", "load_state_dict"], [191, 1, 1, "", "modules"], [191, 1, 1, "", "mtia"], [191, 1, 1, "", "named_buffers"], [191, 1, 1, "", "named_children"], [191, 1, 1, "", "named_modules"], [191, 1, 1, "", "named_parameters"], [191, 1, 1, "", "parameters"], [191, 2, 1, "", "parent"], [191, 1, 1, "", "register_backward_hook"], [191, 1, 1, "", "register_buffer"], [191, 1, 1, "", "register_forward_hook"], [191, 1, 1, "", "register_forward_pre_hook"], [191, 1, 1, "", "register_full_backward_hook"], [191, 1, 1, "", "register_full_backward_pre_hook"], [191, 1, 1, "", "register_load_state_dict_post_hook"], [191, 1, 1, "", "register_load_state_dict_pre_hook"], [191, 1, 1, "", "register_module"], [191, 1, 1, "", "register_parameter"], [191, 1, 1, "", "register_state_dict_post_hook"], [191, 1, 1, "", "register_state_dict_pre_hook"], [191, 1, 1, "", "requires_grad_"], [191, 1, 1, "", "set_extra_state"], [191, 1, 1, "", "set_submodule"], [191, 1, 1, "", "share_memory"], [191, 1, 1, "", "state_dict"], [191, 1, 1, "", "to"], [191, 1, 1, "", "to_empty"], [191, 1, 1, "", "train"], [191, 1, 1, "", "transform_action_spec"], [191, 1, 1, "", "transform_done_spec"], [191, 1, 1, "", "transform_env_batch_size"], [191, 1, 1, "", "transform_env_device"], [191, 1, 1, "", "transform_input_spec"], [191, 1, 1, "", "transform_observation_spec"], [191, 1, 1, "", "transform_output_spec"], [191, 1, 1, "", "transform_reward_spec"], [191, 1, 1, "", "transform_state_spec"], [191, 1, 1, "", "type"], [191, 1, 1, "", "xpu"], [191, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.PythonInterpreter": [[192, 1, 1, "", "add_module"], [192, 1, 1, "", "apply"], [192, 1, 1, "", "bfloat16"], [192, 1, 1, "", "buffers"], [192, 1, 1, "", "children"], [192, 1, 1, "", "clone"], [192, 1, 1, "", "close"], [192, 1, 1, "", "compile"], [192, 2, 1, "", "container"], [192, 1, 1, "", "cpu"], [192, 1, 1, "", "cuda"], [192, 1, 1, "", "double"], [192, 1, 1, "", "eval"], [192, 1, 1, "", "extra_repr"], [192, 1, 1, "", "float"], [192, 1, 1, "", "forward"], [192, 1, 1, "", "get_buffer"], [192, 1, 1, "", "get_extra_state"], [192, 1, 1, "", "get_parameter"], [192, 1, 1, "", "get_submodule"], [192, 1, 1, "", "half"], [192, 1, 1, "", "init"], [192, 1, 1, "", "inv"], [192, 1, 1, "", "ipu"], [192, 1, 1, "", "load_state_dict"], [192, 1, 1, "", "modules"], [192, 1, 1, "", "mtia"], [192, 1, 1, "", "named_buffers"], [192, 1, 1, "", "named_children"], [192, 1, 1, "", "named_modules"], [192, 1, 1, "", "named_parameters"], [192, 1, 1, "", "parameters"], [192, 2, 1, "", "parent"], [192, 1, 1, "", "register_backward_hook"], [192, 1, 1, "", "register_buffer"], [192, 1, 1, "", "register_forward_hook"], [192, 1, 1, "", "register_forward_pre_hook"], [192, 1, 1, "", "register_full_backward_hook"], [192, 1, 1, "", "register_full_backward_pre_hook"], [192, 1, 1, "", "register_load_state_dict_post_hook"], [192, 1, 1, "", "register_load_state_dict_pre_hook"], [192, 1, 1, "", "register_module"], [192, 1, 1, "", "register_parameter"], [192, 1, 1, "", "register_state_dict_post_hook"], [192, 1, 1, "", "register_state_dict_pre_hook"], [192, 1, 1, "", "requires_grad_"], [192, 1, 1, "", "set_extra_state"], [192, 1, 1, "", "set_submodule"], [192, 1, 1, "", "share_memory"], [192, 1, 1, "", "state_dict"], [192, 1, 1, "", "to"], [192, 1, 1, "", "to_empty"], [192, 1, 1, "", "train"], [192, 1, 1, "", "transform_action_spec"], [192, 1, 1, "", "transform_done_spec"], [192, 1, 1, "", "transform_env_batch_size"], [192, 1, 1, "", "transform_env_device"], [192, 1, 1, "", "transform_input_spec"], [192, 1, 1, "", "transform_observation_spec"], [192, 1, 1, "", "transform_output_spec"], [192, 1, 1, "", "transform_reward_spec"], [192, 1, 1, "", "transform_state_spec"], [192, 1, 1, "", "type"], [192, 1, 1, "", "xpu"], [192, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.TemplateTransform": [[193, 1, 1, "", "add_module"], [193, 1, 1, "", "apply"], [193, 1, 1, "", "bfloat16"], [193, 1, 1, "", "buffers"], [193, 1, 1, "", "children"], [193, 1, 1, "", "close"], [193, 1, 1, "", "compile"], [193, 2, 1, "", "container"], [193, 1, 1, "", "cpu"], [193, 1, 1, "", "cuda"], [193, 1, 1, "", "double"], [193, 1, 1, "", "eval"], [193, 1, 1, "", "extra_repr"], [193, 1, 1, "", "float"], [193, 1, 1, "", "forward"], [193, 1, 1, "", "get_buffer"], [193, 1, 1, "", "get_extra_state"], [193, 1, 1, "", "get_parameter"], [193, 1, 1, "", "get_submodule"], [193, 1, 1, "", "half"], [193, 1, 1, "", "init"], [193, 1, 1, "", "inv"], [193, 1, 1, "", "ipu"], [193, 1, 1, "", "load_state_dict"], [193, 1, 1, "", "modules"], [193, 1, 1, "", "mtia"], [193, 1, 1, "", "named_buffers"], [193, 1, 1, "", "named_children"], [193, 1, 1, "", "named_modules"], [193, 1, 1, "", "named_parameters"], [193, 1, 1, "", "parameters"], [193, 2, 1, "", "parent"], [193, 1, 1, "", "register_backward_hook"], [193, 1, 1, "", "register_buffer"], [193, 1, 1, "", "register_forward_hook"], [193, 1, 1, "", "register_forward_pre_hook"], [193, 1, 1, "", "register_full_backward_hook"], [193, 1, 1, "", "register_full_backward_pre_hook"], [193, 1, 1, "", "register_load_state_dict_post_hook"], [193, 1, 1, "", "register_load_state_dict_pre_hook"], [193, 1, 1, "", "register_module"], [193, 1, 1, "", "register_parameter"], [193, 1, 1, "", "register_state_dict_post_hook"], [193, 1, 1, "", "register_state_dict_pre_hook"], [193, 1, 1, "", "requires_grad_"], [193, 1, 1, "", "set_extra_state"], [193, 1, 1, "", "set_submodule"], [193, 1, 1, "", "share_memory"], [193, 1, 1, "", "state_dict"], [193, 1, 1, "", "to"], [193, 1, 1, "", "to_empty"], [193, 1, 1, "", "train"], [193, 1, 1, "", "transform_action_spec"], [193, 1, 1, "", "transform_done_spec"], [193, 1, 1, "", "transform_env_batch_size"], [193, 1, 1, "", "transform_env_device"], [193, 1, 1, "", "transform_input_spec"], [193, 1, 1, "", "transform_observation_spec"], [193, 1, 1, "", "transform_output_spec"], [193, 1, 1, "", "transform_reward_spec"], [193, 1, 1, "", "transform_state_spec"], [193, 1, 1, "", "type"], [193, 1, 1, "", "xpu"], [193, 1, 1, "", "zero_grad"]], "torchrl.envs.llm.transforms.Tokenizer": [[194, 1, 1, "", "add_module"], [194, 1, 1, "", "apply"], [194, 1, 1, "", "bfloat16"], [194, 1, 1, "", "buffers"], [194, 1, 1, "", "children"], [194, 1, 1, "", "close"], [194, 1, 1, "", "compile"], [194, 2, 1, "", "container"], [194, 1, 1, "", "cpu"], [194, 1, 1, "", "cuda"], [194, 1, 1, "", "double"], [194, 1, 1, "", "eval"], [194, 1, 1, "", "extra_repr"], [194, 1, 1, "", "float"], [194, 1, 1, "", "forward"], [194, 1, 1, "", "get_buffer"], [194, 1, 1, "", "get_extra_state"], [194, 1, 1, "", "get_parameter"], [194, 1, 1, "", "get_submodule"], [194, 1, 1, "", "half"], [194, 1, 1, "", "init"], [194, 1, 1, "", "inv"], [194, 1, 1, "", "ipu"], [194, 1, 1, "", "load_state_dict"], [194, 1, 1, "", "modules"], [194, 1, 1, "", "mtia"], [194, 1, 1, "", "named_buffers"], [194, 1, 1, "", "named_children"], [194, 1, 1, "", "named_modules"], [194, 1, 1, "", "named_parameters"], [194, 1, 1, "", "parameters"], [194, 2, 1, "", "parent"], [194, 1, 1, "", "register_backward_hook"], [194, 1, 1, "", "register_buffer"], [194, 1, 1, "", "register_forward_hook"], [194, 1, 1, "", "register_forward_pre_hook"], [194, 1, 1, "", "register_full_backward_hook"], [194, 1, 1, "", "register_full_backward_pre_hook"], [194, 1, 1, "", "register_load_state_dict_post_hook"], [194, 1, 1, "", "register_load_state_dict_pre_hook"], [194, 1, 1, "", "register_module"], [194, 1, 1, "", "register_parameter"], [194, 1, 1, "", "register_state_dict_post_hook"], [194, 1, 1, "", "register_state_dict_pre_hook"], [194, 1, 1, "", "requires_grad_"], [194, 1, 1, "", "set_extra_state"], [194, 1, 1, "", "set_submodule"], [194, 1, 1, "", "share_memory"], [194, 1, 1, "", "state_dict"], [194, 1, 1, "", "to"], [194, 1, 1, "", "to_empty"], [194, 1, 1, "", "train"], [194, 1, 1, "", "transform_action_spec"], [194, 1, 1, "", "transform_done_spec"], [194, 1, 1, "", "transform_env_batch_size"], [194, 1, 1, "", "transform_env_device"], [194, 1, 1, "", "transform_input_spec"], [194, 1, 1, "", "transform_observation_spec"], [194, 1, 1, "", "transform_output_spec"], [194, 1, 1, "", "transform_reward_spec"], [194, 1, 1, "", "transform_state_spec"], [194, 1, 1, "", "type"], [194, 1, 1, "", "xpu"], [194, 1, 1, "", "zero_grad"]], "torchrl.envs.model_based.dreamer": [[198, 3, 1, "", "DreamerDecoder"], [199, 3, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[205, 0, 1, "", "ActionDiscretizer"], [206, 0, 1, "", "ActionMask"], [207, 0, 1, "", "AutoResetEnv"], [208, 0, 1, "", "AutoResetTransform"], [209, 0, 1, "", "BatchSizeTransform"], [210, 0, 1, "", "BinarizeReward"], [211, 0, 1, "", "BurnInTransform"], [212, 0, 1, "", "CatFrames"], [213, 0, 1, "", "CatTensors"], [214, 0, 1, "", "CenterCrop"], [215, 0, 1, "", "ClipTransform"], [216, 0, 1, "", "Compose"], [217, 0, 1, "", "ConditionalPolicySwitch"], [218, 0, 1, "", "ConditionalSkip"], [219, 0, 1, "", "Crop"], [220, 0, 1, "", "DTypeCastTransform"], [221, 0, 1, "", "DeviceCastTransform"], [222, 0, 1, "", "DiscreteActionProjection"], [223, 0, 1, "", "DoubleToFloat"], [224, 0, 1, "", "EndOfLifeTransform"], [225, 0, 1, "", "ExcludeTransform"], [226, 0, 1, "", "FiniteTensorDictCheck"], [227, 0, 1, "", "FlattenObservation"], [228, 0, 1, "", "FrameSkipTransform"], [229, 0, 1, "", "GrayScale"], [230, 0, 1, "", "Hash"], [231, 0, 1, "", "InitTracker"], [232, 0, 1, "", "KLRewardTransform"], [233, 0, 1, "", "LineariseRewards"], [234, 0, 1, "", "MultiAction"], [235, 0, 1, "", "NoopResetEnv"], [236, 0, 1, "", "ObservationNorm"], [237, 0, 1, "", "ObservationTransform"], [238, 0, 1, "", "PermuteTransform"], [239, 0, 1, "", "PinMemoryTransform"], [240, 0, 1, "", "R3MTransform"], [241, 0, 1, "", "RandomCropTensorDict"], [242, 0, 1, "", "RemoveEmptySpecs"], [243, 0, 1, "", "RenameTransform"], [244, 0, 1, "", "Resize"], [245, 0, 1, "", "Reward2GoTransform"], [246, 0, 1, "", "RewardClipping"], [247, 0, 1, "", "RewardScaling"], [248, 0, 1, "", "RewardSum"], [249, 0, 1, "", "SelectTransform"], [250, 0, 1, "", "SignTransform"], [251, 0, 1, "", "SqueezeTransform"], [252, 0, 1, "", "Stack"], [253, 0, 1, "", "StepCounter"], [254, 0, 1, "", "TargetReturn"], [255, 0, 1, "", "TensorDictPrimer"], [256, 0, 1, "", "TimeMaxPool"], [257, 0, 1, "", "Timer"], [258, 0, 1, "", "ToTensorImage"], [259, 0, 1, "", "Tokenizer"], [260, 0, 1, "", "TrajCounter"], [261, 0, 1, "", "Transform"], [262, 0, 1, "", "TransformedEnv"], [263, 0, 1, "", "UnaryTransform"], [264, 0, 1, "", "UnsqueezeTransform"], [265, 0, 1, "", "VC1Transform"], [266, 0, 1, "", "VIPRewardTransform"], [267, 0, 1, "", "VIPTransform"], [268, 0, 1, "", "VecGymEnvTransform"], [269, 0, 1, "", "VecNorm"], [270, 0, 1, "", "VecNormV2"], [271, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionDiscretizer": [[205, 0, 1, "", "SamplingStrategy"], [205, 1, 1, "", "inv"], [205, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.ActionMask": [[206, 1, 1, "", "forward"]], "torchrl.envs.transforms.AutoResetEnv": [[207, 1, 1, "", "insert_transform"]], "torchrl.envs.transforms.AutoResetTransform": [[208, 1, 1, "", "forward"]], "torchrl.envs.transforms.BatchSizeTransform": [[209, 1, 1, "", "forward"], [209, 1, 1, "", "transform_env_batch_size"], [209, 1, 1, "", "transform_input_spec"], [209, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.BinarizeReward": [[210, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[211, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[212, 1, 1, "", "forward"], [212, 1, 1, "", "make_rb_transform_and_sampler"], [212, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[213, 1, 1, "", "forward"], [213, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[214, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[215, 1, 1, "", "transform_observation_spec"], [215, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[216, 1, 1, "", "append"], [216, 1, 1, "", "close"], [216, 1, 1, "", "forward"], [216, 1, 1, "", "init"], [216, 1, 1, "", "insert"], [216, 1, 1, "", "to"], [216, 1, 1, "", "transform_action_spec"], [216, 1, 1, "", "transform_env_batch_size"], [216, 1, 1, "", "transform_env_device"], [216, 1, 1, "", "transform_input_spec"], [216, 1, 1, "", "transform_observation_spec"], [216, 1, 1, "", "transform_output_spec"], [216, 1, 1, "", "transform_reward_spec"], [216, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.ConditionalPolicySwitch": [[217, 1, 1, "", "forward"]], "torchrl.envs.transforms.ConditionalSkip": [[218, 1, 1, "", "forward"]], "torchrl.envs.transforms.Crop": [[219, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[220, 1, 1, "", "forward"], [220, 1, 1, "", "transform_input_spec"], [220, 1, 1, "", "transform_observation_spec"], [220, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[221, 1, 1, "", "forward"], [221, 1, 1, "", "transform_action_spec"], [221, 1, 1, "", "transform_done_spec"], [221, 1, 1, "", "transform_env_device"], [221, 1, 1, "", "transform_input_spec"], [221, 1, 1, "", "transform_observation_spec"], [221, 1, 1, "", "transform_output_spec"], [221, 1, 1, "", "transform_reward_spec"], [221, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[222, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[224, 1, 1, "", "forward"], [224, 1, 1, "", "register_keys"], [224, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[225, 1, 1, "", "forward"], [225, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[226, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[227, 1, 1, "", "forward"], [227, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[228, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[229, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Hash": [[230, 1, 1, "", "get_input_from_hash"], [230, 1, 1, "", "reproducible_hash"], [230, 1, 1, "", "state_dict"]], "torchrl.envs.transforms.InitTracker": [[231, 1, 1, "", "forward"], [231, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[232, 1, 1, "", "forward"], [232, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.LineariseRewards": [[233, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.MultiAction": [[234, 1, 1, "", "transform_input_spec"], [234, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[236, 1, 1, "", "init_stats"], [236, 1, 1, "", "transform_action_spec"], [236, 1, 1, "", "transform_observation_spec"], [236, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.PermuteTransform": [[238, 1, 1, "", "transform_input_spec"], [238, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[239, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[240, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[241, 1, 1, "", "forward"]], "torchrl.envs.transforms.RemoveEmptySpecs": [[242, 1, 1, "", "forward"], [242, 1, 1, "", "transform_input_spec"], [242, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.RenameTransform": [[243, 1, 1, "", "forward"], [243, 1, 1, "", "transform_input_spec"], [243, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[244, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[245, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[246, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[247, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[248, 1, 1, "", "forward"], [248, 1, 1, "", "transform_input_spec"], [248, 1, 1, "", "transform_observation_spec"], [248, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.SelectTransform": [[249, 1, 1, "", "forward"], [249, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.SignTransform": [[250, 1, 1, "", "transform_observation_spec"], [250, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Stack": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "transform_done_spec"], [252, 1, 1, "", "transform_input_spec"], [252, 1, 1, "", "transform_observation_spec"], [252, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.StepCounter": [[253, 1, 1, "", "forward"], [253, 1, 1, "", "transform_input_spec"], [253, 1, 1, "", "transform_observation_spec"], [253, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[254, 1, 1, "", "forward"], [254, 1, 1, "", "transform_input_spec"], [254, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[255, 1, 1, "", "forward"], [255, 1, 1, "", "to"], [255, 1, 1, "", "transform_input_spec"], [255, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[256, 1, 1, "", "forward"], [256, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Timer": [[257, 1, 1, "", "forward"], [257, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[258, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Tokenizer": [[259, 1, 1, "", "forward"], [259, 1, 1, "", "transform_done_spec"], [259, 1, 1, "", "transform_input_spec"], [259, 1, 1, "", "transform_observation_spec"], [259, 1, 1, "", "transform_output_spec"], [259, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TrajCounter": [[260, 1, 1, "", "forward"], [260, 1, 1, "", "load_state_dict"], [260, 1, 1, "", "state_dict"], [260, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[261, 1, 1, "", "clone"], [261, 1, 1, "", "close"], [261, 2, 1, "", "container"], [261, 1, 1, "", "forward"], [261, 1, 1, "", "init"], [261, 1, 1, "", "inv"], [261, 2, 1, "", "parent"], [261, 1, 1, "", "reset_parent"], [261, 1, 1, "", "set_container"], [261, 1, 1, "", "to"], [261, 1, 1, "", "transform_action_spec"], [261, 1, 1, "", "transform_done_spec"], [261, 1, 1, "", "transform_env_batch_size"], [261, 1, 1, "", "transform_env_device"], [261, 1, 1, "", "transform_input_spec"], [261, 1, 1, "", "transform_observation_spec"], [261, 1, 1, "", "transform_output_spec"], [261, 1, 1, "", "transform_reward_spec"], [261, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.TransformedEnv": [[262, 1, 1, "", "add_truncated_keys"], [262, 1, 1, "", "append_transform"], [262, 2, 1, "", "batch_locked"], [262, 2, 1, "", "batch_size"], [262, 1, 1, "", "empty_cache"], [262, 1, 1, "", "eval"], [262, 2, 1, "", "input_spec"], [262, 1, 1, "", "insert_transform"], [262, 1, 1, "", "load_state_dict"], [262, 2, 1, "", "output_spec"], [262, 1, 1, "", "rand_action"], [262, 1, 1, "", "set_missing_tolerance"], [262, 1, 1, "", "set_seed"], [262, 1, 1, "", "state_dict"], [262, 1, 1, "", "to"], [262, 1, 1, "", "train"]], "torchrl.envs.transforms.UnaryTransform": [[263, 1, 1, "", "transform_action_spec"], [263, 1, 1, "", "transform_done_spec"], [263, 1, 1, "", "transform_input_spec"], [263, 1, 1, "", "transform_observation_spec"], [263, 1, 1, "", "transform_output_spec"], [263, 1, 1, "", "transform_reward_spec"], [263, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.UnsqueezeTransform": [[264, 1, 1, "", "transform_action_spec"], [264, 1, 1, "", "transform_observation_spec"], [264, 1, 1, "", "transform_reward_spec"], [264, 1, 1, "", "transform_state_spec"]], "torchrl.envs.transforms.VC1Transform": [[265, 1, 1, "", "forward"], [265, 1, 1, "", "make_noload_model"], [265, 1, 1, "", "to"], [265, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[267, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[268, 1, 1, "", "forward"], [268, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[269, 1, 1, "", "build_td_for_shared_vecnorm"], [269, 1, 1, "", "forward"], [269, 1, 1, "", "freeze"], [269, 1, 1, "", "frozen_copy"], [269, 1, 1, "", "get_extra_state"], [269, 2, 1, "", "loc"], [269, 2, 1, "", "scale"], [269, 1, 1, "", "set_extra_state"], [269, 2, 1, "", "standard_normal"], [269, 1, 1, "", "to_observation_norm"], [269, 1, 1, "", "transform_observation_spec"], [269, 1, 1, "", "unfreeze"]], "torchrl.envs.transforms.VecNormV2": [[270, 1, 1, "", "clone"], [270, 1, 1, "id0", "freeze"], [270, 1, 1, "id1", "frozen_copy"], [270, 1, 1, "id2", "get_extra_state"], [270, 2, 1, "id3", "loc"], [270, 2, 1, "id4", "scale"], [270, 1, 1, "id5", "set_extra_state"], [270, 2, 1, "id6", "standard_normal"], [270, 1, 1, "", "to_observation_norm"], [270, 1, 1, "id7", "transform_observation_spec"], [270, 1, 1, "id8", "transform_output_spec"], [270, 1, 1, "id9", "transform_reward_spec"], [270, 1, 1, "id10", "unfreeze"]], "torchrl.envs.transforms.rb_transforms": [[272, 0, 1, "", "MultiStepTransform"]], "torchrl.envs.transforms.rb_transforms.MultiStepTransform": [[272, 1, 1, "", "add_module"], [272, 1, 1, "", "apply"], [272, 1, 1, "", "bfloat16"], [272, 1, 1, "", "buffers"], [272, 1, 1, "", "children"], [272, 1, 1, "", "close"], [272, 1, 1, "", "compile"], [272, 2, 1, "", "container"], [272, 1, 1, "", "cpu"], [272, 1, 1, "", "cuda"], [272, 1, 1, "", "double"], [272, 1, 1, "", "eval"], [272, 1, 1, "", "extra_repr"], [272, 1, 1, "", "float"], [272, 1, 1, "", "forward"], [272, 1, 1, "", "get_buffer"], [272, 1, 1, "", "get_extra_state"], [272, 1, 1, "", "get_parameter"], [272, 1, 1, "", "get_submodule"], [272, 1, 1, "", "half"], [272, 1, 1, "", "init"], [272, 1, 1, "", "inv"], [272, 1, 1, "", "ipu"], [272, 1, 1, "", "load_state_dict"], [272, 1, 1, "", "modules"], [272, 1, 1, "", "mtia"], [272, 2, 1, "", "n_steps"], [272, 1, 1, "", "named_buffers"], [272, 1, 1, "", "named_children"], [272, 1, 1, "", "named_modules"], [272, 1, 1, "", "named_parameters"], [272, 1, 1, "", "parameters"], [272, 2, 1, "", "parent"], [272, 1, 1, "", "register_backward_hook"], [272, 1, 1, "", "register_buffer"], [272, 1, 1, "", "register_forward_hook"], [272, 1, 1, "", "register_forward_pre_hook"], [272, 1, 1, "", "register_full_backward_hook"], [272, 1, 1, "", "register_full_backward_pre_hook"], [272, 1, 1, "", "register_load_state_dict_post_hook"], [272, 1, 1, "", "register_load_state_dict_pre_hook"], [272, 1, 1, "", "register_module"], [272, 1, 1, "", "register_parameter"], [272, 1, 1, "", "register_state_dict_post_hook"], [272, 1, 1, "", "register_state_dict_pre_hook"], [272, 1, 1, "", "requires_grad_"], [272, 1, 1, "", "set_extra_state"], [272, 1, 1, "", "set_submodule"], [272, 1, 1, "", "share_memory"], [272, 1, 1, "", "state_dict"], [272, 1, 1, "", "to"], [272, 1, 1, "", "to_empty"], [272, 1, 1, "", "train"], [272, 1, 1, "", "transform_action_spec"], [272, 1, 1, "", "transform_done_spec"], [272, 1, 1, "", "transform_env_batch_size"], [272, 1, 1, "", "transform_env_device"], [272, 1, 1, "", "transform_input_spec"], [272, 1, 1, "", "transform_observation_spec"], [272, 1, 1, "", "transform_output_spec"], [272, 1, 1, "", "transform_reward_spec"], [272, 1, 1, "", "transform_state_spec"], [272, 1, 1, "", "type"], [272, 1, 1, "", "xpu"], [272, 1, 1, "", "zero_grad"]], "torchrl.implement_for": [[273, 1, 1, "", "get_class_that_defined_method"], [273, 1, 1, "", "import_module"], [273, 1, 1, "", "module_set"], [273, 1, 1, "", "reset"]], "torchrl.modules": [[274, 0, 1, "", "AdditiveGaussianModule"], [275, 0, 1, "", "BatchRenorm1d"], [276, 0, 1, "", "CEMPlanner"], [277, 0, 1, "", "ConsistentDropout"], [278, 0, 1, "", "ConsistentDropoutModule"], [279, 0, 1, "", "Conv3dNet"], [280, 0, 1, "", "ConvNet"], [281, 0, 1, "", "DTActor"], [282, 0, 1, "", "DdpgCnnActor"], [283, 0, 1, "", "DdpgCnnQNet"], [284, 0, 1, "", "DdpgMlpActor"], [285, 0, 1, "", "DdpgMlpQNet"], [286, 0, 1, "", "DecisionTransformer"], [287, 0, 1, "", "Delta"], [288, 0, 1, "", "DistributionalDQNnet"], [289, 0, 1, "", "DistributionalQValueHook"], [290, 0, 1, "", "DreamerActor"], [291, 0, 1, "", "DuelingCnnDQNet"], [292, 0, 1, "", "EGreedyModule"], [293, 0, 1, "", "GRU"], [294, 0, 1, "", "GRUCell"], [295, 0, 1, "", "GRUModule"], [296, 0, 1, "", "IndependentNormal"], [297, 0, 1, "", "LSTM"], [298, 0, 1, "", "LSTMCell"], [299, 0, 1, "", "LSTMModule"], [300, 0, 1, "", "MLP"], [301, 0, 1, "", "MPCPlannerBase"], [302, 0, 1, "", "MPPIPlanner"], [303, 0, 1, "", "MaskedCategorical"], [304, 0, 1, "", "MaskedOneHotCategorical"], [305, 0, 1, "", "MultiAgentConvNet"], [306, 0, 1, "", "MultiAgentMLP"], [307, 0, 1, "", "MultiAgentNetBase"], [308, 0, 1, "", "NoisyLazyLinear"], [309, 0, 1, "", "NoisyLinear"], [310, 0, 1, "", "ObsDecoder"], [311, 0, 1, "", "ObsEncoder"], [312, 0, 1, "", "OneHotCategorical"], [313, 0, 1, "", "OneHotOrdinal"], [314, 0, 1, "", "OnlineDTActor"], [315, 0, 1, "", "Ordinal"], [316, 0, 1, "", "OrnsteinUhlenbeckProcessModule"], [317, 0, 1, "", "QMixer"], [318, 0, 1, "", "QValueHook"], [319, 0, 1, "", "RSSMPosterior"], [320, 0, 1, "", "RSSMPrior"], [321, 0, 1, "", "Squeeze2dLayer"], [322, 0, 1, "", "SqueezeLayer"], [323, 0, 1, "", "TanhDelta"], [324, 0, 1, "", "TanhNormal"], [325, 0, 1, "", "TruncatedNormal"], [326, 0, 1, "", "VDNMixer"], [327, 0, 1, "", "VmapModule"], [335, 0, 1, "", "recurrent_mode"], [336, 0, 1, "", "reset_noise"], [337, 0, 1, "", "set_recurrent_mode"]], "torchrl.modules.AdditiveGaussianModule": [[274, 1, 1, "", "forward"], [274, 1, 1, "", "step"]], "torchrl.modules.BatchRenorm1d": [[275, 1, 1, "", "forward"]], "torchrl.modules.CEMPlanner": [[276, 1, 1, "", "planning"]], "torchrl.modules.ConsistentDropout": [[277, 1, 1, "", "forward"]], "torchrl.modules.ConsistentDropoutModule": [[278, 1, 1, "", "forward"], [278, 1, 1, "", "make_tensordict_primer"]], "torchrl.modules.Conv3dNet": [[279, 1, 1, "", "forward"]], "torchrl.modules.ConvNet": [[280, 1, 1, "", "default_atari_dqn"], [280, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[281, 1, 1, "", "default_config"], [281, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[282, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[283, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[284, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[285, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[286, 0, 1, "", "DTConfig"], [286, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[287, 1, 1, "", "expand"], [287, 1, 1, "", "log_prob"], [287, 2, 1, "", "mean"], [287, 2, 1, "", "mode"], [287, 1, 1, "", "rsample"], [287, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[288, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[290, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[291, 1, 1, "", "forward"]], "torchrl.modules.EGreedyModule": [[292, 1, 1, "", "forward"], [292, 1, 1, "", "step"]], "torchrl.modules.GRU": [[293, 1, 1, "", "forward"]], "torchrl.modules.GRUCell": [[294, 1, 1, "", "forward"]], "torchrl.modules.GRUModule": [[295, 1, 1, "", "forward"], [295, 1, 1, "", "make_cudnn_based"], [295, 1, 1, "", "make_python_based"], [295, 1, 1, "id0", "make_tensordict_primer"], [295, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[296, 2, 1, "", "mode"]], "torchrl.modules.LSTM": [[297, 1, 1, "", "forward"]], "torchrl.modules.LSTMCell": [[298, 1, 1, "", "forward"]], "torchrl.modules.LSTMModule": [[299, 1, 1, "", "forward"], [299, 1, 1, "", "make_cudnn_based"], [299, 1, 1, "", "make_python_based"], [299, 1, 1, "id0", "make_tensordict_primer"], [299, 1, 1, "", "set_recurrent_mode"]], "torchrl.modules.MLP": [[300, 1, 1, "", "forward"]], "torchrl.modules.MPCPlannerBase": [[301, 1, 1, "", "forward"], [301, 1, 1, "", "planning"]], "torchrl.modules.MPPIPlanner": [[302, 1, 1, "", "planning"]], "torchrl.modules.MaskedCategorical": [[303, 1, 1, "", "log_prob"], [303, 1, 1, "", "sample"]], "torchrl.modules.MaskedOneHotCategorical": [[304, 1, 1, "", "log_prob"], [304, 2, 1, "", "mode"], [304, 1, 1, "", "rsample"], [304, 1, 1, "", "sample"]], "torchrl.modules.MultiAgentNetBase": [[307, 1, 1, "", "forward"], [307, 1, 1, "", "from_stateful_net"], [307, 1, 1, "", "get_stateful_net"], [307, 1, 1, "", "reset_parameters"]], "torchrl.modules.NoisyLazyLinear": [[308, 1, 1, "", "initialize_parameters"]], "torchrl.modules.ObsDecoder": [[310, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[311, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[312, 1, 1, "", "entropy"], [312, 1, 1, "", "log_prob"], [312, 2, 1, "", "mode"], [312, 1, 1, "", "rsample"], [312, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[314, 1, 1, "", "default_config"], [314, 1, 1, "", "forward"]], "torchrl.modules.OrnsteinUhlenbeckProcessModule": [[316, 1, 1, "", "forward"], [316, 1, 1, "", "step"]], "torchrl.modules.QMixer": [[317, 1, 1, "", "mix"]], "torchrl.modules.RSSMPosterior": [[319, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[320, 1, 1, "", "forward"]], "torchrl.modules.SqueezeLayer": [[322, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[323, 2, 1, "", "mean"], [323, 2, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[324, 1, 1, "", "get_mode"], [324, 2, 1, "", "mean"], [324, 2, 1, "", "mode"], [324, 2, 1, "", "support"]], "torchrl.modules.TruncatedNormal": [[325, 1, 1, "", "log_prob"], [325, 2, 1, "", "mode"]], "torchrl.modules.VDNMixer": [[326, 1, 1, "", "mix"]], "torchrl.modules.VmapModule": [[327, 1, 1, "", "forward"]], "torchrl.modules.llm": [[328, 0, 1, "", "CategoricalSequential"], [329, 0, 1, "", "LLMOnDevice"], [330, 0, 1, "", "TransformersWrapper"], [331, 0, 1, "", "make_vllm_worker"], [332, 0, 1, "", "stateless_init_process_group"], [333, 0, 1, "", "vLLMWorker"], [334, 0, 1, "", "vLLMWrapper"]], "torchrl.modules.llm.CategoricalSequential": [[328, 1, 1, "", "add_module"], [328, 1, 1, "", "apply"], [328, 1, 1, "", "bfloat16"], [328, 1, 1, "", "buffers"], [328, 1, 1, "", "children"], [328, 1, 1, "", "compile"], [328, 1, 1, "", "cpu"], [328, 1, 1, "", "cuda"], [328, 1, 1, "", "double"], [328, 1, 1, "", "eval"], [328, 1, 1, "", "extra_repr"], [328, 1, 1, "", "float"], [328, 1, 1, "", "forward"], [328, 1, 1, "", "get_buffer"], [328, 1, 1, "", "get_extra_state"], [328, 1, 1, "", "get_parameter"], [328, 1, 1, "", "get_submodule"], [328, 1, 1, "", "half"], [328, 1, 1, "", "ipu"], [328, 1, 1, "", "is_tdmodule_compatible"], [328, 1, 1, "", "load_state_dict"], [328, 1, 1, "", "modules"], [328, 1, 1, "", "mtia"], [328, 1, 1, "", "named_buffers"], [328, 1, 1, "", "named_children"], [328, 1, 1, "", "named_modules"], [328, 1, 1, "", "named_parameters"], [328, 1, 1, "", "parameters"], [328, 1, 1, "", "register_backward_hook"], [328, 1, 1, "", "register_buffer"], [328, 1, 1, "", "register_forward_hook"], [328, 1, 1, "", "register_forward_pre_hook"], [328, 1, 1, "", "register_full_backward_hook"], [328, 1, 1, "", "register_full_backward_pre_hook"], [328, 1, 1, "", "register_load_state_dict_post_hook"], [328, 1, 1, "", "register_load_state_dict_pre_hook"], [328, 1, 1, "", "register_module"], [328, 1, 1, "", "register_parameter"], [328, 1, 1, "", "register_state_dict_post_hook"], [328, 1, 1, "", "register_state_dict_pre_hook"], [328, 1, 1, "", "requires_grad_"], [328, 1, 1, "", "reset_out_keys"], [328, 1, 1, "", "reset_parameters_recursive"], [328, 1, 1, "", "select_out_keys"], [328, 1, 1, "", "set_extra_state"], [328, 1, 1, "", "set_submodule"], [328, 1, 1, "", "share_memory"], [328, 1, 1, "", "state_dict"], [328, 1, 1, "", "to"], [328, 1, 1, "", "to_empty"], [328, 1, 1, "", "train"], [328, 1, 1, "", "type"], [328, 1, 1, "", "xpu"], [328, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.TransformersWrapper": [[330, 1, 1, "", "add_module"], [330, 1, 1, "", "apply"], [330, 1, 1, "", "bfloat16"], [330, 1, 1, "", "buffers"], [330, 1, 1, "", "children"], [330, 1, 1, "", "compile"], [330, 1, 1, "", "cpu"], [330, 1, 1, "", "cuda"], [330, 1, 1, "", "double"], [330, 1, 1, "", "eval"], [330, 1, 1, "", "extra_repr"], [330, 1, 1, "", "float"], [330, 1, 1, "", "forward"], [330, 1, 1, "", "get_buffer"], [330, 1, 1, "", "get_extra_state"], [330, 1, 1, "", "get_parameter"], [330, 1, 1, "", "get_submodule"], [330, 1, 1, "", "half"], [330, 1, 1, "", "ipu"], [330, 1, 1, "", "is_tdmodule_compatible"], [330, 1, 1, "", "load_state_dict"], [330, 1, 1, "", "modules"], [330, 1, 1, "", "mtia"], [330, 1, 1, "", "named_buffers"], [330, 1, 1, "", "named_children"], [330, 1, 1, "", "named_modules"], [330, 1, 1, "", "named_parameters"], [330, 1, 1, "", "parameters"], [330, 1, 1, "", "register_backward_hook"], [330, 1, 1, "", "register_buffer"], [330, 1, 1, "", "register_forward_hook"], [330, 1, 1, "", "register_forward_pre_hook"], [330, 1, 1, "", "register_full_backward_hook"], [330, 1, 1, "", "register_full_backward_pre_hook"], [330, 1, 1, "", "register_load_state_dict_post_hook"], [330, 1, 1, "", "register_load_state_dict_pre_hook"], [330, 1, 1, "", "register_module"], [330, 1, 1, "", "register_parameter"], [330, 1, 1, "", "register_state_dict_post_hook"], [330, 1, 1, "", "register_state_dict_pre_hook"], [330, 1, 1, "", "requires_grad_"], [330, 1, 1, "", "reset_out_keys"], [330, 1, 1, "", "reset_parameters_recursive"], [330, 1, 1, "", "select_out_keys"], [330, 1, 1, "", "set_extra_state"], [330, 1, 1, "", "set_submodule"], [330, 1, 1, "", "share_memory"], [330, 1, 1, "", "state_dict"], [330, 1, 1, "", "to"], [330, 1, 1, "", "to_empty"], [330, 1, 1, "", "train"], [330, 1, 1, "", "type"], [330, 1, 1, "", "xpu"], [330, 1, 1, "", "zero_grad"]], "torchrl.modules.llm.vLLMWorker": [[333, 1, 1, "", "check_weights_changed"]], "torchrl.modules.llm.vLLMWrapper": [[334, 1, 1, "", "add_module"], [334, 1, 1, "", "apply"], [334, 1, 1, "", "bfloat16"], [334, 1, 1, "", "buffers"], [334, 1, 1, "", "children"], [334, 1, 1, "", "compile"], [334, 1, 1, "", "cpu"], [334, 1, 1, "", "cuda"], [334, 1, 1, "", "double"], [334, 1, 1, "", "eval"], [334, 1, 1, "", "extra_repr"], [334, 1, 1, "", "float"], [334, 1, 1, "", "forward"], [334, 1, 1, "", "get_buffer"], [334, 1, 1, "", "get_extra_state"], [334, 1, 1, "", "get_parameter"], [334, 1, 1, "", "get_submodule"], [334, 1, 1, "", "half"], [334, 1, 1, "", "ipu"], [334, 1, 1, "", "is_tdmodule_compatible"], [334, 1, 1, "", "load_state_dict"], [334, 1, 1, "", "modules"], [334, 1, 1, "", "mtia"], [334, 1, 1, "", "named_buffers"], [334, 1, 1, "", "named_children"], [334, 1, 1, "", "named_modules"], [334, 1, 1, "", "named_parameters"], [334, 1, 1, "", "parameters"], [334, 1, 1, "", "register_backward_hook"], [334, 1, 1, "", "register_buffer"], [334, 1, 1, "", "register_forward_hook"], [334, 1, 1, "", "register_forward_pre_hook"], [334, 1, 1, "", "register_full_backward_hook"], [334, 1, 1, "", "register_full_backward_pre_hook"], [334, 1, 1, "", "register_load_state_dict_post_hook"], [334, 1, 1, "", "register_load_state_dict_pre_hook"], [334, 1, 1, "", "register_module"], [334, 1, 1, "", "register_parameter"], [334, 1, 1, "", "register_state_dict_post_hook"], [334, 1, 1, "", "register_state_dict_pre_hook"], [334, 1, 1, "", "requires_grad_"], [334, 1, 1, "", "reset_out_keys"], [334, 1, 1, "", "reset_parameters_recursive"], [334, 1, 1, "", "select_out_keys"], [334, 1, 1, "", "set_extra_state"], [334, 1, 1, "", "set_submodule"], [334, 1, 1, "", "share_memory"], [334, 1, 1, "", "state_dict"], [334, 1, 1, "", "to"], [334, 1, 1, "", "to_empty"], [334, 1, 1, "", "train"], [334, 1, 1, "", "type"], [334, 1, 1, "", "xpu"], [334, 1, 1, "", "zero_grad"]], "torchrl.modules.tensordict_module": [[338, 0, 1, "", "Actor"], [339, 0, 1, "", "ActorCriticOperator"], [340, 0, 1, "", "ActorCriticWrapper"], [341, 0, 1, "", "ActorValueOperator"], [342, 0, 1, "", "DecisionTransformerInferenceWrapper"], [343, 0, 1, "", "DistributionalQValueActor"], [344, 0, 1, "", "DistributionalQValueModule"], [345, 0, 1, "", "LMHeadActorValueOperator"], [346, 0, 1, "", "MultiStepActorWrapper"], [347, 0, 1, "", "ProbabilisticActor"], [348, 0, 1, "", "QValueActor"], [349, 0, 1, "", "QValueModule"], [350, 0, 1, "", "SafeModule"], [351, 0, 1, "", "SafeProbabilisticModule"], [352, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [353, 0, 1, "", "SafeSequential"], [354, 0, 1, "", "TanhModule"], [355, 0, 1, "", "ValueOperator"], [356, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.tensordict_module.ActorCriticOperator": [[339, 1, 1, "", "get_critic_operator"], [339, 1, 1, "", "get_policy_head"], [339, 1, 1, "", "get_value_head"], [339, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorCriticWrapper": [[340, 1, 1, "", "get_policy_head"], [340, 1, 1, "", "get_policy_operator"], [340, 1, 1, "", "get_value_head"], [340, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorValueOperator": [[341, 1, 1, "", "get_policy_head"], [341, 1, 1, "", "get_policy_operator"], [341, 1, 1, "", "get_value_head"], [341, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper": [[342, 1, 1, "", "forward"], [342, 1, 1, "", "mask_context"], [342, 1, 1, "", "set_tensor_keys"]], "torchrl.modules.tensordict_module.DistributionalQValueModule": [[344, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.MultiStepActorWrapper": [[346, 1, 1, "", "forward"], [346, 2, 1, "", "init_key"]], "torchrl.modules.tensordict_module.QValueModule": [[349, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.SafeModule": [[350, 1, 1, "", "random"], [350, 1, 1, "", "random_sample"], [350, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[351, 1, 1, "", "random"], [351, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[354, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.WorldModelWrapper": [[356, 1, 1, "", "get_reward_operator"], [356, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.utils": [[357, 0, 1, "", "biased_softplus"], [358, 0, 1, "", "get_primers_from_module"], [359, 0, 1, "", "inv_softplus"], [360, 0, 1, "", "mappings"]], "torchrl.modules.utils.biased_softplus": [[357, 1, 1, "", "forward"]], "torchrl.objectives": [[361, 0, 1, "", "A2CLoss"], [362, 0, 1, "", "CQLLoss"], [363, 0, 1, "", "ClipPPOLoss"], [364, 0, 1, "", "CrossQLoss"], [365, 0, 1, "", "DDPGLoss"], [366, 0, 1, "", "DQNLoss"], [367, 0, 1, "", "DTLoss"], [368, 0, 1, "", "DiscreteCQLLoss"], [369, 0, 1, "", "DiscreteIQLLoss"], [370, 0, 1, "", "DiscreteSACLoss"], [371, 0, 1, "", "DistributionalDQNLoss"], [372, 0, 1, "", "DreamerActorLoss"], [373, 0, 1, "", "DreamerModelLoss"], [374, 0, 1, "", "DreamerValueLoss"], [375, 0, 1, "", "GAILLoss"], [376, 0, 1, "", "HardUpdate"], [377, 0, 1, "", "IQLLoss"], [378, 0, 1, "", "KLPENPPOLoss"], [379, 0, 1, "", "LossModule"], [380, 0, 1, "", "OnlineDTLoss"], [381, 0, 1, "", "PPOLoss"], [382, 0, 1, "", "REDQLoss"], [383, 0, 1, "", "ReinforceLoss"], [384, 0, 1, "", "SACLoss"], [385, 0, 1, "", "SoftUpdate"], [386, 0, 1, "", "TD3BCLoss"], [387, 0, 1, "", "TD3Loss"], [388, 0, 1, "", "ValueEstimators"], [389, 0, 1, "", "default_value_kwargs"], [390, 0, 1, "", "distance_loss"], [391, 0, 1, "", "group_optimizers"], [392, 0, 1, "", "hold_out_net"], [393, 0, 1, "", "hold_out_params"], [398, 0, 1, "", "next_state_value"]], "torchrl.objectives.A2CLoss": [[361, 4, 1, "", "default_keys"], [361, 1, 1, "", "forward"], [361, 2, 1, "", "functional"], [361, 1, 1, "", "loss_critic"], [361, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[362, 4, 1, "", "default_keys"], [362, 1, 1, "", "forward"], [362, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[363, 1, 1, "", "forward"]], "torchrl.objectives.CrossQLoss": [[364, 1, 1, "", "actor_loss"], [364, 1, 1, "", "alpha_loss"], [364, 4, 1, "", "default_keys"], [364, 1, 1, "", "forward"], [364, 1, 1, "", "load_state_dict"], [364, 1, 1, "", "make_value_estimator"], [364, 1, 1, "", "maybe_init_target_entropy"], [364, 1, 1, "", "qvalue_loss"], [364, 1, 1, "", "set_keys"], [364, 1, 1, "", "state_dict"], [364, 2, 1, "", "target_entropy_buffer"]], "torchrl.objectives.DDPGLoss": [[365, 4, 1, "", "default_keys"], [365, 1, 1, "", "forward"], [365, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[366, 4, 1, "", "default_keys"], [366, 1, 1, "", "forward"], [366, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[367, 4, 1, "", "default_keys"], [367, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[368, 4, 1, "", "default_keys"], [368, 1, 1, "", "forward"], [368, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteIQLLoss": [[369, 4, 1, "", "default_keys"], [369, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteSACLoss": [[370, 4, 1, "", "default_keys"], [370, 1, 1, "", "forward"], [370, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[371, 4, 1, "", "default_keys"], [371, 1, 1, "", "forward"], [371, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[372, 4, 1, "", "default_keys"], [372, 1, 1, "", "forward"], [372, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[373, 4, 1, "", "default_keys"], [373, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[374, 4, 1, "", "default_keys"], [374, 1, 1, "", "forward"]], "torchrl.objectives.GAILLoss": [[375, 4, 1, "", "default_keys"], [375, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[377, 4, 1, "", "default_keys"], [377, 1, 1, "", "forward"], [377, 1, 1, "", "loss_value_diff"], [377, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[378, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[379, 1, 1, "", "convert_to_functional"], [379, 1, 1, "", "forward"], [379, 1, 1, "", "from_stateful_net"], [379, 2, 1, "", "functional"], [379, 1, 1, "", "get_stateful_net"], [379, 1, 1, "", "make_value_estimator"], [379, 1, 1, "", "named_parameters"], [379, 1, 1, "", "parameters"], [379, 1, 1, "", "reset_parameters_recursive"], [379, 1, 1, "", "set_keys"], [379, 2, 1, "", "value_estimator"], [379, 2, 1, "", "vmap_randomness"]], "torchrl.objectives.OnlineDTLoss": [[380, 4, 1, "", "default_keys"], [380, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[381, 4, 1, "", "default_keys"], [381, 1, 1, "", "forward"], [381, 2, 1, "", "functional"], [381, 1, 1, "", "loss_critic"], [381, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[382, 4, 1, "", "default_keys"], [382, 1, 1, "", "forward"], [382, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[383, 4, 1, "", "default_keys"], [383, 1, 1, "", "forward"], [383, 2, 1, "", "functional"], [383, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[384, 4, 1, "", "default_keys"], [384, 1, 1, "", "forward"], [384, 1, 1, "", "load_state_dict"], [384, 1, 1, "", "make_value_estimator"], [384, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3BCLoss": [[386, 1, 1, "", "actor_loss"], [386, 4, 1, "", "default_keys"], [386, 1, 1, "", "forward"], [386, 1, 1, "", "make_value_estimator"], [386, 1, 1, "", "qvalue_loss"]], "torchrl.objectives.TD3Loss": [[387, 4, 1, "", "default_keys"], [387, 1, 1, "", "forward"], [387, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.llm": [[394, 0, 1, "", "GRPOLoss"], [395, 0, 1, "", "GRPOLossOutput"], [396, 0, 1, "", "MCAdvantage"]], "torchrl.objectives.llm.GRPOLoss": [[394, 1, 1, "", "add_module"], [394, 1, 1, "", "apply"], [394, 1, 1, "", "bfloat16"], [394, 1, 1, "", "buffers"], [394, 1, 1, "", "children"], [394, 1, 1, "", "compile"], [394, 1, 1, "", "convert_to_functional"], [394, 1, 1, "", "cpu"], [394, 1, 1, "", "cuda"], [394, 4, 1, "", "default_keys"], [394, 1, 1, "", "double"], [394, 1, 1, "", "eval"], [394, 1, 1, "", "extra_repr"], [394, 1, 1, "", "float"], [394, 1, 1, "", "forward"], [394, 1, 1, "", "from_stateful_net"], [394, 2, 1, "", "functional"], [394, 1, 1, "", "get_buffer"], [394, 1, 1, "", "get_extra_state"], [394, 1, 1, "", "get_parameter"], [394, 1, 1, "", "get_stateful_net"], [394, 1, 1, "", "get_submodule"], [394, 1, 1, "", "half"], [394, 1, 1, "", "ipu"], [394, 1, 1, "", "is_tdmodule_compatible"], [394, 1, 1, "", "load_state_dict"], [394, 1, 1, "", "loss_critic"], [394, 1, 1, "", "make_value_estimator"], [394, 1, 1, "", "modules"], [394, 1, 1, "", "mtia"], [394, 1, 1, "", "named_buffers"], [394, 1, 1, "", "named_children"], [394, 1, 1, "", "named_modules"], [394, 1, 1, "", "named_parameters"], [394, 1, 1, "", "parameters"], [394, 1, 1, "", "register_backward_hook"], [394, 1, 1, "", "register_buffer"], [394, 1, 1, "", "register_forward_hook"], [394, 1, 1, "", "register_forward_pre_hook"], [394, 1, 1, "", "register_full_backward_hook"], [394, 1, 1, "", "register_full_backward_pre_hook"], [394, 1, 1, "", "register_load_state_dict_post_hook"], [394, 1, 1, "", "register_load_state_dict_pre_hook"], [394, 1, 1, "", "register_module"], [394, 1, 1, "", "register_parameter"], [394, 1, 1, "", "register_state_dict_post_hook"], [394, 1, 1, "", "register_state_dict_pre_hook"], [394, 1, 1, "", "requires_grad_"], [394, 1, 1, "", "reset_out_keys"], [394, 1, 1, "", "reset_parameters_recursive"], [394, 1, 1, "", "select_out_keys"], [394, 1, 1, "", "set_extra_state"], [394, 1, 1, "", "set_keys"], [394, 1, 1, "", "set_submodule"], [394, 1, 1, "", "share_memory"], [394, 1, 1, "", "state_dict"], [394, 1, 1, "", "to"], [394, 1, 1, "", "to_empty"], [394, 1, 1, "", "train"], [394, 1, 1, "", "type"], [394, 2, 1, "", "value_estimator"], [394, 2, 1, "", "vmap_randomness"], [394, 1, 1, "", "xpu"], [394, 1, 1, "", "zero_grad"]], "torchrl.objectives.llm.GRPOLossOutput": [[395, 2, 1, "", "device"], [395, 1, 1, "", "dumps"], [395, 1, 1, "", "fields"], [395, 1, 1, "", "from_tensordict"], [395, 1, 1, "", "get"], [395, 1, 1, "", "load"], [395, 1, 1, "", "load_"], [395, 1, 1, "", "load_memmap"], [395, 1, 1, "", "load_state_dict"], [395, 1, 1, "", "memmap"], [395, 1, 1, "", "memmap_"], [395, 1, 1, "", "memmap_like"], [395, 1, 1, "", "memmap_refresh_"], [395, 1, 1, "", "save"], [395, 1, 1, "", "set"], [395, 1, 1, "", "state_dict"], [395, 1, 1, "", "to_tensordict"], [395, 1, 1, "", "unbind"]], "torchrl.objectives.llm.MCAdvantage": [[396, 1, 1, "", "add_module"], [396, 1, 1, "", "apply"], [396, 1, 1, "", "bfloat16"], [396, 1, 1, "", "buffers"], [396, 1, 1, "", "children"], [396, 1, 1, "", "close"], [396, 1, 1, "", "compile"], [396, 2, 1, "", "container"], [396, 1, 1, "", "cpu"], [396, 1, 1, "", "cuda"], [396, 1, 1, "", "double"], [396, 1, 1, "", "eval"], [396, 1, 1, "", "extra_repr"], [396, 1, 1, "", "float"], [396, 1, 1, "", "forward"], [396, 1, 1, "", "get_buffer"], [396, 1, 1, "", "get_extra_state"], [396, 1, 1, "", "get_parameter"], [396, 1, 1, "", "get_submodule"], [396, 1, 1, "", "half"], [396, 1, 1, "", "init"], [396, 1, 1, "", "inv"], [396, 1, 1, "", "ipu"], [396, 1, 1, "", "load_state_dict"], [396, 1, 1, "", "modules"], [396, 1, 1, "", "mtia"], [396, 1, 1, "", "named_buffers"], [396, 1, 1, "", "named_children"], [396, 1, 1, "", "named_modules"], [396, 1, 1, "", "named_parameters"], [396, 1, 1, "", "parameters"], [396, 2, 1, "", "parent"], [396, 1, 1, "", "register_backward_hook"], [396, 1, 1, "", "register_buffer"], [396, 1, 1, "", "register_forward_hook"], [396, 1, 1, "", "register_forward_pre_hook"], [396, 1, 1, "", "register_full_backward_hook"], [396, 1, 1, "", "register_full_backward_pre_hook"], [396, 1, 1, "", "register_load_state_dict_post_hook"], [396, 1, 1, "", "register_load_state_dict_pre_hook"], [396, 1, 1, "", "register_module"], [396, 1, 1, "", "register_parameter"], [396, 1, 1, "", "register_state_dict_post_hook"], [396, 1, 1, "", "register_state_dict_pre_hook"], [396, 1, 1, "", "requires_grad_"], [396, 1, 1, "", "set_extra_state"], [396, 1, 1, "", "set_submodule"], [396, 1, 1, "", "share_memory"], [396, 1, 1, "", "state_dict"], [396, 1, 1, "", "to"], [396, 1, 1, "", "to_empty"], [396, 1, 1, "", "train"], [396, 1, 1, "", "transform_action_spec"], [396, 1, 1, "", "transform_done_spec"], [396, 1, 1, "", "transform_env_batch_size"], [396, 1, 1, "", "transform_env_device"], [396, 1, 1, "", "transform_input_spec"], [396, 1, 1, "", "transform_observation_spec"], [396, 1, 1, "", "transform_output_spec"], [396, 1, 1, "", "transform_reward_spec"], [396, 1, 1, "", "transform_state_spec"], [396, 1, 1, "", "type"], [396, 1, 1, "", "xpu"], [396, 1, 1, "", "zero_grad"]], "torchrl.objectives.multiagent": [[397, 0, 1, "", "QMixerLoss"]], "torchrl.objectives.multiagent.QMixerLoss": [[397, 4, 1, "", "default_keys"], [397, 1, 1, "", "forward"], [397, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.value": [[399, 0, 1, "", "GAE"], [400, 0, 1, "", "TD0Estimator"], [401, 0, 1, "", "TD1Estimator"], [402, 0, 1, "", "TDLambdaEstimator"], [403, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[399, 1, 1, "", "forward"], [399, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[400, 1, 1, "", "forward"], [400, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[401, 1, 1, "", "forward"], [401, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[402, 1, 1, "", "forward"], [402, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[403, 4, 1, "", "default_keys"], [403, 1, 1, "", "forward"], [403, 1, 1, "", "set_keys"], [403, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.functional": [[404, 0, 1, "", "generalized_advantage_estimate"], [405, 0, 1, "", "reward2go"], [406, 0, 1, "", "td0_advantage_estimate"], [407, 0, 1, "", "td0_return_estimate"], [408, 0, 1, "", "td1_advantage_estimate"], [409, 0, 1, "", "td1_return_estimate"], [410, 0, 1, "", "td_lambda_advantage_estimate"], [411, 0, 1, "", "td_lambda_return_estimate"], [412, 0, 1, "", "vec_generalized_advantage_estimate"], [413, 0, 1, "", "vec_td1_advantage_estimate"], [414, 0, 1, "", "vec_td1_return_estimate"], [415, 0, 1, "", "vec_td_lambda_advantage_estimate"], [416, 0, 1, "", "vec_td_lambda_return_estimate"]], "torchrl.record": [[417, 3, 1, "", "PixelRenderTransform"], [418, 3, 1, "", "TensorDictRecorder"], [419, 3, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[420, 3, 1, "", "Logger"], [422, 3, 1, "", "generate_exp_name"], [423, 3, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[421, 3, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[424, 3, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[425, 3, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.wandb": [[426, 3, 1, "", "WandbLogger"]], "torchrl.trainers": [[428, 0, 1, "", "BatchSubSampler"], [429, 0, 1, "", "ClearCudaCache"], [430, 0, 1, "", "CountFramesLog"], [431, 0, 1, "", "LogScalar"], [432, 0, 1, "", "LogValidationReward"], [433, 0, 1, "", "OptimizerHook"], [434, 0, 1, "", "ReplayBufferTrainer"], [435, 0, 1, "", "RewardNormalizer"], [436, 0, 1, "", "SelectKeys"], [437, 0, 1, "", "Trainer"], [438, 0, 1, "", "TrainerHookBase"], [439, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[428, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[429, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[430, 1, 1, "", "register"]], "torchrl.trainers.LogScalar": [[431, 1, 1, "", "register"]], "torchrl.trainers.LogValidationReward": [[432, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[433, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[434, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[435, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[436, 1, 1, "", "register"]], "torchrl.trainers.Trainer": [[437, 1, 1, "", "load_from_file"]], "torchrl.trainers.TrainerHookBase": [[438, 1, 1, "", "register"]], "torchrl.trainers.UpdateWeights": [[439, 1, 1, "", "register"]], "torchrl.trainers.helpers": [[440, 3, 1, "", "correct_for_frame_skip"], [441, 3, 1, "", "get_stats_random_rollout"], [442, 3, 1, "", "make_collector_offpolicy"], [443, 3, 1, "", "make_collector_onpolicy"], [444, 3, 1, "", "make_dqn_loss"], [445, 3, 1, "", "make_replay_buffer"], [446, 3, 1, "", "make_target_updater"], [447, 3, 1, "", "make_trainer"], [448, 3, 1, "", "parallel_env_constructor"], [449, 3, 1, "", "sync_async_collector"], [450, 3, 1, "", "sync_sync_collector"], [451, 3, 1, "", "transformed_env_constructor"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchrl": [0, 1, 2, 3, 6, 9, 456, 457, 458, 459, 461, 462, 463, 465, 467, 474, 475, 476, 480, 481], "instal": [0, 6, 7, 480], "get": [0, 466, 467, 468, 469, 470, 471], "start": [0, 466, 467, 468, 469, 470, 471], "tutori": [0, 463, 474, 475], "basic": [0, 478], "intermedi": [0, 8], "advanc": 0, "refer": [0, 453], "knowledg": [0, 454], "base": [0, 2, 7, 454, 465], "indic": 0, "tabl": 0, "collector": [1, 455, 461, 462, 463, 464, 469, 471, 474, 475, 480], "packag": [1, 2, 3, 456, 457, 458, 459], "batch": [1, 3, 461, 476, 478], "size": [1, 3, 461, 478], "polici": [1, 2, 4, 457, 461, 463, 464, 465, 467, 471, 473, 474, 475, 476], "copi": 1, "weight": 1, "synchron": 1, "distribut": [1, 456], "environ": [1, 3, 4, 6, 7, 455, 461, 462, 463, 464, 466, 471, 473, 474, 475, 476, 480, 481], "send": 1, "receiv": 1, "model": [1, 2, 4, 456, 461, 462, 464, 465, 468, 477, 480], "weightupdat": 1, "extend": 1, "updat": [1, 461], "class": [1, 3, 455, 476, 480], "replai": [1, 2, 3, 461, 462, 463, 464, 469, 471, 474, 475, 478, 480], "buffer": [1, 2, 3, 461, 462, 463, 464, 469, 471, 474, 475, 478, 480], "interoper": 1, "run": [1, 465, 466, 481], "asynchron": 1, "singl": [1, 4], "node": 1, "data": [1, 2, 4, 455, 461, 462, 463, 469, 471, 474, 475, 480], "helper": [1, 3], "function": [1, 4, 457, 462, 463, 468, 474, 475, 480], "compos": [2, 216], "support": 2, "type": 2, "choos": 2, "storag": [2, 116, 461, 469, 478], "sampl": [2, 478], "index": 2, "share": 2, "across": 2, "process": 2, "store": [2, 462, 478], "trajectori": [2, 478], "checkpoint": [2, 458], "episod": [2, 4], "format": 2, "ted": [2, 466], "The": [2, 461], "rational": 2, "behind": 2, "structur": [2, 455, 478], "A": [2, 462, 478], "note": 2, "singleton": [2, 4], "dimens": 2, "flatten": 2, "reduc": 2, "memori": 2, "consumpt": 2, "dimension": [2, 4], "tensordict": [2, 456, 478, 480], "special": [2, 467, 480], "case": 2, "footnot": 2, "multi": [2, 3, 456, 457, 473, 474, 475], "agent": [2, 3, 4, 456, 457, 474, 475], "present": 2, "rnn": 2, "transform": [2, 3, 261, 455, 461, 463, 466, 474, 475, 476, 478, 480, 481], "step": [2, 3, 461, 463, 466, 469, 474, 475, 478, 481], "what": [2, 5], "about": 2, "requir": 2, "dataset": 2, "tensorspec": [2, 82], "numer": 2, "subclass": [2, 3], "categor": [2, 38], "tree": [2, 84], "forest": 2, "tensordictmap": [2, 77], "mctsforest": [2, 50], "larg": 2, "languag": 2, "reinforc": [2, 457, 463, 474, 475], "learn": [2, 4, 456, 463, 474, 475], "from": [2, 6, 7], "human": 2, "feedback": 2, "rlhf": 2, "util": [2, 455, 456, 457, 458, 474], "env": [3, 476, 480, 481], "spec": [3, 476, 481], "lock": 3, "method": [3, 461], "partial": 3, "reset": [3, 476, 481], "vector": [3, 480], "async": [3, 480], "exampl": [3, 11, 462, 478], "custom": [3, 11, 476, 478], "nativ": 3, "auto": 3, "dynam": [3, 4, 478], "forward": [3, 4, 461], "invers": 3, "understand": 3, "kei": 3, "tensor": [3, 478], "expos": 3, "outsid": 3, "world": 3, "design": [3, 471], "your": [3, 4, 6, 461, 465, 471, 476], "own": [3, 471], "tip": 3, "us": [3, 4, 6, 9, 457, 464, 477, 478, 480], "clone": [3, 7], "mask": 3, "action": [3, 4, 457, 464, 476], "record": [3, 458, 461, 470], "video": [3, 11, 470], "domain": [3, 456], "specif": [3, 456, 473], "librari": [3, 480], "thing": [4, 461, 476], "consid": 4, "when": [4, 7], "debug": 4, "rl": [4, 9, 466, 468, 480], "gener": [4, 11, 456], "have": 4, "you": 4, "valid": 4, "algorithm": [4, 456], "implement": 4, "few": 4, "small": 4, "toi": 4, "problem": 4, "known": 4, "optim": [4, 461, 462, 468, 471], "return": [4, 457], "e": 4, "g": 4, "gridworld": 4, "mountaincar": 4, "visual": 4, "Be": 4, "veri": 4, "care": 4, "ani": 4, "augment": 4, "doe": 4, "entropi": 4, "converg": 4, "too": [4, 8], "quickli": 4, "slowli": 4, "chang": [4, 480], "drastic": 4, "reward": 4, "beyond": 4, "go": 4, "up": [4, 6], "Is": 4, "favor": 4, "compon": 4, "i": 4, "veloc": 4, "vs": 4, "l2": 4, "magnitud": 4, "task": [4, 473], "horizon": 4, "extrem": 4, "long": 4, "ar": 4, "normal": [4, 461, 462, 463], "standard": 4, "explor": [4, 456, 461, 462, 467], "valu": [4, 456, 457, 461, 463, 464, 467], "loss": [4, 461, 462, 463, 464, 471, 474, 475], "earli": 4, "train": [4, 8, 457, 461, 463, 464, 465, 468, 471, 474, 475, 476], "roughli": 4, "uniformli": 4, "random": [4, 457, 474, 475], "intrins": 4, "decai": 4, "progress": 4, "remain": 4, "constant": [4, 462], "increas": 4, "an": [4, 463, 464, 466, 476], "can": 4, "low": 4, "also": 4, "offlin": 4, "observ": [4, 461], "space": 4, "effect": [4, 476], "dramat": 4, "dure": [4, 7], "high": 4, "work": [5, 6, 7, 465], "gym": [5, 480, 481], "openai": 5, "version": [5, 7, 10], "habitat": 6, "lab": 6, "set": [6, 11], "pip": [6, 7], "common": [6, 7, 8], "issu": [6, 7, 10], "mujoco": 7, "prerequisit": [7, 461], "render": [7, 11, 471, 474, 475, 481], "all": 7, "new": 7, "bindindg": 7, "2": 7, "1": 7, "old": 7, "bind": 7, "py": 7, "option": 7, "repo": [7, 9], "import": [7, 461], "pytorch": [8, 9, 10, 465], "error": 8, "solut": 8, "gradient": 8, "relat": 8, "newcom": 8, "my": 8, "slow": 8, "bug": 8, "resourc": 9, "paper": 9, "document": 9, "functorch": 9, "blog": 9, "websit": 9, "educ": 9, "forum": 9, "how": 10, "reproduc": [10, 476], "workaround": 10, "customis": 11, "tweak": 11, "principl": 11, "auto_unwrap_transformed_env": 12, "datacollectorbas": 13, "multiprocessedweightupdat": 14, "multisyncdatacollector": 15, "multiasyncdatacollector": 16, "rayweightupdat": 17, "syncdatacollector": 18, "vanillaweightupdat": 19, "weightupdaterbas": 20, "asyncdatacollector": 21, "distributeddatacollector": 22, "distributedsyncdatacollector": 23, "distributedweightupdat": 24, "rpcdatacollector": 25, "rpcweightupdat": 26, "raycollector": 27, "submitit_delayed_launch": 28, "llmcollector": 29, "vllmupdat": 30, "split_trajectori": 31, "adaptiveklcontrol": 32, "binari": [33, 465], "binarydiscretetensorspec": 34, "binarytodecim": 35, "bound": 36, "boundedtensorspec": 37, "composit": 39, "compositespec": 40, "constantklcontrol": 41, "densifyreward": 42, "discretetensorspec": 43, "flat2t": 44, "h5combin": 45, "h5split": 46, "hashtoint": 47, "lazystackedcompositespec": 48, "lazystackedtensorspec": 49, "multicategor": 51, "multidiscretetensorspec": 52, "multionehot": 53, "multionehotdiscretetensorspec": 54, "multistep": 55, "nested2t": 56, "nontensor": 57, "nontensorspec": 58, "onehot": 59, "onehotdiscretetensorspec": 60, "pairwisedataset": 61, "prioritizedreplaybuff": 62, "promptdata": 63, "prompttensordicttoken": 64, "querymodul": 65, "randomprojectionhash": 66, "rayreplaybuff": 67, "remotetensordictreplaybuff": 68, "replaybuff": 69, "rewarddata": 70, "rolloutfrommodel": 71, "siphash": 72, "stack": [73, 252], "stackedcomposit": 74, "ted2flat": 75, "ted2nest": 76, "tensordictprioritizedreplaybuff": 78, "tensordictreplaybuff": 79, "tensordicttoken": 80, "tensormap": 81, "tokenizeddatasetload": 83, "unbound": 85, "unboundedcontinu": 86, "unboundedcontinuoustensorspec": 87, "unboundeddiscret": 88, "unboundeddiscretetensorspec": 89, "check_no_exclusive_kei": 90, "consolidate_spec": 91, "contains_lazy_spec": 92, "create_infinite_iter": 93, "get_dataload": 94, "histori": 95, "llmdata": 96, "flatstoragecheckpoint": 97, "h5storagecheckpoint": 98, "immutabledatasetwrit": 99, "lazymemmapstorag": 100, "lazystackstorag": 101, "lazytensorstorag": 102, "liststorag": 103, "liststoragecheckpoint": 104, "nestedstoragecheckpoint": 105, "prioritizedsampl": 106, "prioritizedslicesampl": 107, "randomsampl": 108, "replaybufferensembl": 109, "roundrobinwrit": 110, "sampler": 111, "samplerensembl": 112, "samplerwithoutreplac": 113, "slicesampl": 114, "slicesamplerwithoutreplac": 115, "storagecheckpointerbas": 117, "storageensembl": 118, "storageensemblecheckpoint": 119, "tensordictmaxvaluewrit": 120, "tensordictroundrobinwrit": 121, "tensorstorag": 122, "tensorstoragecheckpoint": 123, "writer": 124, "writerensembl": 125, "asyncenvpool": 126, "braxenv": 127, "braxwrapp": 128, "chessenv": 129, "dmcontrolenv": 130, "dmcontrolwrapp": 131, "envbas": [132, 476], "envcreat": 133, "envmetadata": 134, "gymenv": 135, "gymlikeenv": 136, "gymwrapp": 137, "habitatenv": 138, "isaacgymenv": 139, "isaacgymwrapp": 140, "isaaclabwrapp": 141, "jumanjienv": 142, "jumanjiwrapp": 143, "llmhashingenv": [144, 186], "mogymenv": 145, "mogymwrapp": 146, "marlgroupmaptyp": 147, "meltingpotenv": 148, "meltingpotwrapp": 149, "modelbasedenvbas": 150, "multithreadedenv": 151, "multithreadedenvwrapp": 152, "openmlenv": 153, "openspielenv": 154, "openspielwrapp": 155, "parallelenv": 156, "pendulumenv": 157, "pettingzooenv": 158, "pettingzoowrapp": 159, "processorasyncenvpool": 160, "randompolici": 161, "robohiveenv": 162, "smacv2env": 163, "smacv2wrapp": 164, "serialenv": 165, "threadingasyncenvpool": 166, "tictactoeenv": 167, "unitymlagentsenv": 168, "unitymlagentswrapp": 169, "vmasenv": 170, "vmaswrapp": 171, "check_env_spec": 172, "check_marl_group": 173, "exploration_typ": 174, "get_available_librari": 175, "gym_backend": 176, "chatenv": 177, "datasetchatenv": 178, "gsm8kenv": 179, "gsm8kpreparequest": 180, "gsm8krewardpars": 181, "ifevalenv": 182, "ifevalscoredata": 183, "ifevalscor": 184, "llmenv": 185, "mlgymwrapp": 187, "make_gsm8k_env": 188, "make_mlgym": 189, "dataloadingprim": 190, "klrewardtransform": [191, 232], "pythoninterpret": 192, "templatetransform": 193, "token": [194, 259], "as_nested_tensor": 195, "as_padded_tensor": 196, "make_composite_from_td": 197, "dreamerdecod": 198, "dreamerenv": 199, "register_gym_spec_convers": 200, "set_exploration_typ": 201, "set_gym_backend": 202, "step_mdp": 203, "terminated_or_trunc": 204, "actiondiscret": 205, "actionmask": 206, "autoresetenv": 207, "autoresettransform": 208, "batchsizetransform": 209, "binarizereward": 210, "burnintransform": 211, "catfram": [212, 478], "cattensor": 213, "centercrop": 214, "cliptransform": 215, "conditionalpolicyswitch": 217, "conditionalskip": 218, "crop": 219, "dtypecasttransform": 220, "devicecasttransform": 221, "discreteactionproject": 222, "doubletofloat": 223, "endoflifetransform": 224, "excludetransform": 225, "finitetensordictcheck": 226, "flattenobserv": 227, "frameskiptransform": 228, "grayscal": 229, "hash": 230, "inittrack": 231, "linearisereward": 233, "multiact": 234, "noopresetenv": 235, "observationnorm": 236, "observationtransform": 237, "permutetransform": 238, "pinmemorytransform": 239, "r3mtransform": 240, "randomcroptensordict": 241, "removeemptyspec": 242, "renametransform": 243, "resiz": 244, "reward2gotransform": 245, "rewardclip": 246, "rewardsc": 247, "rewardsum": 248, "selecttransform": 249, "signtransform": 250, "squeezetransform": 251, "stepcount": 253, "targetreturn": 254, "tensordictprim": 255, "timemaxpool": 256, "timer": 257, "totensorimag": 258, "trajcount": 260, "transformedenv": 262, "unarytransform": 263, "unsqueezetransform": 264, "vc1transform": 265, "viprewardtransform": 266, "viptransform": 267, "vecgymenvtransform": 268, "vecnorm": [269, 481], "vecnormv2": 270, "gsdenois": 271, "multisteptransform": 272, "implement_for": 273, "additivegaussianmodul": 274, "batchrenorm1d": 275, "cemplann": 276, "consistentdropout": 277, "consistentdropoutmodul": 278, "conv3dnet": 279, "convnet": 280, "dtactor": 281, "ddpgcnnactor": 282, "ddpgcnnqnet": 283, "ddpgmlpactor": 284, "ddpgmlpqnet": 285, "decisiontransform": 286, "delta": 287, "distributionaldqnnet": 288, "distributionalqvaluehook": 289, "dreameractor": 290, "duelingcnndqnet": 291, "egreedymodul": 292, "gru": 293, "grucel": 294, "grumodul": 295, "independentnorm": 296, "lstm": [297, 464], "lstmcell": 298, "lstmmodul": 299, "mlp": [300, 464], "mpcplannerbas": 301, "mppiplann": 302, "maskedcategor": 303, "maskedonehotcategor": 304, "multiagentconvnet": 305, "multiagentmlp": 306, "multiagentnetbas": 307, "noisylazylinear": 308, "noisylinear": 309, "obsdecod": 310, "obsencod": 311, "onehotcategor": 312, "onehotordin": 313, "onlinedtactor": 314, "ordin": 315, "ornsteinuhlenbeckprocessmodul": 316, "qmixer": [317, 457], "qvaluehook": 318, "rssmposterior": 319, "rssmprior": 320, "squeeze2dlay": 321, "squeezelay": 322, "tanhdelta": 323, "tanhnorm": 324, "truncatednorm": 325, "vdnmixer": 326, "vmapmodul": 327, "categoricalsequenti": 328, "llmondevic": 329, "transformerswrapp": 330, "make_vllm_work": 331, "stateless_init_process_group": 332, "vllmworker": 333, "vllmwrapper": 334, "recurrent_mod": 335, "reset_nois": 336, "set_recurrent_mod": 337, "actor": [338, 456, 461, 467], "actorcriticoper": 339, "actorcriticwrapp": 340, "actorvalueoper": 341, "decisiontransformerinferencewrapp": 342, "distributionalqvalueactor": 343, "distributionalqvaluemodul": 344, "lmheadactorvalueoper": 345, "multistepactorwrapp": 346, "probabilisticactor": 347, "qvalueactor": [348, 456], "qvaluemodul": 349, "safemodul": [350, 456], "safeprobabilisticmodul": 351, "safeprobabilistictensordictsequenti": 352, "safesequenti": 353, "tanhmodul": 354, "valueoper": 355, "worldmodelwrapp": 356, "biased_softplu": 357, "get_primers_from_modul": 358, "inv_softplu": 359, "map": [360, 474], "a2closs": 361, "cqlloss": 362, "clipppoloss": 363, "crossqloss": 364, "ddpgloss": 365, "dqnloss": 366, "dtloss": 367, "discretecqlloss": 368, "discreteiqlloss": 369, "discretesacloss": 370, "distributionaldqnloss": 371, "dreameractorloss": 372, "dreamermodelloss": 373, "dreamervalueloss": 374, "gailloss": 375, "hardupd": 376, "iqlloss": 377, "klpenppoloss": 378, "lossmodul": [379, 461, 468], "onlinedtloss": 380, "ppoloss": 381, "redqloss": 382, "reinforceloss": 383, "sacloss": 384, "softupd": 385, "td3bcloss": 386, "td3loss": 387, "valueestim": 388, "default_value_kwarg": 389, "distance_loss": 390, "group_optim": 391, "hold_out_net": 392, "hold_out_param": 393, "grpoloss": 394, "grpolossoutput": 395, "mcadvantag": 396, "qmixerloss": 397, "next_state_valu": 398, "gae": 399, "td0estim": 400, "td1estim": 401, "tdlambdaestim": 402, "valueestimatorbas": 403, "generalized_advantage_estim": 404, "reward2go": 405, "td0_advantage_estim": 406, "td0_return_estim": 407, "td1_advantage_estim": 408, "td1_return_estim": 409, "td_lambda_advantage_estim": 410, "td_lambda_return_estim": 411, "vec_generalized_advantage_estim": 412, "vec_td1_advantage_estim": 413, "vec_td1_return_estim": 414, "vec_td_lambda_advantage_estim": 415, "vec_td_lambda_return_estim": 416, "pixelrendertransform": 417, "tensordictrecord": 418, "videorecord": 419, "logger": [420, 458, 470, 471], "csvlogger": 421, "generate_exp_nam": 422, "get_logg": 423, "mlflowlogg": 424, "tensorboardlogg": 425, "wandblogg": 426, "set_auto_unwrap_transformed_env": 427, "batchsubsampl": 428, "clearcudacach": 429, "countframeslog": 430, "logscalar": 431, "logvalidationreward": 432, "optimizerhook": 433, "replaybuffertrain": 434, "rewardnorm": 435, "selectkei": 436, "trainer": [437, 458, 462], "trainerhookbas": 438, "updateweight": 439, "correct_for_frame_skip": 440, "get_stats_random_rollout": 441, "make_collector_offpolici": 442, "make_collector_onpolici": 443, "make_dqn_loss": 444, "make_replay_buff": 445, "make_target_updat": 446, "make_train": 447, "parallel_env_constructor": 448, "sync_async_collector": 449, "sync_sync_collector": 450, "transformed_env_constructor": 451, "readm": [452, 472], "tuto": [452, 472], "api": 453, "contribut": [454, 480], "content": 454, "llm": 455, "interfac": 455, "avail": 455, "modul": [455, 456, 461, 464, 465, 467, 471, 480], "wrapper": [455, 456, 467], "object": [455, 457, 461, 468, 480], "grpo": 455, "tensordictmodul": [456, 465, 467, 480], "probabilist": [456, 467], "q": [456, 462, 464, 467], "oper": 456, "join": 456, "hook": [456, 458, 462], "regular": 456, "planner": 456, "torch": 457, "vmap": [457, 480], "dqn": [457, 462, 464], "ddpg": [457, 461, 474], "sac": 457, "redq": 457, "crossq": 457, "iql": 457, "cql": 457, "gail": 457, "dt": 457, "td3": 457, "bc": 457, "ppo": [457, 463, 475], "head": 457, "a2c": 457, "dreamer": 457, "builder": 458, "_util": 459, "comput": [460, 462, 476, 479], "time": [460, 461, 479], "code": [461, 476], "overview": [461, 464], "setup": [461, 464], "__init__": 461, "estim": 461, "put": 461, "togeth": [461, 476], "call": 461, "parallel": [461, 473, 481], "execut": [461, 473, 476], "stat": 461, "build": [461, 462, 471, 478], "evalu": 461, "construct": 461, "target": [461, 462, 468], "network": [461, 462, 463, 464, 467, 474, 475], "experi": [461, 476], "result": [461, 463, 474, 475], "conclus": [461, 462, 463, 464, 465, 474, 475, 476, 478], "next": [461, 463, 466, 469, 474, 475, 478], "deep": 462, "collect": [462, 463, 469], "paramet": [462, 463, 468], "hyperparamet": [462, 463, 474, 475], "regist": 462, "possibl": 462, "improv": 462, "defin": [463, 474, 475], "loop": [463, 464, 465, 471, 474, 475, 476], "recurr": [464, 465], "convolut": 464, "select": 464, "further": [464, 468], "read": 464, "export": 465, "introduct": [465, 480], "fast": 465, "recap": 465, "simpl": [465, 476], "stochast": 465, "aotinductor": 465, "free": 465, "c": 465, "onnx": 465, "rollout": [465, 466, 473, 474, 475, 476, 481], "creat": 466, "s": [467, 468], "output": 468, "consider": 468, "log": 470, "first": 471, "divers": 473, "competit": 474, "group": 474, "critic": [474, 475], "pendulum": 476, "write": 476, "_step": 476, "simul": 476, "_reset": 476, "metadata": 476, "_spec": 476, "shape": 476, "seed": [476, 481], "wrap": 476, "test": 476, "our": 476, "pretrain": 477, "vanilla": 478, "integr": 478, "tensorclass": 478, "other": 478, "pytre": 478, "iter": 478, "over": 478, "fix": 478, "priorit": 478, "save": 478, "raw": 478, "imag": 478, "more": 478, "complex": 478, "config": 480, "sequenc": 480, "program": 480, "ensembl": 480, "meta": 480, "sync": 480, "multiprocess": 480, "frame_skip": 481, "deepmind": 481, "control": 481, "devic": 481, "close": 481, "access": 481, "attribut": 481, "kwarg": 481}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})